{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "import requests\n",
    "import csv\n",
    "import re\n",
    "MAX_DEPTH = 3\n",
    "STEM = \"https://en.wikipedia.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filtering out only raw text from the html file\n",
    "def visible(element):\n",
    "    if element.parent.name in ['style', 'script', '[document]', 'head', 'title']:\n",
    "        return False\n",
    "    elif re.match('<!--.*-->', str(element.encode('utf-8'))):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build the json entry for a singular page\n",
    "def read_page(page):\n",
    "    #if depth == -1: return\n",
    "    print(\"reading page: \" + page)\n",
    "    page1 = requests.get(page)\n",
    "    full_text = \"\"\n",
    "    links=[]\n",
    "    desc_links = []\n",
    "    title=\"\"\n",
    "    try:\n",
    "        soup = bs4(page1.text, \"html5lib\")\n",
    "        text = soup.find_all('p')\n",
    "        #extract text only before the \"see also\" section\n",
    "        see_also = soup.find('span', id='See_also')\n",
    "        title = str(soup.find('h1').getText())\n",
    "        toc = soup.find(\"div\", {\"class\": \"toc\"})\n",
    "        for p in see_also.parent.previous_siblings:\n",
    "            alt = p.find('img')\n",
    "            if not alt and p.name == 'p':\n",
    "                full_text += str(p.getText())#.encode('utf-8', 'ignore'))\n",
    "                for a in p.find_all('a'):\n",
    "                    if a['href'][:6] == \"/wiki/\": links.append(a['href'])\n",
    "        for p in toc.previous_siblings:\n",
    "            if p.name == \"p\":\n",
    "                for a in p.find_all('a'):\n",
    "                    if a['href'][:6] == \"/wiki/\": desc_links.append(a['href'])\n",
    "    except AttributeError:\n",
    "        print(\"invalid page, skipping\")\n",
    "    except KeyError: \n",
    "        pass\n",
    "    filter(visible,full_text)\n",
    "    #print(title + full_text)\n",
    "    page_dict = {'title': title, 'url': page, 'links': links, 'text': full_text, 'desc_links': desc_links}\n",
    "    return page_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading page: https://en.wikipedia.org/wiki/Linear_algebra\n",
      "reading page: https://en.wikipedia.org/wiki/Geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Line_(geometry)\n",
      "reading page: https://en.wikipedia.org/wiki/Plane_(geometry)\n",
      "reading page: https://en.wikipedia.org/wiki/Rotation_(mathematics)\n",
      "reading page: https://en.wikipedia.org/wiki/Functional_analysis\n",
      "reading page: https://en.wikipedia.org/wiki/Engineering\n",
      "reading page: https://en.wikipedia.org/wiki/Mathematical_model\n",
      "reading page: https://en.wikipedia.org/wiki/Nonlinear_system\n",
      "reading page: https://en.wikipedia.org/wiki/Matrix_(mathematics)\n",
      "reading page: https://en.wikipedia.org/wiki/Vector_space\n",
      "reading page: https://en.wikipedia.org/wiki/Linear_map\n",
      "reading page: https://en.wikipedia.org/wiki/Mathematics\n",
      "reading page: https://en.wikipedia.org/wiki/Linear_equation\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "data['pages'] = [] #nested array so can append new pages as needed\n",
    "data['pages'].append(read_page(\"https://en.wikipedia.org/wiki/Linear_algebra\"))\n",
    "origin_links = data['pages'][0]['desc_links']\n",
    "for l in origin_links:\n",
    "    data['pages'].append(read_page(STEM + l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading page: https://en.wikipedia.org/wiki/Length\n",
      "reading page: https://en.wikipedia.org/wiki/Area\n",
      "reading page: https://en.wikipedia.org/wiki/Volume\n",
      "reading page: https://en.wikipedia.org/wiki/Mathematical_science\n",
      "invalid page, skipping\n",
      "reading page: https://en.wikipedia.org/wiki/Axiomatic_system\n",
      "reading page: https://en.wikipedia.org/wiki/Euclid\n",
      "reading page: https://en.wikipedia.org/wiki/Euclid%27s_Elements\n",
      "reading page: https://en.wikipedia.org/wiki/Middle_Ages\n",
      "invalid page, skipping\n",
      "reading page: https://en.wikipedia.org/wiki/Ren%C3%A9_Descartes\n",
      "reading page: https://en.wikipedia.org/wiki/Pierre_de_Fermat\n",
      "reading page: https://en.wikipedia.org/wiki/Non-Euclidean_geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Topological_manifold\n",
      "invalid page, skipping\n",
      "reading page: https://en.wikipedia.org/wiki/Ancient_Greek_language\n",
      "reading page: https://en.wikipedia.org/wiki/Mathematics\n",
      "reading page: https://en.wikipedia.org/wiki/Geometer\n",
      "invalid page, skipping\n",
      "reading page: https://en.wikipedia.org/wiki/Axiom\n",
      "reading page: https://en.wikipedia.org/wiki/Primitive_notion\n",
      "reading page: https://en.wikipedia.org/wiki/Differential_geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Geodesic\n",
      "reading page: https://en.wikipedia.org/wiki/Projective_geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Analytic_geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Linear_equation\n",
      "reading page: https://en.wikipedia.org/wiki/Incidence_geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Euclid\n",
      "reading page: https://en.wikipedia.org/wiki/Postulate\n",
      "reading page: https://en.wikipedia.org/wiki/Euclidean_geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Non-Euclidean_geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Projective_geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Affine_geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Curvature\n",
      "reading page: https://en.wikipedia.org/wiki/Euclidean_space\n",
      "reading page: https://en.wikipedia.org/wiki/Geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Trigonometry\n",
      "reading page: https://en.wikipedia.org/wiki/Graph_theory\n",
      "reading page: https://en.wikipedia.org/wiki/Graph_of_a_function\n",
      "reading page: https://en.wikipedia.org/wiki/Mathematics\n",
      "reading page: https://en.wikipedia.org/wiki/Dimension\n",
      "reading page: https://en.wikipedia.org/wiki/Surface_(topology)\n",
      "reading page: https://en.wikipedia.org/wiki/Two-dimensional_space\n",
      "reading page: https://en.wikipedia.org/wiki/Point_(geometry)\n",
      "reading page: https://en.wikipedia.org/wiki/Line_(geometry)\n",
      "reading page: https://en.wikipedia.org/wiki/Three-dimensional_space\n",
      "reading page: https://en.wikipedia.org/wiki/Euclidean_geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Map_(mathematics)\n",
      "reading page: https://en.wikipedia.org/wiki/Group_(mathematics)\n",
      "reading page: https://en.wikipedia.org/wiki/Function_composition\n",
      "reading page: https://en.wikipedia.org/wiki/Mechanics\n",
      "reading page: https://en.wikipedia.org/wiki/Physics\n",
      "reading page: https://en.wikipedia.org/wiki/Coordinate_transformation\n",
      "reading page: https://en.wikipedia.org/wiki/Orthonormal_basis\n",
      "reading page: https://en.wikipedia.org/wiki/Frame_of_reference\n",
      "reading page: https://en.wikipedia.org/wiki/Clockwise\n",
      "reading page: https://en.wikipedia.org/wiki/Active_and_passive_transformation\n",
      "reading page: https://en.wikipedia.org/wiki/Mathematics\n",
      "reading page: https://en.wikipedia.org/wiki/Geometry\n",
      "reading page: https://en.wikipedia.org/wiki/Motion_(geometry)\n",
      "invalid page, skipping\n",
      "reading page: https://en.wikipedia.org/wiki/Space_(mathematics)\n",
      "reading page: https://en.wikipedia.org/wiki/Point_(geometry)\n",
      "reading page: https://en.wikipedia.org/wiki/Rigid_body\n",
      "reading page: https://en.wikipedia.org/wiki/Translation_(geometry)\n",
      "reading page: https://en.wikipedia.org/wiki/Reflection_(mathematics)\n",
      "reading page: https://en.wikipedia.org/wiki/Flat_(geometry)\n",
      "reading page: https://en.wikipedia.org/wiki/Dimension_(mathematics)\n",
      "reading page: https://en.wikipedia.org/wiki/Dimension_(vector_space)\n",
      "reading page: https://en.wikipedia.org/wiki/Linear_algebra\n",
      "reading page: https://en.wikipedia.org/wiki/Measure_(mathematics)\n",
      "reading page: https://en.wikipedia.org/wiki/Integral\n",
      "reading page: https://en.wikipedia.org/wiki/Probability\n",
      "reading page: https://en.wikipedia.org/wiki/Functional_(mathematics)\n",
      "reading page: https://en.wikipedia.org/wiki/Calculus_of_variations\n",
      "reading page: https://en.wikipedia.org/wiki/Higher-order_function\n",
      "reading page: https://en.wikipedia.org/wiki/Jacques_Hadamard\n",
      "reading page: https://en.wikipedia.org/wiki/Vito_Volterra\n",
      "reading page: https://en.wikipedia.org/wiki/Maurice_Ren%C3%A9_Fr%C3%A9chet\n",
      "reading page: https://en.wikipedia.org/wiki/Paul_L%C3%A9vy_(mathematician)\n",
      "reading page: https://en.wikipedia.org/wiki/Frigyes_Riesz\n",
      "reading page: https://en.wikipedia.org/wiki/Lw%C3%B3w_School_of_Mathematics\n",
      "invalid page, skipping\n",
      "reading page: https://en.wikipedia.org/wiki/Poland\n",
      "reading page: https://en.wikipedia.org/wiki/Stefan_Banach\n",
      "reading page: https://en.wikipedia.org/wiki/Mathematical_analysis\n",
      "reading page: https://en.wikipedia.org/wiki/Vector_space\n",
      "reading page: https://en.wikipedia.org/wiki/Inner_product_space#Definition\n",
      "reading page: https://en.wikipedia.org/wiki/Norm_(mathematics)#Definition\n",
      "reading page: https://en.wikipedia.org/wiki/Topological_space#Definition\n",
      "reading page: https://en.wikipedia.org/wiki/Linear_transformation\n",
      "reading page: https://en.wikipedia.org/wiki/Function_space\n",
      "reading page: https://en.wikipedia.org/wiki/Fourier_transform\n",
      "reading page: https://en.wikipedia.org/wiki/Continuous_function\n",
      "reading page: https://en.wikipedia.org/wiki/Unitary_operator\n",
      "reading page: https://en.wikipedia.org/wiki/Differential_equations\n",
      "reading page: https://en.wikipedia.org/wiki/Integral_equations\n",
      "reading page: https://en.wikipedia.org/wiki/Latin\n",
      "reading page: https://en.wikipedia.org/wiki/Science\n",
      "reading page: https://en.wikipedia.org/wiki/Empirical_evidence\n",
      "reading page: https://en.wikipedia.org/wiki/Innovation\n",
      "reading page: https://en.wikipedia.org/wiki/Design\n",
      "reading page: https://en.wikipedia.org/wiki/Construction\n",
      "reading page: https://en.wikipedia.org/wiki/Maintenance_(technical)\n",
      "reading page: https://en.wikipedia.org/wiki/Structure\n",
      "reading page: https://en.wikipedia.org/wiki/Machine\n",
      "reading page: https://en.wikipedia.org/wiki/Material\n",
      "reading page: https://en.wikipedia.org/wiki/System\n",
      "reading page: https://en.wikipedia.org/wiki/Process\n",
      "invalid page, skipping\n",
      "reading page: https://en.wikipedia.org/wiki/Organization\n",
      "reading page: https://en.wikipedia.org/wiki/List_of_engineering_branches\n",
      "reading page: https://en.wikipedia.org/wiki/Applied_mathematics\n",
      "reading page: https://en.wikipedia.org/wiki/Applied_science\n",
      "reading page: https://en.wikipedia.org/wiki/Glossary_of_engineering\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f35810668a19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'desc_links'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m#print(p['url'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mdata_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pages'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTEM\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# this making it depth 3, not 2!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"wikipedia is bad, waiting 1 second\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-00001056eb93>\u001b[0m in \u001b[0;36mread_page\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html5lib\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#extract text only before the \"see also\" section\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\builder\\_html5lib.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mextra_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_specified_encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# Set the character encoding detected by the tokenizer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\html5lib\\html5parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, stream, encoding, parseMeta, useChardet)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \"\"\"\n\u001b[0;32m    235\u001b[0m         self._parse(stream, innerHTML=False, encoding=encoding,\n\u001b[1;32m--> 236\u001b[1;33m                     parseMeta=parseMeta, useChardet=useChardet)\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\html5lib\\html5parser.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(self, stream, innerHTML, container, encoding, parseMeta, useChardet, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mReparseException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\html5lib\\html5parser.py\u001b[0m in \u001b[0;36mmainLoop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mParseErrorToken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenTypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ParseError\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalizedTokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m             \u001b[0mnew_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mnew_token\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\html5lib\\html5parser.py\u001b[0m in \u001b[0;36mnormalizedTokens\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnormalizedTokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalizeToken\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\html5lib\\tokenizer.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# Start processing. When EOF is reached self.state will return False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# instead of True and the loop will terminate.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtokenTypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ParseError\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\html5lib\\tokenizer.py\u001b[0m in \u001b[0;36mdataState\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentityDataState\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"<\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagOpenState\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"\\u0000\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             self.tokenQueue.append({\"type\": tokenTypes[\"ParseError\"],\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try: \n",
    "    data_2 = {}\n",
    "    data_2['pages'] = []\n",
    "    for i in range(1, len(data['pages'])):\n",
    "    #for p in data['pages']:#once done, change to no include the first entry- that's our root entry and already computed\n",
    "        p = data['pages'][i]\n",
    "        for l in p['desc_links']:\n",
    "        #print(p['url'])\n",
    "            data_2['pages'].append(read_page(STEM + l))# this making it depth 3, not 2!\n",
    "except ConnectionError: \n",
    "    print(\"wikipedia is bad, waiting 1 second\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('linalg_desclinks.json', 'w') as f: \n",
    "    json.dump(data, f)\n",
    "    json.dump(data_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build the json entry for a singular page\n",
    "def read_page_txt(page):\n",
    "    #if depth == -1: return\n",
    "    print(\"reading page: \" + page)\n",
    "    page1 = requests.get(page)\n",
    "    full_text = \"\"\n",
    "    links=[]\n",
    "    title=\"\"\n",
    "    try:\n",
    "        soup = bs4(page1.text, \"html5lib\")\n",
    "        text = soup.find_all('p')\n",
    "        #extract text only before the \"see also\" section\n",
    "        see_also = soup.find('span', id='See_also')\n",
    "        title = str(soup.find('h1').getText())\n",
    "        toc = soup.find(\"div\", {\"class\": \"toc\"})\n",
    "        for p in see_also.parent.previous_siblings:\n",
    "            alt = p.find('img')\n",
    "            if not alt and p.name == 'p':\n",
    "                full_text += str(p.getText())#.encode('utf-8', 'ignore'))\n",
    "        for p in toc.previous_siblings:\n",
    "            if p.name == \"p\":\n",
    "                for a in p.find_all('a'):\n",
    "                    if a['href'][:6] == \"/wiki/\": desc_links.append(a['href'])\n",
    "    except AttributeError:\n",
    "        print(\"invalid page, skipping\")\n",
    "    except KeyError: \n",
    "        pass\n",
    "    filter(visible,full_text)\n",
    "    return links"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
