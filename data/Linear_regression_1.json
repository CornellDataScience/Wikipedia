{
    "pages": [
        {
            "desc_links": [
                "/wiki/Multivariate_linear_regression",
                "/wiki/Simple_linear_regression",
                "/wiki/Independent_variable",
                "/wiki/Explanatory_variable",
                "/wiki/Dependent_variable",
                "/wiki/Linearity",
                "/wiki/Statistics",
                "/wiki/Multivariate_analysis",
                "/wiki/Joint_probability_distribution",
                "/wiki/Conditional_probability_distribution",
                "/wiki/Regression_analysis",
                "/wiki/Quantile",
                "/wiki/Median",
                "/wiki/Affine_transformation",
                "/wiki/Conditional_expectation",
                "/wiki/Linear_model",
                "/wiki/Data",
                "/wiki/Estimation_theory",
                "/wiki/Parameters",
                "/wiki/Linear_predictor_function",
                "/wiki/Lasso_(statistics)",
                "/wiki/Ridge_regression",
                "/wiki/Loss_function",
                "/wiki/Least_absolute_deviations",
                "/wiki/Norm_(mathematics)",
                "/wiki/Least_squares"
            ],
            "desc_text": "b'In statistics, linear regression is a linear approach to modelling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression.[1] This term is distinct from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable.[2]\\n'b'In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Such models are called linear models.[3] Most commonly, the conditional mean of the response given the values of the explanatory variables (or predictors) is assumed to be an affine function of those values; less commonly, the conditional median or some other quantile is used. Like all forms of regression analysis, linear regression focuses on the conditional probability distribution of the response given the values of the predictors, rather than on the joint probability distribution of all of these variables, which is the domain of multivariate analysis.\\n'b'Linear regression was the first type of regression analysis to be studied rigorously, and to be used extensively in practical applications.[4] This is because models which depend linearly on their unknown parameters are easier to fit than models which are non-linearly related to their parameters and because the statistical properties of the resulting estimators are easier to determine.\\n'b'Linear regression has many practical uses. Most applications fall into one of the following two broad categories:\\n'b'Linear regression models are often fitted using the least squares approach, but they may also be fitted in other ways, such as by minimizing the \"lack of fit\" in some other norm (as with least absolute deviations regression), or by minimizing a penalized version of the least squares cost function as in ridge regression (L2-norm penalty) and lasso (L1-norm penalty). Conversely, the least squares approach can be used to fit models that are not linear models. Thus, although the terms \"least squares\" and \"linear model\" are closely linked, they are not synonymous.\\n'",
            "links": [
                "/wiki/Multivariate_linear_regression",
                "/wiki/Simple_linear_regression",
                "/wiki/Independent_variable",
                "/wiki/Explanatory_variable",
                "/wiki/Dependent_variable",
                "/wiki/Linearity",
                "/wiki/Statistics",
                "/wiki/Multivariate_analysis",
                "/wiki/Joint_probability_distribution",
                "/wiki/Conditional_probability_distribution",
                "/wiki/Regression_analysis",
                "/wiki/Quantile",
                "/wiki/Median",
                "/wiki/Affine_transformation",
                "/wiki/Conditional_expectation",
                "/wiki/Linear_model",
                "/wiki/Data",
                "/wiki/Estimation_theory",
                "/wiki/Parameters",
                "/wiki/Linear_predictor_function",
                "/wiki/Lasso_(statistics)",
                "/wiki/Ridge_regression",
                "/wiki/Loss_function",
                "/wiki/Least_absolute_deviations",
                "/wiki/Norm_(mathematics)",
                "/wiki/Least_squares",
                "/wiki/Coordinate_vector",
                "/wiki/Inner_product",
                "/wiki/Transpose",
                "/wiki/Matrix_notation",
                "/wiki/Standard_gravity",
                "/wiki/Ordinary_least_squares",
                "/wiki/Total_derivative",
                "/wiki/Simple_linear_regression",
                "/wiki/Pearson_correlation",
                "/wiki/Partial_derivative",
                "/wiki/Expected_value",
                "/wiki/Dummy_variable_(statistics)",
                "/wiki/Euclidean_vector",
                "/wiki/Simple_linear_regression",
                "/wiki/Scalar_(mathematics)",
                "/wiki/Heteroscedasticity-consistent_standard_errors",
                "/wiki/Generalized_least_squares",
                "/wiki/Linear_least_squares_(mathematics)#Weighted_linear_least_squares",
                "/wiki/Weighted_least_squares",
                "/wiki/Variance",
                "/wiki/Heteroscedasticity",
                "/wiki/Generalized_linear_model",
                "/wiki/Wikipedia:Please_clarify",
                "/wiki/Hierarchical_linear_models",
                "/wiki/Errors-in-variables_model",
                "/wiki/Efficiency_(statistics)",
                "/wiki/Consistent_estimator",
                "/wiki/Parameter",
                "/wiki/Time_series",
                "/wiki/Instrumental_variables",
                "/wiki/Randomized_controlled_trial",
                "/wiki/Confounding",
                "/wiki/Socioeconomic_status",
                "/wiki/Spurious_correlation",
                "/wiki/Observational_studies",
                "/wiki/Morbidity",
                "/wiki/Tobacco_smoking",
                "/wiki/Beta_(finance)",
                "/wiki/Capital_asset_pricing_model",
                "/wiki/Labor_supply",
                "/wiki/Labour_economics",
                "/wiki/Money_demand",
                "/wiki/Imports",
                "/wiki/Exports",
                "/wiki/Inventory_investment",
                "/wiki/Fixed_investment",
                "/wiki/Consumption_(economics)",
                "/wiki/Economics",
                "/wiki/Benthic_zone",
                "/wiki/Supervised_learning",
                "/wiki/Machine_learning",
                "/wiki/Artificial_intelligence"
            ],
            "text": "Linear regression plays an important role in the field of artificial intelligence such as machine learning. The linear regression algorithm is one of the fundamental supervised machine-learning algorithms due to its relative simplicity and well-known properties.[25]\nLinear regression finds application in a wide range of environmental science applications. In Canada, the Environmental Effects Monitoring Program uses statistical analyses on fish and benthic surveys to measure the effects of pulp mill or metal mine effluent on the aquatic ecosystem.[24]\nLinear regression is the predominant empirical tool in economics.  For example, it is used to predict consumption spending,[20] fixed investment spending, inventory investment, purchases of a country's exports,[21] spending on imports,[21] the demand to hold liquid assets,[22] labor demand,[23] and labor supply.[23]\nThe capital asset pricing model uses linear regression as well as the concept of beta for analyzing and quantifying the systematic risk of an investment. This comes directly from the beta coefficient of the linear regression model that relates the return on the investment to the return on all risky assets.\nEarly evidence relating tobacco smoking to mortality and morbidity came from observational studies employing regression analysis. In order to reduce spurious correlations when analyzing observational data, researchers usually include several variables in their regression models in addition to the variable of primary interest. For example, in a regression model in which cigarette smoking is the independent variable of primary interest and the dependent variable is lifespan measured in years, researchers might include education and income as additional independent variables, to ensure that any observed effect of smoking on lifespan is not due to those other socio-economic factors. However, it is never possible to include all possible confounding variables in an empirical analysis. For example, a hypothetical gene might increase mortality and also cause people to smoke more. For this reason, randomized controlled trials are often able to generate more compelling evidence of causal relationships than can be obtained using regression analyses of observational data. When controlled experiments are not feasible, variants of regression analysis such as instrumental variables regression may be used to attempt to estimate causal relationships from observational data.\nTrend lines are sometimes used in business analytics to show changes in data over time. This has the advantage of being simple. Trend lines are often used to argue that a particular action or event (such as training, or an advertising campaign) caused observed changes at a point in time. This is a simple technique, and does not require a control group, experimental design, or a sophisticated analysis technique. However, it suffers from a lack of scientific validity in cases where other potential changes can affect the data.\nA trend line represents a trend, the long-term movement in time series data after other components have been accounted for. It tells whether a particular data set (say GDP, oil prices or stock prices) have increased or decreased over the period of time. A trend line could simply be drawn by eye through a set of data points, but more properly their position and slope is calculated using statistical techniques like linear regression. Trend lines typically are straight lines, although some variations use higher degree polynomials depending on the degree of curvature desired in the line.\nLinear regression is widely used in biological, behavioral and social sciences to describe possible relationships between variables. It ranks as one of the most important tools used in these disciplines.\nLinear least squares methods include mainly:\nSome of the more common estimation techniques for linear regression are summarized below.\nA large number of procedures have been developed for parameter estimation and inference in linear regression. These methods differ in computational simplicity of algorithms, presence of a closed-form solution, robustness with respect to heavy-tailed distributions, and theoretical assumptions needed to validate desirable statistical properties such as consistency and asymptotic efficiency.\nErrors-in-variables models (or \"measurement error models\") extend the traditional linear regression model to allow the predictor variables X to be observed with error. This error causes standard estimators of \u03b2 to become biased. Generally, the form of bias is an attenuation, meaning that the effects are biased toward zero.\nHierarchical linear models (or multilevel regression) organizes the data into a hierarchy of regressions, for example where A is regressed on B, and B is regressed on C. It is often used where the variables of interest have a natural hierarchical structure such as in educational statistics, where students are nested in classrooms, classrooms are nested in schools, and schools are nested in some administrative grouping, such as a school district. The response variable might be a measure of student achievement such as a test score, and different covariates would be collected at the classroom, school, and school district levels.\nSingle index models[clarification needed] allow some degree of nonlinearity in the relationship between x and y, while preserving the central role of the linear predictor \u03b2\u2032x as in the classical linear regression model. Under certain conditions, simply applying OLS to data from a single-index model will consistently estimate \u03b2 up to a proportionality constant.[11]\nSome common examples of GLMs are:\nGeneralized linear models (GLMs) are a framework for modeling response variables that are bounded or discrete. This is used, for example:\nVarious models have been created that allow for heteroscedasticity, i.e. the errors for different response variables may have different variances.  For example, weighted least squares is a method for estimating linear regression models when the response variables may have different error variances, possibly with correlated errors. (See also Weighted linear least squares, and Generalized least squares.) Heteroscedasticity-consistent standard errors is an improved method for use with uncorrelated but potentially heteroscedastic errors.\nThe very simplest case of a single scalar predictor variable x and a single scalar response variable y is known as simple linear regression.  The extension to multiple and/or vector-valued predictor variables (denoted with a capital X) is known as multiple linear regression, also known as multivariable linear regression.  Nearly all real-world regression models involve multiple predictors, and basic descriptions of linear regression are often phrased in terms of the multiple regression model.  Note, however, that in these cases the response variable y is still a scalar. Another term, multivariate linear regression, refers to cases where y is a vector, i.e., the same as general linear regression.\nNumerous extensions of linear regression have been developed, which allow some or all of the assumptions underlying the basic model to be relaxed.\nThe notion of a \"unique effect\" is appealing when studying a complex system where multiple interrelated components influence the response variable. In some cases, it can literally be interpreted as the causal effect of an intervention that is linked to the value of a predictor variable. However, it has been argued that in many cases multiple regression analysis fails to clarify the relationships between the predictor variables and the response variable when the predictors are correlated with each other and are not assigned following a study design.[9] A commonality analysis may be helpful in disentangling the shared and unique impacts of correlated independent variables.[10]\nThe meaning of the expression \"held fixed\" may depend on how the values of the predictor variables arise. If the experimenter directly sets the values of the predictor variables according to a study design, the comparisons of interest may literally correspond to comparisons among units whose predictor variables have been \"held fixed\" by the experimenter. Alternatively, the expression \"held fixed\" can refer to a selection that takes place in the context of data analysis. In this case, we \"hold a variable fixed\" by restricting our attention to the subsets of the data that happen to have a common value for the given predictor variable. This is the only interpretation of \"held fixed\" that can be used in an observational study.\nIt is possible that the unique effect can be nearly zero even when the marginal effect is large. This may imply that some other covariate captures all the information in xj, so that once that variable is in the model, there is no contribution of xj to the variation in y. Conversely, the unique effect of xj can be large while its marginal effect is nearly zero. This would happen if the other covariates explained a great deal of the variation of y, but they mainly explain variation in a way that is complementary to what is captured by xj. In this case, including the other variables in the model reduces the part of the variability of y that is unrelated to xj, thereby strengthening the apparent relationship with xj.\nCare must be taken when interpreting regression results, as some of the regressors may not allow for marginal changes (such as dummy variables, or the intercept term), while others cannot be held fixed (recall the example from the introduction: it would be impossible to \"hold ti fixed\" and at the same time change the value of ti2).\nA fitted linear regression model can be used to identify the relationship between a single predictor variable xj and the response variable y when all the other predictor variables in the model are \"held fixed\". Specifically, the interpretation of \u03b2j is the expected change in y for a one-unit change in xj when the other covariates are held fixed\u2014that is, the expected value of the partial derivative of y with respect to xj. This is sometimes called the unique effect of xj on y. In contrast, the marginal effect of xj on y can be assessed using a correlation coefficient or simple linear regression model relating only xj to y; this effect is the total derivative of y with respect to xj.\nBeyond these assumptions, several other statistical properties of the data strongly influence the performance of different estimation methods:\nThe following are the major assumptions made by standard linear regression models with standard estimation techniques (e.g. ordinary least squares):\nStandard linear regression models with standard estimation techniques make a number of assumptions about the predictor variables, the response variables and their relationship.  Numerous extensions have been developed that allow each of these assumptions to be relaxed (i.e. reduced to a weaker form), and in some cases eliminated entirely. Generally these extensions make the estimation procedure more complex and time-consuming, and may also require more data in order to produce an equally precise model.\nwhere \u03b21 determines the initial velocity of the ball, \u03b22 is proportional to the standard gravity, and \u03b5i is due to measurement errors. Linear regression can be used to estimate the values of \u03b21 and \u03b22 from the measured data. This model is non-linear in the time variable, but it is linear in the parameters \u03b21 and \u03b22; if we take regressors xi\u00a0=\u00a0(xi1, xi2) \u00a0=\u00a0(ti, ti2), the model takes on the standard form\nExample. Consider a situation where a small ball is being tossed up in the air and then we measure its heights of ascent hi at various moments in time ti. Physics tells us that, ignoring the drag, the relationship can be modeled as\nSome remarks on notation and terminology:\nwhere\nOften these n equations are stacked together and written in matrix notation as\nwhere T denotes the transpose, so that xiT\u03b2 is the inner product between vectors xi and \u03b2.\nLinear regression models are often fitted using the least squares approach, but they may also be fitted in other ways, such as by minimizing the \"lack of fit\" in some other norm (as with least absolute deviations regression), or by minimizing a penalized version of the least squares cost function as in ridge regression (L2-norm penalty) and lasso (L1-norm penalty). Conversely, the least squares approach can be used to fit models that are not linear models. Thus, although the terms \"least squares\" and \"linear model\" are closely linked, they are not synonymous.\nLinear regression has many practical uses. Most applications fall into one of the following two broad categories:\nLinear regression was the first type of regression analysis to be studied rigorously, and to be used extensively in practical applications.[4] This is because models which depend linearly on their unknown parameters are easier to fit than models which are non-linearly related to their parameters and because the statistical properties of the resulting estimators are easier to determine.\nIn linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Such models are called linear models.[3] Most commonly, the conditional mean of the response given the values of the explanatory variables (or predictors) is assumed to be an affine function of those values; less commonly, the conditional median or some other quantile is used. Like all forms of regression analysis, linear regression focuses on the conditional probability distribution of the response given the values of the predictors, rather than on the joint probability distribution of all of these variables, which is the domain of multivariate analysis.\nIn statistics, linear regression is a linear approach to modelling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression.[1] This term is distinct from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable.[2]\n",
            "title": "Linear regression",
            "url": "https://en.wikipedia.org/wiki/Linear_regression"
        },
        {
            "desc_links": [
                "/wiki/Linear_model",
                "/wiki/Generalized_linear_model",
                "/wiki/Multivariate_normal_distribution",
                "/wiki/Errors_and_residuals_in_statistics",
                "/wiki/Design_matrix",
                "/wiki/Independent_variable",
                "/wiki/Dependent_variable",
                "/wiki/Column_vector",
                "/wiki/F-test",
                "/wiki/T-test",
                "/wiki/Linear_regression",
                "/wiki/MANCOVA",
                "/wiki/MANOVA",
                "/wiki/ANCOVA",
                "/wiki/ANOVA",
                "/wiki/Univariate",
                "/wiki/Multivariate_statistics"
            ],
            "desc_text": "b'The general linear model or multivariate regression model is a statistical linear model. It may be written as[1]\\n'b'where Y is a matrix with series of multivariate measurements (each column being a set of measurements on one of the dependent variables), X is a matrix of observations on independent variables that might be a design matrix (each column being a set of observations on one of the independent variables), B is a matrix containing parameters that are usually to be estimated and U is a matrix containing errors (noise).\\nThe errors are usually assumed to be uncorrelated across measurements, and follow a multivariate normal distribution.  If the errors do not follow a multivariate normal distribution, generalized linear models may be used to relax assumptions about Y and U.\\n'b'The general linear model incorporates a number of different statistical models: ANOVA, ANCOVA, MANOVA, MANCOVA, ordinary linear regression, t-test and F-test. The general linear model is a generalization of multiple linear regression model to the case of more than one dependent variable. If Y, B, and U were column vectors, the matrix equation above would represent multiple linear regression.\\n'b'Hypothesis tests with the general linear model can be made in two ways: multivariate or as several independent univariate tests. In multivariate tests the columns of Y are tested together, whereas in univariate tests the columns of Y are tested independently, i.e., as multiple univariate tests with the same design matrix.\\n'",
            "links": [
                "/wiki/Linear_model",
                "/wiki/Generalized_linear_model",
                "/wiki/Multivariate_normal_distribution",
                "/wiki/Errors_and_residuals_in_statistics",
                "/wiki/Design_matrix",
                "/wiki/Independent_variable",
                "/wiki/Dependent_variable",
                "/wiki/Column_vector",
                "/wiki/F-test",
                "/wiki/T-test",
                "/wiki/Linear_regression",
                "/wiki/MANCOVA",
                "/wiki/MANOVA",
                "/wiki/ANCOVA",
                "/wiki/ANOVA",
                "/wiki/Univariate",
                "/wiki/Multivariate_statistics",
                "/wiki/Special_case",
                "/wiki/Simple_linear_regression",
                "/wiki/Statistical_parametric_mapping",
                "/wiki/Brain_scan"
            ],
            "text": "An application of the general linear model appears in the analysis of multiple brain scans in scientific experiments where Y contains data from brain scanners, X contains experimental design variables and confounds. It is usually tested in a univariate way (usually referred to a mass-univariate in this setting) and is often referred to as statistical parametric mapping.[2]\nfor all observations indexed as i = 1, ... , n and for all dependent variables indexed as j = 1, ... , m.\nIn the more general multivariate linear regression, there is one equation of the above form for each of m > 1 dependent variables that share the same set of explanatory variables and hence are estimated simultaneously with each other:\nIn the formula above we consider n observations of one dependent variable and p independent variables. Thus, Yi is the ith observation of the dependent variable, Xij is ith observation of the jth independent variable, j = 1, 2, ..., p. The values \u03b2j represent parameters to be estimated, and \u03b5i is the ith independent identically distributed normal error.\nfor each observation i = 1, ... , n.\nMultiple linear regression is a generalization of simple linear regression to the case of more than one independent variable, and a special case of general linear models, restricted to one dependent variable. The basic model for multiple linear regression is\nHypothesis tests with the general linear model can be made in two ways: multivariate or as several independent univariate tests. In multivariate tests the columns of Y are tested together, whereas in univariate tests the columns of Y are tested independently, i.e., as multiple univariate tests with the same design matrix.\nThe general linear model incorporates a number of different statistical models: ANOVA, ANCOVA, MANOVA, MANCOVA, ordinary linear regression, t-test and F-test. The general linear model is a generalization of multiple linear regression model to the case of more than one dependent variable. If Y, B, and U were column vectors, the matrix equation above would represent multiple linear regression.\nwhere Y is a matrix with series of multivariate measurements (each column being a set of measurements on one of the dependent variables), X is a matrix of observations on independent variables that might be a design matrix (each column being a set of observations on one of the independent variables), B is a matrix containing parameters that are usually to be estimated and U is a matrix containing errors (noise).\nThe errors are usually assumed to be uncorrelated across measurements, and follow a multivariate normal distribution.  If the errors do not follow a multivariate normal distribution, generalized linear models may be used to relax assumptions about Y and U.\nThe general linear model or multivariate regression model is a statistical linear model. It may be written as[1]\n",
            "title": "General linear model",
            "url": "https://en.wikipedia.org/wiki/Multivariate_linear_regression"
        },
        {
            "desc_links": [
                "/wiki/Straight_line",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Covariate",
                "/wiki/Linear_regression",
                "/wiki/Statistics",
                "/wiki/Deming_regression",
                "/wiki/Median",
                "/wiki/Slope",
                "/wiki/Theil%E2%80%93Sen_estimator",
                "/wiki/Least_absolute_deviations",
                "/wiki/Errors_and_residuals",
                "/wiki/Ordinary_least_squares"
            ],
            "desc_text": "b'In statistics, simple linear regression is a linear regression model with a single explanatory variable.[1][2][3][4] That is, it concerns two-dimensional sample points with one independent variable and one dependent variable (conventionally, the x and y coordinates in a Cartesian coordinate system) and finds a linear function (a non-vertical straight line) that, as accurately as possible, predicts the dependent variable values as a function of the independent variables.\\nThe adjective simple refers to the fact that the outcome variable is related to a single predictor.\\n'b'It is common to make the additional stipulation that the ordinary least squares method should be used: the accuracy of each predicted value is measured by its squared residual (vertical distance between the point of the data set and the fitted line), and the goal is to make the sum of these squared deviations as small as possible. Other regression methods that can be used in place of ordinary least squares include least absolute deviations (minimizing the sum of absolute values of residuals) and the Theil\\xe2\\x80\\x93Sen estimator (which chooses a line whose slope is the median of the slopes determined by pairs of sample points).  Deming regression (total least squares) also finds a line that fits a set of two-dimensional sample points, but (unlike ordinary least squares, least absolute deviations, and median slope regression) it is not really an instance of simple linear regression, because it does not separate the coordinates into one dependent and one independent variable and could potentially return a vertical line as its fit.\\n'b'The remainder of the article assumes an ordinary least squares regression.\\nIn this case, the slope of the fitted line is equal to the correlation between y and x corrected by the ratio of standard deviations of these variables. The intercept of the fitted line is such that the line passes through the center of mass (x, y) of the data points.\\n'",
            "links": [
                "/wiki/Straight_line",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Covariate",
                "/wiki/Linear_regression",
                "/wiki/Statistics",
                "/wiki/Deming_regression",
                "/wiki/Median",
                "/wiki/Slope",
                "/wiki/Theil%E2%80%93Sen_estimator",
                "/wiki/Least_absolute_deviations",
                "/wiki/Errors_and_residuals",
                "/wiki/Ordinary_least_squares",
                "/wiki/Errors_and_residuals",
                "/wiki/Standard_score",
                "/wiki/Wikipedia:Please_clarify",
                "/wiki/Homoscedasticity",
                "/wiki/Statistical_model",
                "/wiki/Central_limit_theorem",
                "/wiki/Student%27s_t-distribution",
                "/wiki/Okun%27s_law",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Standard_normal_distribution",
                "/wiki/Student%27s_t-distribution",
                "/wiki/Central_limit_theorem",
                "/wiki/Law_of_large_numbers",
                "/wiki/Ordinary_least_squares",
                "/wiki/Pearson_product-moment_correlation_coefficient"
            ],
            "text": "Thus a seemingly small variation in the data has a real effect.\nThis example also demonstrates that sophisticated calculations will not overcome the use of badly prepared data. The heights were originally given in inches, and have been converted to the nearest centimetre. Since the conversion has introduced rounding error, this is not an exact conversion. The original inches can be recovered by Round(x/0.0254) and then re-converted to metric without rounding: if this is done, the results become\nThe product-moment correlation coefficient might also be calculated:\nThe 0.975 quantile of Student's t-distribution with 13 degrees of freedom is t*13 = 2.1604, and thus the 95% confidence intervals for \u03b1 and \u03b2 are\nThese quantities would be used to calculate the estimates of the regression coefficients, and their standard errors.\nThere are n = 15 points in this data set. Hand calculations would be started by finding the following five sums:\nThis data set gives average masses for women as a function of their height in a sample of American women of age 30\u201339. Although the OLS article argues that it would be more appropriate to run a quadratic regression for this data, the simple linear regression model is applied here instead.\nThe alternative second assumption states that when the number of points in the dataset is \"large enough\", the law of large numbers and the central limit theorem become applicable, and then the distribution of the estimators is approximately normal. Under this assumption all formulas derived in the previous section remain valid, with the only exception that the quantile t*n\u22122 of Student's t distribution is replaced with the quantile q* of the standard normal distribution. Occasionally the fraction 1/n\u22122 is replaced with 1/n. When n is large such a change does not alter the results appreciably.\nIn order to represent this information graphically, in the form of the confidence bands around the regression line, one has to proceed carefully and account for the joint distribution of the estimators. It can be shown[citation needed] that at confidence level (1 \u2212 \u03b3) the confidence band has hyperbolic form given by the equation\nThe 95% confidence intervals for these estimates are\nThe confidence intervals for \u03b1 and \u03b2 give us the general idea where these regression coefficients are most likely to be. For example, in the Okun's law regression shown here the point estimates are\nat confidence level (1 \u2212 \u03b3), where\nSimilarly, the confidence interval for the intercept coefficient \u03b1 is given by\nThis t-value has a Student's t-distribution with n \u2212 2 degrees of freedom. Using it we can construct a confidence interval for \u03b2:\nwhere\nThe latter case is justified by the central limit theorem.\nThe standard method of constructing confidence intervals for linear regression coefficients relies on the normality assumption, which is justified if either:\nDescription of the statistical properties of estimators from the simple linear regression estimates requires the use of a statistical model. The following is based on assuming the validity of a model under which the estimates are optimal. It is also possible to evaluate the properties under other assumptions, such as inhomogeneity, but this is discussed elsewhere.[clarification needed]\nThe last form above demonstrates how moving the line away from the center of mass of the data points affects the slope.\nwhere Cov and Var refer to the covariance and variance of the sample data (uncorrected for bias).\nSubstituting (x \u2212 h, y \u2212 k) in place of (x, y) gives the regression through (h, k):\nSometimes it is appropriate to force the regression line to pass through the origin, because x and y are assumed to be proportional. For the model without the intercept term, y = \u03b2x, the OLS estimator for \u03b2 simplifies to\nThis notation allows us a concise formula for rxy:\nThis shows that rxy is the slope of the regression line of the standardized data points (and that this line passes through the origin).\nyields\nHere we have introduced\nThis relationship between the true (but unobserved) underlying parameters \u03b1 and \u03b2 and the data points is called a linear regression model.\nwhich describes a line with slope \u03b2 and y-intercept \u03b1. In general such a relationship may not hold exactly for the largely unobserved population of values of the independent and dependent variables; we call the unobserved deviations from the above equation the errors.   Suppose we observe n data pairs and call them {(xi, yi), i = 1, ..., n}. We can describe the underlying relationship between yi and xi involving this error term \u03b5i by\nConsider the model function\nThe remainder of the article assumes an ordinary least squares regression.\nIn this case, the slope of the fitted line is equal to the correlation between y and x corrected by the ratio of standard deviations of these variables. The intercept of the fitted line is such that the line passes through the center of mass (x, y) of the data points.\nIt is common to make the additional stipulation that the ordinary least squares method should be used: the accuracy of each predicted value is measured by its squared residual (vertical distance between the point of the data set and the fitted line), and the goal is to make the sum of these squared deviations as small as possible. Other regression methods that can be used in place of ordinary least squares include least absolute deviations (minimizing the sum of absolute values of residuals) and the Theil\u2013Sen estimator (which chooses a line whose slope is the median of the slopes determined by pairs of sample points).  Deming regression (total least squares) also finds a line that fits a set of two-dimensional sample points, but (unlike ordinary least squares, least absolute deviations, and median slope regression) it is not really an instance of simple linear regression, because it does not separate the coordinates into one dependent and one independent variable and could potentially return a vertical line as its fit.\nIn statistics, simple linear regression is a linear regression model with a single explanatory variable.[1][2][3][4] That is, it concerns two-dimensional sample points with one independent variable and one dependent variable (conventionally, the x and y coordinates in a Cartesian coordinate system) and finds a linear function (a non-vertical straight line) that, as accurately as possible, predicts the dependent variable values as a function of the independent variables.\nThe adjective simple refers to the fact that the outcome variable is related to a single predictor.\n",
            "title": "Simple linear regression",
            "url": "https://en.wikipedia.org/wiki/Simple_linear_regression"
        },
        {
            "desc_links": [
                "/wiki/Confounding",
                "/wiki/Variable_and_attribute_(research)",
                "/wiki/Experimental_science",
                "/wiki/Statistical_model",
                "/wiki/Mathematical_modeling"
            ],
            "desc_text": "b'\\nIn mathematical modeling, statistical modeling and experimental sciences, the values of dependent variables depend on the values of independent variables. The dependent variables represent the output or outcome whose variation is being studied. The independent variables, also known in a statistical context as regressors, represent inputs or causes, that is, potential reasons for variation. In an experiment, any variable that the experimenter manipulates can be called an independent variable.  Models and experiments test the effects that the independent variables have on the dependent variables. Sometimes, even if their influence if not of direct interest, independent variables may be included for other reasons, such as to account for their potential confounding effect.'",
            "links": [
                "/wiki/Confounding",
                "/wiki/Variable_and_attribute_(research)",
                "/wiki/Experimental_science",
                "/wiki/Statistical_model",
                "/wiki/Mathematical_modeling",
                "/wiki/Design_of_experiments",
                "/wiki/Supervised_learning",
                "/wiki/Test_data",
                "/wiki/Machine_learning",
                "/wiki/Multivariate_statistics",
                "/wiki/Data_mining",
                "/wiki/Simulation",
                "/wiki/Econometrics",
                "/wiki/Pattern_recognition",
                "/wiki/Machine_learning",
                "/wiki/Feature_(machine_learning)",
                "/wiki/Medical_statistics",
                "/wiki/Risk_factor",
                "/wiki/Reliability_theory",
                "/wiki/Dependent_variable",
                "/wiki/Control_variable",
                "/wiki/Omitted_variable_bias",
                "/wiki/Confounding",
                "/wiki/Bias_(statistics)",
                "/wiki/Covariance",
                "/wiki/Dependent_variable",
                "/wiki/Hypothesis",
                "/wiki/Goodness_of_fit",
                "/wiki/Prediction"
            ],
            "text": "Extraneous variables are often classified into three types:\nExtraneous variables, if included in a regression analysis as independent variables, may aid a researcher with accurate response parameter estimation, prediction, and goodness of fit, but are not of substantive interest to the hypothesis under examination. For example, in a study examining the effect of post-secondary education on lifetime earnings, some extraneous variables might be gender, ethnicity, social class, genetics, intelligence, age, and so forth. A variable is extraneous only when it can be assumed (or shown) to influence the dependent variable. If included in a regression, it can improve the fit of the model. If it is excluded from the regression and if it has a non-zero covariance with one or more of the independent variables of interest, its omission will bias the regression's result for the effect of that independent variable of interest. This effect is called confounding or omitted variable bias; in these situations, design changes and/or controlling for a variable statistical control is necessary.\nA variable may be thought to alter the dependent or independent variables, but may not actually be the focus of the experiment. So that variable will be kept constant or monitored to try to minimize its effect on the experiment. Such variables may be designated as either a \"controlled variable\", \"control variable\", or \"extraneous variable\".\nAn example is provided by the analysis of trend in sea level by Woodworth (1987). Here the dependent variable (and variable of most interest) was the annual mean sea level at a given location for which a series of yearly values were available. The primary independent variable was time. Use was made of a covariate consisting of yearly values of annual mean atmospheric pressure at sea level. The results showed that inclusion of the covariate allowed improved estimates of the trend against time to be obtained, compared to analyses which omitted the covariate.\nVariables may also be referred to by their form: continuous, binary/dichotomous, nominal categorical, and ordinal categorical, among others.\n\"Explained variable\" is preferred by some authors over \"dependent variable\" when the quantities treated as \"dependent variables\" may not be statistically dependent.[20] If the dependent variable is referred to as an \"explained variable\" then the term \"predictor variable\" is preferred by some authors for the independent variable.[20]\n\"Explanatory variable\" is preferred by some authors over \"independent variable\" when the quantities treated as independent variables may not be statistically independent or independently manipulable by the researcher.[18][19] If the independent variable is referred to as an \"explanatory variable\" then the term \"response variable\" is preferred by some authors for the dependent variable.[12][18][19]\nDepending on the context, a dependent variable is sometimes called a \"response variable\", \"regressand\", \"criterion\", \"predicted variable\", \"measured variable\", \"explained variable\", \"experimental variable\", \"responding variable\", \"outcome variable\", \"output variable\" or \"label\".[12]\nDepending on the context, an independent variable is sometimes called a \"predictor variable\", regressor, covariate, \"controlled variable\", \"manipulated variable\", \"explanatory variable\", exposure variable (see reliability theory), \"risk factor\" (see medical statistics), \"feature\" (in machine learning and pattern recognition) or \"input variable.\"[11][12]\nIn econometrics, the term \"control variable\" is usually used instead of \"covariate\".[13][14] \n[15]\n[16]\n[17]\nIn simulation, the dependent variable is changed in response to changes in the independent variables.\nIn data mining  tools (for multivariate statistics and machine learning), the dependent variable is assigned a role as target variable (or in some tools as label attribute), while an independent variable may be assigned a role as regular variable.[10] Known values for the target variable are provided for the training data set and test data set, but should be predicted for other data. The target variable is used in supervised learning algorithms but not in unsupervised learning.\nIn an experiment, a variable, manipulated by an experimenter, is called an independent variable.[8] The dependent variable is the event expected to change when the independent variable is manipulated.[9]\n\nIn mathematical modeling, statistical modeling and experimental sciences, the values of dependent variables depend on the values of independent variables. The dependent variables represent the output or outcome whose variation is being studied. The independent variables, also known in a statistical context as regressors, represent inputs or causes, that is, potential reasons for variation. In an experiment, any variable that the experimenter manipulates can be called an independent variable.  Models and experiments test the effects that the independent variables have on the dependent variables. Sometimes, even if their influence if not of direct interest, independent variables may be included for other reasons, such as to account for their potential confounding effect.",
            "title": "Dependent and independent variables",
            "url": "https://en.wikipedia.org/wiki/Independent_variable"
        },
        {
            "desc_links": [
                "/wiki/Confounding",
                "/wiki/Variable_and_attribute_(research)",
                "/wiki/Experimental_science",
                "/wiki/Statistical_model",
                "/wiki/Mathematical_modeling"
            ],
            "desc_text": "b'\\nIn mathematical modeling, statistical modeling and experimental sciences, the values of dependent variables depend on the values of independent variables. The dependent variables represent the output or outcome whose variation is being studied. The independent variables, also known in a statistical context as regressors, represent inputs or causes, that is, potential reasons for variation. In an experiment, any variable that the experimenter manipulates can be called an independent variable.  Models and experiments test the effects that the independent variables have on the dependent variables. Sometimes, even if their influence if not of direct interest, independent variables may be included for other reasons, such as to account for their potential confounding effect.'",
            "links": [
                "/wiki/Confounding",
                "/wiki/Variable_and_attribute_(research)",
                "/wiki/Experimental_science",
                "/wiki/Statistical_model",
                "/wiki/Mathematical_modeling",
                "/wiki/Design_of_experiments",
                "/wiki/Supervised_learning",
                "/wiki/Test_data",
                "/wiki/Machine_learning",
                "/wiki/Multivariate_statistics",
                "/wiki/Data_mining",
                "/wiki/Simulation",
                "/wiki/Econometrics",
                "/wiki/Pattern_recognition",
                "/wiki/Machine_learning",
                "/wiki/Feature_(machine_learning)",
                "/wiki/Medical_statistics",
                "/wiki/Risk_factor",
                "/wiki/Reliability_theory",
                "/wiki/Dependent_variable",
                "/wiki/Control_variable",
                "/wiki/Omitted_variable_bias",
                "/wiki/Confounding",
                "/wiki/Bias_(statistics)",
                "/wiki/Covariance",
                "/wiki/Dependent_variable",
                "/wiki/Hypothesis",
                "/wiki/Goodness_of_fit",
                "/wiki/Prediction"
            ],
            "text": "Extraneous variables are often classified into three types:\nExtraneous variables, if included in a regression analysis as independent variables, may aid a researcher with accurate response parameter estimation, prediction, and goodness of fit, but are not of substantive interest to the hypothesis under examination. For example, in a study examining the effect of post-secondary education on lifetime earnings, some extraneous variables might be gender, ethnicity, social class, genetics, intelligence, age, and so forth. A variable is extraneous only when it can be assumed (or shown) to influence the dependent variable. If included in a regression, it can improve the fit of the model. If it is excluded from the regression and if it has a non-zero covariance with one or more of the independent variables of interest, its omission will bias the regression's result for the effect of that independent variable of interest. This effect is called confounding or omitted variable bias; in these situations, design changes and/or controlling for a variable statistical control is necessary.\nA variable may be thought to alter the dependent or independent variables, but may not actually be the focus of the experiment. So that variable will be kept constant or monitored to try to minimize its effect on the experiment. Such variables may be designated as either a \"controlled variable\", \"control variable\", or \"extraneous variable\".\nAn example is provided by the analysis of trend in sea level by Woodworth (1987). Here the dependent variable (and variable of most interest) was the annual mean sea level at a given location for which a series of yearly values were available. The primary independent variable was time. Use was made of a covariate consisting of yearly values of annual mean atmospheric pressure at sea level. The results showed that inclusion of the covariate allowed improved estimates of the trend against time to be obtained, compared to analyses which omitted the covariate.\nVariables may also be referred to by their form: continuous, binary/dichotomous, nominal categorical, and ordinal categorical, among others.\n\"Explained variable\" is preferred by some authors over \"dependent variable\" when the quantities treated as \"dependent variables\" may not be statistically dependent.[20] If the dependent variable is referred to as an \"explained variable\" then the term \"predictor variable\" is preferred by some authors for the independent variable.[20]\n\"Explanatory variable\" is preferred by some authors over \"independent variable\" when the quantities treated as independent variables may not be statistically independent or independently manipulable by the researcher.[18][19] If the independent variable is referred to as an \"explanatory variable\" then the term \"response variable\" is preferred by some authors for the dependent variable.[12][18][19]\nDepending on the context, a dependent variable is sometimes called a \"response variable\", \"regressand\", \"criterion\", \"predicted variable\", \"measured variable\", \"explained variable\", \"experimental variable\", \"responding variable\", \"outcome variable\", \"output variable\" or \"label\".[12]\nDepending on the context, an independent variable is sometimes called a \"predictor variable\", regressor, covariate, \"controlled variable\", \"manipulated variable\", \"explanatory variable\", exposure variable (see reliability theory), \"risk factor\" (see medical statistics), \"feature\" (in machine learning and pattern recognition) or \"input variable.\"[11][12]\nIn econometrics, the term \"control variable\" is usually used instead of \"covariate\".[13][14] \n[15]\n[16]\n[17]\nIn simulation, the dependent variable is changed in response to changes in the independent variables.\nIn data mining  tools (for multivariate statistics and machine learning), the dependent variable is assigned a role as target variable (or in some tools as label attribute), while an independent variable may be assigned a role as regular variable.[10] Known values for the target variable are provided for the training data set and test data set, but should be predicted for other data. The target variable is used in supervised learning algorithms but not in unsupervised learning.\nIn an experiment, a variable, manipulated by an experimenter, is called an independent variable.[8] The dependent variable is the event expected to change when the independent variable is manipulated.[9]\n\nIn mathematical modeling, statistical modeling and experimental sciences, the values of dependent variables depend on the values of independent variables. The dependent variables represent the output or outcome whose variation is being studied. The independent variables, also known in a statistical context as regressors, represent inputs or causes, that is, potential reasons for variation. In an experiment, any variable that the experimenter manipulates can be called an independent variable.  Models and experiments test the effects that the independent variables have on the dependent variables. Sometimes, even if their influence if not of direct interest, independent variables may be included for other reasons, such as to account for their potential confounding effect.",
            "title": "Dependent and independent variables",
            "url": "https://en.wikipedia.org/wiki/Explanatory_variable"
        },
        {
            "desc_links": [
                "/wiki/Confounding",
                "/wiki/Variable_and_attribute_(research)",
                "/wiki/Experimental_science",
                "/wiki/Statistical_model",
                "/wiki/Mathematical_modeling"
            ],
            "desc_text": "b'\\nIn mathematical modeling, statistical modeling and experimental sciences, the values of dependent variables depend on the values of independent variables. The dependent variables represent the output or outcome whose variation is being studied. The independent variables, also known in a statistical context as regressors, represent inputs or causes, that is, potential reasons for variation. In an experiment, any variable that the experimenter manipulates can be called an independent variable.  Models and experiments test the effects that the independent variables have on the dependent variables. Sometimes, even if their influence if not of direct interest, independent variables may be included for other reasons, such as to account for their potential confounding effect.'",
            "links": [
                "/wiki/Confounding",
                "/wiki/Variable_and_attribute_(research)",
                "/wiki/Experimental_science",
                "/wiki/Statistical_model",
                "/wiki/Mathematical_modeling",
                "/wiki/Design_of_experiments",
                "/wiki/Supervised_learning",
                "/wiki/Test_data",
                "/wiki/Machine_learning",
                "/wiki/Multivariate_statistics",
                "/wiki/Data_mining",
                "/wiki/Simulation",
                "/wiki/Econometrics",
                "/wiki/Pattern_recognition",
                "/wiki/Machine_learning",
                "/wiki/Feature_(machine_learning)",
                "/wiki/Medical_statistics",
                "/wiki/Risk_factor",
                "/wiki/Reliability_theory",
                "/wiki/Dependent_variable",
                "/wiki/Control_variable",
                "/wiki/Omitted_variable_bias",
                "/wiki/Confounding",
                "/wiki/Bias_(statistics)",
                "/wiki/Covariance",
                "/wiki/Dependent_variable",
                "/wiki/Hypothesis",
                "/wiki/Goodness_of_fit",
                "/wiki/Prediction"
            ],
            "text": "Extraneous variables are often classified into three types:\nExtraneous variables, if included in a regression analysis as independent variables, may aid a researcher with accurate response parameter estimation, prediction, and goodness of fit, but are not of substantive interest to the hypothesis under examination. For example, in a study examining the effect of post-secondary education on lifetime earnings, some extraneous variables might be gender, ethnicity, social class, genetics, intelligence, age, and so forth. A variable is extraneous only when it can be assumed (or shown) to influence the dependent variable. If included in a regression, it can improve the fit of the model. If it is excluded from the regression and if it has a non-zero covariance with one or more of the independent variables of interest, its omission will bias the regression's result for the effect of that independent variable of interest. This effect is called confounding or omitted variable bias; in these situations, design changes and/or controlling for a variable statistical control is necessary.\nA variable may be thought to alter the dependent or independent variables, but may not actually be the focus of the experiment. So that variable will be kept constant or monitored to try to minimize its effect on the experiment. Such variables may be designated as either a \"controlled variable\", \"control variable\", or \"extraneous variable\".\nAn example is provided by the analysis of trend in sea level by Woodworth (1987). Here the dependent variable (and variable of most interest) was the annual mean sea level at a given location for which a series of yearly values were available. The primary independent variable was time. Use was made of a covariate consisting of yearly values of annual mean atmospheric pressure at sea level. The results showed that inclusion of the covariate allowed improved estimates of the trend against time to be obtained, compared to analyses which omitted the covariate.\nVariables may also be referred to by their form: continuous, binary/dichotomous, nominal categorical, and ordinal categorical, among others.\n\"Explained variable\" is preferred by some authors over \"dependent variable\" when the quantities treated as \"dependent variables\" may not be statistically dependent.[20] If the dependent variable is referred to as an \"explained variable\" then the term \"predictor variable\" is preferred by some authors for the independent variable.[20]\n\"Explanatory variable\" is preferred by some authors over \"independent variable\" when the quantities treated as independent variables may not be statistically independent or independently manipulable by the researcher.[18][19] If the independent variable is referred to as an \"explanatory variable\" then the term \"response variable\" is preferred by some authors for the dependent variable.[12][18][19]\nDepending on the context, a dependent variable is sometimes called a \"response variable\", \"regressand\", \"criterion\", \"predicted variable\", \"measured variable\", \"explained variable\", \"experimental variable\", \"responding variable\", \"outcome variable\", \"output variable\" or \"label\".[12]\nDepending on the context, an independent variable is sometimes called a \"predictor variable\", regressor, covariate, \"controlled variable\", \"manipulated variable\", \"explanatory variable\", exposure variable (see reliability theory), \"risk factor\" (see medical statistics), \"feature\" (in machine learning and pattern recognition) or \"input variable.\"[11][12]\nIn econometrics, the term \"control variable\" is usually used instead of \"covariate\".[13][14] \n[15]\n[16]\n[17]\nIn simulation, the dependent variable is changed in response to changes in the independent variables.\nIn data mining  tools (for multivariate statistics and machine learning), the dependent variable is assigned a role as target variable (or in some tools as label attribute), while an independent variable may be assigned a role as regular variable.[10] Known values for the target variable are provided for the training data set and test data set, but should be predicted for other data. The target variable is used in supervised learning algorithms but not in unsupervised learning.\nIn an experiment, a variable, manipulated by an experimenter, is called an independent variable.[8] The dependent variable is the event expected to change when the independent variable is manipulated.[9]\n\nIn mathematical modeling, statistical modeling and experimental sciences, the values of dependent variables depend on the values of independent variables. The dependent variables represent the output or outcome whose variation is being studied. The independent variables, also known in a statistical context as regressors, represent inputs or causes, that is, potential reasons for variation. In an experiment, any variable that the experimenter manipulates can be called an independent variable.  Models and experiments test the effects that the independent variables have on the dependent variables. Sometimes, even if their influence if not of direct interest, independent variables may be included for other reasons, such as to account for their potential confounding effect.",
            "title": "Dependent and independent variables",
            "url": "https://en.wikipedia.org/wiki/Dependent_variable"
        },
        {
            "desc_links": [
                "/wiki/Proportionality_(mathematics)",
                "/wiki/Weight",
                "/wiki/Mass",
                "/wiki/Ohm%27s_law",
                "/wiki/Resistor",
                "/wiki/Electric_current",
                "/wiki/Voltage",
                "/wiki/Line_(geometry)"
            ],
            "desc_text": "b\"Linearity is the property of a mathematical relationship or function which means that it can be graphically represented as a straight line. Examples are the relationship of voltage and current across a resistor (Ohm's law), or the mass and weight of an object. Proportionality implies linearity, but linearity does not imply proportionality.\\n\"",
            "links": [
                "/wiki/Proportionality_(mathematics)",
                "/wiki/Weight",
                "/wiki/Mass",
                "/wiki/Ohm%27s_law",
                "/wiki/Resistor",
                "/wiki/Electric_current",
                "/wiki/Voltage",
                "/wiki/Line_(geometry)",
                "/wiki/Linear_function",
                "/wiki/Linear_map",
                "/wiki/Mathematics",
                "/wiki/Mathematical_induction",
                "/wiki/Rational_number",
                "/wiki/Linear_function#As_a_polynomial_function",
                "/wiki/Vector_space",
                "/wiki/Real_number",
                "/wiki/Differential_equation",
                "/wiki/Laplacian",
                "/wiki/Del",
                "/wiki/Differential_operator",
                "/wiki/Derivative",
                "/wiki/Operator_(mathematics)",
                "/wiki/Linear_algebra",
                "/wiki/Chaos_theory",
                "/wiki/Mathematician",
                "/wiki/Physicist",
                "/wiki/Nonlinear",
                "/wiki/Linear_equation",
                "/wiki/Latin",
                "/wiki/Graph_of_a_function",
                "/wiki/Polynomial",
                "/wiki/Linear_equation",
                "/wiki/Y-intercept",
                "/wiki/Gradient",
                "/wiki/Slope",
                "/wiki/Affine_transformation",
                "/wiki/If_and_only_if",
                "/wiki/Truth_table",
                "/wiki/Truth_value",
                "/wiki/Contradiction",
                "/wiki/Tautology_(logic)",
                "/wiki/Exclusive_or",
                "/wiki/Logical_biconditional",
                "/wiki/Negation",
                "/wiki/Diffusion_equation",
                "/wiki/Maxwell_equations",
                "/wiki/Differential_equations",
                "/wiki/Physics",
                "/wiki/Linear_combination",
                "/wiki/Differential_equation",
                "/wiki/Absolute_threshold",
                "/wiki/Linear_amplifier",
                "/wiki/Linear_regulator",
                "/wiki/Linear_filter",
                "/wiki/Audio_amplifier",
                "/wiki/High_fidelity",
                "/wiki/Independent_variable",
                "/wiki/Proportionality_(mathematics)",
                "/wiki/Electric_current",
                "/wiki/Dependent_variable",
                "/wiki/Transistor",
                "/wiki/Electronics",
                "/wiki/Transfer_function",
                "/wiki/Technology",
                "/wiki/Science",
                "/wiki/Rifle",
                "/wiki/Breech-loading_weapon",
                "/wiki/Skirmisher",
                "/wiki/The_Thin_Red_Line_(1854_battle)",
                "/wiki/Pike_(weapon)",
                "/wiki/Formation_(military)",
                "/wiki/Nonlinear_narrative",
                "/wiki/Hypertext_fiction",
                "/wiki/Digital_art",
                "/wiki/Shape",
                "/wiki/Diego_Vel%C3%A1zquez",
                "/wiki/Rembrandt",
                "/wiki/Peter_Paul_Rubens",
                "/wiki/Painterly",
                "/wiki/Albrecht_D%C3%BCrer",
                "/wiki/Raphael",
                "/wiki/Leonardo_da_Vinci",
                "/wiki/Baroque",
                "/wiki/Renaissance_art",
                "/wiki/Heinrich_W%C3%B6lfflin",
                "/wiki/Interval_(music)",
                "/wiki/Simultaneity_(music)",
                "/wiki/Melodic",
                "/wiki/Interval_(music)",
                "/wiki/Latin"
            ],
            "text": "In measurement, the term \"linear foot\" refers to the number of feet in a straight line of material (such as lumber or fabric) generally without regard to the width.  It is sometimes incorrectly referred to as \"lineal feet\"; however, \"lineal\" is typically reserved for usage when referring to ancestry or heredity.[1] The words \"linear\"[2] & \"lineal\" [3]\nboth descend from the same root meaning, the Latin word for line, which is \"linea\".\nIn music the linear aspect is succession, either intervals or melody, as opposed to simultaneity or the vertical aspect.\nLinear is one of the five categories proposed by Swiss art historian Heinrich W\u00f6lfflin to distinguish \"Classic\", or Renaissance art, from the Baroque. According to W\u00f6lfflin, painters of the fifteenth and early sixteenth centuries (Leonardo da Vinci, Raphael or Albrecht D\u00fcrer) are more linear than \"painterly\" Baroque painters of the seventeenth century (Peter Paul Rubens, Rembrandt, and Vel\u00e1zquez) because they primarily use outline to create shape.[7] Linearity in art can also be referenced in digital art. For example, hypertext fiction can be an example of nonlinear narrative, but there are also websites designed to go in a specified, organized manner, following a linear path.\nIn military tactical formations, \"linear formations\" were adapted from phalanx-like formations of pike protected by handgunners towards shallow formations of handgunners protected by progressively fewer pikes. This kind of formation would get thinner until its extreme in the age of Wellington with the 'Thin Red Line'. It would eventually be replaced by skirmish order at the time of the invention of the breech-loading rifle that allowed soldiers to move and fire independently of the large-scale formations and fight in small, mobile units.\nFor an electronic device (or other physical device) that converts a quantity to another quantity, Bertram S. Kolts writes:[5][6]\nIn most scientific and technological, as distinct from mathematical, applications, something may be described as linear if the characteristic is approximately but not exactly a straight line; and linearity may be valid only within a certain operating region\u2014for example, a high-fidelity amplifier may distort a small signal, but sufficiently little to be acceptable (acceptable but imperfect linearity); and may distort very badly if the input exceeds a certain value, taking it away from the approximately linear part of the transfer function.[4]\nIn electronics, the linear operating region of a device, for example a transistor, is where a dependent variable (such as the transistor collector current) is directly proportional to an independent variable (such as the base current). This ensures that an analog output is an accurate representation of an input, typically with higher amplitude (amplified). A typical example of linear equipment is a high fidelity audio amplifier, which must amplify a signal without changing its waveform. Others are linear filters, linear regulators, and linear amplifiers in general.\nIn instrumentation, linearity means that for every change in the variable you are observing, you get the same change in the output of the measurement apparatus - this is highly desirable in scientific work. In general, instruments are close to linear over a useful certain range, and most useful within that range.  In contrast, human senses are highly nonlinear- for instance, the brain totally ignores incoming light unless it exceeds a certain absolute threshold number of photons.\nLinearity of a differential equation means that if two functions f and g are solutions of the equation, then any linear combination af + bg is, too.\nIn physics, linearity is a property of the differential equations governing many systems; for instance, the Maxwell equations or the diffusion equation.[3]\nNegation, Logical biconditional, exclusive or, tautology, and contradiction are linear functions.\nAnother way to express this is that each variable always makes a difference in the truth value of the operation or it never makes a difference.\nA Boolean function is linear if one of the following holds for the function's truth table:\nNote that this usage of the term linear is not the same as in the section above, because linear polynomials over the real numbers do not in general satisfy either additivity or homogeneity. In fact, they do so if and only if b = 0. Hence, if b \u2260 0, the function is often called an affine function (see in greater generality affine transformation).\nwhere m is often called the slope or gradient; b the y-intercept, which gives the point of intersection between the graph of the function and the y-axis.\nOver the reals, a linear equation is one of the forms:\nIn a different usage to the above definition, a polynomial of degree 1 is said to be linear, because the graph of a function of that form is a line.[2]\nThe word linear comes from the Latin word linearis, which means pertaining to or resembling a line.  For a description of linear and nonlinear equations, see linear equation. Nonlinear equations and functions are of interest to physicists and mathematicians because they can be used to represent many natural phenomena, including chaos.\nLinear algebra is the branch of mathematics concerned with the study of vectors, vector spaces (also called linear spaces), linear transformations (also called linear maps), and systems of linear equations.\nThe concept of linearity can be extended to linear operators. Important examples of linear operators include the derivative considered as a differential operator, and many constructed from it, such as del and the Laplacian.  When a differential equation can be expressed in linear form, it is generally straightforward to solve by breaking the equation up into smaller pieces, solving each of those pieces, and summing the solutions.\nIn this definition, x is not necessarily a real number, but can in general be a member of any vector space. A more specific definition of linear function, not coinciding with the definition of linear map, is used in elementary mathematics.\nThe homogeneity and additivity properties together are called the superposition principle. It can be shown that additivity implies homogeneity in all cases where \u03b1 is rational; this is done by proving the case where \u03b1 is a natural number by mathematical induction and then extending the result to arbitrary rational numbers. If f is assumed to be continuous as well, then this can be extended to show homogeneity for any real number \u03b1, using the fact that rationals form a dense subset of the reals.\nIn mathematics, a linear map or linear function f(x) is a function that satisfies the following two properties:[1]\nLinearity is the property of a mathematical relationship or function which means that it can be graphically represented as a straight line. Examples are the relationship of voltage and current across a resistor (Ohm's law), or the mass and weight of an object. Proportionality implies linearity, but linearity does not imply proportionality.\n",
            "title": "Linearity",
            "url": "https://en.wikipedia.org/wiki/Linearity"
        },
        {
            "desc_links": [],
            "desc_text": "",
            "links": [
                "/wiki/Glossary_of_probability_and_statistics",
                "/wiki/Experimental_design",
                "/wiki/Statistical_survey",
                "/wiki/Statistical_model",
                "/wiki/Statistical_population",
                "/wiki/Data",
                "/wiki/Mathematics",
                "/wiki/Observational_study",
                "/wiki/Experimental_study",
                "/wiki/Sample_(statistics)",
                "/wiki/Statistician",
                "/wiki/Census",
                "/wiki/Probability_theory",
                "/wiki/Statistical_dispersion",
                "/wiki/Central_tendency",
                "/wiki/Statistical_inference",
                "/wiki/Standard_deviation",
                "/wiki/Mean",
                "/wiki/Index_(statistics)",
                "/wiki/Descriptive_statistics",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Type_II_error",
                "/wiki/Type_I_error",
                "/wiki/Null_hypothesis",
                "/wiki/Alternative_hypothesis",
                "/wiki/Statistical_hypothesis_testing",
                "/wiki/Censoring_(statistics)",
                "/wiki/Missing_data",
                "/wiki/Bias_(statistics)",
                "/wiki/Probability_theory",
                "/wiki/Calculus",
                "/wiki/Mathematics",
                "/wiki/Data",
                "/wiki/Measure-theoretic_probability_theory",
                "/wiki/Differential_equations",
                "/wiki/Stochastic_analysis",
                "/wiki/Linear_algebra",
                "/wiki/Mathematical_analysis",
                "/wiki/Mathematics",
                "/wiki/Statistical_population",
                "/wiki/Categorical_data",
                "/wiki/Continuous_probability_distribution",
                "/wiki/Standard_deviation",
                "/wiki/Mean",
                "/wiki/Descriptive_statistics",
                "/wiki/Census",
                "/wiki/Data_mining",
                "/wiki/Spatial_data_analysis",
                "/wiki/Time_series",
                "/wiki/Interpolation",
                "/wiki/Extrapolation",
                "/wiki/Prediction",
                "/wiki/Forecasting",
                "/wiki/Regression_analysis",
                "/wiki/Correlation_and_dependence",
                "/wiki/Association_(statistics)",
                "/wiki/Estimation_theory",
                "/wiki/Hypothesis_testing",
                "/wiki/Inferential_statistics",
                "/wiki/Experiment",
                "/wiki/Sampling_(statistics)",
                "/wiki/Statistical_model",
                "/wiki/Survey_sampling",
                "/wiki/Design_of_experiments",
                "/wiki/Sampling_(statistics)",
                "/wiki/Inductive_reasoning",
                "/wiki/Deductive_reasoning",
                "/wiki/Statistical_decision_theory",
                "/wiki/Sample_statistic",
                "/wiki/Sampling_distribution",
                "/wiki/Statistical_theory",
                "/wiki/Probability_theory",
                "/wiki/Mathematics",
                "/wiki/Consistent_estimator",
                "/wiki/Instrumental_variable",
                "/wiki/Difference_in_differences",
                "/wiki/Observational_study",
                "/wiki/Natural_experiment",
                "/wiki/Randomized_controlled_trial",
                "/wiki/Scientific_control",
                "/wiki/Observational_study",
                "/wiki/Experiment",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Causality",
                "/wiki/Hawthorne_effect",
                "/wiki/Double-blind",
                "/wiki/Control_group",
                "/wiki/Assembly_line",
                "/wiki/Western_Electric_Company",
                "/wiki/Hawthorne_study",
                "/wiki/Case-control_study",
                "/wiki/Cohort_study",
                "/wiki/Fahrenheit",
                "/wiki/Celsius",
                "/wiki/Temperature",
                "/wiki/Longitude",
                "/wiki/Stanley_Smith_Stevens",
                "/wiki/Level_of_measurement",
                "/wiki/Floating_point",
                "/wiki/Real_data_type",
                "/wiki/Integer_(computer_science)",
                "/wiki/Integer",
                "/wiki/Boolean_data_type",
                "/wiki/Data_type",
                "/wiki/Probability_distribution#Continuous_probability_distribution",
                "/wiki/Probability_distribution#Discrete_probability_distribution",
                "/wiki/Variable_(mathematics)#Applied_statistics",
                "/wiki/Categorical_variable",
                "/wiki/Statistical_population",
                "/wiki/Column_vector",
                "/wiki/Random_vector",
                "/wiki/Random_sample",
                "/wiki/Estimation_theory",
                "/wiki/Statistical_inference",
                "/wiki/Probability_distribution",
                "/wiki/Independent_identically_distributed",
                "/wiki/Statistic",
                "/wiki/Sample_covariance#Sample_covariance",
                "/wiki/Sample_variance",
                "/wiki/Sample_mean#Sample_mean",
                "/wiki/Estimator",
                "/wiki/Student%27s_t-distribution#How_the_t-distribution_arises",
                "/wiki/Chi-squared_distribution#Applications",
                "/wiki/Z-score",
                "/wiki/Pivotal_quantity",
                "/wiki/Limit_(mathematics)",
                "/wiki/Expected_value",
                "/wiki/Unbiased_estimator",
                "/wiki/Efficient_estimator",
                "/wiki/Mean_squared_error",
                "/wiki/Converges_in_probability",
                "/wiki/Consistency_(statistics)",
                "/wiki/UMVUE",
                "/wiki/Estimating_equations",
                "/wiki/Least_squares",
                "/wiki/Maximum_likelihood",
                "/wiki/Method_of_moments_(statistics)",
                "/wiki/Null_hypothesis",
                "/wiki/Statistical_power",
                "/wiki/Null_hypothesis",
                "/wiki/Alternative_hypothesis",
                "/wiki/Statisticians",
                "/wiki/Null_hypothesis",
                "/wiki/Standard_error_(statistics)#Standard_error_of_the_mean",
                "/wiki/Standard_deviation",
                "/wiki/Errors_and_residuals_in_statistics#Introduction",
                "/wiki/Expected_value",
                "/wiki/Errors_and_residuals_in_statistics#Introduction",
                "/wiki/Root_mean_square_error",
                "/wiki/Efficient_estimators",
                "/wiki/Mean_squared_error",
                "/wiki/Polynomial_least_squares",
                "/wiki/Non-linear_least_squares",
                "/wiki/Nonlinear_regression",
                "/wiki/Ordinary_least_squares",
                "/wiki/Linear_regression",
                "/wiki/Regression_analysis",
                "/wiki/Differentiable_function",
                "/wiki/Least_absolute_deviations",
                "/wiki/Least_squares",
                "/wiki/Residual_sum_of_squares",
                "/wiki/Bias_(statistics)",
                "/wiki/Censoring_(statistics)",
                "/wiki/Missing_data",
                "/wiki/Bias",
                "/wiki/Systematic_error",
                "/wiki/Random_error",
                "/wiki/Bayesian_probability",
                "/wiki/Probability_interpretations",
                "/wiki/Bayesian_statistics",
                "/wiki/Credible_interval",
                "/wiki/Random_variable",
                "/wiki/Random_variable",
                "/wiki/Frequentist_inference",
                "/wiki/Confidence_intervals",
                "/wiki/P-value",
                "/wiki/Statistical_power",
                "/wiki/Statistical_significance",
                "/wiki/Critical_region#Definition_of_terms",
                "/wiki/Test_statistic",
                "/wiki/P-value",
                "/wiki/Statistical_significance",
                "/wiki/Statistical_hypothesis_testing#Criticism",
                "/wiki/Procedure_(term)",
                "/wiki/Statistical_hypothesis_testing",
                "/wiki/Misuse_of_statistics",
                "/wiki/Statistical_literacy",
                "/wiki/Statistical_significance",
                "/wiki/How_to_Lie_with_Statistics",
                "/wiki/Lies,_damned_lies,_and_statistics",
                "/wiki/Misuse_of_statistics",
                "/wiki/Sampling_(statistics)",
                "/wiki/Hasty_generalization",
                "/wiki/Bias_(statistics)",
                "/wiki/Correlation_does_not_imply_causation",
                "/wiki/Confounding_variable",
                "/wiki/Data_set",
                "/wiki/Correlation",
                "/wiki/History_of_statistics#Etymology",
                "/wiki/John_Graunt",
                "/wiki/Adrien-Marie_Legendre",
                "/wiki/Method_of_least_squares",
                "/wiki/Juan_Caramuel",
                "/wiki/Medieval_Roman_law",
                "/wiki/Probability_theory",
                "/wiki/Pierre_de_Fermat",
                "/wiki/Blaise_Pascal",
                "/wiki/Gerolamo_Cardano",
                "/wiki/Probability_theory",
                "/wiki/University_College_London",
                "/wiki/Biostatistics",
                "/wiki/Biometrika",
                "/wiki/Pearson_distribution",
                "/wiki/Method_of_moments_(statistics)",
                "/wiki/Pearson_product-moment_correlation_coefficient",
                "/wiki/Regression_analysis",
                "/wiki/Correlation",
                "/wiki/Standard_deviation",
                "/wiki/Karl_Pearson",
                "/wiki/Francis_Galton",
                "/wiki/Lady_tasting_tea",
                "/wiki/Null_hypothesis",
                "/wiki/Ronald_Fisher",
                "/wiki/Evolution",
                "/wiki/Sexual_selection",
                "/wiki/Fisherian_runaway",
                "/wiki/Sex_ratio",
                "/wiki/Evolutionary_biology",
                "/wiki/A._W._F._Edwards",
                "/wiki/Fisher%27s_principle",
                "/wiki/Biology",
                "/wiki/The_Genetical_Theory_of_Natural_Selection",
                "/wiki/Fisher_information",
                "/wiki/Linear_discriminant_analysis",
                "/wiki/Ancillary_statistic",
                "/wiki/Sufficiency_(statistics)",
                "/wiki/Design_of_experiments",
                "/wiki/The_Design_of_Experiments",
                "/wiki/Statistical_Methods_for_Research_Workers",
                "/wiki/Variance",
                "/wiki/The_Correlation_between_Relatives_on_the_Supposition_of_Mendelian_Inheritance",
                "/wiki/Ronald_Fisher",
                "/wiki/William_Gosset",
                "/wiki/Jerzy_Neyman",
                "/wiki/Confidence_interval",
                "/wiki/Type_I_and_type_II_errors",
                "/wiki/Jerzy_Neyman",
                "/wiki/Egon_Pearson",
                "/wiki/Big_data",
                "/wiki/Computer",
                "/wiki/Design_of_experiments",
                "/wiki/Computational_statistics",
                "/wiki/Probability_distribution",
                "/wiki/Statistical_inference",
                "/wiki/Data_mining",
                "/wiki/Machine_learning",
                "/wiki/Statistical_consultant",
                "/wiki/Social_science",
                "/wiki/Natural",
                "/wiki/Academic_discipline",
                "/wiki/Multilevel_model",
                "/wiki/Generalized_linear_model",
                "/wiki/Neural_networks",
                "/wiki/Nonlinear_regression",
                "/wiki/Algorithms",
                "/wiki/Linear_model",
                "/wiki/R_(programming_language)",
                "/wiki/SPSS",
                "/wiki/SAS_(software)",
                "/wiki/Mathematica",
                "/wiki/List_of_statistical_packages",
                "/wiki/Gibbs_sampling",
                "/wiki/Bootstrapping_(statistics)",
                "/wiki/Resampling_(statistics)",
                "/wiki/Wikipedia:Manual_of_Style/Words_to_watch#Unsupported_attributions",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Specialized_terminology",
                "/wiki/Social_research",
                "/wiki/Sociology",
                "/wiki/Social_science",
                "/wiki/Network_biology",
                "/wiki/Computational_sociology",
                "/wiki/Computational_biology",
                "/wiki/Biostatistics",
                "/wiki/Statistical_process_control"
            ],
            "text": "Statistics form a key basis tool in business and manufacturing as well. It is used to understand measurement systems variability, control processes (as in statistical process control or SPC), for summarizing data, and to make data-driven decisions. In these roles, it is a key tool, and perhaps the only reliable tool.\nIn addition, there are particular types of statistical analysis that have also developed their own specialised terminology and methodology:\nStatistical techniques are used in a wide range of types of scientific and social research, including: biostatistics,  computational biology,  computational sociology,  network biology,  social science,  sociology and  social research. Some fields of inquiry use applied statistics so extensively that they have specialized terminology. These disciplines include:\nTraditionally, statistics was concerned with drawing inferences using a semi-standardized methodology that was \"required learning\" in most sciences.[citation needed] This tradition has changed with use of statistics in non-inferential contexts. What was once considered a dry subject, taken in many fields as a degree-requirement, is now viewed enthusiastically.[according to whom?] Initially derided by some mathematical purists, it is now considered essential methodology in certain areas.\nIncreased computing power has also led to the growing popularity of computationally intensive methods based on resampling, such as permutation tests and the bootstrap, while techniques such as Gibbs sampling have made use of Bayesian models more feasible. The computer revolution has implications for the future of statistics with new emphasis on \"experimental\" and \"empirical\" statistics. A large number of both general and special purpose statistical software are now available. Examples of available software capable of complex statistical computation include programs such as Mathematica,  SAS, SPSS, and  R.\nThe rapid and sustained increases in computing power starting from the second half of the 20th century have had a substantial impact on the practice of statistical science. Early statistical models were almost always from the class of linear models, but powerful computers, coupled with suitable numerical algorithms, caused an increased interest in nonlinear models (such as neural networks) as well as the creation of new types, such as generalized linear models and multilevel models.\nStatistics is applicable to a wide variety of academic disciplines, including natural and social sciences, government, and business. Statistical consultants can help organizations and companies that don't have in-house expertise relevant to their particular questions.\nThere are two applications for machine learning and data mining: data management and data analysis.  Statistics tools are necessary for the data analysis.\nApplied statistics comprises descriptive statistics and the application of inferential statistics.[58][59] Theoretical statistics concerns the logical arguments underlying justification of approaches to statistical inference, as well as encompassing mathematical statistics. Mathematical statistics includes not only the manipulation of probability distributions necessary for deriving results related to methods of estimation and inference, but also various aspects of computational statistics and the design of experiments.\nToday, statistical methods are applied in all fields that involve decision making, for making accurate inferences from a collated body of data and for making decisions in the face of uncertainty based on statistical methodology. The use of modern computers has expedited large-scale statistical computations, and has also made possible new methods that are impractical to perform manually. Statistics continues to be an area of active research, for example on the problem of how to analyze Big data.[57]\nThe final wave, which mainly saw the refinement and expansion of earlier developments, emerged from the collaborative work between Egon Pearson and Jerzy Neyman in the 1930s. They introduced the concepts of \"Type II\" error, power of a test and confidence intervals. Jerzy Neyman in 1934 showed that stratified random sampling was in general a better method of estimation than purposive (quota) sampling.[56]\nThe second wave of the 1910s and 20s was initiated by William Gosset, and reached its culmination in the insights of Ronald Fisher, who wrote the textbooks that were to define the academic discipline in universities around the world. Fisher's most important publications were his 1918 seminal paper The Correlation between Relatives on the Supposition of Mendelian Inheritance, which was the first to use the statistical term, variance, his classic 1925 work Statistical Methods for Research Workers and his 1935 The Design of Experiments,[44][45][46][47] where he developed rigorous design of experiments models. He originated the concepts of sufficiency, ancillary statistics, Fisher's linear discriminator and Fisher information.[48] In his 1930 book The Genetical Theory of Natural Selection he applied statistics to various biological concepts such as Fisher's principle[49]). Nevertheless, A. W. F. Edwards has remarked that it is \"probably the most celebrated argument in evolutionary biology\".[49] (about the sex ratio), the Fisherian runaway,[50][51][52][53][54][55] a concept in sexual selection about a positive feedback runaway affect found in evolution.\nRonald Fisher coined the term null hypothesis during the Lady tasting tea experiment, which \"is never proved or established, but is possibly disproved, in the course of experimentation\".[42][43]\nThe modern field of statistics emerged in the late 19th and early 20th century in three stages.[37] The first wave, at the turn of the century, was led by the work of Francis Galton and Karl Pearson, who transformed statistics into a rigorous mathematical discipline used for analysis, not just in science, but in industry and politics as well. Galton's contributions included introducing the concepts of standard deviation, correlation, regression analysis and the application of these methods to the study of the variety of human characteristics\u2014height, weight, eyelash length among others.[38] Pearson developed the Pearson product-moment correlation coefficient, defined as a product-moment,[39] the method of moments for the fitting of distributions to samples and the Pearson distribution, among many other things.[40] Galton and Pearson founded Biometrika as the first journal of mathematical statistics and biostatistics (then called biometry), and the latter founded the world's first university statistics department at University College London.[41]\nIts mathematical foundations were laid in the 17th century with the development of the probability theory by Gerolamo Cardano, Blaise Pascal and Pierre de Fermat. Mathematical probability theory arose from the study of games of chance, although the concept of probability was already examined in medieval law and by philosophers such as Juan Caramuel.[36] The method of least squares was first described by  Adrien-Marie Legendre in 1805.\nSome scholars pinpoint the origin of statistics to 1663, with the publication of Natural and Political Observations upon the Bills of Mortality by John Graunt.[35] Early applications of statistical thinking revolved around the needs of states to base policy on demographic and economic data, hence its stat- etymology. The scope of the discipline of statistics broadened in the early 19th century to include the collection and analysis of data in general. Today, statistics is widely employed in government, business, and natural and social sciences.\nThe concept of correlation is particularly noteworthy for the potential confusion it can cause. Statistical analysis of a data set often reveals that two variables (properties) of the population under consideration tend to vary together, as if they were connected. For example, a study of annual income that also looks at age of death might find that poor people tend to have shorter lives than affluent people. The two variables are said to be correlated; however, they may or may not be the cause of one another. The correlation phenomena could be caused by a third, previously unconsidered phenomenon, called a lurking variable or confounding variable. For this reason, there is no way to immediately infer the existence of a causal relationship between the two variables. (See Correlation does not imply causation.)\nTo assist in the understanding of statistics Huff proposed a series of questions to be asked in each case:[34]\nWays to avoid misuse of statistics include using proper diagrams and avoiding bias.[30] Misuse can occur when conclusions are overgeneralized and claimed to be representative of more than they really are, often by either deliberately or unconsciously overlooking sampling bias.[31] Bar graphs are arguably the easiest diagrams to use and understand, and they can be made either by hand or with simple computer programs.[30] Unfortunately, most people do not look for bias or errors, so they are not noticed. Thus, people may often believe that something is true even if it is not well represented.[31] To make data gathered from statistics believable and accurate, the sample taken must be representative of the whole.[32]  According to Huff, \"The dependability of a sample can be destroyed by [bias]... allow yourself some degree of skepticism.\"[33]\nThere is a general perception that statistical knowledge is all-too-frequently intentionally misused by finding ways to interpret only the data that are favorable to the presenter.[28] A  mistrust and misunderstanding of statistics is associated with the quotation, \"There are three kinds of lies: lies, damned lies, and statistics\". Misuse of statistics can be both inadvertent and intentional, and the book How to Lie with Statistics[28] outlines a range of considerations. In an attempt to shed light on the use and misuse of statistics, reviews of statistical techniques used in particular fields are conducted (e.g. Warne, Lazo, Ramos, and Ritter (2012)).[29]\nEven when statistical techniques are correctly applied, the results can be difficult to interpret for those lacking expertise. The statistical significance of a trend in the data\u2014which measures the extent to which a trend could be caused by random variation in the sample\u2014may or may not agree with an intuitive sense of its significance. The set of basic statistical skills (and skepticism) that people need to deal with information in their everyday lives properly is referred to as statistical literacy.\nMisuse of statistics can produce subtle, but serious errors in description and interpretation\u2014subtle in the sense that even experienced professionals make such errors, and serious in the sense that they can lead to devastating decision errors. For instance, social policy, medical practice, and the reliability of structures like bridges all rely on the proper use of statistics.\nSome well-known statistical tests and procedures are:\nSome problems are usually associated with this framework (See criticism of hypothesis testing):\nAlthough in principle the acceptable level of statistical significance may be subject to debate, the p-value is the smallest significance level that allows the test to reject the null hypothesis. This test is logically equivalent to saying that the p-value is the probability, assuming the null hypothesis is true, of observing a result at least as extreme as the test statistic. Therefore, the smaller the p-value, the lower the probability of committing type I error.\nReferring to statistical significance does not necessarily mean that the overall result is significant in real world terms. For example, in a large study of a drug it may be shown that the drug has a statistically significant but very small beneficial effect, such that the drug is unlikely to help the patient noticeably.\nThe standard approach[23] is to test a null hypothesis against an alternative hypothesis. A critical region is the set of values of the estimator that leads to refuting the null hypothesis. The probability of type I error is therefore the probability that the estimator belongs to the critical region given that null hypothesis is true (statistical significance) and the probability of type II error is the probability that the estimator doesn't belong to the critical region given that the alternative hypothesis is true. The statistical power of a test is the probability that it correctly rejects the null hypothesis when the null hypothesis is false.\nStatistics rarely give a simple Yes/No type answer to the question under analysis. Interpretation often comes down to the level of statistical significance applied to the numbers and often refers to the probability of a value accurately rejecting the null hypothesis (sometimes referred to as the p-value).\nIn principle confidence intervals can be symmetrical or asymmetrical. An interval can be asymmetrical because it works as lower or upper bound for a parameter (left-sided interval or right sided interval), but it can also be asymmetrical because the two sided interval is built violating symmetry around the estimate. Sometimes the bounds for a confidence interval are reached asymptotically and these are used to approximate the true bounds.\nMost studies only sample part of a population, so results don't fully represent the whole population. Any estimates obtained from the sample only approximate the population value. Confidence intervals allow statisticians to express how closely the sample estimate matches the true value in the whole population. Often they are expressed as 95% confidence intervals. Formally, a 95% confidence interval for a value is a range where, if the sampling and analysis were repeated under the same conditions (yielding a different dataset), the interval would include the true (population) value in 95% of all possible cases. This does not imply that the probability that the true value is in the confidence interval is 95%. From the frequentist perspective, such a claim does not even make sense, as the true value is not a random variable.  Either the true value is or is not within the given interval. However, it is true that, before any data are sampled and given a plan for how to construct the confidence interval, the probability is 95% that the yet-to-be-calculated interval will cover the true value: at this point, the limits of the interval are yet-to-be-observed random variables. One approach that does yield an interval that can be interpreted as having a given probability of containing the true value is to use a credible interval from Bayesian statistics: this approach depends on a different way of interpreting what is meant by \"probability\", that is as a Bayesian probability.\nMeasurement processes that generate statistical data are also subject to error.  Many of these errors are classified as random (noise) or systematic (bias), but other types of errors (e.g., blunder, such as when an analyst reports incorrect units) can also be important. The presence of missing data or censoring may result in biased estimates and specific techniques have been developed to address these problems.[26]\nMany statistical methods seek to minimize the residual sum of squares, and these are called \"methods of least squares\" in contrast to Least absolute deviations. The latter gives equal weight to small and big errors, while the former gives more weight to large errors. Residual sum of squares is also differentiable, which provides a handy property for doing regression. Least squares applied to linear regression is called ordinary least squares method and least squares applied to nonlinear regression is called non-linear least squares. Also in a linear regression model the non deterministic part of the model is called error term, disturbance or more simply noise. Both linear regression and non-linear regression are addressed in polynomial least squares, which also describes the variance in a prediction of the dependent variable (y axis) as a function of the independent variable (x axis) and the deviations (errors, noise, disturbances) from the estimated (fitted) curve.\nMean squared error is used for obtaining efficient estimators, a widely used class of estimators. Root mean square error is simply the square root of mean squared error.\nA statistical error is the amount by which an observation differs from its expected value, a residual is the amount an observation differs from the value the estimator of the expected value assumes on a given sample (also called prediction).\nStandard deviation refers to the extent to which individual observations in a sample differ from a central value, such as the sample or population mean, while Standard error refers to an estimate of difference between sample mean and population mean.\nWorking from a null hypothesis, two basic forms of error are recognized:\nWhat statisticians call an alternative hypothesis is simply a hypothesis that contradicts the null hypothesis.\nThe best illustration for a novice is the predicament encountered by a criminal trial. The null hypothesis, H0, asserts that the defendant is innocent, whereas the alternative hypothesis, H1, asserts that the defendant is guilty. The indictment comes because of suspicion of the guilt. The H0 (status quo) stands in opposition to H1 and is maintained unless H1 is supported by evidence \"beyond a reasonable doubt\". However, \"failure to reject H0\" in this case does not imply innocence, but merely that the evidence was insufficient to convict. So the jury does not necessarily accept H0 but fails to reject H0. While one can not \"prove\" a null hypothesis, one can test how close it is to being true with a power test, which tests for type II errors.\nInterpretation of statistical information can often involve the development of a null hypothesis which is usually (but not necessarily) that no relationship exists among variables or that no change occurred over time.[24][25]\nThis still leaves the question of how to obtain estimators in a given situation and carry the computation, several methods have been proposed: the method of moments, the maximum likelihood method, the least squares method and the more recent method of estimating equations.\nOther desirable properties for estimators include: UMVUE estimators that have the lowest variance for all possible values of the parameter to be estimated (this is usually an easier property to verify than efficiency) and consistent estimators which converges in probability to the true value of such parameter.\nBetween two estimators of a given parameter, the one with lower mean squared error is said to be more efficient. Furthermore, an estimator is said to be unbiased if its expected value is equal to the true value of the unknown parameter being estimated, and asymptotically unbiased if its expected value converges at the limit to the true value of such parameter.\nA random variable that is a function of the random sample and of the unknown parameter, but whose probability distribution does not depend on the unknown parameter is called a pivotal quantity or pivot. Widely used pivots include the z-score, the chi square statistic and Student's t-value.\nConsider now a function of the unknown parameter: an estimator is a statistic used to estimate such function. Commonly used estimators include sample mean, unbiased sample variance and sample covariance.\nA statistic is a random variable that is a function of the random sample, but not a function of unknown parameters. The probability distribution of the statistic, though, may have unknown parameters.\nConsider independent identically distributed (IID) random variables with a given probability distribution: standard statistical inference and estimation theory defines a random sample as the random vector given by the column vector of these IID variables.[23] The population being examined is described by a probability distribution that may have unknown parameters.\nThe issue of whether or not it is appropriate to apply different kinds of statistical methods to data obtained from different kinds of measurement procedures is complicated by issues concerning the transformation of variables and the precise interpretation of research questions. \"The relationship between the data and what they describe merely reflects the fact that certain kinds of statistical statements may have truth values which are not invariant under some transformations. Whether or not a transformation is sensible to contemplate depends on the question one is trying to answer\" (Hand, 2004, p.\u00a082).[22]\nOther categorizations have been proposed. For example, Mosteller and Tukey (1977)[18] distinguished grades, ranks, counted fractions, counts, amounts, and balances. Nelder (1990)[19] described continuous counts, continuous ratios, count ratios, and categorical modes of data. See also Chrisman (1998),[20] van den Berg (1991).[21]\nBecause variables conforming only to nominal or ordinal measurements cannot be reasonably measured numerically, sometimes they are grouped together as categorical variables, whereas ratio and interval measurements are grouped together as quantitative variables, which can be either discrete or continuous, due to their numerical nature. Such distinctions can often be loosely correlated with data type in computer science, in that dichotomous categorical variables may be represented with the Boolean data type, polytomous categorical variables with arbitrarily assigned integers in the integral data type, and continuous variables with the real data type involving floating point computation. But the mapping of computer science data types to statistical data types depends on which categorization of the latter is being implemented.\nVarious attempts have been made to produce a taxonomy of levels of measurement. The psychophysicist Stanley Smith Stevens defined nominal, ordinal, interval, and ratio scales. Nominal measurements do not have meaningful rank order among values, and permit any one-to-one transformation. Ordinal measurements have imprecise differences between consecutive values, but have a meaningful order to those values, and permit any order-preserving transformation. Interval measurements have meaningful distances between measurements defined, but the zero value is arbitrary (as in the case with longitude and temperature measurements in Celsius or Fahrenheit), and permit any linear transformation. Ratio measurements have both a meaningful zero value and the distances between different measurements defined, and permit any rescaling transformation.\nAn example of an observational study is one that explores the association between smoking and lung cancer. This type of study typically uses a survey to collect observations about the area of interest and then performs statistical analysis. In this case, the researchers would collect observations of both smokers and non-smokers, perhaps through a cohort study, and then look for the number of cases of lung cancer in each group.[17] A case-control study is another type of observational study in which people with and without the outcome of interest (e.g. lung cancer) are invited to participate and their exposure histories are collected.\nExperiments on human behavior have special concerns. The famous Hawthorne study examined changes to the working environment at the Hawthorne plant of the Western Electric Company. The researchers were interested in determining whether increased illumination would increase the productivity of the assembly line workers. The researchers first measured the productivity in the plant, then modified the illumination in an area of the plant and checked if the changes in illumination affected productivity. It turned out that productivity indeed improved (under the experimental conditions). However, the study is heavily criticized today for errors in experimental procedures, specifically for the lack of a control group and blindness. The Hawthorne effect refers to finding that an outcome (in this case, worker productivity) changed due to observation itself. Those in the Hawthorne study became more productive not because the lighting was changed but because they were being observed.[16]\nThe basic steps of a statistical experiment are:\nA common goal for a statistical research project is to investigate causality, and in particular to draw a conclusion on the effect of changes in the values of predictors or independent variables on dependent variables. There are two major types of causal statistical studies: experimental studies and observational studies. In both types of studies, the effect of differences of an independent variable (or variables) on the behavior of the dependent variable are observed. The difference between the two types lies in how the study is actually conducted. Each can be very effective.\nAn experimental study involves taking measurements of the system under study, manipulating the system, and then taking additional measurements using the same procedure to determine if the manipulation has modified the values of the measurements. In contrast, an observational study does not involve experimental manipulation. Instead, data are gathered and correlations between predictors and response are investigated.\nWhile the tools of data analysis work best on data from randomized studies, they are also applied to other kinds of data\u2014like natural experiments and observational studies[15]\u2014for which a statistician would use a modified, more structured estimation method (e.g., Difference in differences estimation and instrumental variables, among many others) that produce consistent estimators.\nSampling theory is part of the mathematical discipline of probability theory. Probability is used in mathematical statistics to study the sampling distributions of sample statistics and, more generally, the properties of statistical procedures. The use of any statistical method is valid when the system or population under consideration satisfies the assumptions of the method.\nThe difference in point of view between classic probability theory and sampling theory is, roughly, that probability theory starts from the given parameters of a total population to deduce probabilities that pertain to samples. Statistical inference, however, moves in the opposite direction\u2014inductively inferring from samples to the parameters of a larger or total population.\nTo use a sample as a guide to an entire population, it is important that it truly represents the overall population. Representative sampling assures that inferences and conclusions can safely extend from the sample to the population as a whole. A major problem lies in determining the extent that the sample chosen is actually representative. Statistics offers methods to estimate and correct for any bias within the sample and data collection procedures. There are also methods of experimental design for experiments that can lessen these issues at the outset of a study, strengthening its capability to discern truths about the population.\nWhen full census data cannot be collected, statisticians collect sample data by developing specific experiment designs and survey samples. Statistics itself also provides tools for prediction and forecasting through statistical models. The idea of making inferences based on sampled data began around the mid-1600s in connection with estimating populations and developing precursors of life insurance.[14]\nWhen a census is not feasible, a chosen subset of the population called a sample is studied. Once a sample that is representative of the population is determined, data is collected for the sample members in an observational or experimental setting. Again, descriptive statistics can be used to summarize the sample data. However, the drawing of the sample has been subject to an element of randomness, hence the established numerical descriptors from the sample are also due to uncertainty. To still draw meaningful conclusions about the entire population, inferential statistics is needed. It uses patterns in the sample data to draw inferences about the population represented, accounting for randomness. These inferences may take the form of: answering yes/no questions about the data (hypothesis testing), estimating numerical characteristics of the data (estimation), describing associations within the data (correlation) and modeling relationships within the data (for example, using regression analysis).  Inference can extend to forecasting, prediction and estimation of unobserved values either in or associated with the population being studied; it can include extrapolation and interpolation of time series or spatial data, and can also include data mining.\nIdeally, statisticians compile data about the entire population (an operation called census). This may be organized by governmental statistical institutes. Descriptive statistics can be used to summarize the population data. Numerical descriptors include mean and standard deviation for continuous data types (like income), while frequency and percentage are more useful in terms of describing categorical data (like race).\nIn applying statistics to a problem, it is common practice to start with a population or process to be studied. Populations can be diverse topics such as \"all persons living in a country\" or \"every atom composing a crystal\".\nMathematical statistics is the application of mathematics to statistics. Mathematical techniques used for this include mathematical analysis, linear algebra, stochastic analysis, differential equations, and measure-theoretic probability theory.[12][13]\nStatistics is a mathematical body of science that pertains to the collection, analysis, interpretation or explanation, and presentation of data,[8] or as a branch of mathematics.[9] Some consider statistics to be a distinct mathematical science rather than a branch of mathematics. While many scientific investigations make use of data, statistics is concerned with the use of data in the context of uncertainty and decision making in the face of uncertainty.[10][11]\nSome definitions are:\nStatistics can be said to have begun in ancient civilization, going back at least to the 5th century BC, but it was not until the 18th century that it started to draw more heavily from calculus and probability theory. In more recent years statistics has relied more on statistical software to produce tests such as descriptive analysis.[5]\nMeasurement processes that generate statistical data are also subject to error. Many of these errors are classified as random (noise) or systematic (bias), but other types of errors (e.g., blunder, such as when an analyst reports incorrect units) can also be important. The presence of missing data or censoring may result in biased estimates and specific techniques have been developed to address these problems.\nA standard statistical procedure involves the test of the relationship between two statistical data sets, or a data set and synthetic data drawn from an idealized model. A hypothesis is proposed for the statistical relationship between the two data sets, and this is compared as an alternative to an idealized null hypothesis of no relationship between two data sets. Rejecting or disproving the null hypothesis is done using statistical tests that quantify the sense in which the null can be proven false, given the data that are used in the test. Working from a null hypothesis, two basic forms of error are recognized: Type I errors (null hypothesis is falsely rejected giving a \"false positive\") and Type II errors (null hypothesis fails to be rejected and an actual difference between populations is missed giving a \"false negative\").[4] Multiple problems have come to be associated with this framework: ranging from obtaining a sufficient sample size to specifying an adequate null hypothesis.[citation needed]\nTwo main statistical methods are used in data analysis: descriptive statistics, which summarize data from a sample using indexes such as the mean or standard deviation, and inferential statistics, which draw conclusions from data that are subject to random variation (e.g., observational errors, sampling variation).[3] Descriptive statistics are most often concerned with two sets of properties of a distribution (sample or population): central tendency (or location) seeks to characterize the distribution's central or typical value, while dispersion (or variability) characterizes the extent to which members of the distribution depart from its center and each other. Inferences on mathematical statistics are made under the framework of probability theory, which deals with the analysis of random phenomena.\nWhen census data cannot be collected, statisticians collect data by developing specific experiment designs and survey samples. Representative sampling assures that inferences and conclusions can reasonably extend from the sample to the population as a whole. An experimental study involves taking measurements of the system under study, manipulating the system, and then taking additional measurements using the same procedure to determine if the manipulation has modified the values of the measurements. In contrast, an observational study does not involve experimental manipulation.\nStatistics is a branch of mathematics dealing with the collection, organization, analysis, interpretation and presentation of data.[1][2] In applying statistics to, for example, a scientific, industrial, or social problem, it is conventional to begin with a statistical population or a statistical model process to be studied. Populations can be diverse topics such as \"all people living in a country\" or \"every atom composing a crystal\". Statistics deals with all aspects of data including the planning of data collection in terms of the design of surveys and experiments.[1]\nSee glossary of probability and statistics.\n",
            "title": "Statistics",
            "url": "https://en.wikipedia.org/wiki/Statistics"
        },
        {
            "desc_links": [
                "/wiki/Dimension_(disambiguation)",
                "/wiki/Trade_study",
                "/wiki/Multivariate_statistics",
                "/wiki/Statistics",
                "/wiki/Response_surface_methodology",
                "/wiki/Monte_Carlo_simulation",
                "/wiki/Surrogate_model"
            ],
            "desc_text": "b'Multivariate analysis (MVA) is based on the statistical principle of multivariate statistics, which involves observation and analysis of more than one statistical outcome variable at a time. In design and analysis, the technique is used to perform trade studies across multiple dimensions while taking into account the effects of all variables on the responses of interest.\\n'b'Uses for multivariate analysis include:\\n'b'Multivariate analysis can be complicated by the desire to include physics-based analysis to calculate the effects of variables for a hierarchical \"system-of-systems\". Often, studies that wish to use multivariate analysis are stalled by the dimensionality of the problem. These concerns are often eased through the use of surrogate models, highly accurate approximations of the physics-based code. Since surrogate models take the form of an equation, they can be evaluated very quickly. This becomes an enabler for large-scale MVA studies: while a Monte Carlo simulation across the design space is difficult with physics-based codes, it becomes trivial when evaluating surrogate models, which often take the form of response-surface equations.\\n'",
            "links": [
                "/wiki/Dimension_(disambiguation)",
                "/wiki/Trade_study",
                "/wiki/Multivariate_statistics",
                "/wiki/Statistics",
                "/wiki/Response_surface_methodology",
                "/wiki/Monte_Carlo_simulation",
                "/wiki/Surrogate_model",
                "/wiki/Charles_Spearman",
                "/wiki/General_linear_model",
                "/wiki/Monotonicity",
                "/wiki/Bias_of_an_estimator",
                "/wiki/Admissible_decision_rule",
                "/wiki/Statistical_power",
                "/wiki/Likelihood_ratio_test",
                "/wiki/Hypothesis_testing"
            ],
            "text": "Anderson's 1958 textbook, An Introduction to Multivariate Statistical Analysis, educated a generation of theorists and applied  statisticians; Anderson's book emphasizes hypothesis testing via likelihood ratio tests and the properties of power functions: Admissibility, unbiasedness and monotonicity.[2][3]\nFactor analysis is part of the general linear model (GLM) family of procedures and makes many of the same assumptions as multiple regression, but it uses multiple outcomes.\nApplications:\nOverview:\nFactor analysis is used to uncover the latent structure (dimensions) of a set of variables. It reduces attribute space from a larger number of variables to a smaller number of factors. Factor analysis originated in the 20th century with Charles Spearman's attempts to show that a wide variety of mental tests could be explained by a single, underlying intelligence factor.\nMultivariate analysis can be complicated by the desire to include physics-based analysis to calculate the effects of variables for a hierarchical \"system-of-systems\". Often, studies that wish to use multivariate analysis are stalled by the dimensionality of the problem. These concerns are often eased through the use of surrogate models, highly accurate approximations of the physics-based code. Since surrogate models take the form of an equation, they can be evaluated very quickly. This becomes an enabler for large-scale MVA studies: while a Monte Carlo simulation across the design space is difficult with physics-based codes, it becomes trivial when evaluating surrogate models, which often take the form of response-surface equations.\nUses for multivariate analysis include:\nMultivariate analysis (MVA) is based on the statistical principle of multivariate statistics, which involves observation and analysis of more than one statistical outcome variable at a time. In design and analysis, the technique is used to perform trade studies across multiple dimensions while taking into account the effects of all variables on the responses of interest.\n",
            "title": "Multivariate analysis",
            "url": "https://en.wikipedia.org/wiki/Multivariate_analysis"
        },
        {
            "desc_links": [
                "/wiki/Probability_distribution",
                "/wiki/Probability_space",
                "/wiki/Random_variable",
                "/wiki/Conditional_probability_distribution",
                "/wiki/Marginal_density",
                "/wiki/Discrete_probability_distribution",
                "/wiki/Probability_mass_function",
                "/wiki/Continuous_variable",
                "/wiki/Probability_density_function",
                "/wiki/Cumulative_distribution_function"
            ],
            "desc_text": "b'Given random variables X, Y, ..., that are defined on a probability space, the joint probability distribution for X, Y, ... is a probability distribution that gives the probability that each of X, Y, ... falls in any particular range or discrete set of values specified for that variable. In the case of only two random variables, this is called a bivariate distribution, but the concept generalizes to any number of random variables, giving a multivariate distribution.\\n'b'The joint probability distribution can be expressed either in terms of a joint cumulative distribution function or in terms of a joint probability density function (in the case of continuous variables) or joint probability mass function (in the case of discrete variables). These in turn can be used to find two other types of distributions: the marginal distribution giving the probabilities for any one of the variables with no reference to any specific ranges of values for the other variables, and the conditional probability distribution giving the probabilities for any subset of the variables conditional on particular values of the remaining variables.\\n'",
            "links": [
                "/wiki/Probability_distribution",
                "/wiki/Probability_space",
                "/wiki/Random_variable",
                "/wiki/Conditional_probability_distribution",
                "/wiki/Marginal_density",
                "/wiki/Discrete_probability_distribution",
                "/wiki/Probability_mass_function",
                "/wiki/Continuous_variable",
                "/wiki/Probability_density_function",
                "/wiki/Cumulative_distribution_function",
                "/wiki/Marginal_probability_distribution",
                "/wiki/Bernoulli_distribution",
                "/wiki/Bernoulli_trial",
                "/wiki/Fair_coin",
                "/wiki/Volume",
                "/wiki/Statistics",
                "/wiki/Multivariate_normal_distribution",
                "/wiki/Chain_rule_(probability)",
                "/wiki/Continuous_random_variable",
                "/wiki/Probability_density_function",
                "/wiki/Marginal_distribution",
                "/wiki/Conditional_distribution",
                "/wiki/Support_(measure_theory)",
                "/wiki/Product_measure",
                "/wiki/Logistic_regression",
                "/wiki/Elliptical_distribution",
                "/wiki/Multivariate_hypergeometric_distribution",
                "/wiki/Negative_multinomial_distribution",
                "/wiki/Multinomial_distribution",
                "/wiki/Multivariate_stable_distribution",
                "/wiki/Multivariate_normal_distribution"
            ],
            "text": "Named joint distributions that arise frequently in statistics include the multivariate normal distribution, the multivariate stable distribution, the multinomial distribution, the negative multinomial distribution, the multivariate hypergeometric distribution, and the elliptical distribution.\nfor all x and y. This means that acquiring any information about the value of one or more of the random variables leads to a conditional distribution of any other variable that is identical to its unconditional (marginal) distribution; thus no variable provides any information about any other variable.\nSimilarly, two absolutely continuous random variables are independent if\nfor all x and y.\nThe definition generalizes to a mixture of arbitrary numbers of discrete and continuous random variables.\nOne example of a situation in which one may wish to find the cumulative distribution of one random variable which is continuous and another random variable which is discrete arises when one wishes to use a logistic regression in predicting the probability of a binary outcome Y conditional on the value of a continuously distributed outcome X. One must use the \"mixed\" joint density when finding the cumulative distribution of this binary outcome because the input variables (X, Y) were initially defined in such a way that one could not collectively assign it either a probability density function or a probability mass function.  Formally, fX,Y(x, y) is the probability density function of (X, Y) with respect to the product measure on the respective supports of X and Y. Either of these two decompositions can then be used to recover the joint cumulative distribution function:\nThe \"mixed joint density\" may be defined where one or more random variables are continuous and the other random variables are discrete, or vice versa. With one variable of each type we have\nAgain, since these are probability distributions, one has\nwhere fY|X(y|x) and fX|Y(x|y) are the conditional distributions of Y given X\u00a0=\u00a0x and of X given Y\u00a0=\u00a0y respectively, and fX(x) and fY(y) are the marginal distributions for X and Y respectively.\nThe joint probability density function fX,Y(x,\u00a0y) for two continuous random variables is equal to:\nSince these are probabilities, we have in the two-variable case\nThis identity is known as the chain rule of probability.\nThe multivariate normal distribution, which is a continuous distribution,  is the most commonly encountered distribution in statistics. When there are specifically two random variables, this is the bivariate normal distribution, shown in the graph, with the possible values of the two variables plotted in two of the dimensions and the value of the density function for any pair of such values plotted in the third dimension. The probability that the two variables together fall in any region of their two dimensions is given by the volume under the density function above that region.\nThese probabilities necessarily sum to 1, since the probability of some combination of A and B occurring is 1.\nThen, the joint distribution of A and B, expressed as a probability mass function, is\nConsider the roll of a fair die and let A = 1 if the number is even (i.e. 2, 4, or 6) and A = 0 otherwise. Furthermore, let B = 1 if the number is prime (i.e. 2, 3, or 5) and B = 0 otherwise.\nSince the coin flips are independent, the joint probability density function is the product\nof the marginals:\nSince each outcome is equally likely the joint probability density function becomes\nThe joint probability density function of A and B defines probabilities for each pair of outcomes. All possible outcomes are\nConsider the flip of two fair coins; let A and B be discrete random variables associated with the outcomes of the first and second coin flips respectively. Each coin flip is a Bernoulli trial and has a Bernoulli distribution. If a coin displays \"heads\" then the associated random variable takes the value 1, and it takes the value 0 otherwise. The probability of each of these outcomes is 1/2, so the marginal (unconditional) density functions are\nMoreover, the final row and the final column give the marginal probability distribution for A and the marginal probability distribution for B respectively. For example, for A the first of these cells gives the sum of the probabilities for A being red, regardless of which possibility for B in the column above the cell occurs, as 2/3. Thus the marginal probability distribution for A gives A's probabilities unconditional on B, in a margin of the table.\nEach of the four inner cells shows the probability of a particular combination of results from the two draws; these probabilities are the joint distribution. In any one cell the probability of a particular combination occurring is (since the draws are independent) the product of the probability of the specified result for A and the probability of the specified result for B. The probabilities in these four cells sum to 1, as is always true for probability distributions.\nSuppose each of  two urns contains twice as many red balls as blue balls, and no others, and suppose one ball is randomly selected from each urn, with the two draws independent of each other. Let A and B be discrete random variables associated with the outcomes of the draw from the first urn and second urn respectively. The probability of drawing a red ball from either of the urns is 2/3, and the probability of drawing a blue ball is 1/3. We can present the joint probability distribution as the following table:\nThe joint probability distribution can be expressed either in terms of a joint cumulative distribution function or in terms of a joint probability density function (in the case of continuous variables) or joint probability mass function (in the case of discrete variables). These in turn can be used to find two other types of distributions: the marginal distribution giving the probabilities for any one of the variables with no reference to any specific ranges of values for the other variables, and the conditional probability distribution giving the probabilities for any subset of the variables conditional on particular values of the remaining variables.\nGiven random variables X, Y, ..., that are defined on a probability space, the joint probability distribution for X, Y, ... is a probability distribution that gives the probability that each of X, Y, ... falls in any particular range or discrete set of values specified for that variable. In the case of only two random variables, this is called a bivariate distribution, but the concept generalizes to any number of random variables, giving a multivariate distribution.\n",
            "title": "Joint probability distribution",
            "url": "https://en.wikipedia.org/wiki/Joint_probability_distribution"
        },
        {
            "desc_links": [
                "/wiki/Marginal_distribution",
                "/wiki/Conditional_probability_table",
                "/wiki/Categorical_variable",
                "/wiki/Probability_distribution",
                "/wiki/Random_variable",
                "/wiki/Joint_probability_distribution",
                "/wiki/Statistics",
                "/wiki/Probability_theory",
                "/wiki/Conditional_variance",
                "/wiki/Conditional_mean",
                "/wiki/Moment_(mathematics)",
                "/wiki/Probability_density_function",
                "/wiki/Continuous_distribution",
                "/wiki/Joint_distribution"
            ],
            "desc_text": "b'In probability theory and statistics, given two jointly distributed random variables X and Y, the conditional probability distribution of Y given X is the probability distribution of Y when X is known to be a particular value; in some cases the conditional probabilities may be expressed as functions containing the unspecified value x of X as a parameter. When both \"X\" and \"Y\" are categorical variables, a conditional probability table is typically used to represent the conditional probability. The conditional distribution contrasts with the marginal distribution of a random variable, which is its distribution without reference to the value of the other variable.\\n'b'If the conditional distribution of Y given X is a continuous distribution, then its probability density function is known as the conditional density function. The properties of a conditional distribution, such as the moments, are often referred to by corresponding names such as the conditional mean and conditional variance.\\n'b'More generally, one can refer to the conditional distribution of a subset of a set of more than two variables; this conditional distribution is contingent on the values of all the remaining variables, and if more than one variable is included in the subset then this conditional distribution is the conditional joint distribution of the included variables.\\n'",
            "links": [
                "/wiki/Marginal_distribution",
                "/wiki/Conditional_probability_table",
                "/wiki/Categorical_variable",
                "/wiki/Probability_distribution",
                "/wiki/Random_variable",
                "/wiki/Joint_probability_distribution",
                "/wiki/Statistics",
                "/wiki/Probability_theory",
                "/wiki/Conditional_variance",
                "/wiki/Conditional_mean",
                "/wiki/Moment_(mathematics)",
                "/wiki/Probability_density_function",
                "/wiki/Continuous_distribution",
                "/wiki/Joint_distribution",
                "/wiki/Conditional_probability",
                "/wiki/Discrete_random_variable",
                "/wiki/Dice",
                "/wiki/Probability_density_function",
                "/wiki/Continuous_random_variable",
                "/wiki/Borel%27s_paradox",
                "/wiki/Plane_(geometry)",
                "/wiki/Bivariate_normal_distribution",
                "/wiki/Joint_density_function",
                "/wiki/Statistical_independence",
                "/wiki/Likelihood_function"
            ],
            "text": "which is a random variable. Note that the expectation of this random variable is equal to the probability of A itself:\nalmost surely.\nSeen as a function of y for given x, P(Y = y | X = x) is a probability and so the sum over all y (or integral if it is a conditional probability density) is 1.  Seen as a function of x for given y, it is a likelihood function, so that the sum over all x need not be 1.\nRandom variables X, Y are independent if and only if the conditional distribution of Y given X is, for all possible realizations of X, equal to the unconditional distribution of Y. For discrete random variables this means P(Y = y | X = x) = P(Y = y) for all possible x and y. For continuous random variables X and Y, having a joint density function, it means fY(y | X = x) = fY(y) for all possible x and y.\nThe graph shows a bivariate normal joint density for random variables X and Y. To see the distribution of Y conditional on X = 70, one can first visualize the line X = 70 in the X, Y plane, and then visualize the plane containing that line and perpendicular to the X, Y plane. The intersection of that plane with the joint normal density, once rescaled to give unit area under the intersection, is the relevant conditional density of Y.\nThe concept of the conditional distribution of a continuous random variable is not as intuitive as it might seem: Borel's paradox shows that conditional probability density functions need not be invariant under coordinate transformations.\nThe relation with the probability distribution of X given Y is given by:\nSimilarly for continuous random variables, the conditional probability density function of Y given the occurrence of the value x of X can be written as\nThen the unconditional probability that A = 1 is 3/6 = 1/2 (since there are six possible rolls of the die, of which three are even), whereas the probability that A = 1 conditional on B = 1 is 1/3 (since there are three possible prime number rolls\u20142, 3, and 5\u2014of which one is even).\nConsider the roll of a fair die and let A = 1 if the number is even (i.e. 2, 4, or 6) and A = 0 otherwise. Furthermore, let B = 1 if the number is prime (i.e. 2, 3, or 5) and B = 0 otherwise.\nThe relation with the probability distribution of X given Y is:\nFor discrete random variables, the conditional probability mass function of Y given the occurrence of the value x of X can be written according to its definition as:\nMore generally, one can refer to the conditional distribution of a subset of a set of more than two variables; this conditional distribution is contingent on the values of all the remaining variables, and if more than one variable is included in the subset then this conditional distribution is the conditional joint distribution of the included variables.\nIf the conditional distribution of Y given X is a continuous distribution, then its probability density function is known as the conditional density function. The properties of a conditional distribution, such as the moments, are often referred to by corresponding names such as the conditional mean and conditional variance.\nIn probability theory and statistics, given two jointly distributed random variables X and Y, the conditional probability distribution of Y given X is the probability distribution of Y when X is known to be a particular value; in some cases the conditional probabilities may be expressed as functions containing the unspecified value x of X as a parameter. When both \"X\" and \"Y\" are categorical variables, a conditional probability table is typically used to represent the conditional probability. The conditional distribution contrasts with the marginal distribution of a random variable, which is its distribution without reference to the value of the other variable.\n",
            "title": "Conditional probability distribution",
            "url": "https://en.wikipedia.org/wiki/Conditional_probability_distribution"
        },
        {
            "desc_links": [
                "/wiki/Independent_variable",
                "/wiki/Dependent_variable",
                "/wiki/Estimation_theory",
                "/wiki/Statistical_model",
                "/wiki/Necessity_and_sufficiency",
                "/wiki/Probability_distribution",
                "/wiki/Function_(mathematics)",
                "/wiki/Location_parameter",
                "/wiki/Quantile",
                "/wiki/Average_value",
                "/wiki/Conditional_expectation",
                "/wiki/Causality",
                "/wiki/Machine_learning",
                "/wiki/Forecasting",
                "/wiki/Prediction",
                "/wiki/Dimension",
                "/wiki/Function_(mathematics)",
                "/wiki/Nonparametric_regression",
                "/wiki/Data",
                "/wiki/Parameter",
                "/wiki/Parametric_statistics",
                "/wiki/Ordinary_least_squares",
                "/wiki/Linear_regression",
                "/wiki/Observational_study",
                "/wiki/Causality",
                "/wiki/Effect_size",
                "/wiki/Data_collection",
                "/wiki/Statistical_classification"
            ],
            "desc_text": "b\"In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or 'predictors'). More specifically, regression analysis helps one understand how the typical value of the dependent variable  (or 'criterion variable') changes when any one of the independent variables is varied, while the other independent variables are held fixed.\\n\"b'Most commonly, regression analysis estimates the conditional expectation of the dependent variable given the independent variables \\xe2\\x80\\x93 that is, the average value of the dependent variable when the independent variables are fixed. Less commonly, the focus is on a quantile, or other location parameter of the conditional distribution of the dependent variable given the independent variables. In all cases, a function of the independent variables called the regression function is to be estimated. In regression analysis, it is also of interest to characterize the variation of the dependent variable around the prediction of the  regression function using a probability distribution. A related but distinct approach is Necessary Condition Analysis[1] (NCA), which estimates the maximum (rather than average) value of the dependent variable for a given value of the independent variable (ceiling line rather than central line) in order to identify what value of the independent variable is necessary but not sufficient for a given value of the dependent variable.\\n'b'Regression analysis is widely used for prediction and forecasting, where its use has substantial overlap with the field of machine learning. Regression analysis is also used to understand which among the independent variables are related to the dependent variable, and to explore the forms of these relationships. In restricted circumstances, regression analysis can be used to infer causal relationships between the independent and dependent variables. However this can lead to illusions or false relationships, so caution is advisable. \\n'b'Many techniques for carrying out regression analysis have been developed. Familiar methods such as linear regression and ordinary least squares regression are parametric, in that the regression function is defined in terms of a finite number of unknown parameters that are estimated from the data. Nonparametric regression refers to techniques that allow the regression function to lie in a specified set of functions, which may be infinite-dimensional.\\n'b'The performance of regression analysis methods in practice depends on the form of the data generating process, and how it relates to the regression approach being used. Since the true form of the data-generating process is generally not known, regression analysis often depends to some extent on making assumptions about this process. These assumptions are sometimes testable if a sufficient quantity of data is available. Regression models for prediction are often useful even when the assumptions are moderately violated, although they may not perform optimally. However, in many applications, especially with small effects or questions of causality based on observational data, regression methods can give misleading results.[2][3]\\n'b'In a narrower sense, regression may refer specifically to the estimation of continuous response (dependent) variables, as opposed to the discrete response variables used in classification.[4] The case of a continuous dependent variable may be more specifically referred to as metric regression to distinguish it from related problems.[5]\\n'",
            "links": [
                "/wiki/Independent_variable",
                "/wiki/Dependent_variable",
                "/wiki/Estimation_theory",
                "/wiki/Statistical_model",
                "/wiki/Necessity_and_sufficiency",
                "/wiki/Probability_distribution",
                "/wiki/Function_(mathematics)",
                "/wiki/Location_parameter",
                "/wiki/Quantile",
                "/wiki/Average_value",
                "/wiki/Conditional_expectation",
                "/wiki/Causality",
                "/wiki/Machine_learning",
                "/wiki/Forecasting",
                "/wiki/Prediction",
                "/wiki/Dimension",
                "/wiki/Function_(mathematics)",
                "/wiki/Nonparametric_regression",
                "/wiki/Data",
                "/wiki/Parameter",
                "/wiki/Parametric_statistics",
                "/wiki/Ordinary_least_squares",
                "/wiki/Linear_regression",
                "/wiki/Observational_study",
                "/wiki/Causality",
                "/wiki/Effect_size",
                "/wiki/Data_collection",
                "/wiki/Statistical_classification",
                "/wiki/Gauss%E2%80%93Markov_theorem",
                "/wiki/Carl_Friedrich_Gauss",
                "/wiki/Adrien_Marie_Legendre",
                "/wiki/Method_of_least_squares",
                "/wiki/Conditional_distribution",
                "/wiki/Ronald_A._Fisher",
                "/wiki/Normal_distribution",
                "/wiki/Joint_distribution",
                "/wiki/Karl_Pearson",
                "/wiki/Udny_Yule",
                "/wiki/Regression_toward_the_mean",
                "/wiki/Francis_Galton",
                "/wiki/Bayesian_statistics",
                "/wiki/Nonparametric_regression",
                "/wiki/Growth_curve_(statistics)",
                "/wiki/Time_series",
                "/wiki/Robust_regression",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/List_of_fields_of_application_of_statistics",
                "/wiki/Statistical_assumption",
                "/wiki/Efficient_(statistics)",
                "/wiki/Consistent_estimator",
                "/wiki/Bias_of_an_estimator",
                "/wiki/Modifiable_areal_unit_problem",
                "/wiki/Standard_error_(statistics)",
                "/wiki/Population_parameter",
                "/wiki/Hypothesis_test",
                "/wiki/Confidence_interval",
                "/wiki/T-test",
                "/wiki/F-test",
                "/wiki/Errors_and_residuals_in_statistics",
                "/wiki/R-squared",
                "/wiki/Statistical_significance",
                "/wiki/Goodness_of_fit",
                "/wiki/Central_limit_theorem",
                "/wiki/F-test",
                "/wiki/T-test",
                "/wiki/Econometrics",
                "/wiki/Categorical_variable",
                "/wiki/Limited_dependent_variable",
                "/wiki/Negative_binomial",
                "/wiki/Poisson_regression",
                "/wiki/Polychoric_correlation",
                "/wiki/Heckman_correction",
                "/wiki/Censored_regression_model",
                "/wiki/Ordered_probit",
                "/wiki/Ordered_logit",
                "/wiki/Ordinal_variable",
                "/wiki/Multinomial_logit",
                "/wiki/Categorical_variable",
                "/wiki/Multivariate_probit",
                "/wiki/Logistic_regression",
                "/wiki/Probit_model",
                "/wiki/Linear_probability_model",
                "/wiki/Least_squares#Differences_between_linear_and_nonlinear_least_squares",
                "/wiki/Extrapolation",
                "/wiki/Interpolation",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Spreadsheet",
                "/wiki/Simple_linear_regression",
                "/wiki/Least_squares"
            ],
            "text": "All major statistical software packages perform least squares regression analysis and inference. Simple linear regression and multiple regression using least squares can be done in some spreadsheet applications and on some calculators. While many statistical software packages can perform various types of nonparametric and robust regression, these methods are less standardized; different software packages implement different methods, and a method with a given name may be implemented differently in different packages. Specialized regression software has been developed for use in fields such as survey analysis and neuroimaging.\nAlthough the parameters of a regression model are usually estimated using the method of least squares, other methods which have been used include:\nHowever, this does not cover the full set of modeling errors that may be made: in particular, the assumption of a particular form for the relation between Y and X. A properly conducted regression analysis will include an assessment of how well the assumed form is matched by the observed data, but it can only do so within the range of values of the independent variables actually available. This means that any extrapolation is particularly reliant on the assumptions being made about the structural form of the regression relationship. Best-practice advice here[citation needed] is that a linear-in-variables and linear-in-parameters relationship should not be chosen simply for computational convenience, but that all available knowledge should be deployed in constructing a regression model. If this knowledge includes the fact that the dependent variable cannot go outside a certain range of values, this can be made use of in selecting the model \u2013 even if the observed dataset has no values particularly near such bounds. The implications of this step of choosing an appropriate functional form for the regression can be great when extrapolation is considered. At a minimum, it can ensure that any extrapolation arising from a fitted model is \"realistic\" (or in accord with what is known).\nFor such reasons and others, some tend to say that it might be unwise to undertake extrapolation.[23]\nIt is generally advised[citation needed] that when performing extrapolation, one should accompany the estimated value of the dependent variable with a prediction interval that represents the uncertainty. Such intervals tend to expand rapidly as the values of the independent variable(s) moved outside the range covered by the observed data.\nRegression models predict a value of the Y variable given known values of the X variables. Prediction within the range of values in the dataset used for model-fitting is known informally as interpolation. Prediction outside this range of the data is known as extrapolation. Performing extrapolation relies strongly on the regression assumptions. The further the extrapolation goes outside the data, the more room there is for the model to fail due to differences between the assumptions and the sample data or the true values.\nWhen the model function is not linear in the parameters, the sum of squares must be minimized by an iterative procedure. This introduces many complications which are summarized in Differences between linear and non-linear least squares.\nThe response variable may be non-continuous (\"limited\" to lie on some subset of the real line). For binary (zero or one) variables, if analysis proceeds with least-squares linear regression, the model is called the linear probability model. Nonlinear models for binary dependent variables include the probit and logit model. The multivariate probit model is a standard method of estimating a joint relationship between several binary dependent variables and some independent variables. For categorical variables with more than two values there is the multinomial logit. For ordinal variables with more than two values, there are the ordered logit and ordered probit models. Censored regression models may be used when the dependent variable is only sometimes observed, and Heckman correction type models may be used when the sample is not randomly selected from the population of interest. An alternative to such procedures is linear regression based on polychoric correlation (or polyserial correlations) between the categorical variables. Such procedures differ in the assumptions made about the distribution of the variables in the population. If the variable is positive with low values and represents the repetition of the occurrence of an event, then count models like the Poisson regression or the negative binomial model may be used.\nLimited dependent variables, which are response variables that are categorical variables or are variables constrained to fall only in a certain range, often arise in econometrics.\nInterpretations of these diagnostic tests rest heavily on the model assumptions. Although examination of the residuals can be used to invalidate a model, the results of a t-test or F-test are sometimes more difficult to interpret if the model's assumptions are violated. For example, if the error term does not have a normal distribution, in small samples the estimated parameters will not follow normal distributions and complicate inference. With relatively large samples, however, a central limit theorem can be invoked such that hypothesis testing may proceed using asymptotic approximations.\nOnce a regression model has been constructed, it may be important to confirm the goodness of fit of the model and the statistical significance of the estimated parameters. Commonly used checks of goodness of fit include the R-squared, analyses of the pattern of residuals and hypothesis testing. Statistical significance can be checked by an F-test of the overall fit, followed by t-tests of individual parameters.\nIn matrix notation, the normal equations are written as\nThe normal equations are\nUnder the further assumption that the population error term is normally distributed, the researcher can use these estimated standard errors to create confidence intervals and conduct hypothesis tests about the population parameters.\nThe standard errors of the parameter estimates are given by\nUnder the assumption that the population error term has a constant variance, the estimate of that variance is given by:\nIn the case of simple regression, the formulas for the least squares estimates are\nReturning our attention to the straight line case: Given a random sample from the population, we estimate the population parameters and obtain the sample linear regression model:\nIn multiple linear regression, there are several independent variables or functions of independent variables.\nIndependent and dependent variables often refer to values measured at point locations. There may be spatial trends and spatial autocorrelation in the variables that violate statistical assumptions of regression. Geographic weighted regression is one technique to deal with such data.[19] Also, variables may include values aggregated by areas. With aggregated data the modifiable areal unit problem can cause extreme variation in regression parameters.[20] When analyzing data aggregated by political boundaries, postal codes or census areas results may be very distinct with a different choice of units.\nThese are sufficient conditions for the least-squares estimator to possess desirable properties; in particular, these assumptions imply that the parameter estimates will be unbiased, consistent, and efficient in the class of linear unbiased estimators. It is important to note that actual data rarely satisfies the assumptions. That is, the method is used even though the assumptions are not true. Variation from the assumptions can sometimes be used as a measure of how far the model is from being useful. Many of these assumptions may be relaxed in more advanced treatments. Reports of statistical analyses usually include analyses of tests on the sample data and methodology for the fit and usefulness of the model.\nClassical assumptions for regression analysis include:\nIn the last case, the regression analysis provides the tools for:\nIn various fields of application, different terminologies are used in place of dependent and independent variables.\nRegression models involve the following parameters and variables:\nRegression methods continue to be an area of active research. In recent decades, new methods have been developed for robust regression, regression involving correlated responses such as time series and growth curves, regression in which the predictor (independent variable) or response variables are curves, images, graphs, or other complex data objects, regression methods accommodating various types of missing data, nonparametric regression, Bayesian methods for regression, regression in which the predictor variables are measured with error, regression with more predictor variables than observations, and causal inference with regression.\nIn the 1950s and 1960s, economists used electromechanical desk \"calculators\" to calculate regressions. Before 1970, it sometimes took up to 24 hours to receive the result from one regression.[18]\nThe term \"regression\" was coined by Francis Galton in the nineteenth century to describe a biological phenomenon. The phenomenon was that the heights of descendants of tall ancestors tend to regress down towards a normal average (a phenomenon also known as regression toward the mean).[9][10]\nFor Galton, regression had only this biological meaning,[11][12] but his work was later extended by Udny Yule and Karl Pearson to a more general statistical context.[13][14] In the work of Yule and Pearson, the joint distribution of the response and explanatory variables is assumed to be Gaussian. This assumption was weakened by R.A. Fisher in his works of 1922 and 1925.[15][16][17] Fisher assumed that the conditional distribution of the response variable is Gaussian, but the joint distribution need not be. In this respect, Fisher's assumption is closer to Gauss's formulation of 1821.\nThe earliest form of regression was the method of least squares, which was published by Legendre in 1805,[6] and by Gauss in 1809.[7] Legendre and Gauss both applied the method to the problem of determining, from astronomical observations, the orbits of bodies about the Sun (mostly comets, but also later the then newly discovered minor planets). Gauss published a further development of the theory of least squares in 1821,[8] including a version of the Gauss\u2013Markov theorem.\nIn a narrower sense, regression may refer specifically to the estimation of continuous response (dependent) variables, as opposed to the discrete response variables used in classification.[4] The case of a continuous dependent variable may be more specifically referred to as metric regression to distinguish it from related problems.[5]\nThe performance of regression analysis methods in practice depends on the form of the data generating process, and how it relates to the regression approach being used. Since the true form of the data-generating process is generally not known, regression analysis often depends to some extent on making assumptions about this process. These assumptions are sometimes testable if a sufficient quantity of data is available. Regression models for prediction are often useful even when the assumptions are moderately violated, although they may not perform optimally. However, in many applications, especially with small effects or questions of causality based on observational data, regression methods can give misleading results.[2][3]\nMany techniques for carrying out regression analysis have been developed. Familiar methods such as linear regression and ordinary least squares regression are parametric, in that the regression function is defined in terms of a finite number of unknown parameters that are estimated from the data. Nonparametric regression refers to techniques that allow the regression function to lie in a specified set of functions, which may be infinite-dimensional.\nRegression analysis is widely used for prediction and forecasting, where its use has substantial overlap with the field of machine learning. Regression analysis is also used to understand which among the independent variables are related to the dependent variable, and to explore the forms of these relationships. In restricted circumstances, regression analysis can be used to infer causal relationships between the independent and dependent variables. However this can lead to illusions or false relationships, so caution is advisable. \nMost commonly, regression analysis estimates the conditional expectation of the dependent variable given the independent variables \u2013 that is, the average value of the dependent variable when the independent variables are fixed. Less commonly, the focus is on a quantile, or other location parameter of the conditional distribution of the dependent variable given the independent variables. In all cases, a function of the independent variables called the regression function is to be estimated. In regression analysis, it is also of interest to characterize the variation of the dependent variable around the prediction of the  regression function using a probability distribution. A related but distinct approach is Necessary Condition Analysis[1] (NCA), which estimates the maximum (rather than average) value of the dependent variable for a given value of the independent variable (ceiling line rather than central line) in order to identify what value of the independent variable is necessary but not sufficient for a given value of the dependent variable.\nIn statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or 'predictors'). More specifically, regression analysis helps one understand how the typical value of the dependent variable  (or 'criterion variable') changes when any one of the independent variables is varied, while the other independent variables are held fixed.\n",
            "title": "Regression analysis",
            "url": "https://en.wikipedia.org/wiki/Regression_analysis"
        },
        {
            "desc_links": [
                "/wiki/Quartiles",
                "/wiki/Probability_distribution",
                "/wiki/Cumulative_distribution_function",
                "/wiki/Inverse_function",
                "/wiki/Quantile_function",
                "/wiki/Random_variable",
                "/wiki/Cumulative_distribution_function",
                "/wiki/Rank_statistics",
                "/wiki/Median"
            ],
            "desc_text": "b'In statistics and probability quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities, or dividing the observations in a sample in the same way. There is one less quantile than the number of groups created. Thus quartiles are the three cut points that will divide a dataset into four equal-sized groups. Common quantiles have special names: for instance quartile, decile (creating 10 groups: see below for more).  The groups created are termed halves, thirds, quarters, etc., though sometimes the terms for the quantile are used for the groups created, rather than for the cut points.\\n'b'q-quantiles are values that partition a finite set of values into q subsets of (nearly) equal sizes.  There are q \\xe2\\x88\\x92 1 of the q-quantiles, one for each integer k satisfying 0 < k < q.  In some cases the value of a quantile may not be uniquely determined, as can be the case for the median (2-quantile) of a uniform probability distribution on a set of even size.  Quantiles can also be applied to continuous distributions, providing a way to generalize rank statistics to continuous variables.  When the cumulative distribution function of a random variable is known, the q-quantiles are the application of the quantile function (the inverse function of the cumulative distribution function) to the values {1/q, 2/q, \\xe2\\x80\\xa6, (q \\xe2\\x88\\x92 1)/q}.\\n'",
            "links": [
                "/wiki/Quartiles",
                "/wiki/Probability_distribution",
                "/wiki/Cumulative_distribution_function",
                "/wiki/Inverse_function",
                "/wiki/Quantile_function",
                "/wiki/Random_variable",
                "/wiki/Cumulative_distribution_function",
                "/wiki/Rank_statistics",
                "/wiki/Median",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Sample_(statistics)",
                "/wiki/Statistical_population",
                "/wiki/Standard_deviation",
                "/wiki/Microsoft_Excel",
                "/wiki/Real_number",
                "/wiki/Percentile",
                "/wiki/Microsoft_Excel",
                "/wiki/STATA",
                "/wiki/EViews",
                "/wiki/Maple_(software)",
                "/wiki/SciPy",
                "/wiki/SAS_(software)",
                "/wiki/GNU_Octave",
                "/wiki/R_(programming_language)",
                "/wiki/Matlab",
                "/wiki/Mathematica",
                "/wiki/Estimation_theory",
                "/wiki/Quantile_function",
                "/wiki/Cumulative_distribution_function",
                "/wiki/Floor_and_ceiling_functions",
                "/wiki/Bootstrap_(statistics)",
                "/wiki/Standard_error_(statistics)",
                "/wiki/Exponential_distribution",
                "/wiki/Robust_regression",
                "/wiki/Least_absolute_deviations",
                "/wiki/Least_absolute_deviations",
                "/wiki/Ordinal_scale"
            ],
            "text": "The quantiles of a random variable are preserved under increasing transformations, in the sense that, for example, if m is the median of a random variable X, then 2m is the median of 2X, unless an arbitrary choice has been made from a range of values to specify a particular quantile. (See quantile estimation, above, for examples of such interpolation.)   Quantiles can also be used in cases where only ordinal data are available.\nClosely related is the subject of least absolute deviations, a method of regression that is more robust to outliers than is least squares, in which the sum of the absolute value of the observed errors is used in place of the squared error.  The connection is that the mean is the single estimate of a distribution that minimizes expected squared error while the median minimizes expected absolute error.  Least absolute deviations shares the ability to be relatively insensitive to large deviations in outlying observations, although even better methods of robust regression are available.\nQuantiles are useful measures because they are less susceptible than means to long-tailed distributions and outliers.  Empirically, if the data being analyzed are not actually distributed according to an assumed distribution, or if there are other potential sources for outliers that are far removed from the mean, then quantiles may be more useful descriptive statistics than means and other moment-related statistics.\nIf a distribution is symmetric, then the median is the mean (so long as the latter exists). But, in general, the median and the mean can differ. For instance, with a random variable that has an exponential distribution, any particular sample of this random variable will have roughly a 63% chance of being less than the mean.  This is because the exponential distribution has a long tail for positive values but is zero for negative numbers.\nStandardized test results are commonly misinterpreted as a student scoring \"in the 80th percentile,\" for example, as if the 80th percentile is an interval to score \"in,\" which it is not; one can score \"at\" some percentile, or between two percentiles, but not \"in\" some percentile.  Perhaps by this example it is meant that the student scores between the 80th and 81st percentiles, or \"in\" the group of students whose score placed them at the 80th percentile.\nThe standard error of a quantile estimate can in general be estimated via the bootstrap.  The Maritz\u2013Jarrett method can also be used.[9]\nNotes:\nThe estimate types and interpolation schemes used include:\nIn effect, the methods compute Qp, the estimate for the k-th q-quantile, where p = k/q, from a sample of size N by computing a real valued index h.  When h is an integer, the h-th smallest of the N values, xh, is the quantile estimate.  Otherwise a rounding or interpolation scheme is used to compute the quantile estimate from h, x\u230ah\u230b, and x\u2308h\u2309.  (For notation, see floor and ceiling functions).\nWhen one has a sample drawn from an unknown population, the cumulative distribution function and quantile function of the underlying population are not known and the task becomes that of estimating the quantiles.  There are several methods.[1] Mathematica,[2] Matlab,[3] R[4] and GNU Octave[5] programming languages include nine sample quantile methods. SAS includes five sample quantile methods, SciPy[6] and Maple[7] both include eight, EViews[8] includes the six piecewise linear functions, STATA includes two, and Microsoft Excel includes two. Mathematica supports an arbitrary parameter for methods that allows for other, non-standard, methods.\nSo the first, second and third 4-quantiles (the \"quartiles\") of the dataset {3, 6, 7, 8, 8, 9, 10, 13, 15, 16, 20}  are {7, 9, 15}. If also required, the zeroth quartile is 3 and the fourth quartile is 20.\nConsider an ordered population of 11 data values {3, 6, 7, 8, 8, 9, 10, 13, 15, 16, 20}. What are the 4-quantiles (the \"quartiles\") of this dataset?\nSo the first, second and third 4-quantiles (the \"quartiles\") of the dataset {3, 6, 7, 8, 8, 10, 13, 15, 16, 20}  are {7, 9, 15}. If also required, the zeroth quartile is 3 and the fourth quartile is 20.\nConsider an ordered population of 10 data values {3, 6, 7, 8, 8, 10, 13, 15, 16, 20}. What are the 4-quantiles (the \"quartiles\") of this dataset?\nThe following two examples use the Nearest Rank definition of quantile with rounding. For an explanation of this definition, see percentiles.\nIf, instead of using integers k and q, the \u201cp-quantile\u201d is based on a real number p with 0 < p < 1 then p replaces k/q in the above formulas.  Some software programs (including Microsoft Excel) regard the minimum and maximum as the 0th and 100th percentile, respectively; however, such terminology is an extension beyond traditional statistics definitions.\nFor a finite population of N equally probable values indexed 1, \u2026, N from lowest to highest, the k-th q-quantile of this population can equivalently be computed via the value of Ip = N k/q.  If Ip is not an integer, then round up to the next integer to get the appropriate index; the corresponding data value is the k-th q-quantile.  On the other hand, if Ip is an integer then any number from the data value at that index to the data value of the next can be taken as the quantile, and it is conventional (though arbitrary) to take the average of those two values (see Estimating the quantiles).\nand\nAs in the computation of, for example, standard deviation, the estimation of a quantile depends upon whether one is operating with a statistical population or with a sample drawn from it.  For a population, of discrete values or for a continuous population density, the k-th q-quantile is the data value where the cumulative distribution function crosses k/q.  That is, x is a k-th q-quantile for a variable X if\nSome q-quantiles have special names:[citation needed] \nq-quantiles are values that partition a finite set of values into q subsets of (nearly) equal sizes.  There are q \u2212 1 of the q-quantiles, one for each integer k satisfying 0 < k < q.  In some cases the value of a quantile may not be uniquely determined, as can be the case for the median (2-quantile) of a uniform probability distribution on a set of even size.  Quantiles can also be applied to continuous distributions, providing a way to generalize rank statistics to continuous variables.  When the cumulative distribution function of a random variable is known, the q-quantiles are the application of the quantile function (the inverse function of the cumulative distribution function) to the values {1/q, 2/q, \u2026, (q \u2212 1)/q}.\nIn statistics and probability quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities, or dividing the observations in a sample in the same way. There is one less quantile than the number of groups created. Thus quartiles are the three cut points that will divide a dataset into four equal-sized groups. Common quantiles have special names: for instance quartile, decile (creating 10 groups: see below for more).  The groups created are termed halves, thirds, quarters, etc., though sometimes the terms for the quantile are used for the groups created, rather than for the cut points.\n",
            "title": "Quantile",
            "url": "https://en.wikipedia.org/wiki/Quantile"
        },
        {
            "desc_links": [
                "/wiki/Continuous_probability_distribution",
                "/wiki/Probability_distribution",
                "/wiki/Statistical_population",
                "/wiki/Sample_(statistics)",
                "/wiki/Skewness",
                "/wiki/Arithmetic_mean",
                "/wiki/Probability_theory",
                "/wiki/Statistics",
                "/wiki/Breakdown_point",
                "/wiki/Resistant_statistic",
                "/wiki/Robust_statistics"
            ],
            "desc_text": "b'The median is the value separating the higher half from the lower half of a data sample (a population or a probability distribution). For a data set, it may be thought of as the \"middle\" value. For example, in the data set {1, 3, 3, 6, 7, 8, 9}, the median is 6, the fourth largest, and also the fourth smallest, number in the sample. For a continuous probability distribution, the median is the value such that a number is equally likely to fall above or below it.\\n'b'The median is a commonly used measure of the properties of a data set in statistics and probability theory. The basic advantage of the median in describing data compared to the mean (often simply described as the \"average\") is that it is not skewed so much by extremely large or small values, and so it may give a better idea of a \"typical\" value. For example, in understanding statistics like household income or assets which vary greatly, a mean may be skewed by a small number of extremely high or low values. Median income, for example, may be a better way to suggest what a \"typical\" income is.\\n'b'Because of this, the median is of central importance in robust statistics, as it is the most resistant statistic, having a breakdown point of 50%: so long as no more than half the data are contaminated, the median will not give an arbitrarily large or small result.\\n'",
            "links": [
                "/wiki/Continuous_probability_distribution",
                "/wiki/Probability_distribution",
                "/wiki/Statistical_population",
                "/wiki/Sample_(statistics)",
                "/wiki/Skewness",
                "/wiki/Arithmetic_mean",
                "/wiki/Probability_theory",
                "/wiki/Statistics",
                "/wiki/Breakdown_point",
                "/wiki/Resistant_statistic",
                "/wiki/Robust_statistics",
                "/wiki/Arithmetic_mean",
                "/wiki/Stem-and-leaf_display",
                "/wiki/Arithmetic_mean",
                "/wiki/Central_tendency",
                "/wiki/Mode_(statistics)",
                "/wiki/Multiset",
                "/wiki/Arithmetic_mean",
                "/wiki/Skewness",
                "/wiki/Mean",
                "/wiki/Outlier",
                "/wiki/Descriptive_statistics",
                "/wiki/Summary_statistic",
                "/wiki/Medoid",
                "/wiki/Outlier",
                "/wiki/Skewness",
                "/wiki/Location_parameter",
                "/wiki/Geometric_median",
                "/wiki/Distance_metric",
                "/wiki/Weak_ordering",
                "/wiki/Quartile",
                "/wiki/Percentile",
                "/wiki/Decile",
                "/wiki/Quartile",
                "/wiki/Location_parameter",
                "/wiki/Median_absolute_deviation",
                "/wiki/Mean_absolute_deviation",
                "/wiki/Interquartile_range",
                "/wiki/Range_(statistics)",
                "/wiki/Efficiency_(statistics)#Asymptotic_efficiency",
                "/wiki/Efficiency_(statistics)",
                "/wiki/Probability_density_function",
                "/wiki/Absolute_continuity",
                "/wiki/Cumulative_distribution_function",
                "/wiki/Real_number",
                "/wiki/Probability_distribution",
                "/wiki/Probability_density_function",
                "/wiki/Lebesgue%E2%80%93Stieltjes_integral",
                "/wiki/Cumulative_distribution_function",
                "/wiki/Probability_distribution",
                "/wiki/Cauchy_distribution",
                "/wiki/Random_variable",
                "/wiki/Spatial_median",
                "/wiki/Multivariate_median",
                "/wiki/K-medians_clustering",
                "/wiki/Standard_deviation",
                "/wiki/Jensen%27s_inequality",
                "/wiki/Absolute_deviation",
                "/wiki/Cantelli%27s_inequality",
                "/wiki/Empty_set",
                "/wiki/Singleton_(mathematics)",
                "/wiki/Interval_(mathematics)",
                "/wiki/Arithmetic_mean",
                "/wiki/Order_statistic",
                "/wiki/Selection_algorithm",
                "/wiki/Big_O_notation",
                "/wiki/Sorting_algorithm",
                "/wiki/Array_(data_structure)",
                "/wiki/John_Tukey",
                "/wiki/Robust_estimator",
                "/wiki/Quicksort",
                "/wiki/Efficiency_(statistics)",
                "/wiki/Robust_statistics",
                "/wiki/Hodges%E2%80%93Lehmann_estimator",
                "/wiki/Pareto_distribution",
                "/wiki/Pareto_interpolation",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Probability_distribution",
                "/wiki/Statistical_model",
                "/wiki/South_Dakota",
                "/wiki/New_York_(state)",
                "/wiki/Iowa",
                "/wiki/K-medoids",
                "/wiki/Vector_space",
                "/wiki/Normed_space",
                "/wiki/L1-norm",
                "/wiki/Location_theory",
                "/wiki/Geometric_median",
                "/wiki/Strictly_convex_function",
                "/wiki/Euclidean_norm",
                "/wiki/Banach_space",
                "/wiki/Dimension_(linear_algebra)",
                "/wiki/Population_(statistics)",
                "/wiki/Central_tendency",
                "/wiki/Efficiency_(statistics)",
                "/wiki/Robust_statistics",
                "/wiki/Centerpoint_(geometry)",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Hodges%E2%80%93Lehmann_estimator",
                "/wiki/Slope",
                "/wiki/Linear_regression",
                "/wiki/Robust_statistics",
                "/wiki/Theil%E2%80%93Sen_estimator",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Noise_reduction",
                "/wiki/Salt_and_pepper_noise",
                "/wiki/Raster_image",
                "/wiki/Monochrome",
                "/wiki/Image_processing",
                "/wiki/K-means_clustering",
                "/wiki/K-medians_clustering",
                "/wiki/Cluster_analysis",
                "/wiki/Robust_statistics",
                "/wiki/Statistical_theory",
                "/wiki/Loss_functions",
                "/wiki/Laplace",
                "/wiki/Absolute_deviation",
                "/wiki/Bias_of_an_estimator#Median_unbiased_estimators,_and_bias_with_respect_to_other_loss_functions",
                "/wiki/Gauss",
                "/wiki/Loss_function",
                "/wiki/Expected_loss",
                "/wiki/Risk",
                "/wiki/Bias_of_an_estimator",
                "/wiki/Injective_function",
                "/wiki/Loss_function",
                "/wiki/Rao%E2%80%93Blackwell_theorem",
                "/wiki/Monotone_likelihood_ratio",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Talmud",
                "/wiki/Compass",
                "/wiki/Edward_Wright_(mathematician)",
                "/wiki/L1_norm",
                "/wiki/Roger_Joseph_Boscovich",
                "/wiki/Gustav_Theodor_Fechner",
                "/wiki/Gustav_Theodor_Fechner",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Antoine_Augustin_Cournot",
                "/wiki/Francis_Galton"
            ],
            "text": "Francis Galton used the English term median in 1881,[59] having earlier used the terms middle-most value in 1869, and the medium in 1880.[60][61]\nAntoine Augustin Cournot in 1843 was the first[citation needed] to use the term median (valeur m\u00e9diane) for the value that divides a probability distribution into two equal halves. Gustav Theodor Fechner used the median (Centralwerth) in sociological and psychological phenomena.[58] It had earlier been used only in astronomy and related fields. Gustav Fechner popularized the median into the formal analysis of data, although it had been used previously by Laplace.[58]\nIn 1757, Roger Joseph Boscovich developed a regression method based on the L1 norm and therefore implicitly on the median.[55]\nThe idea of the median also appeared later in Edward Wright's book on navigation (Certaine Errors in Navigation) in 1599 in a section concerning the determination of location with a compass. Wright felt that this value was the most likely to be the correct value in a series of observations.\nThe idea of the median appeared in the 13th century in the Talmud [53][54] (further[citation needed] for possible older mentions)\nThere are methods of construction median-unbiased estimators that are optimal (in a sense analogous to minimum-variance property considered for mean-unbiased estimators). Such constructions exist for probability distributions having monotone likelihood-functions.[50][51] One such procedure is an analogue of the Rao\u2013Blackwell procedure for mean-unbiased estimators: The procedure holds for a smaller class of probability distributions than does the Rao\u2014Blackwell procedure but for a larger class of loss functions.[52]\nFurther properties of median-unbiased estimators have been reported.[46][47][48][49]  Median-unbiased estimators are invariant under one-to-one transformations.\nThe theory of median-unbiased estimators was revived by George W. Brown in 1947:[45]\nAny mean-unbiased estimator minimizes the risk (expected loss) with respect to the squared-error loss function, as observed by Gauss. A median-unbiased estimator minimizes the risk with respect to the absolute-deviation loss function, as observed by Laplace. Other loss functions are used in statistical theory, particularly in robust statistics.\nNair and Shrivastava in 1942 suggested a similar idea but instead advocated dividing the sample into three equal parts before calculating the means of the subsamples.[42] Brown and Mood in 1951 proposed the idea of using the medians of two subsamples rather the means.[43] Tukey combined these ideas and recommended dividing the sample into three equal size subsamples and estimating the line based on the medians of the subsamples.[44]\nIn cluster analysis, the k-medians clustering algorithm provides a way of defining clusters, in which the criterion of maximising the distance between cluster-means that is used in k-means clustering, is replaced by maximising the distance between cluster-medians.\nIn the context of image processing of monochrome raster images there is a type of noise, known as the salt and pepper noise, when each pixel independently becomes black (with some small probability) or white (with some small probability), and is unchanged otherwise (with the probability close to 1). An image constructed of median values of neighborhoods (like 3\u00d73 square) can effectively reduce noise in this case.[citation needed]\nThe Theil\u2013Sen estimator is a method for robust linear regression based on finding medians of slopes.[40]\nFor univariate distributions that are symmetric about one median, the Hodges\u2013Lehmann estimator is a robust and highly efficient estimator of the population median; for non-symmetric distributions, the Hodges\u2013Lehmann estimator is a robust and highly efficient estimator of the population pseudo-median, which is the median of a symmetrized distribution and which is close to the population median.[citation needed] The Hodges\u2013Lehmann estimator has been generalized to multivariate distributions.[37]\nAn alternative generalization of the spatial median in higher dimensions that does not relate to a particular metric is the centerpoint.\nThe spatial median is a robust and highly efficient estimator of a central tendency of a population.[27][37][38][39]\nthis general definition is convenient for defining a spatial median of a population in a finite-dimensional normed space, for example, for distributions without a finite mean.[14][27] Spatial medians are defined for random vectors with values in a Banach space.[14]\nMore generally, a spatial median is defined as a minimizer of\nwhere xn and a are vectors. The spatial median is unique when the data-set's dimension is two or more and the norm is the Euclidean norm (or another strictly convex norm).[14][15][27] The spatial median is also called the L1 median, even when the norm is Euclidean. Other names are used especially for finite sets of points: geometric median, Fermat point (in mechanics), or Weber or Fermat-Weber point (in geographical location theory).[36] In the special case where the norm is an L1-norm, then the spatial median and the marginal median are the same.\nFor N vectors in a normed vector space, a spatial median  minimizes the average distance\n\nThe marginal median is defined for vectors defined with respect to a fixed set of coordinates. A marginal median is defined to be the vector whose components are univariate medians. The marginal median is easy to compute, and its properties were studied by Puri and Sen.[27][35]\nThe medoid is often used in clustering using the k-medoid algorithm.\nPreviously, this article discussed the univariate median, when the sample or population had one-dimension. When the dimension is two or higher, there are multiple concepts that extend the definition of the univariate median; each such multivariate median agrees with the univariate median when the dimension is exactly one.[27][32][33][34]\na and b here are constants equal to 1 and 2, x is a variate and s is the standard deviation of the sample.\nwhere r is the Pearson correlation coefficient between the squared deviation scores\nwhere tj is the mean absolute deviation of the jth sample, var() is the variance and z\u03b1 is the value from the normal distribution for the chosen value of \u03b1: for \u03b1 = 0.05, z\u03b1 = 1.96. The following formulae are used in the derivation of these confidence intervals\nConfidence intervals for a two-sample test in which the sample sizes are large have been derived by Bonett and Seier[28] This test assumes that both samples have the same median but differ in the dispersion around it. The confidence interval (CI) is bounded inferiorly by\nwhere n is the sample size, m is the sample median and x is a variate. The sum is taken over the whole sample.\nThe coefficient of dispersion (CD) is defined as the ratio of the average absolute deviation from the median to the median of the data.[28] It is a statistical measure used by the states of Iowa, New York and South Dakota in estimating dues taxes.[29][30][31] In symbols\nIf data are represented by a statistical model specifying a particular family of probability distributions, then estimates of the median can be obtained by fitting that family of probability distributions to the data and calculating the theoretical median of the fitted distribution.[citation needed] Pareto interpolation is an application of this when the population is assumed to have a Pareto distribution.\nFor univariate distributions that are symmetric about one median, the Hodges\u2013Lehmann estimator is a robust and highly efficient estimator of the population median.[27]\nThe expected value of the median falls slightly as sample size increases while, as would be expected, the standard errors of both the median and the mean are proportionate to the inverse square root of the sample size.  The asymptotic approximation errs on the side of caution by overestimating the standard error.\nIn this case, the arithmetic mean of the two middlemost terms is (2 + 6)/2 = 4. Therefore, the median is 4 since it is the arithmetic mean of the middle observations in the ordered list.\nStart by sorting the values: 1, 2, 2, 6, 7, 8.\nAs an example, we will calculate the sample median for the following set of observations: 1, 6, 2, 8, 7, 2.\nThe median is the ((n\u00a0+\u00a01)/2)th item, where n is the number of values. For example, for the list {1,\u00a02,\u00a05,\u00a07,\u00a08}, we have n\u00a0=\u00a05, so the median is the ((5\u00a0+\u00a01)/2)th item.\nIn this case, the median is 5 since it is the middle observation in the ordered list.\nStart by sorting the values: 1, 2, 5, 7, 8.\nAs an example, we will calculate the sample median for the following set of observations: 1, 5, 2, 8, 7.\nIf n is even then Median (M) = value of [(n/2)th item term + (n/2 + 1)th item term]/2\nIf n is odd then Median (M) = value of ((n\u00a0+\u00a01)/2)th item term.\nIn individual series (if number of observation is very low) first one must arrange all the observations in order. Then count(n) is the total number of observation in given data.\nThe remedian is an estimator for the median that requires linear time but sub-linear memory, operating in a single pass over the sample.[18]\nthen\nSelection algorithms still have the downside of requiring \u03a9(n) memory, that is, they need to have the full sample (or a linear-sized portion of it) in memory. Because this, as well as the linear time requirement, can be prohibitive, several estimation procedures for the median have been developed. A simple one is the median of three rule, which estimates the median as the median of a three-element subsample; this is commonly used as a subroutine in the quicksort sorting algorithm, which uses an estimate of its input's median. A more robust estimator is Tukey's ninther, which is the median of three rule applied with limited recursion:[17] if A is the sample laid out as an array, and\nEven though comparison-sorting n items requires \u03a9(n log n) operations, selection algorithms can compute the k'th-smallest of n items with only \u0398(n) operations. This includes the median, which is the n/2'th order statistic (or for an even number of samples, the arithmetic mean of the two middle order statistics).\nis a closed interval, a singleton or an empty set.\nA C function is a real valued function, defined on the set of real numbers R, with the property that for any real t\nIt has been shown[16] that if x is a real variable with a unique median m and f is a C function then\nJensen's inequality states that for any random variable x with a finite expectation E(x) and for any convex function f\nThis proof also follows directly from Cantelli's inequality.[12]\nThe result can be generalized to obtain a multivariate version of the inequality,[13] as follows:\nThe first and third inequalities come from Jensen's inequality applied to the absolute-value function and the square function, which are each convex.  The second inequality comes from the fact that a median minimizes the absolute deviation function\nThis bound was proved by Mallows,[11] who used Jensen's inequality twice, as follows. We have\nIf the distribution has finite variance, then the distance between the median and the mean is bounded by one standard deviation.\nA similar relation holds between the median and the mode: they lie within 31/2 \u2248 1.732 standard deviations of each other:\nwhere |\u00b7| is the absolute value.\nThis optimization-based definition of the median is useful in statistical data-analysis, for example, in k-medians clustering.\nas discussed below in the section on multivariate medians (specifically, the spatial median).\nMore generally, a median is defined as a minimum of\nProvided that the probability distribution of X is such that the above expectation exists, then m is a median of  X if and only if m is a minimizer of the mean absolute error with respect to X.[9] In particular, m is a sample median if and only if m minimizes the arithmetic mean of the absolute deviations.\nThe mean absolute error of a real variable c with respect to the random variable\u00a0X is\nThe medians of certain types of distributions can be easily calculated from their parameters; furthermore, they exist even for some distributions lacking a well-defined mean, such as the Cauchy distribution:\nAny probability distribution on R has at least one median, but in specific cases there may be more than one median. Specifically, if a probability distribution is zero on an interval [a,\u00a0b], and the cumulative distribution function at a is 1/2, any value between a and b will also be a median.\nin which a Lebesgue\u2013Stieltjes integral is used. For an absolutely continuous probability distribution with probability density function \u0192, the median satisfies\nor, equivalently, the inequalities\nFor any probability distribution on the real line R with cumulative distribution function\u00a0F, regardless of whether it is any kind of continuous probability distribution, in particular an absolutely continuous distribution (which has a probability density function), or a discrete probability distribution, a median is by definition any real number\u00a0m that satisfies the inequalities\nFor practical purposes, different measures of location and dispersion are often compared on the basis of how well the corresponding population values can be estimated from a sample of data. The median, estimated using the sample median, has good properties in this regard. While it is not usually optimal if a given population distribution is assumed, its properties are always reasonably good. For example, a comparison of the efficiency of candidate estimators shows that the sample mean is more statistically efficient than the sample median when data are uncontaminated by data from heavy-tailed distributions or from mixtures of distributions, but less efficient otherwise, and that the efficiency of the sample median is higher than that for a wide range of distributions. More specifically, the median has a 64% efficiency compared to the minimum-variance mean (for large normal samples), which is to say the variance of the median will be ~50% greater than the variance of the mean\u2014see asymptotic efficiency and references therein.\nWhen the median is used as a location parameter in descriptive statistics, there are several choices for a measure of variability: the range, the interquartile range, the mean absolute deviation, and the median absolute deviation.\nThe median is one of a number of ways of summarising the typical values associated with members of a statistical population; thus, it is a possible location parameter. The median is the 2nd quartile, 5th decile, and 50th percentile. Since the median is the same as the second quartile, its calculation is illustrated in the article on quartiles. A median can be worked out for ranked but not numerical classes (e.g. working out a median grade when students are graded from A to F), although the result might be halfway between grades if there is an even number of cases.\nA median is only defined on ordered one-dimensional data, and is independent of any distance metric. A geometric median, on the other hand, is defined in any number of dimensions.\nThe median can be used as a measure of location when a distribution is skewed, when end-values are not known, or when one requires reduced importance to be attached to outliers, e.g., because they may be measurement errors.\nIn a population, at most half have values strictly less than the median and at most half have values strictly greater than it. If each group contains less than half the population, then some of the population is exactly equal to the median. For example, if a\u00a0<\u00a0b\u00a0<\u00a0c, then the median of the list {a,\u00a0b,\u00a0c} is b, and, if a\u00a0<\u00a0b\u00a0<\u00a0c\u00a0<\u00a0d, then the median of the list {a,\u00a0b,\u00a0c,\u00a0d} is the mean of b and c; i.e., it is (b\u00a0+\u00a0c)/2. Indeed, as it is based on the middle data in a group, it is not necessary to even know the value of extreme results in order to calculate a median. For example, in a psychology test investigating the time needed to solve a problem, if a small number of people failed to solve the problem at all in the given time a median can still be calculated.[6]\nWith an even number of observations (as shown above) no value need be exactly at the value of the median. Nonetheless, the value of the median is uniquely determined with the usual definition. A related concept, in which the outcome is forced to correspond to a member of the sample, is the medoid.\nThe median is a popular summary statistic used in descriptive statistics, since it is simple to understand and easy to calculate, while also giving a measure that is more robust in the presence of outlier values than is the mean. The widely cited empirical relationship between the relative locations of the mean and the median for skewed distributions is, however, not generally true.[5] There are, however, various relationships for the absolute difference between them; see below.\nThe median is used primarily for skewed distributions, which it summarizes differently from the arithmetic mean. Consider the multiset { 1, 2, 2, 2, 3, 14 }. The median is 2 in this case, (as is the mode), and it might be seen as a better indication of central tendency (less susceptible to the exceptionally large value in data) than the arithmetic mean of 4.\nThere is no widely accepted standard notation for the median, but some authors represent the median of a variable x either as x\u0342 or as \u03bc1/2[1] sometimes also M.[3][4] In any of these cases, the use of these or other symbols for the median needs to be explicitly defined when they are introduced.\nOne can find the median using the Stem-and-Leaf Plot.\nIf there is an even number of observations, then there is no single middle value; the median is then usually defined to be the mean of the two middle values.[1][2] For example, in the data set\nThis list contains seven numbers. The median is the fourth of them, which is 6.\nIf there is an odd number of numbers, the middle one is picked. For example, consider the list of numbers\nThe median of a finite list of numbers can be found by arranging all the numbers from smallest to greatest.\nBecause of this, the median is of central importance in robust statistics, as it is the most resistant statistic, having a breakdown point of 50%: so long as no more than half the data are contaminated, the median will not give an arbitrarily large or small result.\nThe median is a commonly used measure of the properties of a data set in statistics and probability theory. The basic advantage of the median in describing data compared to the mean (often simply described as the \"average\") is that it is not skewed so much by extremely large or small values, and so it may give a better idea of a \"typical\" value. For example, in understanding statistics like household income or assets which vary greatly, a mean may be skewed by a small number of extremely high or low values. Median income, for example, may be a better way to suggest what a \"typical\" income is.\nThe median is the value separating the higher half from the lower half of a data sample (a population or a probability distribution). For a data set, it may be thought of as the \"middle\" value. For example, in the data set {1, 3, 3, 6, 7, 8, 9}, the median is 6, the fourth largest, and also the fourth smallest, number in the sample. For a continuous probability distribution, the median is the value such that a number is equally likely to fall above or below it.\n",
            "title": "Median",
            "url": "https://en.wikipedia.org/wiki/Median"
        },
        {
            "desc_links": [
                "/wiki/Parallel_(geometry)",
                "/wiki/Affine_spaces",
                "/wiki/Geometry",
                "/wiki/Function_composition",
                "/wiki/Shear_mapping",
                "/wiki/Rotation_(mathematics)",
                "/wiki/Reflection_(mathematics)",
                "/wiki/Similarity_transformation_(geometry)",
                "/wiki/Homothetic_transformation",
                "/wiki/Scaling_(geometry)",
                "/wiki/Translation_(geometry)",
                "/wiki/Linear_transformation",
                "/wiki/Affine_space",
                "/wiki/Translation_(geometry)",
                "/wiki/Position_(vector)",
                "/wiki/Linear_transformation",
                "/wiki/Origin_(mathematics)",
                "/wiki/Linear_function_(calculus)",
                "/wiki/Cartesian_coordinates",
                "/wiki/Affine_coordinates"
            ],
            "desc_text": "b'In geometry, an affine transformation, affine map[1] or an affinity (from the Latin, affinis, \"connected with\") is a function between affine spaces which preserves points, straight lines and planes. Also, sets of parallel lines remain parallel after an affine transformation. An affine transformation does not necessarily preserve angles between lines or distances between points, though it does preserve ratios of distances between points lying on a straight line.\\n'b'Examples of affine transformations include translation, scaling, homothety, similarity transformation, reflection, rotation, shear mapping, and compositions of them in any combination and sequence.\\n'b'If \\n  \\n    \\n      \\n        X\\n      \\n    \\n    {\\\\displaystyle X}\\n  \\n and \\n  \\n    \\n      \\n        Y\\n      \\n    \\n    {\\\\displaystyle Y}\\n  \\n are affine spaces, then every affine transformation \\n  \\n    \\n      \\n        f\\n        :\\n        X\\n        \\xe2\\x86\\x92\\n        Y\\n      \\n    \\n    {\\\\displaystyle f\\\\colon X\\\\to Y}\\n  \\n is of the form \\n  \\n    \\n      \\n        x\\n        \\xe2\\x86\\xa6\\n        M\\n        x\\n        +\\n        b\\n      \\n    \\n    {\\\\displaystyle x\\\\mapsto Mx+b}\\n  \\n, where \\n  \\n    \\n      \\n        M\\n      \\n    \\n    {\\\\displaystyle M}\\n  \\n is a linear transformation on the space \\n  \\n    \\n      \\n        X\\n      \\n    \\n    {\\\\displaystyle X}\\n  \\n, \\n  \\n    \\n      \\n        x\\n      \\n    \\n    {\\\\displaystyle x}\\n  \\n is a vector in \\n  \\n    \\n      \\n        X\\n      \\n    \\n    {\\\\displaystyle X}\\n  \\n, and \\n  \\n    \\n      \\n        b\\n      \\n    \\n    {\\\\displaystyle b}\\n  \\n is a vector in \\n  \\n    \\n      \\n        Y\\n      \\n    \\n    {\\\\displaystyle Y}\\n  \\n. Unlike a purely linear transformation, an affine map need not preserve the zero point in a linear space. Thus, every linear transformation is affine, but not every affine transformation is linear.\\n'b'All Euclidean spaces are affine, but there are affine spaces that are non-Euclidean. In affine coordinates, which include Cartesian coordinates in Euclidean spaces, each output coordinate of an affine map is a linear function (in the sense of calculus) of all input coordinates. Another way to deal with affine transformations systematically is to select a point as the origin; then, any affine transformation is equivalent to a linear transformation (of position vectors) followed by a translation.\\n'",
            "links": [
                "/wiki/Parallel_(geometry)",
                "/wiki/Affine_spaces",
                "/wiki/Geometry",
                "/wiki/Function_composition",
                "/wiki/Shear_mapping",
                "/wiki/Rotation_(mathematics)",
                "/wiki/Reflection_(mathematics)",
                "/wiki/Similarity_transformation_(geometry)",
                "/wiki/Homothetic_transformation",
                "/wiki/Scaling_(geometry)",
                "/wiki/Translation_(geometry)",
                "/wiki/Translation_(geometry)",
                "/wiki/Position_(vector)",
                "/wiki/Linear_transformation",
                "/wiki/Origin_(mathematics)",
                "/wiki/Linear_function_(calculus)",
                "/wiki/Cartesian_coordinates",
                "/wiki/Affine_coordinates",
                "/wiki/Projective_transformation",
                "/wiki/Transformation_matrix#Affine_transformations",
                "/wiki/Robotics",
                "/wiki/Computer_vision",
                "/wiki/Computer_graphics",
                "/wiki/Function_composition",
                "/wiki/Homogeneous_coordinates",
                "/wiki/Interpolation",
                "/wiki/Digital_image_processing",
                "/wiki/Image_stitching",
                "/wiki/Distortion_(optics)",
                "/wiki/Area",
                "/wiki/Parallelogram",
                "/wiki/Euclidean_plane",
                "/wiki/Cross_product",
                "/wiki/Galois_field"
            ],
            "text": "In fact, all triangles are related to one another by affine transformations. This is also true for all parallelograms, but not for all quadrilaterals.\nTransforming the three corner points of the original triangle (in red) gives three new points which form the new triangle (in blue).  This transformation skews and translates the original triangle.\nIn \u211d2, the transformation shown at left is accomplished using the map given by:\nThe following equation expresses an affine transformation in GF(28):\nA given T may either be direct (respect orientation), or indirect (reverse orientation), and this may be determined by its effect on signed areas (as defined, for example, by the cross product of vectors).\nAffine transformations do not respect lengths or angles; they multiply area by a constant factor\nTo visualise the general affine transformation of the Euclidean plane, take labelled parallelograms ABCD and A\u2032B\u2032C\u2032D\u2032. Whatever the choices of points, there is an affine transformation T of the plane taking A to A\u2032, and each vertex similarly. Supposing we exclude the degenerate case where ABCD has zero area, there is a unique such affine transformation T. Drawing out a whole grid of parallelograms based on ABCD, the image T(P) of any point P is determined by noting that T(A) = A\u2032, T applied to the line segment AB is A\u2032B\u2032, T applied to the line segment AC is A\u2032C\u2032, and T respects scalar multiples of vectors based at A. [If A, E, F are collinear then the ratio length(AF)/length(AE) is equal to length(A\u2032F\u2032)/length(A\u2032E\u2032).] Geometrically T transforms the grid based on ABCD to that based in A\u2032B\u2032C\u2032D\u2032.\nAffine transformations in two real dimensions include:\nThis is an example of image warping. However, the affine transformations do not facilitate projection onto a curved surface or radial distortions.\nThe affine transform preserves parallel lines. However, the stretching and shearing transformations warp shapes, as the following example shows: \nThe affine transforms are applicable to the registration process where two or more images are aligned (registered). An example of image registration is the generation of panoramic images that are the product of multiple images stitched together.\nIn their applications to digital image processing, the affine transformations are analogous to printing on a sheet of rubber and stretching the sheet's edges parallel to the plane. This transform relocates pixels requiring intensity interpolation to approximate the value of moved pixels, bicubic interpolation is the standard for image transformations in image processing applications. Affine transformations scale, rotate, translate, mirror and shear images as shown in the following examples:[5] \nIf there is a fixed point, we can take that as the origin, and the affine transformation reduces to a linear transformation. This may make it easier to classify and understand the transformation. For example, describing a transformation as a rotation by a certain angle with respect to a certain axis may give a clearer idea of the overall behavior of the transformation than describing it as a combination of a translation and a rotation. However, this depends on application and context.\nAn affine transformation preserves:\nFor example, the affine transformation of a vector plane is uniquely determined from the knowledge of where the three vertices of a non-degenerate triangle are mapped to.\nThis formulation works irrespective of whether any of the domain, codomain and image vector spaces have the same number of dimensions.\nis\nThe advantage of using homogeneous coordinates is that one can combine any number of affine transformations into one by multiplying the respective matrices. This property is used extensively in computer graphics, computer vision and robotics.\nThe above-mentioned augmented matrix is called an affine transformation matrix, or projective transformation matrix (as it can also be used to perform projective transformations).\nis equivalent to the following\nwe have[2]\nWe can interpret this definition in a few other ways, as follows.\nor\nAll Euclidean spaces are affine, but there are affine spaces that are non-Euclidean. In affine coordinates, which include Cartesian coordinates in Euclidean spaces, each output coordinate of an affine map is a linear function (in the sense of calculus) of all input coordinates. Another way to deal with affine transformations systematically is to select a point as the origin; then, any affine transformation is equivalent to a linear transformation (of position vectors) followed by a translation.\nExamples of affine transformations include translation, scaling, homothety, similarity transformation, reflection, rotation, shear mapping, and compositions of them in any combination and sequence.\nIn geometry, an affine transformation, affine map[1] or an affinity (from the Latin, affinis, \"connected with\") is a function between affine spaces which preserves points, straight lines and planes. Also, sets of parallel lines remain parallel after an affine transformation. An affine transformation does not necessarily preserve angles between lines or distances between points, though it does preserve ratios of distances between points lying on a straight line.\n",
            "title": "Affine transformation",
            "url": "https://en.wikipedia.org/wiki/Affine_transformation"
        },
        {
            "desc_links": [
                "/wiki/Partition_of_a_set",
                "/wiki/Probability_space",
                "/wiki/Expected_value",
                "/wiki/Random_variable",
                "/wiki/Probability_theory",
                "/wiki/Independence_(probability)",
                "/wiki/Mean_independent",
                "/wiki/Measure_theory",
                "/wiki/Conditional_probability"
            ],
            "desc_text": "b'In probability theory, the conditional expectation, conditional expected value, or conditional mean of a random variable is its expected value \\xe2\\x80\\x93 the value it would take \\xe2\\x80\\x9con average\\xe2\\x80\\x9d over an arbitrarily large number of occurrences \\xe2\\x80\\x93 given that a certain set of \"conditions\" is known to occur. If the random variable can take on only a finite number of values, the \\xe2\\x80\\x9cconditions\\xe2\\x80\\x9d are that the variable can only take on a subset of those values. More formally, in the case when the random variable is defined over a discrete probability space, the \"conditions\" are a partition of this probability space. \\n'b\"With multiple random variables, for one random variable to be mean independent of all others both individually and collectively means that each conditional expectation equals the random variable's (unconditional) expected value. This always holds if the variables are independent, but mean independence is a weaker condition.\\n\"b'Depending on the nature of the conditioning, the conditional expectation can be either a random variable itself or a fixed value. With two random variables, if the expectation of a random variable \\n  \\n    \\n      \\n        X\\n      \\n    \\n    {\\\\displaystyle X}\\n  \\n is expressed conditional on another random variable \\n  \\n    \\n      \\n        Y\\n      \\n    \\n    {\\\\displaystyle Y}\\n  \\n without a particular value of \\n  \\n    \\n      \\n        Y\\n      \\n    \\n    {\\\\displaystyle Y}\\n  \\n being specified, then the expectation of \\n  \\n    \\n      \\n        X\\n      \\n    \\n    {\\\\displaystyle X}\\n  \\n conditional on \\n  \\n    \\n      \\n        Y\\n      \\n    \\n    {\\\\displaystyle Y}\\n  \\n, denoted \\n  \\n    \\n      \\n        E\\n        (\\n        X\\n        \\n          |\\n        \\n        Y\\n        )\\n      \\n    \\n    {\\\\displaystyle E(X|Y)}\\n  \\n, is a function of the random variable \\n  \\n    \\n      \\n        Y\\n      \\n    \\n    {\\\\displaystyle Y}\\n  \\n and hence is itself a random variable. Alternatively, if the expectation of \\n  \\n    \\n      \\n        X\\n      \\n    \\n    {\\\\displaystyle X}\\n  \\n is expressed conditional on the occurrence of a particular value of \\n  \\n    \\n      \\n        Y\\n      \\n    \\n    {\\\\displaystyle Y}\\n  \\n, denoted \\n  \\n    \\n      \\n        y\\n      \\n    \\n    {\\\\displaystyle y}\\n  \\n, then the conditional expectation \\n  \\n    \\n      \\n        E\\n        (\\n        X\\n        \\n          |\\n        \\n        Y\\n        =\\n        y\\n        )\\n      \\n    \\n    {\\\\displaystyle E(X|Y=y)}\\n  \\n is a fixed value.\\n'b'This concept generalizes to any probability space using measure theory.\\n'b'In modern probability theory the concept of conditional probability is defined in terms of conditional expectation.\\n'",
            "links": [
                "/wiki/Partition_of_a_set",
                "/wiki/Probability_space",
                "/wiki/Expected_value",
                "/wiki/Random_variable",
                "/wiki/Probability_theory",
                "/wiki/Independence_(probability)",
                "/wiki/Mean_independent",
                "/wiki/Measure_theory",
                "/wiki/Conditional_probability",
                "/wiki/Dice",
                "/wiki/Sigma-algebra",
                "/wiki/Joseph_L._Doob",
                "/wiki/Paul_Halmos",
                "/wiki/Radon%E2%80%93Nikodym_theorem",
                "/wiki/Andrey_Nikolaevich_Kolmogorov",
                "/wiki/Pierre-Simon_Laplace",
                "/wiki/Conditional_probability",
                "/wiki/Radon%E2%80%93Nikodym_derivative",
                "/wiki/Radon%E2%80%93Nikodym_theorem",
                "/wiki/Change_of_variables",
                "/wiki/Commutative_diagram",
                "/wiki/Discrete_random_variable",
                "/wiki/Continuous_random_variable"
            ],
            "text": "If both X and Y are continuous random variables, then the conditional expectation is\nIf X is a continuous random variable, while Y remains a discrete variable, the conditional expectation is\nWhen X and Y are both discrete random variables, then the conditional expectation of X given the event Y\u00a0=\u00a0y can be considered as function of y for y in the range of Y:\nThis equation can be interpreted to say that the following diagram is commutative on average.\nWe can further interpret this equality by considering the abstract change of variables formula to transport the integral on the right hand side to an integral over \u03a9:\nComparing with conditional expectation with respect to sub-\u03c3-algebras, it holds that\nthen\nConsider, in addition to the above,\nwhere the derivatives are Radon\u2013Nikodym derivatives of measures.\nThus, we have \nimplies\nConsider the following:\nReplacing this limiting process by the Radon\u2013Nikodym derivative yields an analogous definition that works more generally.\nThis function, which is different from the previous one, is the conditional expectation of X with respect to the \u03c3-algebra generated by Y.  The two are related by\nThe related concept of conditional probability dates back at least to Laplace who calculated conditional distributions.  It was Andrey Kolmogorov who in 1933 formalized it using the Radon\u2013Nikodym theorem.[1]  In works of Paul Halmos[2] and Joseph L. Doob[3] from 1953, conditional expectation was generalized to its modern definition using sub-\u03c3-algebras.[4]\nExample 2. Suppose we have daily rainfall data (mm of rain each day) collected by a weather station on every day of the ten\u2013year (3652\u2013day) period from Jan 1, 1990 to Dec 31, 1999.  The unconditional expectation of rainfall for an unspecified day is the average of the rainfall amounts of those 3652 days. The conditional expectation of rainfall for an otherwise unspecified day known to be (conditional on being) in the month of March is the average of daily rainfall over all 310 days of the ten\u2013year period that falls in March. And the conditional expectation of rainfall conditional on days dated March 2 is the average of the rainfall amounts that occurred on the ten days with that specific date.\nExample 1. Consider the roll of a fair die and let A = 1 if the number is even (i.e. 2, 4, or 6) and A = 0 otherwise. Furthermore, let B = 1 if the number is prime (i.e. 2, 3, or 5) and B = 0 otherwise.\nIn modern probability theory the concept of conditional probability is defined in terms of conditional expectation.\nThis concept generalizes to any probability space using measure theory.\nWith multiple random variables, for one random variable to be mean independent of all others both individually and collectively means that each conditional expectation equals the random variable's (unconditional) expected value. This always holds if the variables are independent, but mean independence is a weaker condition.\nIn probability theory, the conditional expectation, conditional expected value, or conditional mean of a random variable is its expected value \u2013 the value it would take \u201con average\u201d over an arbitrarily large number of occurrences \u2013 given that a certain set of \"conditions\" is known to occur. If the random variable can take on only a finite number of values, the \u201cconditions\u201d are that the variable can only take on a subset of those values. More formally, in the case when the random variable is defined over a discrete probability space, the \"conditions\" are a partition of this probability space. \n",
            "title": "Conditional expectation",
            "url": "https://en.wikipedia.org/wiki/Conditional_expectation"
        },
        {
            "desc_links": [
                "/wiki/Statistical_theory",
                "/wiki/Time_series_analysis",
                "/wiki/Linear_regression",
                "/wiki/Statistics"
            ],
            "desc_text": "b'In statistics, the term linear model is used in different ways according to the context. The most common occurrence is in connection with regression models and the term is often taken as synonymous with linear regression model.  However, the term is also used in time series analysis with a different meaning. In each case, the designation \"linear\" is used to identify a subclass of models for which substantial reduction in the complexity of the related statistical theory is possible.\\n'",
            "links": [
                "/wiki/Statistical_theory",
                "/wiki/Time_series_analysis",
                "/wiki/Linear_regression",
                "/wiki/Statistics",
                "/wiki/Least_squares",
                "/wiki/Autoregressive_moving_average_model",
                "/wiki/Covariance",
                "/wiki/Innovation_(signal_processing)",
                "/wiki/Nonlinear_dimensionality_reduction"
            ],
            "text": "There are some other instances where \"nonlinear model\" is used to contrast with a linearly structured model, although the term \"linear model\" is not usually applied. One example of this is nonlinear dimensionality reduction.\nwhere again the quantities \u03b5t are random variables representing innovations which are new random effects that appear at a certain time but also affect values of X at later times. In this instance the use of the term \"linear model\" refers to the structure of the above relationship in representing Xt as a linear function of past values of the same time series and of current and past values of the innovations.[1] This particular aspect of the structure means that it is relatively simple to derive relations for the mean and covariance properties of the time series. Note that here the \"linear\" part of the term \"linear model\" is not referring to the coefficients \u03c6i and \u03b8i, as it would be in the case of a regression model, which looks structurally similar.\nAn example of a linear time series model is an autoregressive moving average model. Here the model for values {Xt} in a time series can be written in the form\nFrom this, it can readily be seen that the \"linear\" aspect of the model means the following:\nGiven that estimation is undertaken on the basis of a least squares analysis, estimates of the unknown parameters \u03b2j are determined by minimising a sum of squares function\nare linear functions of the \u03b2j.\nIn statistics, the term linear model is used in different ways according to the context. The most common occurrence is in connection with regression models and the term is often taken as synonymous with linear regression model.  However, the term is also used in time series analysis with a different meaning. In each case, the designation \"linear\" is used to identify a subclass of models for which substantial reduction in the complexity of the related statistical theory is possible.\n",
            "title": "Linear model",
            "url": "https://en.wikipedia.org/wiki/Linear_model"
        },
        {
            "desc_links": [
                "/wiki/Variable_(research)",
                "/wiki/Quantitative_data",
                "/wiki/Qualitative_property",
                "/wiki/Set_(mathematics)",
                "/wiki/Help:Pronunciation_respelling_key",
                "/wiki/Help:IPA/English",
                "/wiki/Help:Pronunciation_respelling_key",
                "/wiki/Help:IPA/English",
                "/wiki/Help:Pronunciation_respelling_key",
                "/wiki/Help:IPA/English",
                "/wiki/Shannon_entropy",
                "/wiki/Information",
                "/wiki/Homelessness",
                "/wiki/Literacy",
                "/wiki/Unemployment_rate",
                "/wiki/Crime_rate",
                "/wiki/Stock_price",
                "/wiki/Scientific_research",
                "/wiki/Digital_economy",
                "/wiki/Petroleum",
                "/wiki/Experimental_data",
                "/wiki/In_situ",
                "/wiki/Field_work",
                "/wiki/Outlier",
                "/wiki/Character_(computing)",
                "/wiki/Number",
                "/wiki/Raw_data",
                "/wiki/Data_processing",
                "/wiki/Code",
                "/wiki/Knowledge_representation_and_reasoning",
                "/wiki/Knowledge",
                "/wiki/Information",
                "/wiki/Concept",
                "/wiki/Data_visualization",
                "/wiki/Data_analysis",
                "/wiki/Data_reporting",
                "/wiki/Measurement"
            ],
            "desc_text": "b'Data (/\\xcb\\x88de\\xc9\\xaat\\xc9\\x99/ DAY-t\\xc9\\x99, /\\xcb\\x88d\\xc3\\xa6t\\xc9\\x99/ DAT-\\xc9\\x99, /\\xcb\\x88d\\xc9\\x91\\xcb\\x90t\\xc9\\x99/ DAH-t\\xc9\\x99)[1] is a set of values of qualitative or quantitative variables.\\n'b'Data and information are often used interchangeably; however, the extent to which a set of data is informative to someone depends on the extent to which it is unexpected by that person. The amount of information content in a data stream may be characterized by its Shannon entropy.\\n'b'While the concept of data is commonly associated with scientific research, data is collected by a huge range of organizations and institutions, including businesses (e.g., sales data, revenue, profits, stock price), governments (e.g., crime rates, unemployment rates, literacy rates) and non-governmental organizations (e.g., censuses of the number of homeless people by non-profit organizations).\\n'b'Data is measured, collected and reported, and analyzed, whereupon it can be visualized using graphs, images or other analysis tools. Data as a general concept refers to the fact that some existing information or knowledge is represented or coded in some form suitable for better usage or processing. Raw data (\"unprocessed data\") is a collection of numbers or characters before it has been \"cleaned\" and corrected by researchers. Raw data needs to be corrected to remove outliers or obvious instrument or data entry errors (e.g., a thermometer reading from an outdoor Arctic location recording a tropical temperature).  Data processing commonly occurs by stages, and the \"processed data\" from one stage may be considered the \"raw data\" of the next stage. Field data is raw data that is collected in an uncontrolled \"in situ\" environment. Experimental data is data that is generated within the context of a scientific investigation by observation and recording. Data has been described as the new oil of the digital economy.[2][3]\\n'",
            "links": [
                "/wiki/Variable_(research)",
                "/wiki/Quantitative_data",
                "/wiki/Qualitative_property",
                "/wiki/Set_(mathematics)",
                "/wiki/Help:Pronunciation_respelling_key",
                "/wiki/Help:IPA/English",
                "/wiki/Help:Pronunciation_respelling_key",
                "/wiki/Help:IPA/English",
                "/wiki/Help:Pronunciation_respelling_key",
                "/wiki/Help:IPA/English",
                "/wiki/Shannon_entropy",
                "/wiki/Information",
                "/wiki/Homelessness",
                "/wiki/Literacy",
                "/wiki/Unemployment_rate",
                "/wiki/Crime_rate",
                "/wiki/Stock_price",
                "/wiki/Scientific_research",
                "/wiki/Digital_economy",
                "/wiki/Petroleum",
                "/wiki/Experimental_data",
                "/wiki/In_situ",
                "/wiki/Field_work",
                "/wiki/Outlier",
                "/wiki/Character_(computing)",
                "/wiki/Number",
                "/wiki/Raw_data",
                "/wiki/Data_processing",
                "/wiki/Code",
                "/wiki/Knowledge_representation_and_reasoning",
                "/wiki/Knowledge",
                "/wiki/Information",
                "/wiki/Concept",
                "/wiki/Data_visualization",
                "/wiki/Data_analysis",
                "/wiki/Data_reporting",
                "/wiki/Measurement",
                "/wiki/Mass_noun",
                "/wiki/Data_(word)",
                "/wiki/Altimeter",
                "/wiki/Mount_Everest",
                "/wiki/Knowledge",
                "/wiki/Wisdom",
                "/wiki/Knowledge",
                "/wiki/Information",
                "/wiki/Sign",
                "/wiki/Truth",
                "/wiki/Social_services",
                "/wiki/Marketing",
                "/wiki/Metadata",
                "/wiki/Lisp_(programming_language)",
                "/wiki/Computer_program",
                "/wiki/Alphabet",
                "/wiki/Computer",
                "/wiki/Analog_computer",
                "/wiki/Johanna_Drucker"
            ],
            "text": "Although data is also increasingly used in other fields, it has been suggested that the highly interpretive nature of them might be at odds with the ethos of data as \"given\". Peter Checkland introduced the term capta (from the Latin capere, \u201cto take\u201d) to distinguish between an immense number of possible data and a sub-set of them, to which attention is oriented.[13] Johanna Drucker has argued that since the humanities affirm knowledge production as \"situated, partial, and constitutive,\" using data may introduce assumptions that are counterproductive, for example that phenomena are discrete or are observer-independent.[14] The term capta, which emphasizes the act of observation as constitutive, is offered as an alternative to data for visual representations in the humanities.\nGathering data can be accomplished through a primary source (the researcher is the first person to obtain the data) or a secondary source (the researcher obtains \nthe data that has already been collected by other sources, such as data disseminated in a scientific journal). Data analysis methodologies vary and include data triangulation \nand data percolation.[12] The latter offers an articulate method of collecting, classifying and analyzing data using five possible angles of analysis (at least three) in order to maximize \nthe research's objectivity and permit an understanding of the phenomena under investigation as complete as possible: qualitative and quantitative methods, literature reviews \n(including scholarly articles), interviews with experts, and computer simulation. The data are thereafter \"percolated\" using a series of pre-determined steps so as to extract \nthe most relevant information.\nMechanical computing devices are classified according to the means by which they represent data. An analog computer represents a datum as a voltage, distance, position, or other physical quantity. A digital computer represents a piece of data as a sequence of symbols drawn from a fixed alphabet. The most common digital computers use a binary alphabet, that is, an alphabet of two characters, typically denoted \"0\" and \"1\". More familiar representations, such as numbers or letters, are then constructed from the binary alphabet. Some special forms of data are distinguished. A computer program is a collection of data, which can be interpreted as instructions. Most computer languages make a distinction between programs and the other data on which programs operate, but in some languages, notably Lisp and similar languages, programs are essentially indistinguishable from other data. It is also useful to distinguish metadata, that is, a description of other data. A similar yet earlier term for metadata is \"ancillary data.\"  The prototypical example of metadata is the library catalog, which is a description of the contents of books.\nBefore the development of computing devices and machines, only people could collect data and impose patterns on it. Since the development of computing devices and machines, these devices can also collect data. In the 2010s, computers are widely used in many fields to collect data and sort or process it, in disciplines ranging from marketing, analysis of social services usage by citizens to scientific research. These patterns in data are seen as information which can be used to enhance knowledge. These patterns may be interpreted as \"truth\" (though \"truth\" can be a subjective concept), and may be authorized as aesthetic and ethical criteria in some disciplines or cultures. Events that leave behind perceivable physical or virtual remains can be traced back through data. Marks are no longer considered data once the link between the mark and observation is broken.[11]\nData is often assumed to be the least abstract concept, information the next least, and knowledge the most abstract.[7] In this view, data becomes information by interpretation; e.g., the height of Mount Everest is generally considered \"data\", a book on Mount Everest geological characteristics may be considered \"information\", and a climber's guidebook containing practical information on the best way to reach Mount Everest's peak may be considered \"knowledge\". \"Information\" bears a diversity of meanings that ranges from everyday usage to technical use. This view, however, has also been argued to provide an upside-down model of the relation between data, information, and knowledge.[8] Generally speaking, the concept of information is closely related to notions of constraint, communication, control, data, form, instruction, knowledge, meaning, mental stimulus, pattern, perception, and representation. Beynon-Davies uses the concept of a sign to differentiate between data and information; data is a series of symbols, while information occurs when the symbols are used to refer to something.[9][10]\nData, information, knowledge and wisdom are closely related concepts, but each has its own role in relation to the other, and each term has its own meaning. According to a common view, data is collected and analyzed; data only becomes information suitable for making decisions once it has been analyzed in some fashion.[6] Knowledge is derived from extensive amounts of experience dealing with information on a subject. For example, the height of Mount Everest is generally considered data. The height can be recorded precisely with an altimeter and entered into a database. This data may be included in a book along with other data on Mount Everest to describe the mountain in a manner useful for those who wish to make a decision about the best method to climb it. Using an understanding based on experience climbing mountains to advise persons on the way to reach Mount Everest's peak may be seen as \"knowledge\". Some complement the series \"data\", \"information\" and \"knowledge\" with \"wisdom\", which would mean the status of a person in possession of a certain \"knowledge\" who also knows under which circumstances is good to use it.\nThe Latin word data is the plural of datum, \"(thing) given,\" neuter past participle of dare \"to give\".[4]  Data may be used as a plural noun in this sense, with some writers\u2014usually scientific writers\u2014in the 20th century using datum in the singular and data for plural. However, in non-specialist, everyday writing, \"data\" is most commonly used in the singular, as a mass noun (like \"information\", \"sand\" or \"rain\").[5]\nThe first English use of the word \"data\" is from the 1640s. The word \"data\" was first used to mean \"transmissible and storable computer information\" in 1946. The expression \"data processing\" was first used in 1954.[4]\nData is measured, collected and reported, and analyzed, whereupon it can be visualized using graphs, images or other analysis tools. Data as a general concept refers to the fact that some existing information or knowledge is represented or coded in some form suitable for better usage or processing. Raw data (\"unprocessed data\") is a collection of numbers or characters before it has been \"cleaned\" and corrected by researchers. Raw data needs to be corrected to remove outliers or obvious instrument or data entry errors (e.g., a thermometer reading from an outdoor Arctic location recording a tropical temperature).  Data processing commonly occurs by stages, and the \"processed data\" from one stage may be considered the \"raw data\" of the next stage. Field data is raw data that is collected in an uncontrolled \"in situ\" environment. Experimental data is data that is generated within the context of a scientific investigation by observation and recording. Data has been described as the new oil of the digital economy.[2][3]\nWhile the concept of data is commonly associated with scientific research, data is collected by a huge range of organizations and institutions, including businesses (e.g., sales data, revenue, profits, stock price), governments (e.g., crime rates, unemployment rates, literacy rates) and non-governmental organizations (e.g., censuses of the number of homeless people by non-profit organizations).\nData and information are often used interchangeably; however, the extent to which a set of data is informative to someone depends on the extent to which it is unexpected by that person. The amount of information content in a data stream may be characterized by its Shannon entropy.\nData (/\u02c8de\u026at\u0259/ DAY-t\u0259, /\u02c8d\u00e6t\u0259/ DAT-\u0259, /\u02c8d\u0251\u02d0t\u0259/ DAH-t\u0259)[1] is a set of values of qualitative or quantitative variables.\n",
            "title": "Data",
            "url": "https://en.wikipedia.org/wiki/Data"
        },
        {
            "desc_links": [
                "/wiki/Regression_analysis",
                "/wiki/Relation_(mathematics)",
                "/wiki/Estimator",
                "/wiki/Statistical_parameter",
                "/wiki/Statistics"
            ],
            "desc_text": "b'Estimation theory is a branch of statistics that deals with estimating the values of parameters based on measured empirical data that has a random component.  The parameters describe an underlying physical setting in such a way that their value affects the distribution of the measured data. An estimator attempts to approximate the unknown parameters using the measurements. When the data consist of multiple variables and one is estimating the relationship between them, estimation is known as regression analysis.\\n'b'In estimation theory, two approaches are generally considered.[1]\\n'",
            "links": [
                "/wiki/Regression_analysis",
                "/wiki/Relation_(mathematics)",
                "/wiki/Estimator",
                "/wiki/Statistical_parameter",
                "/wiki/Statistics",
                "/wiki/Radar",
                "/wiki/Signal_(electrical_engineering)",
                "/wiki/Noise_(physics)",
                "/wiki/Vector_(geometric)",
                "/wiki/Random_vector",
                "/wiki/Statistical_sample",
                "/wiki/Probability_mass_function",
                "/wiki/Probability_density_function",
                "/wiki/Bayesian_probability",
                "/wiki/Bayesian_statistics",
                "/wiki/Minimum_mean_squared_error",
                "/wiki/Expected_value",
                "/wiki/Natural_logarithm",
                "/wiki/Derivative",
                "/wiki/Fisher_information",
                "/wiki/Cram%C3%A9r%E2%80%93Rao_lower_bound",
                "/wiki/Likelihood_functions",
                "/wiki/Maximum_likelihood",
                "/wiki/World_War_II",
                "/wiki/German_tank_problem",
                "/wiki/Sample_size",
                "/wiki/Sample_maximum",
                "/wiki/Maximum_likelihood",
                "/wiki/Fisher_information",
                "/wiki/Optimization_(mathematics)",
                "/wiki/Probability",
                "/wiki/Noise_(physics)"
            ],
            "text": "Measured data are likely to be subject to noise or uncertainty and it is through statistical probability that optimal solutions are sought to extract as much information from the data as possible.\nNumerous fields require the use of estimation theory.\nSome of these fields include (but are by no means limited to):\nThe sample maximum is the maximum likelihood estimator for the population maximum, but, as discussed above, it is biased.\nThis has a variance of[2]\nthe gap being added to compensate for the negative bias of the sample maximum as an estimator for the population maximum.[note 1]\nThe formula may be understood intuitively as;\nwhere m is the sample maximum and k is the sample size, sampling without replacement.[2][3] This problem is commonly known as the German tank problem, due to application of maximum estimation to estimates of German tank production during World War II.\nOne of the simplest non-trivial examples of estimation is the estimation of the maximum of a uniform distribution. It is used as a hands-on classroom exercise and to illustrate basic principles of estimation theory. Further, in the case of estimation based on a single sample, it demonstrates philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions.\nresults in\nFinally, putting the Fisher information into\nTaking the second derivative\nand copying from above\nTo find the Cram\u00e9r\u2013Rao lower bound (CRLB) of the sample mean estimator, it is first necessary to find the Fisher information number\nThis results in the maximum likelihood estimator\nand setting it to zero\nTaking the first derivative of the log-likelihood function\nand the maximum likelihood estimator is\nTaking the natural logarithm of the pdf\nIt would seem that the sample mean is a better estimator since its variance is lower for every\u00a0N\u00a0>\u00a01.\nand\nAt this point, these two estimators would appear to perform the same.\nHowever, the difference between them becomes apparent when comparing the variances.\nand\nThe model for the signal is then\nCommonly used estimators (estimation methods) and topics related to them include:\nas the basis for optimality.  This error term is then squared and the expected value of this squared value is minimized for the MMSE estimator.\nOne common estimator is the minimum mean squared error (MMSE) estimator, which utilizes the error between the estimated parameters and the actual value of the parameters\nIt is also possible for the parameters themselves to have a probability distribution (e.g., Bayesian statistics). It is then necessary to define the Bayesian probability\nwhose values are to be estimated. Third, the continuous probability density function (pdf) or its discrete counterpart, the probability mass function (pmf), of the underlying distribution that generated the data must be stated conditional on the values of the parameters:\nSecondly, there are M parameters\nFor a given model, several statistical \"ingredients\" are needed so the estimator can be implemented. The first is a statistical sample \u2013 a set of data points taken from a random vector (RV) of size N. Put into a vector,\nAs another example, in electrical communication theory, the measurements which contain information regarding the parameters of interest are often associated with a noisy signal.\nOr, for example, in radar the aim is to find the range of objects (airplanes, boats, etc.) by analyzing the two-way transit timing of received echoes of transmitted pulses. Since the reflected pulses are unavoidably embedded in electrical noise, their measured values are randomly distributed, so that the transit time must be estimated.\nFor example, it is desired to estimate the proportion of a population of voters who will vote for a particular candidate.  That proportion is the parameter sought; the estimate is based on a small random sample of voters. Alternatively, it is desired to estimate the probability of a voter voting for a particular candidate, based on some demographic features, such as age; this estimates a relationship, and thus is a regression question.\nIn estimation theory, two approaches are generally considered.[1]\nEstimation theory is a branch of statistics that deals with estimating the values of parameters based on measured empirical data that has a random component.  The parameters describe an underlying physical setting in such a way that their value affects the distribution of the measured data. An estimator attempts to approximate the unknown parameters using the measurements. When the data consist of multiple variables and one is estimating the relationship between them, estimation is known as regression analysis.\n",
            "title": "Estimation theory",
            "url": "https://en.wikipedia.org/wiki/Estimation_theory"
        },
        {
            "desc_links": [
                "/wiki/System",
                "/wiki/Ancient_Greek_language",
                "/wiki/Attribute_(disambiguation)",
                "/wiki/Function_(disambiguation)#Math,_computing_and_engineering",
                "/wiki/Variable_(disambiguation)",
                "/wiki/Axiom",
                "/wiki/Property_(disambiguation)#Philosophy_and_science",
                "/wiki/Argument",
                "/wiki/Linguistics",
                "/wiki/Logic",
                "/wiki/Statistics",
                "/wiki/Engineering",
                "/wiki/Computer_programming",
                "/wiki/Computing",
                "/wiki/Mathematics"
            ],
            "desc_text": "b'A parameter (from the Ancient Greek \\xcf\\x80\\xce\\xb1\\xcf\\x81\\xce\\xac, para: \"beside\", \"subsidiary\"; and \\xce\\xbc\\xce\\xad\\xcf\\x84\\xcf\\x81\\xce\\xbf\\xce\\xbd, metron: \"measure\"), generally, is any characteristic that can help in defining or classifying a particular system (meaning an event, project, object, situation, etc.). That is, a parameter is an element of a system that is useful, or critical, when identifying the system, or when evaluating its performance, status, condition, etc.\\n'b'Parameter has more specific meanings within various disciplines, including mathematics, computing and computer programming, engineering, statistics, logic and linguistics. Within and across these fields, careful distinction must be maintained of the different usages of the term parameter and of other terms often associated with it, such as argument,  property, axiom, variable, function, attribute, etc.[1]\\n'",
            "links": [
                "/wiki/System",
                "/wiki/Ancient_Greek_language",
                "/wiki/Attribute_(disambiguation)",
                "/wiki/Function_(disambiguation)#Math,_computing_and_engineering",
                "/wiki/Variable_(disambiguation)",
                "/wiki/Axiom",
                "/wiki/Property_(disambiguation)#Philosophy_and_science",
                "/wiki/Argument",
                "/wiki/Linguistics",
                "/wiki/Logic",
                "/wiki/Statistics",
                "/wiki/Engineering",
                "/wiki/Computer_programming",
                "/wiki/Computing",
                "/wiki/Mathematics",
                "/wiki/Quadratic_function",
                "/wiki/Variable_(mathematics)",
                "/wiki/Argument_of_a_function",
                "/wiki/Mathematical_function",
                "/wiki/Falling_factorial_power",
                "/wiki/Polynomial#Polynomial_functions",
                "/wiki/Currying",
                "/wiki/Indexed_family",
                "/wiki/Probability_distribution",
                "/wiki/Mathematical_model",
                "/wiki/Curve",
                "/wiki/Analytic_geometry",
                "/wiki/Independent_variable",
                "/wiki/Parametric_equations",
                "/wiki/Mathematical_analysis",
                "/wiki/Bound_variable",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Bayesian_probability",
                "/wiki/Frequentist_inference",
                "/wiki/Hypothesis_testing",
                "/wiki/Statistical_estimation",
                "/wiki/Econometrics",
                "/wiki/Statistics",
                "/wiki/Statistical_population",
                "/wiki/Statistic",
                "/wiki/Estimand",
                "/wiki/Estimator",
                "/wiki/Estimation_theory",
                "/wiki/Correlation_and_dependence",
                "/wiki/Pearson_product-moment_correlation_coefficient",
                "/wiki/Spearman%27s_rank_correlation_coefficient",
                "/wiki/Parametric_statistics",
                "/wiki/Non-parametric_statistics",
                "/wiki/Probability_distribution",
                "/wiki/Probability_mass_function",
                "/wiki/Poisson_distribution",
                "/wiki/Probability_distribution",
                "/wiki/Random_variable",
                "/wiki/Probability_distribution",
                "/wiki/Probability_theory",
                "/wiki/Radioactivity",
                "/wiki/Normal_distribution",
                "/wiki/Statistical_parameter",
                "/wiki/Cumulant",
                "/wiki/Moment_(mathematics)",
                "/wiki/Parameter_(computer_programming)#Parameters_and_arguments",
                "/wiki/Parameter_(computer_programming)",
                "/wiki/Computer_programming",
                "/wiki/Parameter_(computer_programming)#Alternative_convention_in_Eiffel",
                "/wiki/Eiffel_(programming_language)",
                "/wiki/C_(programming_language)",
                "/wiki/Combinatory_logic",
                "/wiki/Lambda_calculus",
                "/wiki/Functional_programming",
                "/wiki/Engineering",
                "/wiki/Percentile",
                "/wiki/Statistics",
                "/wiki/Microbiology",
                "/wiki/Chemistry",
                "/wiki/Principles_and_Parameters",
                "/wiki/Universal_Grammar",
                "/wiki/Bound_variable",
                "/wiki/Free_variable",
                "/wiki/Lawrence_Paulson",
                "/wiki/Dag_Prawitz",
                "/wiki/Logic",
                "/wiki/George_Perle",
                "/wiki/Paul_Lansky",
                "/wiki/Serial_music",
                "/wiki/Timbre",
                "/wiki/Duration_(music)",
                "/wiki/Loudness",
                "/wiki/Pitch_(music)"
            ],
            "text": "In music theory, a parameter denotes an element which may be manipulated (composed), separately from the other elements. The term is used particularly for pitch, loudness, duration, and timbre, though theorists or composers have sometimes considered other musical aspects as parameters. The term is particularly used in serial music, where each parameter may follow some specified series. Paul Lansky and George Perle criticized the extension of the word \"parameter\" to this sense, since it is not closely related to its mathematical sense,[4] but it remains common.  The term is also common in music production, as the functions of audio processing units (such as the attack, release, ratio, threshold, and other variables on a compressor) are defined by parameters specific to the type of unit (compressor, equalizer, delay, etc.).\nIn logic, the parameters passed to (or operated on by) an open predicate are called parameters by some authors (e.g., Prawitz, \"Natural Deduction\"; Paulson, \"Designing a theorem prover\"). Parameters locally defined within the predicate are called variables. This extra distinction pays off when defining substitution (without this distinction special provision must be made to avoid variable capture). Others (maybe most) just call parameters passed to (or operated on by) an open predicate variables, and when defining substitution have to distinguish between free variables and bound variables.\nWithin linguistics, the word \"parameter\" is almost exclusively used to denote a binary switch in a Universal Grammar within a Principles and Parameters framework.\nIn environmental science and particularly in chemistry and microbiology, a parameter is used to describe a discrete chemical or microbiological entity that can be assigned a value: commonly a concentration, but may also be a logical entity (present or absent), a statistical result such as a 95%ile value or in some cases a subjective value.\nThe term can also be used in engineering contexts, however, as it is typically used in the physical sciences.\n\"Speaking generally, properties are those physical quantities which directly describe the physical attributes of the system; parameters are those combinations of the properties which suffice to determine the response of the system. Properties can have all sorts of dimensions, depending upon the system being considered; parameters are dimensionless, or have the dimension of time or its reciprocal.\"[3]\nIn engineering (especially involving data acquisition) the term parameter sometimes loosely refers to an individual measured item. This usage isn't consistent, as sometimes the term channel refers to an individual measured item, with parameter referring to the setup information about that channel.\nThese concepts are discussed in a more precise way in functional programming and its foundational disciplines, lambda calculus and combinatory logic. Terminology varies between languages; some computer languages such as C define parameter and argument as given here, while Eiffel uses an alternative convention.\n3 is the actual parameter (the argument) for evaluation by the defined function; it is a given value (actual value) that is substituted for the formal parameter of the defined function. (In casual usage the terms parameter and argument might inadvertently be interchanged, and thereby used incorrectly.)\nWhen the function is evaluated for a given value, as in\nx is the formal parameter (the parameter) of the defined function.\nFor example, in the definition of a function such as\nIn computer programming, two notions of parameter are commonly used, and are referred to as parameters and arguments\u2014or more formally as a formal parameter and an actual parameter.\nIn computing, a parameter is defined as  \"a reference or value that is passed to a function, procedure, subroutine, command, or program\".[1]  For example, the name of a file, (a parameter), is passed to a computer program, which then performs a specific function; that is, a program may be passed the name of a file on which it will perform the specific function.\nIt is possible to use the sequence of moments (mean, mean square, ...) or cumulants (mean, variance, ...) as parameters for a probability distribution: see Statistical parameter.\nIn these above examples, the distributions of the random variables are completely specified by the type of distribution, i.e. Poisson or normal, and the parameter values, i.e. mean and variance.  In such a case, we have a parameterized distribution.\nAnother common distribution is the normal distribution, which has as parameters the mean \u03bc and the variance \u03c3\u00b2.\nFor instance, suppose we have a radioactive sample that emits, on average, five particles every ten minutes.  We take measurements of how many particles the sample emits over ten-minute periods.  The measurements exhibit different values of k, and if the sample behaves according to Poisson statistics, then each value of k will come up in a proportion given by the probability mass function above.  From measurement to measurement, however, \u03bb remains constant at 5.  If we do not alter the system, then the parameter \u03bb is unchanged from measurement to measurement; if, on the other hand, we modulate the system by replacing the sample with a more radioactive one, then the parameter \u03bb would increase.\nIn probability theory, one may describe the distribution of a random variable as belonging to a family of probability distributions, distinguished from each other by the values of a finite number of parameters. For example, one talks about \"a Poisson distribution with mean value \u03bb\".  The function defining the distribution (the probability mass function) is:\nIt is possible to make statistical inferences without assuming a particular parametric family of probability distributions. In that case, one speaks of non-parametric statistics as opposed to the parametric statistics just described. For example, a test based on Spearman's rank correlation coefficient would be called non-parametric since the statistic is computed from the rank-order of the data disregarding their actual values (and thus regardless of the distribution they were sampled from), whereas those based on the Pearson product-moment correlation coefficient are parametric tests since it is computed directly from the data values and thus estimates the parameter known as the population correlation.\nIn estimation theory of statistics, \"statistic\" or estimator refers to samples, whereas \"parameter\" or estimand refers to populations, where the samples are taken from. A statistic is a numerical characteristic of a sample that can be used as an estimate of the corresponding parameter, the numerical characteristic of the population from which the sample was drawn.\nIn statistics and econometrics, the probability framework above still holds, but attention shifts to estimating the parameters of a distribution based on observed data, or testing hypotheses about them. In frequentist estimation parameters are considered \"fixed but unknown\", whereas in Bayesian estimation they are treated as random variables, and their uncertainty is described as a distribution.[citation needed]\nIn this formula, t is the argument of the function F, and on the right-hand side the parameter on which the integral depends. When evaluating the integral, t is held constant, and so it is considered to be a parameter.  If we are interested in the value of F for different values of t, we then consider t to be a variable. The quantity x is a dummy variable or variable of integration (confusingly, also sometimes called a parameter of integration).\nIn mathematical analysis, integrals dependent on a parameter are often considered. These are of the form\nHence these equations, which might be called functions elsewhere are in analytic geometry characterized as parametric equations and the independent variables are considered as parameters.\nIn analytic geometry, curves are often given as the image of some function. The argument of the function is invariably called \"the parameter\". A circle of radius 1 centered at the origin can be specified in more than one form:\nIn the context of a mathematical model, such as a probability distribution, the distinction between variables and parameters was described by Bard as follows:\nSometimes it is useful to consider all functions with certain parameters as parametric family, i.e. as an indexed family of functions. Examples from probability theory are given further below.\nas the most fundamental object being considered, then defining functions with fewer variables from the main one by means of currying.\ndefines a polynomial function of n (when k is considered a parameter), but is not a polynomial function of k (when n is considered a parameter). Indeed, in the latter case, it is only defined for non-negative integer arguments. More formal presentations of such situations typically start out with a function of several variables (including all those that might sometimes be called \"parameters\") such as\nIn some informal situations it is a matter of convention (or historical accident) whether some or all of the symbols in a function definition are called parameters. However, changing the status of symbols between parameter and variable changes the function as a mathematical object. For instance, the notation for the falling factorial power\nHere, the variable x designates the function's argument, but a, b, and c are parameters that determine which particular quadratic function is being considered. A parameter could be incorporated into the function name to indicate its dependence on the parameter. For instance, one may define the base-b logarithm by the formula\nMathematical functions have one or more arguments that are designated in the definition by variables. A function definition can also contain parameters, but unlike variables, parameters are not listed among the arguments that the function takes. When parameters are present, the definition actually defines a whole family of functions, one for every valid set of values of the parameters. For instance, one could define a general quadratic function by declaring\nParameter has more specific meanings within various disciplines, including mathematics, computing and computer programming, engineering, statistics, logic and linguistics. Within and across these fields, careful distinction must be maintained of the different usages of the term parameter and of other terms often associated with it, such as argument,  property, axiom, variable, function, attribute, etc.[1]\nA parameter (from the Ancient Greek \u03c0\u03b1\u03c1\u03ac, para: \"beside\", \"subsidiary\"; and \u03bc\u03ad\u03c4\u03c1\u03bf\u03bd, metron: \"measure\"), generally, is any characteristic that can help in defining or classifying a particular system (meaning an event, project, object, situation, etc.). That is, a parameter is an element of a system that is useful, or critical, when identifying the system, or when evaluating its performance, status, condition, etc.\n",
            "title": "Parameter",
            "url": "https://en.wikipedia.org/wiki/Parameters"
        },
        {
            "desc_links": [
                "/wiki/Factor_analysis",
                "/wiki/Principal_component_analysis",
                "/wiki/Linear_discriminant_analysis",
                "/wiki/Support_vector_machine",
                "/wiki/Perceptron",
                "/wiki/Logistic_regression",
                "/wiki/Linear_classifier",
                "/wiki/Regression_coefficient",
                "/wiki/Linear_regression",
                "/wiki/Dependent_variable",
                "/wiki/Independent_variable",
                "/wiki/Linear_combination",
                "/wiki/Linear_function",
                "/wiki/Machine_learning",
                "/wiki/Statistics"
            ],
            "desc_text": "b'In statistics and in machine learning, a linear predictor function is a linear function (linear combination) of a set of coefficients and explanatory variables (independent variables), whose value is used to predict the outcome of a dependent variable.  This sort of function usually comes in linear regression, where the coefficients are called regression coefficients. However, they also occur in various types of linear classifiers (e.g. logistic regression, perceptrons, support vector machines, and linear discriminant analysis), as well as in various other models, such as principal component analysis and factor analysis.  In many of these models, the coefficients are referred to as \"weights\".\\n'",
            "links": [
                "/wiki/Factor_analysis",
                "/wiki/Principal_component_analysis",
                "/wiki/Linear_discriminant_analysis",
                "/wiki/Support_vector_machine",
                "/wiki/Perceptron",
                "/wiki/Logistic_regression",
                "/wiki/Linear_classifier",
                "/wiki/Regression_coefficient",
                "/wiki/Linear_regression",
                "/wiki/Dependent_variable",
                "/wiki/Independent_variable",
                "/wiki/Linear_combination",
                "/wiki/Linear_function",
                "/wiki/Machine_learning",
                "/wiki/Statistics",
                "/wiki/Dot_product",
                "/wiki/Continuous_variable",
                "/wiki/Linear_regression",
                "/wiki/Interaction_variable",
                "/wiki/Data_analyst",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Conditional_probability",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Random_variable",
                "/wiki/Real-valued",
                "/wiki/Polynomial",
                "/wiki/Polynomial_regression",
                "/wiki/Basis_function",
                "/wiki/Linear_regression",
                "/wiki/Radial_basis_function",
                "/wiki/Normal_distribution",
                "/wiki/Gaussian_function",
                "/wiki/K-nearest_neighbor_algorithm",
                "/wiki/Nearest_neighbor_interpolation",
                "/wiki/Blood_type",
                "/wiki/Indicator_variable",
                "/wiki/Dummy_variable_(statistics)",
                "/wiki/Discrete_variable",
                "/wiki/Blood_pressure",
                "/wiki/Continuous_variable",
                "/wiki/Categorical_variable",
                "/wiki/Binary_variable",
                "/wiki/Real-valued",
                "/wiki/Statistical_data_type",
                "/wiki/Regularization_(mathematics)",
                "/wiki/Identifiable"
            ],
            "text": "Note that, for K categories, not all K dummy variables are independent of each other.  For example, in the above blood type example, only three of the four dummy variables are independent, in the sense that once the values of three of the variables are known, the fourth is automatically determined.  Thus, it's really only necessary to encode three of the four possibilities as dummy variables, and in fact if all four possibilities are encoded, the overall model becomes non-identifiable.  This causes problems for a number of methods, such as the simple closed-form solution used in linear regression.  The solution is either to avoid such cases by eliminating one of the dummy variables, and/or introduce a regularization constraint (which necessitates a more powerful, typically iterative, method for finding the optimal coefficients).\nThe explanatory variables may be of any type: real-valued, binary, categorical, etc.  The main distinction is between continuous variables (e.g. income, age, blood pressure, etc.) and discrete variables (e.g. sex, race, political party, etc.).  Discrete variables referring to more than two possible choices are typically coded using dummy variables (or indicator variables), i.e. separate explanatory variables taking the value 0 or 1 are created for each possible value of the discrete variable, with a 1 meaning \"variable does have the given value\" and a 0 meaning \"variable does not have the given value\".  For example, a four-way discrete variable of blood type with the possible values \"A, B, AB, O\" would be converted to separate two-way dummy variables, \"is-A, is-B, is-AB, is-O\", where only one of them has the value 1 and all the rest have the value 0.  This allows for separate regression coefficients to be matched for each possible value of the discrete variable.\nA possible usage of RBF's is to create one for every observed data point.  This means that the result of an RBF applied to a new data point will be close to 0 unless the new point is near to the point around which the RBF was applied.  That is, the application of the radial basis functions will pick out the nearest point, and its regression coefficient will dominate.  The result will be a form of nearest neighbor interpolation, where predictions are made by simply using the prediction of the nearest observed data point, possibly interpolating between multiple nearby data points when they are all similar distances away.  This type of nearest neighbor method for prediction is often considered diametrically opposed to the type of prediction used in standard linear regression: But in fact, the transformations that can be applied to the explanatory variables in a linear predictor function are so powerful that even the nearest neighbor method can be implemented as a type of linear regression.\nwhich drops off rapidly as the distance from c increases.\nAn example is the Gaussian RBF, which has the same functional form as the normal distribution:\nThere is no particular need for the inputs to basis functions to be univariate or single-dimensional (or their outputs, for that matter, although in such a case, a K-dimensional output value is likely to be treated as K separate scalar-output basis functions).  An example of this is radial basis functions (RBF's), which compute some transformed version of the distance to some fixed point:\nThis example shows that a linear predictor function can actually be much more powerful than it first appears: It only really needs to be linear in the coefficients.  All sorts of non-linear functions of the explanatory variables can be fit by the model.\nand then standard linear regression is run.  The basis functions in this example would be\nIn this case, for each data point i, a set of explanatory variables is created as follows:\nWhen a fixed set of nonlinear functions are used to transform the value(s) of a data point, these functions are known as basis functions.  An example is polynomial regression, which uses a linear predictor function to fit an arbitrary degree polynomial relationship (up to a given order) between two sets of data points (i.e. a single real-valued explanatory variable and a related real-valued dependent variable), by adding multiple explanatory variables corresponding to various powers of the existing explanatory variable.  Mathematically, the form looks like this:\nAlthough the outcomes (dependent variables) to be predicted are assumed to be random variables, the explanatory variables themselves are usually not assumed to be random[citation needed].  Instead, they are assumed to be fixed values, and any random variables (e.g. the outcomes) are assumed to be conditional on them[citation needed].  As a result, the data analyst is free to transform the explanatory variables in arbitrary ways, including creating multiple copies of a given explanatory variable, each transformed using a different function.  Other common techniques are to create new explanatory variables in the form of interaction variables by taking products of two (or sometimes more) existing explanatory variables.\nwhere\nIn some models (standard linear regression, in particular), the equations for each of the data points i = 1, ..., n are stacked together and written in vector form as\nAn example of the usage of a linear predictor function is in linear regression, where each data point is associated with a continuous outcome yi, and the relationship written\nAn equivalent form using matrix notation is as follows:\nusing the notation for a dot product between two vectors.\nThis makes it possible to write the linear predictor function as follows:\nIt is common to write the predictor function in a more compact form as follows:\nIn statistics and in machine learning, a linear predictor function is a linear function (linear combination) of a set of coefficients and explanatory variables (independent variables), whose value is used to predict the outcome of a dependent variable.  This sort of function usually comes in linear regression, where the coefficients are called regression coefficients. However, they also occur in various types of linear classifiers (e.g. logistic regression, perceptrons, support vector machines, and linear discriminant analysis), as well as in various other models, such as principal component analysis and factor analysis.  In many of these models, the coefficients are referred to as \"weights\".\n",
            "title": "Linear predictor function",
            "url": "https://en.wikipedia.org/wiki/Linear_predictor_function"
        },
        {
            "desc_links": [
                "/wiki/Collinear",
                "/wiki/Covariate",
                "/wiki/Linear_regression",
                "/wiki/Ridge_regression",
                "/wiki/Least_squares",
                "/wiki/Robert_Tibshirani",
                "/wiki/Statistical_model",
                "/wiki/Regularization_(mathematics)",
                "/wiki/Variable_selection",
                "/wiki/Regression_analysis",
                "/wiki/Machine_learning",
                "/wiki/Statistics",
                "/wiki/Convex_analysis",
                "/wiki/Bayesian_statistics",
                "/wiki/Geometry",
                "/wiki/M-estimator",
                "/wiki/Proportional_hazards_model",
                "/wiki/Generalized_estimating_equation",
                "/wiki/Generalized_linear_model",
                "/wiki/Basis_pursuit_denoising"
            ],
            "desc_text": "b'In statistics and machine learning, lasso (least absolute shrinkage and selection operator) (also Lasso or LASSO) is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces.  It was originally introduced in geophysics literature in 1986 but was independently rediscovered and popularized by Robert Tibshirani in 1996 who coined the term and provided further insights into the observed performance.[1][2] Lasso was originally formulated for least squares models and this simple case reveals a substantial amount about the behavior of the estimator, including its relationship to ridge regression and best subset selection and the connections between lasso coefficient estimates and so-called soft thresholding.  It also reveals that (like standard linear regression) the coefficient estimates need not be unique if covariates are collinear.\\n'b'Though originally defined for least squares, lasso regularization is easily extended to a wide variety of statistical models including generalized linear models, generalized estimating equations, proportional hazards models, and M-estimators, in a straightforward fashion.[1][3] Lasso\\xe2\\x80\\x99s ability to perform subset selection relies on the form of the constraint and has a variety of interpretations including in terms of geometry, Bayesian statistics, and convex analysis.\\n'b'The LASSO is closely related to basis pursuit denoising.\\n'",
            "links": [
                "/wiki/Collinear",
                "/wiki/Covariate",
                "/wiki/Linear_regression",
                "/wiki/Ridge_regression",
                "/wiki/Least_squares",
                "/wiki/Robert_Tibshirani",
                "/wiki/Statistical_model",
                "/wiki/Regularization_(mathematics)",
                "/wiki/Variable_selection",
                "/wiki/Regression_analysis",
                "/wiki/Machine_learning",
                "/wiki/Statistics",
                "/wiki/Convex_analysis",
                "/wiki/Bayesian_statistics",
                "/wiki/Geometry",
                "/wiki/M-estimator",
                "/wiki/Proportional_hazards_model",
                "/wiki/Generalized_estimating_equation",
                "/wiki/Generalized_linear_model",
                "/wiki/Basis_pursuit_denoising",
                "/wiki/Overfitting",
                "/wiki/Regression_coefficients",
                "/wiki/Shrinkage_(statistics)",
                "/wiki/Ridge_regression",
                "/wiki/Stepwise_regression",
                "/wiki/Ridge_regression",
                "/wiki/Best_subset_selection",
                "/wiki/M-estimator",
                "/wiki/Proportional_hazards_model",
                "/wiki/Generalized_estimating_equation",
                "/wiki/Generalized_linear_model",
                "/wiki/Laplace_distribution",
                "/wiki/Cross-validation_(statistics)",
                "/wiki/Proximal_gradient_methods",
                "/wiki/Least-angle_regression",
                "/wiki/Subgradient_methods",
                "/wiki/Elastic_net_regularization",
                "/wiki/Elastic_net_regularization",
                "/wiki/Stochastic_gradient_descent",
                "/wiki/Gradient_descent",
                "/wiki/Least-angle_regression",
                "/wiki/Cross-validation_(statistics)"
            ],
            "text": "In addition to fitting the parameters, choosing the regularization parameter is also a fundamental part of using lasso.  Selecting it well is essential to the performance of lasso since it controls the strength of shrinkage and variable selection, which, in moderation can improve both prediction and interpretability.  However, if the regularization becomes too strong, important variables may be left out of the model and coefficients may be shrunk excessively, which can harm both predictive capacity and the inferences drawn about the system being studied.  LARS is unique in this regard as it generates complete regularization paths which makes determining the optimal value of the regularization parameter much more straightforward.[17] With other methods, cross-validation is typically used to select the parameter.  Additionally, a variety of heuristics related to choosing the regularization and optimization parameters are often used in order to attempt to improve performance further.\nThough the lasso penalty is not differentiable, a wide variety of techniques from convex analysis and optimization theory have been developed to extremize such functions. These include coordinate descent [16], subgradient methods, least-angle regression (LARS), and proximal gradient methods.[17] Subgradient methods, are the natural generalization of traditional methods such as gradient descent and stochastic gradient descent to the case in which the objective function is not differentiable at all points.  LARS is a method that is closely tied to lasso models, and in many cases allows them to be fit very efficiently, though it may not perform well in all circumstances.  Proximal methods have become popular because of their flexibility and performance and are an area of active research. The choice of method will depend on the particular lasso variant being used, the data, and the available resources.  However, proximal methods will generally perform well in most circumstances.\nThe adaptive lasso was introduced by Zou (2006, JASA) for linear regression and by Zhang and Lu (2007, Biometrika) for proportional hazards regression.\nThe efficient algorithm for minimization is based on piece-wise quadratic approximation of subquadratic growth (PQSQ).[15]\nwhere\nIn contrast, one can first cluster variables into highly correlated groups, and then extract a single representative covariate from each cluster.[11]\nThe first constraint is just the typical lasso constraint, but the second directly penalizes large changes with respect to the temporal or spatial structure, which forces the coefficients to vary in a smooth fashion that reflects the underlying logic of the system being studied. Clustered lasso[10] is a generalization to fused lasso that identifies and groups relevant covariates based on their effects (coefficients). The basic idea is to penalize the differences between the coefficients so that nonzero ones make clusters together. This can be modeled using the following regularization:\nIn some cases, the object being studied may have important spatial or temporal structure that must be accounted for during analysis, such as time series or image based data.  In 2005, Tibshirani and colleagues introduced the Fused lasso to extend the use of lasso to exactly this type of data.[9] The fused lasso objective function is\nIn 2006, Yuan and Lin introduced the group lasso in order to allow predefined groups of covariates to be selected into or out of a model together, so that all the members of a particular group are either included or not included.[6] While there are many settings in which this is useful, perhaps the most obvious is when levels of a categorical variable are coded as a collection of binary covariates.  In this case, it often doesn't make sense to include only a few levels of the covariate; the group lasso can ensure that all the variables encoding the categorical covariate are either included or excluded from the model together.  Another setting in which grouping is natural is in biological studies.  Since genes and proteins often lie in known pathways, an investigator may be more interested in which pathways are related to an outcome than whether particular individual genes are.  The objective function for the group lasso is a natural generalization of the standard lasso objective\nSo the result of the elastic net penalty is a combination of the effects of the lasso and Ridge penalties.\nletting\nSomewhat surprisingly, this problem can be written in a simple lasso form\nwhich is equivalent to solving\nIn 2005, Zou and Hastie introduced the elastic net to address several shortcomings of lasso.[5] When p\u00a0>\u00a0n (the number of covariates is greater than the sample size) lasso can select only n covariates (even when more are associated with the outcome) and it tends to select only one covariate from any set of highly correlated covariates.  Additionally, even when n\u00a0>\u00a0p, if the covariates are strongly correlated, ridge regression tends to perform better.\nA number of lasso variants have been created in order to remedy certain limitations of the original technique and to make the method more useful for particular problems.  Almost all of these focus on respecting or utilizing different types of dependencies among the covariates. Elastic net regularization adds an additional ridge regression-like penalty which improves performance when the number of predictors is larger than the sample size, allows the method to select strongly correlated variables together, and improves overall prediction accuracy.[5] Group lasso allows groups of related covariates to be selected as a single unit, which can be useful in settings where it does not make sense to include some covariates without others.[6] Further extensions of group lasso to perform variable selection within individual groups (sparse group lasso) and to allow overlap between groups (overlap group lasso) have also been developed.[7][8] Fused lasso can account for the spatial or temporal characteristics of a problem, resulting in estimates that better match the structure of the system being studied.[9] Lasso regularized models can be fit using a variety of techniques including subgradient methods, least-angle regression (LARS), and proximal gradient methods.  Determining the optimal value for the regularization parameter is an important part of ensuring that the model performs well; it is typically chosen using cross-validation.\nJust as ridge regression can be interpreted as linear regression for which the coefficients have been assigned normal prior distributions, lasso can be interpreted as linear regression for which the coefficients have Laplace prior distributions.  The Laplace distribution is sharply peaked at zero (its first derivative is discontinuous) and it concentrates its probability mass closer to zero than does the normal distribution.  This provides an alternative explanation of why lasso tends to set some coefficients to zero, while ridge regression does not.[1]\n\tAs discussed above, lasso can set coefficients to zero, while ridge regression, which appears superficially similar, cannot.  This is due to the difference in the shape of the constraint boundaries in the two cases.  Both lasso and ridge regression can be interpreted as minimizing the same objective function\nthe lasso regularized version of the estimator will be the solution to\nLasso regularization can be extended to a wide variety of objective functions such as those for generalized linear models, generalized estimating equations, proportional hazards models, and M-estimators in general, in the obvious way.[1][3] Given the objective function\nTherefore, the lasso estimates share features of the estimates from both ridge and best subset selection regression since they both shrink the magnitude of all the coefficients, like ridge regression, but also set some of them to zero, as in the best subset selection case.  Additionally, while ridge regression scales all of the coefficients by a constant factor, lasso instead translates the coefficients towards zero by a constant value and sets them to zero if they reach it.\nIt can also be compared to regression with best subset selection, in which the goal is to minimize\nyielding\nThis can be compared to ridge regression, where the objective is to minimize\nSome basic properties of the lasso estimator can now be considered.\nin the so-called Lagrangian form\nIt can be helpful to rewrite\nLasso was originally introduced in the context of least squares, and it can be instructive to consider this case first, since it illustrates many of lasso\u2019s properties in a straightforward setting.\nLasso is able to achieve both of these goals by forcing the sum of the absolute value of the regression coefficients to be less than a fixed value, which forces certain coefficients to be set to zero, effectively choosing a simpler model that does not include those coefficients.  This idea is similar to ridge regression, in which the sum of the squares of the coefficients is forced to be less than a fixed value, though in the case of ridge regression, this only shrinks the size of the coefficients, it does not set any of them to zero.\nPrior to lasso, the most widely used method for choosing which covariates to include was stepwise selection, which only improves prediction accuracy in certain cases, such as when only a few covariates have a strong relationship with the outcome.  However, in other cases, it can make prediction error worse.  Also, at the time, ridge regression was the most popular technique for improving prediction accuracy.  Ridge regression improves prediction error by shrinking large regression coefficients in order to reduce overfitting, but it does not perform covariate selection and therefore does not help to make the model more interpretable.\nThe LASSO is closely related to basis pursuit denoising.\nThough originally defined for least squares, lasso regularization is easily extended to a wide variety of statistical models including generalized linear models, generalized estimating equations, proportional hazards models, and M-estimators, in a straightforward fashion.[1][3] Lasso\u2019s ability to perform subset selection relies on the form of the constraint and has a variety of interpretations including in terms of geometry, Bayesian statistics, and convex analysis.\nIn statistics and machine learning, lasso (least absolute shrinkage and selection operator) (also Lasso or LASSO) is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces.  It was originally introduced in geophysics literature in 1986 but was independently rediscovered and popularized by Robert Tibshirani in 1996 who coined the term and provided further insights into the observed performance.[1][2] Lasso was originally formulated for least squares models and this simple case reveals a substantial amount about the behavior of the estimator, including its relationship to ridge regression and best subset selection and the connections between lasso coefficient estimates and so-called soft thresholding.  It also reveals that (like standard linear regression) the coefficient estimates need not be unique if covariates are collinear.\n",
            "title": "Lasso (statistics)",
            "url": "https://en.wikipedia.org/wiki/Lasso_(statistics)"
        },
        {
            "desc_links": [
                "/wiki/Non-linear_least_squares",
                "/wiki/Levenberg%E2%80%93Marquardt_algorithm",
                "/wiki/Machine_learning",
                "/wiki/Statistics",
                "/wiki/Ill-posed_problem",
                "/wiki/Regularization_(mathematics)",
                "/wiki/Andrey_Nikolayevich_Tikhonov",
                "/wiki/Residual_(numerical_analysis)",
                "/wiki/Eigenvalues",
                "/wiki/High-pass_filter",
                "/wiki/Low-pass_filters",
                "/wiki/Under-fitted",
                "/wiki/Underdetermined_system",
                "/wiki/Over-fitted",
                "/wiki/Overdetermined_system",
                "/wiki/Well-posed_problem",
                "/wiki/Ordinary_least_squares",
                "/wiki/Norm_(mathematics)#Euclidean_norm",
                "/wiki/Discrete_fourier_transform",
                "/wiki/Difference_operator",
                "/wiki/Norm_(mathematics)",
                "/wiki/Identity_matrix",
                "/wiki/Support_vector_machine",
                "/wiki/Logistic_regression",
                "/wiki/Statistical_classification"
            ],
            "desc_text": "b'Tikhonov regularization, named for Andrey Tikhonov, is the most commonly used method of regularization of ill-posed problems.  In statistics, the method is known as ridge regression, in machine learning it is known as weight decay, and with multiple independent discoveries, it is also variously known as the Tikhonov\\xe2\\x80\\x93Miller method, the Phillips\\xe2\\x80\\x93Twomey method, the constrained linear inversion method, and the method of linear regularization. It is related to the Levenberg\\xe2\\x80\\x93Marquardt algorithm for non-linear least-squares problems.\\n'b'Suppose that for a known matrix \\n  \\n    \\n      \\n        A\\n      \\n    \\n    {\\\\displaystyle A}\\n  \\n and vector \\n  \\n    \\n      \\n        \\n          b\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbf {b} }\\n  \\n, we wish to find a vector \\n  \\n    \\n      \\n        \\n          x\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbf {x} }\\n  \\n such that\\n'b'The standard approach is ordinary least squares linear regression. However, if no \\n  \\n    \\n      \\n        \\n          x\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbf {x} }\\n  \\n satisfies the equation or more than one \\n  \\n    \\n      \\n        \\n          x\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbf {x} }\\n  \\n does\\xe2\\x80\\x94that is, the solution is not unique\\xe2\\x80\\x94the problem is said to be ill posed. In such cases, ordinary least squares estimation leads to an overdetermined (over-fitted), or more often an underdetermined (under-fitted) system of equations.  Most real-world phenomena have the effect of low-pass filters in the forward direction where \\n  \\n    \\n      \\n        A\\n      \\n    \\n    {\\\\displaystyle A}\\n  \\n maps \\n  \\n    \\n      \\n        \\n          x\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbf {x} }\\n  \\n to \\n  \\n    \\n      \\n        \\n          b\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbf {b} }\\n  \\n.  Therefore, in solving the inverse-problem, the inverse mapping operates as a high-pass filter that has the undesirable tendency of amplifying noise (eigenvalues / singular values are largest in the reverse mapping where they were smallest in the forward mapping).  In addition, ordinary least squares implicitly nullifies every element of the reconstructed version of \\n  \\n    \\n      \\n        \\n          x\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbf {x} }\\n  \\n that is in the null-space of \\n  \\n    \\n      \\n        A\\n      \\n    \\n    {\\\\displaystyle A}\\n  \\n, rather than allowing for a model to be used as a prior for \\n  \\n    \\n      \\n        \\n          x\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbf {x} }\\n  \\n.\\nOrdinary least squares seeks to minimize the sum of squared residuals, which can be compactly written as\\n'b'where \\n  \\n    \\n      \\n        \\xe2\\x80\\x96\\n        \\xe2\\x8b\\x85\\n        \\n          \\xe2\\x80\\x96\\n          \\n            2\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\|\\\\cdot \\\\|_{2}}\\n  \\n is the Euclidean norm.\\n'b'In order to give preference to a particular solution with desirable properties, a regularization term can be included in this minimization:\\n'b'for some suitably chosen Tikhonov matrix \\n  \\n    \\n      \\n        \\xce\\x93\\n      \\n    \\n    {\\\\displaystyle \\\\Gamma }\\n  \\n. In many cases, this matrix is chosen as a multiple of the identity matrix (\\n  \\n    \\n      \\n        \\xce\\x93\\n        =\\n        \\xce\\xb1\\n        I\\n      \\n    \\n    {\\\\displaystyle \\\\Gamma =\\\\alpha I}\\n  \\n), giving preference to solutions with smaller norms; this is known as L2 regularization.[1] In other cases, high-pass operators (e.g., a difference operator or a weighted Fourier operator) may be used to enforce smoothness if the underlying vector is believed to be mostly continuous.\\nThis regularization improves the conditioning of the problem, thus enabling a direct numerical solution. An explicit solution, denoted by \\n  \\n    \\n      \\n        \\n          \\n            \\n              x\\n              ^\\n            \\n          \\n        \\n      \\n    \\n    {\\\\displaystyle {\\\\hat {x}}}\\n  \\n, is given by\\n'b'The effect of regularization may be varied by the scale of matrix \\n  \\n    \\n      \\n        \\xce\\x93\\n      \\n    \\n    {\\\\displaystyle \\\\Gamma }\\n  \\n. For \\n  \\n    \\n      \\n        \\xce\\x93\\n        =\\n        0\\n      \\n    \\n    {\\\\displaystyle \\\\Gamma =0}\\n  \\n this reduces to the unregularized least-squares solution, provided that (ATA)\\xe2\\x88\\x921 exists.\\n'b'L2 regularization is used in many contexts aside from linear regression, such as classification with logistic regression or support vector machines,[2] and matrix factorization.[3]\\n'",
            "links": [
                "/wiki/Non-linear_least_squares",
                "/wiki/Levenberg%E2%80%93Marquardt_algorithm",
                "/wiki/Machine_learning",
                "/wiki/Statistics",
                "/wiki/Ill-posed_problem",
                "/wiki/Regularization_(mathematics)",
                "/wiki/Andrey_Nikolayevich_Tikhonov",
                "/wiki/Support_vector_machine",
                "/wiki/Logistic_regression",
                "/wiki/Statistical_classification",
                "/wiki/Kriging",
                "/wiki/Andrey_Nikolayevich_Tikhonov",
                "/wiki/Generalized_singular-value_decomposition",
                "/wiki/Condition_number",
                "/wiki/Wiener_filter",
                "/wiki/Bias_of_an_estimator",
                "/wiki/Gauss%E2%80%93Markov_theorem",
                "/wiki/Errors_and_residuals_in_statistics",
                "/wiki/Homoscedasticity",
                "/wiki/Normal_distribution"
            ],
            "text": "If the assumption of normality is replaced by assumptions of homoscedasticity and uncorrelatedness of errors, and if one still assumes zero mean, then the Gauss\u2013Markov theorem entails that the solution is the minimal unbiased estimator. [18]\nand\nUsing the previous SVD decomposition, we can simplify the above expression:\nFinally, it is related to the Wiener filter:\nand is zero elsewhere. This demonstrates the effect of the Tikhonov parameter on the condition number of the regularized problem. For the generalized case, a similar representation can be derived using a generalized singular-value decomposition. [13]\nor equivalently\nTikhonov regularization has been invented independently in many different contexts.\nIt became widely known from its application to integral equations from the work of\nAndrey Tikhonov[4][5][6][7][8] and David L. Phillips.[9] Some authors use the term Tikhonov\u2013Phillips regularization.\nThe finite-dimensional case was expounded by Arthur E. Hoerl, who took a statistical approach,[10] and by Manus Foster, who interpreted this method as a Wiener\u2013Kolmogorov (Kriging) filter.[11] Following Hoerl, it is known in the statistical literature as ridge regression.[12]\nL2 regularization is used in many contexts aside from linear regression, such as classification with logistic regression or support vector machines,[2] and matrix factorization.[3]\nIn order to give preference to a particular solution with desirable properties, a regularization term can be included in this minimization:\nTikhonov regularization, named for Andrey Tikhonov, is the most commonly used method of regularization of ill-posed problems.  In statistics, the method is known as ridge regression, in machine learning it is known as weight decay, and with multiple independent discoveries, it is also variously known as the Tikhonov\u2013Miller method, the Phillips\u2013Twomey method, the constrained linear inversion method, and the method of linear regularization. It is related to the Levenberg\u2013Marquardt algorithm for non-linear least-squares problems.\n",
            "title": "Tikhonov regularization",
            "url": "https://en.wikipedia.org/wiki/Ridge_regression"
        },
        {
            "desc_links": [
                "/wiki/Fitness_function",
                "/wiki/Utility_function",
                "/wiki/Profit_function",
                "/wiki/Reward_function",
                "/wiki/Optimization_problem",
                "/wiki/Real_number",
                "/wiki/Event_(probability_theory)",
                "/wiki/Computational_neuroscience",
                "/wiki/Machine_learning",
                "/wiki/Decision_theory",
                "/wiki/Econometrics",
                "/wiki/Statistics",
                "/wiki/Mathematical_optimization",
                "/wiki/Financial_risk_management",
                "/wiki/Optimal_control",
                "/wiki/Harald_Cram%C3%A9r",
                "/wiki/Actuarial_science",
                "/wiki/Statistical_classification",
                "/wiki/Regret_(decision_theory)",
                "/wiki/Economic_cost",
                "/wiki/Economics",
                "/wiki/Abraham_Wald",
                "/wiki/Pierre-Simon_Laplace",
                "/wiki/Parameter_estimation",
                "/wiki/Nassim_Nicholas_Taleb",
                "/wiki/W._Edwards_Deming"
            ],
            "desc_text": "b'In mathematical optimization, statistics, econometrics, decision theory, machine learning and computational neuroscience, a loss function or cost function is a function that maps an event or values of one or more variables onto a real number intuitively representing some \"cost\" associated with the event. An optimization problem seeks to minimize a loss function. An objective function is either a loss function or its negative (in specific domains, variously called a reward function, a profit function, a utility function, a fitness function, etc.), in which case it is to be maximized.\\n'b'In statistics, typically a  loss function is used for parameter estimation, and the event in question is some function of the difference between estimated and true values for an instance of data. The concept, as old as Laplace, was reintroduced in statistics by Abraham Wald in the middle of the 20th century.[1]  In the context of economics, for example, this is usually economic cost or regret.  In classification, it is the penalty for an incorrect classification of an example. In actuarial science, it is used in an insurance context to model benefits paid over premiums, particularly since the works of Harald Cram\\xc3\\xa9r in the 1920s.[2] In optimal control, the loss is the penalty for failing to achieve a desired value. In financial risk management, the function is mapped to a monetary loss.\\n'b'In classical statistics (both frequentist and Bayesian), a loss function is typically treated as something of a background mathematical convention. Critics such as W. Edwards Deming and Nassim Nicholas Taleb have argued that loss functions require much greater attention than they have traditionally been given and that loss functions used in real world decision making need to reflect actual empirical experience. They argue that real-world loss functions are often very different from the smooth, symmetric ones used by classical convention, and are often highly asymmetric, nonlinear, and discontinuous.\\n'",
            "links": [
                "/wiki/Fitness_function",
                "/wiki/Utility_function",
                "/wiki/Profit_function",
                "/wiki/Reward_function",
                "/wiki/Optimization_problem",
                "/wiki/Real_number",
                "/wiki/Event_(probability_theory)",
                "/wiki/Computational_neuroscience",
                "/wiki/Machine_learning",
                "/wiki/Decision_theory",
                "/wiki/Econometrics",
                "/wiki/Statistics",
                "/wiki/Mathematical_optimization",
                "/wiki/Financial_risk_management",
                "/wiki/Optimal_control",
                "/wiki/Harald_Cram%C3%A9r",
                "/wiki/Actuarial_science",
                "/wiki/Statistical_classification",
                "/wiki/Regret_(decision_theory)",
                "/wiki/Economic_cost",
                "/wiki/Economics",
                "/wiki/Abraham_Wald",
                "/wiki/Pierre-Simon_Laplace",
                "/wiki/Parameter_estimation",
                "/wiki/Nassim_Nicholas_Taleb",
                "/wiki/W._Edwards_Deming",
                "/wiki/Regret_(decision_theory)",
                "/wiki/Minimax",
                "/wiki/Leonard_J._Savage",
                "/wiki/Variance",
                "/wiki/Least_squares",
                "/wiki/Quadratic_function",
                "/wiki/Linear_regression",
                "/wiki/Least_squares",
                "/wiki/Design_of_experiments",
                "/wiki/Regression_analysis",
                "/wiki/T-test",
                "/wiki/Statistic",
                "/wiki/Stochastic_control",
                "/wiki/First-order_condition",
                "/wiki/Closed-form_expression",
                "/wiki/Quadratic_form",
                "/wiki/Linear-quadratic_regulator",
                "/wiki/Decision_theory",
                "/wiki/Statistics",
                "/wiki/Expected_value",
                "/wiki/Bayesian_probability",
                "/wiki/Frequentist",
                "/wiki/Posterior_distribution",
                "/wiki/Von_Neumann-Morgenstern_utility_function",
                "/wiki/Decision_rule",
                "/wiki/Median",
                "/wiki/Least_squares",
                "/wiki/Mean",
                "/wiki/Location_parameter",
                "/wiki/Risk_neutral",
                "/wiki/Utility",
                "/wiki/Risk-loving",
                "/wiki/Risk_aversion",
                "/wiki/Safety_engineering",
                "/wiki/Public_health",
                "/wiki/Morbidity",
                "/wiki/Mortality_rate",
                "/wiki/Differentiable_function",
                "/wiki/Continuous_function",
                "/wiki/Optimization_algorithm",
                "/wiki/I.i.d.",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Nassim_Nicholas_Taleb",
                "/wiki/W._Edwards_Deming",
                "/wiki/Wikipedia:Citation_needed"
            ],
            "text": "Taleb especially has argued that the practice of selecting loss functions based on mathematical niceness rather than actual loss experience is not really different from selecting data based on niceness rather than empirical observation, in other words, Taleb has argued that it should be considered a kind of scientific fraud.[citation needed]\nW. Edwards Deming and Nassim Nicholas Taleb argue that empirical reality, not nice mathematical properties, should be the sole basis for selecting loss functions, and real losses often aren\u2019t mathematically nice and aren\u2019t differentiable, continuous, symmetric, etc. For example, a person who arrives before a plane gate closure can still make the plane, but a person who arrives after can not, a discontinuity and asymmetry which makes arriving slightly late much more costly than arriving slightly early. In drug dosing, the cost of too little drug may be lack of efficacy, while the cost of too much may be tolerable toxicity, another example of assymmetry. Traffic, pipes, beams, ecologies, climates, etc. may tolerate increased load or stress with little noticeable change up to a point, then become backed up or break catastrophically. These situations, Deming and Taleb argue, are common in real-life problems, perhaps more common than classical smooth, continuous, symmetric, differentials cases.[citation needed]\nThe choice of a loss function is not arbitrary. It is very restrictive and sometimes the loss function may be characterized by its desirable properties.[8] Among  the choice principles are, for example, the requirement of completeness of the class of symmetric statistics in the case of i.i.d. observations, the principle of complete information, and some others.\nFor most optimization algorithms, it is desirable to have a loss function that is globally continuous and differentiable.\nOther measures of cost are possible, for example mortality or morbidity in the field of public health or safety engineering.\nBut for risk-averse (or risk-loving) agents, loss is measured as the negative of a utility function, and the objective function to be optimized is the expected value of utility.\nIn economics, when an agent is risk neutral, the objective function is simply expressed as the expected value of a monetary quantity, such as profit, income, or end-of-period wealth.\nA common example involves estimating \"location\". Under typical statistical assumptions, the mean or average is the statistic for estimating location that minimizes the expected loss experienced under the squared-error loss function, while the median is the estimator that minimizes expected loss experienced under the absolute-difference loss function. Still different estimators would be optimal under other, less common circumstances.\nSound statistical practice requires selecting an estimator consistent with the actual acceptable variation experienced in the context of a particular applied problem. Thus, in the applied use of loss functions, selecting which statistical method to use to model an applied problem depends on knowing the losses that will be experienced from being wrong under the problem's particular circumstances.[7]\nA decision rule makes a choice using an optimality criterion. Some commonly used criteria are:\nIn economics, decision-making under uncertainty is often modelled using the von Neumann-Morgenstern utility function of the uncertain variable of interest, such as end-of-period wealth. Since the value of this variable is uncertain, so is the value of the utility function; it is the expected value of utility that is maximized.\nOne then should choose the action a* which minimises the expected loss. Although this will result in choosing the same action as would be chosen using the frequentist risk, the emphasis of the Bayesian approach is that one is only interested in choosing the optimal action under the actual observed data, whereas choosing the actual frequentist optimal decision rule, which is a function of all possible observations, is a much more difficult problem.\nIn a Bayesian approach, the expectation is calculated using the posterior distribution \u03c0* of the parameter\u00a0\u03b8:\nWe first define the expected loss in the frequentist context. It is obtained by taking the expected value with respect to the probability distribution, P\u03b8, of the observed data, X. This is also referred to as the risk function[3][4][5][6] of the decision rule \u03b4 and the parameter \u03b8. Here the decision rule depends on the outcome of X. The risk function is given by:\nBoth frequentist and Bayesian statistical theory involve making a decision based on the expected value of the loss function; however, this quantity is defined differently under the two paradigms.\nIn some contexts, the value of the loss function itself is a random quantity because it depends on the outcome of a random variable X. \nIn statistics and decision theory, a frequently used loss function is the 0-1 loss function\nThe quadratic loss function is also used in linear-quadratic optimal control problems. In these problems, even in the absence of uncertainty, it may not be possible to achieve the desired values of all target variables. Often loss is expressed as a quadratic form in the deviations of the variables of interest from their desired values; this approach is tractable because it results in linear first-order conditions. In the context of stochastic control, the expected value of the quadratic form is used.\nMany common statistics, including t-tests, regression models, design of experiments, and much else, use least squares methods applied using linear regression theory, which is based on the quadratric loss function.\nfor some constant C; the value of the constant makes no difference to a decision, and can be ignored by setting it equal to 1.\nThe use of a quadratic loss function is common, for example when using least squares techniques. It is often more mathematically tractable than other loss functions because of the properties of variances, as well as being symmetric: an error above the target causes the same loss as the same magnitude of error below the target.  If the target is t, then a quadratic loss function is\nLeonard J. Savage argued that using non-Bayesian methods such as minimax, the loss function should be based on the idea of regret, i.e., the loss associated with a decision should be the difference between the consequences of the best decision that could have been made had the underlying circumstances been known and the decision that was in fact taken before they were known.\nIn classical statistics (both frequentist and Bayesian), a loss function is typically treated as something of a background mathematical convention. Critics such as W. Edwards Deming and Nassim Nicholas Taleb have argued that loss functions require much greater attention than they have traditionally been given and that loss functions used in real world decision making need to reflect actual empirical experience. They argue that real-world loss functions are often very different from the smooth, symmetric ones used by classical convention, and are often highly asymmetric, nonlinear, and discontinuous.\nIn statistics, typically a  loss function is used for parameter estimation, and the event in question is some function of the difference between estimated and true values for an instance of data. The concept, as old as Laplace, was reintroduced in statistics by Abraham Wald in the middle of the 20th century.[1]  In the context of economics, for example, this is usually economic cost or regret.  In classification, it is the penalty for an incorrect classification of an example. In actuarial science, it is used in an insurance context to model benefits paid over premiums, particularly since the works of Harald Cram\u00e9r in the 1920s.[2] In optimal control, the loss is the penalty for failing to achieve a desired value. In financial risk management, the function is mapped to a monetary loss.\nIn mathematical optimization, statistics, econometrics, decision theory, machine learning and computational neuroscience, a loss function or cost function is a function that maps an event or values of one or more variables onto a real number intuitively representing some \"cost\" associated with the event. An optimization problem seeks to minimize a loss function. An objective function is either a loss function or its negative (in specific domains, variously called a reward function, a profit function, a utility function, a fitness function, etc.), in which case it is to be maximized.\n",
            "title": "Loss function",
            "url": "https://en.wikipedia.org/wiki/Loss_function"
        },
        {
            "desc_links": [
                "/wiki/Laplace_distribution",
                "/wiki/Maximum_likelihood",
                "/wiki/Maxima_and_minima",
                "/wiki/Cartesian_coordinates",
                "/wiki/Function_(mathematics)",
                "/wiki/Least_squares",
                "/wiki/Optimization_(mathematics)",
                "/wiki/Optimality_criterion",
                "/wiki/L1_norm"
            ],
            "desc_text": "b'Least absolute deviations (LAD), also known as least absolute errors (LAE), least absolute value (LAV), least absolute residual (LAR), sum of absolute deviations, or the L1 norm condition, is a statistical optimality criterion and the statistical optimization technique that relies on it. Similar to the popular least squares technique, it attempts to find a function which closely approximates a set of data. In the simple case of a set of (x,y) data, the approximation function is a simple \"trend line\" in two-dimensional Cartesian coordinates. The method minimizes the sum of absolute errors (SAE) (the sum of the absolute values of the vertical \"residuals\" between points generated by the function and corresponding points in the data). The least absolute deviations estimate also arises as the maximum likelihood estimate if the errors have a Laplace distribution.\\n'",
            "links": [
                "/wiki/Laplace_distribution",
                "/wiki/Maximum_likelihood",
                "/wiki/Maxima_and_minima",
                "/wiki/Cartesian_coordinates",
                "/wiki/Function_(mathematics)",
                "/wiki/Least_squares",
                "/wiki/Optimization_(mathematics)",
                "/wiki/Optimality_criterion",
                "/wiki/L1_norm",
                "/wiki/Quadratic_function",
                "/wiki/Dependent_and_independent_variables#Alternative_terminology_in_statistics",
                "/wiki/Regularization_(mathematics)",
                "/wiki/Lasso_(statistics)",
                "/wiki/Regularization_(mathematics)"
            ],
            "text": "The problem can be solved using any linear programming technique on the following problem specification. We wish to\nSimplex-based methods are the \u201cpreferred\u201d way to solve the least absolute deviations problem.[11] A Simplex method is a method for solving a problem in linear programming. The most popular algorithm is the Barrodale-Roberts modified Simplex algorithm. The algorithms for IRLS, Wesolowsky's Method, and Li's Method can be found in Appendix A of [11]\namong other methods. Checking all combinations of lines traversing any two (x,y) data points is another method of finding the least absolute deviations line. Since it is known that at least one least absolute deviations line traverses at least two data points, this method will find a line by comparing the SAE (Smallest Absolute Error over data points) of each line, and choosing the line with the smallest SAE. In addition, if multiple lines have the same, smallest SAE, then the lines outline the region of multiple solutions. Though simple, this final method is inefficient for large sets of data.\nThough the idea of least absolute deviations regression is just as straightforward as that of least squares regression, the least absolute deviations line is not as simple to compute efficiently. Unlike least squares regression, least absolute deviations regression does not have an analytical solving method. Therefore, an iterative approach is required. The following is an enumeration of some least absolute deviations solving methods.\nRegularization with LASSO may also be combined with LAD.[5]\nThe least absolute deviation problem may be extended to include multiple explanators, constraints and regularization, e.g., a linear model with linear constraints:[4]\nTo understand why there are multiple solutions in the case shown in Figure A, consider the pink line in the green region. Its sum of absolute errors is some value S. If one were to tilt the line upward slightly, while still keeping it within the green region, the sum of errors would still be S. It would not change because the distance from each point to the line grows on one side of the line, while the distance to each point on the opposite side of the line diminishes by exactly the same amount. Thus the sum of absolute errors remains the same. Also, since one can tilt the line in infinitely small increments, this also shows that if there is more than one solution, there are infinitely many solutions.\nOne known case in which multiple solutions exist is a set of points symmetric about a horizontal line, as shown in Figure A below.\nThis \"latching\" of the line to the data points can help to understand the \"instability\" property: if the line always latches to at least two points, then the line will jump between different sets of points as the data points are altered. The \"latching\" also helps to understand the \"robustness\" property: if there exists an outlier, and a least absolute deviations line must latch onto two data points, the outlier will most likely not be one of those two points because that will not minimize the sum of absolute deviations in most cases.\nThere exist other unique properties of the least absolute deviations line. In the case of a set of (x,y) data, the least absolute deviations line will always pass through at least two of the data points, unless there are multiple solutions. If multiple solutions exist, then the region of valid least absolute deviations solutions will be bounded by at least two lines, each of which passes through at least two data points. More generally, if there are k regressors (including the constant), then at least one optimal regression surface will pass through k of the data points.[3]:p.936\nThe method of least absolute deviations finds applications in many areas, due to its robustness compared to the least squares method. Least absolute deviations is robust in that it is resistant to outliers in the data.  LAD gives equal emphasis to all observations, in contrast to OLS which, by squaring the residuals, gives more weight to large residuals, that is, outliers in which predicted values are far from actual observations.  This may be helpful in studies where outliers do not need to be given greater weight than other observations. If it is important to give greater weight to outliers, the method of least squares is a better choice.\nThe following is a table contrasting some properties of the method of least absolute deviations with those of the method of least squares (for non-singular problems).[1][2]\nWe now seek estimated values of the unknown parameters that minimize the sum of the absolute values of the residuals:\nTo attain this goal, we suppose that the function f is of a particular form containing some parameters which need to be determined. For instance, the simplest form would be linear: f(x) = bx + c, where b and c are parameters whose values are not known but which we would like to estimate. Less simply, suppose that f(x) is quadratic, meaning that f(x) = ax2 + bx + c, where a, b and c are not yet known. (More generally, there could be not just one explanator x, but rather multiple explanators, all appearing as arguments of the function f.)\nLeast absolute deviations (LAD), also known as least absolute errors (LAE), least absolute value (LAV), least absolute residual (LAR), sum of absolute deviations, or the L1 norm condition, is a statistical optimality criterion and the statistical optimization technique that relies on it. Similar to the popular least squares technique, it attempts to find a function which closely approximates a set of data. In the simple case of a set of (x,y) data, the approximation function is a simple \"trend line\" in two-dimensional Cartesian coordinates. The method minimizes the sum of absolute errors (SAE) (the sum of the absolute values of the vertical \"residuals\" between points generated by the function and corresponding points in the data). The least absolute deviations estimate also arises as the maximum likelihood estimate if the errors have a Laplace distribution.\n",
            "title": "Least absolute deviations",
            "url": "https://en.wikipedia.org/wiki/Least_absolute_deviations"
        },
        {
            "desc_links": [
                "/wiki/Zero_vector",
                "/wiki/Vector_space",
                "/wiki/Vector_(mathematics_and_physics)",
                "/wiki/Function_(mathematics)",
                "/wiki/Mathematics",
                "/wiki/Functional_analysis",
                "/wiki/Linear_algebra",
                "/wiki/Magnitude_(mathematics)",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Euclidean_space",
                "/wiki/Normed_vector_space"
            ],
            "desc_text": "b'In linear algebra, functional analysis, and related areas of mathematics, a norm is a function that assigns a strictly positive length or size to each vector in a vector space\\xe2\\x80\\x94except for the zero vector, which is assigned a length of zero. A seminorm, on the other hand, is allowed to assign zero length to some non-zero vectors (in addition to the zero vector).\\n'b'A norm must also satisfy certain properties pertaining to scalability and additivity which are given in the formal definition below.\\n'b'A simple example is two dimensional Euclidean space R2 equipped with the \"Euclidean norm\" (see below). Elements in this vector space (e.g., (3, 7)) are usually drawn as arrows in a 2-dimensional cartesian coordinate system starting at the origin (0, 0). The Euclidean norm assigns to each vector the length of its arrow. Because of this, the Euclidean norm is often known as the magnitude.\\n'b'A vector space on which a norm is defined is called a normed vector space. Similarly, a vector space with a seminorm is called a seminormed vector space. It is often possible to supply a norm for a given vector space in more than one way.\\n'",
            "links": [
                "/wiki/Zero_vector",
                "/wiki/Vector_space",
                "/wiki/Vector_(mathematics_and_physics)",
                "/wiki/Function_(mathematics)",
                "/wiki/Mathematics",
                "/wiki/Functional_analysis",
                "/wiki/Linear_algebra",
                "/wiki/Magnitude_(mathematics)",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Euclidean_space",
                "/wiki/Normed_vector_space",
                "/wiki/Function_(mathematics)",
                "/wiki/Complex_number",
                "/wiki/Field_(mathematics)",
                "/wiki/Vector_space",
                "/wiki/Quotient_space_(linear_algebra)",
                "/wiki/Topology",
                "/wiki/Topological_vector_space",
                "/wiki/%C7%81",
                "/wiki/Infix_notation",
                "/wiki/Unicode",
                "/wiki/LaTeX",
                "/wiki/Absolute_value",
                "/wiki/Complex_numbers",
                "/wiki/Real_numbers",
                "/wiki/Dimension_(vector_space)",
                "/wiki/L1_norm",
                "/wiki/Euclidean_space",
                "/wiki/Pythagorean_theorem",
                "/wiki/Complex_coordinate_space",
                "/wiki/Inner_product",
                "/wiki/Square_root",
                "/wiki/Conjugate_transpose",
                "/wiki/Column_vector",
                "/wiki/Dot_product",
                "/wiki/Inner_product_space",
                "/wiki/Lp_space",
                "/wiki/N-sphere",
                "/wiki/Street_grid",
                "/wiki/Generalized_mean",
                "/wiki/Triangle_inequality",
                "/wiki/Harmonic_analysis",
                "/wiki/Probability_theory",
                "/wiki/Functional_analysis",
                "/wiki/Topological_vector_space",
                "/wiki/Hypercube",
                "/wiki/Information_theory",
                "/wiki/Coding_theory",
                "/wiki/Hamming_distance",
                "/wiki/Discrete_metric",
                "/wiki/Metric_geometry",
                "/wiki/Measurable_function",
                "/wiki/Lp_space",
                "/wiki/Wikipedia:Manual_of_Style/Words_to_watch#Unsupported_attributions",
                "/wiki/Abuse_of_terminology",
                "/wiki/Homogeneous_function#Positive_homogeneity",
                "/wiki/David_Donoho",
                "/wiki/Statistics",
                "/wiki/Signal_processing",
                "/wiki/Linear_transformation",
                "/wiki/Prism_(geometry)",
                "/wiki/Octahedron",
                "/wiki/Parallelogram",
                "/wiki/Minkowski_functional",
                "/wiki/Matrix_norms",
                "/wiki/Lp_space",
                "/wiki/Banach_space",
                "/wiki/Uniformly_isomorphic",
                "/wiki/Objective_function",
                "/wiki/Convex_function",
                "/wiki/Sublinear_function",
                "/wiki/H%C3%B6lder%27s_inequality",
                "/wiki/Lp_space",
                "/wiki/Cauchy%E2%80%93Schwarz_inequality",
                "/wiki/Minkowski_functional",
                "/wiki/Absorbing_set",
                "/wiki/Absolutely_convex",
                "/wiki/Continuous_function",
                "/wiki/Locally_convex_topological_vector_space",
                "/wiki/Separation_axiom",
                "/wiki/Local_basis",
                "/wiki/Locally_convex_topological_vector_space",
                "/wiki/Weak_topology",
                "/wiki/Quasinorm",
                "/wiki/Null_vector",
                "/wiki/Isotropic_quadratic_form",
                "/wiki/Quadratic_form",
                "/wiki/Involution_(mathematics)",
                "/wiki/Algebra_over_a_field",
                "/wiki/Composition_algebra"
            ],
            "text": "The concept of norm in composition algebras does not share the usual properties of a norm. A composition algebra (A, *, N) consists of an algebra over a field A, an involution *, and a quadratic form N, which is called the \"norm\". In several cases N is an isotropic quadratic form so that A has at least one null vector, contrary to the separation of points required for the usual norm discussed in this article.\nWe have the following relationship between quasi-seminorms and k-seminorms:\nthen p is called a k-seminorm.\nOn the other hand, if p satisfies the triangle inequality but in place of absolute homogeneity we require that\nthen p satisfies the triangle inequality but is called a quasi-seminorm and the smallest value of b for which this holds is called the multiplier of p; if in addition p separates points then it is called a quasi-norm.\nThere are several generalizations of norms and semi-norms. If p is absolute homogeneity but in place of subadditivity we require that\nnorm case:\nSuch a method is used to design weak and weak* topologies.\nAny locally convex topological vector space has a local basis consisting of absolutely convex sets. A common method to construct such a basis is to use a family (p) of seminorms p that separates points: the collection of all finite intersections of sets {p < 1/n} turns the space into a locally convex topological vector space so that every p is continuous.\nConversely:\nwith the property that\nAll seminorms on a vector space V can be classified in terms of absolutely convex absorbing subsets A of V. To each such subset corresponds a seminorm pA called the gauge of A, defined as\nA special case of this is the Cauchy\u2013Schwarz inequality:[6]\nFor the Lp norms, we have H\u00f6lder's inequality[6]\nThus, p(u \u00b1 v) \u2265 |p(u) \u2212 p(v)|.\nFor any norm p on a vector space V, we have that for all u and v \u2208 V:\nis again a seminorm.\nGiven a finite family of seminorms pi on a vector space the sum\nEvery (semi)-norm is a sublinear function, which implies that every norm is a convex function. As a result, finding a global optimum of a norm-based objective function is often tractable.\nEquivalent norms define the same notions of continuity and convergence and for many purposes do not need to be distinguished. To be more precise the uniform structure defined by equivalent norms on the vector space is uniformly isomorphic.\nIf the vector space is a finite-dimensional real or complex one, all norms are equivalent. On the other hand, in the case of infinite-dimensional vector spaces, not all norms are equivalent.\ni.e., \nIn particular,\nTwo norms \u2016\u2022\u2016\u03b1 and \u2016\u2022\u2016\u03b2 on a vector space V are called equivalent if there exist positive real numbers C and D such that for all x in V\nOther examples of infinite dimensional normed vector spaces can be found in the Banach space article.\nThe generalization of the above norms to an infinite number of components leads to \u2113\u2009p and L\u2009p spaces, with norms\nThere are also norms on spaces of matrices (with real or complex entries), the so-called matrix norms.\nAll the above formulas also yield norms on Cn without modification.\nThere are examples of norms that are not defined by \"entrywise\" formulas. For instance, the Minkowski functional of a centrally-symmetric convex body in Rn (centered at zero) defines a norm on Rn.\nIn 2D, with A a rotation by 45\u00b0 and a suitable scaling, this changes the taxicab norm into the maximum norm. In 2D, each A applied to the taxicab norm, up to inversion and interchanging of axes, gives a different unit ball: a parallelogram of a particular shape, size and orientation. In 3D this is similar but different for the 1-norm (octahedrons) and the maximum norm (prisms with parallelogram base).\nFor any norm and any injective linear transformation A we can define a new norm of x, equal to\nis a norm on R4.\nOther norms on Rn can be constructed by combining the above; for example\nIn signal processing and statistics, David Donoho referred to the zero \"norm\" with quotation marks. Following Donoho's notation, the zero \"norm\" of x is simply the number of non-zero coordinates of x, or the Hamming distance of the vector from zero. When this \"norm\" is localized to a bounded set, it is the limit of p-norms as p approaches 0. Of course, the zero \"norm\" is not truly a norm, because it is not positive homogeneous. Indeed, it is not even an F-norm in the sense described above, since it is discontinuous, jointly and severally, with respect to the scalar argument in scalar\u2013vector multiplication and with respect to its vector argument. Abusing terminology, some engineers[who?] omit Donoho's quotation marks and inappropriately call the number-of-nonzeros function the L0 norm, echoing the notation for the Lebesgue space of measurable functions.\nIn metric geometry, the discrete metric takes the value one for distinct points and zero otherwise. When applied coordinate-wise to the elements of a vector space, the discrete distance defines the Hamming distance, which is important in coding and information theory. In the field of real or complex numbers, the distance of the discrete metric from zero is not homogeneous in the non-zero point; indeed, the distance from zero remains one as its non-zero argument approaches zero. However, the discrete distance of a number from zero does satisfy the other properties of a norm, namely the triangle inequality and positive definiteness. When applied component-wise to vectors, the discrete distance from zero behaves like a non-homogeneous \"norm\", which counts the number of non-zero components in its vector argument; again, this non-homogeneous \"norm\" is discontinuous.\nThe set of vectors whose infinity norm is a given constant, c, forms the surface of a hypercube with edge length 2c.\nor\nFor the special case of p = 2, this becomes\nThe derivative with respect to x, therefore, is\nThe partial derivative of the p-norm is given by\n(without pth root) defines a distance that makes Lp(X) into a complete metric topological vector space. These spaces are of great interest in functional analysis, probability theory, and harmonic analysis.\nHowever, outside trivial cases, this topological vector space is not locally convex and has no continuous nonzero linear forms. Thus the topological dual space contains only the zero functional.\nThis definition is still of some interest for 0 < p < 1, but the resulting function does not define a norm,[3] because it violates the triangle inequality. What is true for this case of 0 < p < 1, even in the measurable analog, is that the corresponding Lp class is a vector space, and it is also true that the function\nThe p-norm is related to the generalized mean or power mean.\nis not a norm because it may yield negative results.\nIn contrast,\nThe 1-norm is simply the sum of the absolute values of the columns.\nThe name relates to the distance a taxi has to drive in a rectangular street grid to get from the origin to the point x.\nThe set of vectors in Rn+1 whose Euclidean norm is a given positive constant forms an n-sphere.\nThe Euclidean norm is also called the Euclidean length, L2 distance, \u21132 distance, L2 norm, or \u21132 norm; see Lp space.\nThis formula is valid for any inner product space, including Euclidean and complex spaces. For Euclidean spaces, the inner product is equivalent to the dot product. Hence, in this specific case the formula can be also written with the following notation:\nwhere x is represented as a column vector ([x1; x2; ...; xn]), and x\u2217 denotes its conjugate transpose.\nIn both cases the norm can be expressed as the square root of the inner product of the vector and itself:\nOn an n-dimensional complex space Cn the most common norm is\nThe Euclidean norm is by far the most commonly used norm on Rn, but there are other norms on this vector space as will be shown below. However, all these norms are equivalent in the sense that they all define the same topology.\nThis gives the ordinary distance from the origin to the point X, a consequence of the Pythagorean theorem.  This operation may also be referred to as \"SRSS\" which is an acronym for the square root of the sum of squares.[2]\nOn an n-dimensional Euclidean space Rn, the intuitive notion of length of the vector x = (x1, x2, ..., xn) is captured by the formula\nThe absolute value norm is a special case of the L1 norm.\nis a norm on the one-dimensional vector spaces formed by the real or complex numbers.\nThe absolute value\nIn LaTeX and related markup languages, the macros '\\|' and '\\parallel' are often used to denote a norm.\nIn Unicode, the code point of the \"double vertical line\" character \u2016 is U+2016. The double vertical line should not be confused with the \"parallel to\" symbol, Unicode U+2225 (\u00a0\u2225\u00a0). This is usually not a problem because the former is used in parenthesis-like fashion, whereas the latter is used as an infix operator. The double vertical line used here should also not be confused with the symbol used to denote lateral clicks in linguistics, Unicode U+01C1 (\u00a0\u01c1\u00a0). The single vertical line | is called \"vertical line\" in Unicode and its code point is U+007C.\nFor the length of a vector in Euclidean space (which is an example of a norm, as explained below), the notation |v| with single vertical lines is also widespread.\nIf a norm p\u00a0: V \u2192 R is given on a vector space V then the norm of a vector v \u2208 V is usually denoted by enclosing it within double vertical lines: \u2016v\u2016 = p(v). Such notation is also sometimes used if p is only a seminorm.\nA topological vector space is called normable (seminormable) if the topology of the space can be induced by a norm (seminorm).\nTwo norms (or seminorms) p and q on a vector space V are equivalent if there exist two real constants c and C, with c > 0, such that\nEvery vector space V with seminorm p induces a normed space V/W, called the quotient space, where W is the subspace of V consisting of all vectors v in V with p(v) = 0. The induced norm on V/W is defined by:\nA seminorm on V is a function p\u00a0: V \u2192 R with the properties 1 and 2 above.\nFor all a \u2208 F and all u, v \u2208 V,\nGiven a vector space V over a subfield F of the complex numbers, a norm on V is a nonnegative-valued scalar function p: V \u2192 [0,+\u221e) with the following properties:[1]\nA vector space on which a norm is defined is called a normed vector space. Similarly, a vector space with a seminorm is called a seminormed vector space. It is often possible to supply a norm for a given vector space in more than one way.\nA simple example is two dimensional Euclidean space R2 equipped with the \"Euclidean norm\" (see below). Elements in this vector space (e.g., (3, 7)) are usually drawn as arrows in a 2-dimensional cartesian coordinate system starting at the origin (0, 0). The Euclidean norm assigns to each vector the length of its arrow. Because of this, the Euclidean norm is often known as the magnitude.\nA norm must also satisfy certain properties pertaining to scalability and additivity which are given in the formal definition below.\nIn linear algebra, functional analysis, and related areas of mathematics, a norm is a function that assigns a strictly positive length or size to each vector in a vector space\u2014except for the zero vector, which is assigned a length of zero. A seminorm, on the other hand, is allowed to assign zero length to some non-zero vectors (in addition to the zero vector).\n",
            "title": "Norm (mathematics)",
            "url": "https://en.wikipedia.org/wiki/Norm_(mathematics)"
        },
        {
            "desc_links": [
                "/wiki/Overdetermined_system",
                "/wiki/Regression_analysis",
                "/wiki/Errors-in-variables_models",
                "/wiki/Independent_variable",
                "/wiki/Errors_and_residuals_in_statistics",
                "/wiki/Curve_fitting",
                "/wiki/Closed-form_solution",
                "/wiki/Regression_analysis",
                "/wiki/Nonlinear_least_squares",
                "/wiki/Ordinary_least_squares",
                "/wiki/Polynomial_least_squares",
                "/wiki/Method_of_moments_(statistics)",
                "/wiki/Maximum_likelihood",
                "/wiki/Exponential_family",
                "/wiki/Generalized_linear_model",
                "/wiki/Fisher_information",
                "/wiki/Linear",
                "/wiki/Adrien-Marie_Legendre",
                "/wiki/Carl_Friedrich_Gauss"
            ],
            "desc_text": "b'The method of least squares is a standard approach in regression analysis to approximate the solution of overdetermined systems, i.e., sets of equations in which there are more equations than unknowns. \"Least squares\" means that the overall solution minimizes the sum of the squares of the residuals made in the results of every single equation.\\n'b'The most important application is in data fitting.  The best fit in the least-squares sense minimizes the sum of squared residuals (a residual being: the difference between an observed value, and the fitted value provided by a model). When the problem has substantial uncertainties in the independent variable (the x variable), then simple regression and least-squares methods have problems; in such cases, the methodology required for fitting errors-in-variables models may be considered instead of that for least squares.\\n'b'Least-squares problems fall into two categories: linear or ordinary least squares and nonlinear least squares, depending on whether or not the residuals are linear in all unknowns. The linear least-squares problem occurs in statistical regression analysis; it has a closed-form solution. The nonlinear problem is usually solved by iterative refinement; at each iteration the system is approximated by a linear one, and thus the core calculation is similar in both cases.\\n'b'Polynomial least squares describes the variance in a prediction of the dependent variable as a function of the independent variable and the deviations from the fitted curve.\\n'b'When the observations come from an exponential family and mild conditions are satisfied, least-squares estimates and maximum-likelihood estimates are identical.[1] The method of least squares can also be derived as a method of moments estimator.\\n'b'The following discussion is mostly presented in terms of linear functions but the use of least squares is valid and practical for more general families of functions. Also, by iteratively applying local quadratic approximation to the likelihood (through the Fisher information), the least-squares method may be used to fit a generalized linear model.\\n'b'The least-squares method is usually credited to Carl Friedrich Gauss (1795),[2] but it was first published by Adrien-Marie Legendre (1805).[3]\\n'",
            "links": [
                "/wiki/Overdetermined_system",
                "/wiki/Regression_analysis",
                "/wiki/Errors-in-variables_models",
                "/wiki/Independent_variable",
                "/wiki/Errors_and_residuals_in_statistics",
                "/wiki/Curve_fitting",
                "/wiki/Closed-form_solution",
                "/wiki/Regression_analysis",
                "/wiki/Nonlinear_least_squares",
                "/wiki/Ordinary_least_squares",
                "/wiki/Polynomial_least_squares",
                "/wiki/Method_of_moments_(statistics)",
                "/wiki/Maximum_likelihood",
                "/wiki/Exponential_family",
                "/wiki/Generalized_linear_model",
                "/wiki/Fisher_information",
                "/wiki/Linear",
                "/wiki/Adrien-Marie_Legendre",
                "/wiki/Carl_Friedrich_Gauss",
                "/wiki/Age_of_Exploration",
                "/wiki/Geodesy",
                "/wiki/Astronomy",
                "/wiki/Adrien-Marie_Legendre",
                "/wiki/Probability_density",
                "/wiki/Arithmetic_mean",
                "/wiki/Normal_distribution",
                "/wiki/Carl_Friedrich_Gauss",
                "/wiki/Franz_Xaver_von_Zach",
                "/wiki/Kepler%27s_laws_of_planetary_motion",
                "/wiki/Giuseppe_Piazzi",
                "/wiki/Ceres_(dwarf_planet)",
                "/wiki/Gauss%27_method",
                "/wiki/Gauss%E2%80%93Markov_theorem",
                "/wiki/Central_limit_theorem",
                "/wiki/Robert_Adrain",
                "/wiki/Total_least_squares",
                "/wiki/Gradient",
                "/wiki/Maxima_and_minima",
                "/wiki/Linear_combination",
                "/wiki/Linear_least_squares_(mathematics)",
                "/wiki/Jacobian_matrix_and_determinant",
                "/wiki/Gauss%E2%80%93Newton_algorithm",
                "/wiki/Hooke%27s_law",
                "/wiki/Overdetermined_system",
                "/wiki/Correlation_does_not_imply_causation",
                "/wiki/Correlated",
                "/wiki/Central_limit_theorem",
                "/wiki/Central_limit_theorem",
                "/wiki/Degrees_of_freedom_(statistics)#Effective_degrees_of_freedom",
                "/wiki/Degrees_of_freedom_(statistics)",
                "/wiki/Probability_distribution",
                "/wiki/Confidence_limits",
                "/wiki/Heteroscedasticity",
                "/wiki/Variance",
                "/wiki/Generalized_least_squares",
                "/wiki/Elastic_net_regularization",
                "/wiki/Compressed_sensing"
            ],
            "text": "The L1-regularized formulation is useful in some contexts due to its tendency to prefer solutions where more parameters are zero, which gives solutions that depend on fewer variables.[8] For this reason, the Lasso and its variants are fundamental to the field of compressed sensing. An extension of this approach is elastic net regularization.\nA special case of generalized least squares called weighted least squares occurs when all the off-diagonal entries of \u03a9 (the correlation matrix of the residuals) are null; the variances of the observations (along the covariance matrix diagonal) may still be unequal (heteroscedasticity).\nConfidence limits can be found if the probability distribution of the parameters is known, or an asymptotic approximation is made, or assumed. Likewise statistical tests on the residuals can be made if the probability distribution of the residuals is known or assumed. The probability distribution of any linear combination of the dependent variables can be derived if the probability distribution of experimental errors is known or assumed. Inference is particularly straightforward if the errors are assumed to follow a normal distribution, which implies that the parameter estimates and residuals will also be normally distributed conditional on the values of the independent variables.\nwhere the true error variance \u03c32 is replaced by an estimate based on the minimised value of the sum of squares objective function S. The denominator, n\u00a0\u2212\u00a0m, is the statistical degrees of freedom; see effective degrees of freedom for generalizations.\nHowever, if the errors are not normally distributed, a central limit theorem often nonetheless implies that the parameter estimates will be approximately normally distributed so long as the sample is reasonably large.  For this reason, given the important property that the error mean is independent of the independent variables, the distribution of the error term is not an important issue in regression analysis.  Specifically, it is not typically important whether the error term follows a normal distribution.\nIn order to make statistical tests on the results it is necessary to make assumptions about the nature of the experimental errors.  A common (but not necessary) assumption is that the errors belong to a normal distribution. The central limit theorem supports the idea that this is a good approximation in many cases.\nIn regression analysis the researcher specifies an empirical model. For example, a very common model is the straight line model which is used to test if there is a linear relationship between dependent and independent variable. If a linear relationship is found to exist, the variables are said to be correlated. However, correlation does not prove causation, as both variables may be correlated with other, hidden, variables, or the dependent variable may \"reverse\" cause the independent variables, or the variables may be otherwise spuriously correlated.  For example, suppose there is a correlation between deaths by drowning and the volume of ice cream sales at a particular beach. Yet, both the number of people going swimming and the volume of ice cream sales increase as the weather gets hotter, and presumably the number of deaths by drowning is correlated with the number of people going swimming. Perhaps an increase in swimmers causes both the other variables to increase.\nHere it is assumed that application of the force causes the spring to expand and, having derived the force constant by least squares fitting, the extension can be predicted from Hooke's law.\nThe least squares estimate of the force constant, k, is given by\nThere are many methods we might use to estimate the unknown parameter k. Noting that the n equations in  the m variables in our data comprise an overdetermined system with one unknown and n equations, we may choose to estimate k using least squares.  The sum of squares to be minimized is\nConsider a simple example drawn from physics. A spring should obey Hooke's law which states that the extension of a spring y is proportional to the force, F, applied to it.\nThe method of least squares is often used to generate estimators and other statistics in regression analysis.\nThese differences must be considered whenever the solution to a nonlinear least squares problem is being sought.\nThese are the defining equations of the Gauss\u2013Newton algorithm.\nThe normal equations are written in matrix notation as\nwhich, on rearrangement, become m simultaneous linear equations, the normal equations:\nThe Jacobian J is a function of constants, the independent variable and the parameters, so it changes from one iteration to the next. The residuals are given by\nFor a derivation of this estimate see Linear least squares (mathematics).\nLetting\nA regression model is a linear one when the model comprises a linear combination of the parameters, i.e.,\nThe gradient equations apply to all least squares problems. Each particular problem requires particular expressions for the model and its partial derivatives.\nThe minimum of the sum of squares is found by setting the gradient to zero. Since the model contains m parameters, there are m gradient equations:\nThis regression formulation considers only residuals in the dependent variable (but the alternative total least squares regression can account for errors in both variables). There are two rather different contexts with  different implications:\nA data point may consist of more than one independent variable. For example, when fitting a plane to a set of height measurements, the plane is a function of two independent variables, x and z, say. In the most general case there may be one or more independent variables and one or more dependent variables at each data point. \nThe idea of least-squares analysis was also independently formulated by the American Robert Adrain in 1808. In the next two centuries workers in the theory of errors and in statistics found many different ways of implementing least squares.[6]\nIn 1810, after reading Gauss's work, Laplace, after proving the central limit theorem, used it to give a large sample justification for the method of least squares and the normal distribution. In 1822, Gauss was able to state that the least-squares approach to regression analysis is optimal in the sense that in a linear model where the errors have a mean of zero, are uncorrelated, and have equal variances, the best linear unbiased estimator of the coefficients is the least-squares estimator. This result is known as the Gauss\u2013Markov theorem.\nAn early demonstration of the strength of Gauss' method came when it was used to predict the future location of the newly discovered asteroid Ceres. On 1 January 1801, the Italian astronomer Giuseppe Piazzi discovered Ceres and was able to track its path for 40 days before it was lost in the glare of the sun. Based on these data, astronomers desired to determine the location of Ceres after it emerged from behind the sun without solving Kepler's complicated nonlinear equations of planetary motion. The only predictions that successfully allowed Hungarian astronomer Franz Xaver von Zach to relocate Ceres were those performed by the 24-year-old Gauss using least-squares analysis.\nIn 1809 Carl Friedrich Gauss published his method of calculating the orbits of celestial bodies. In that work he claimed to have been in possession of the method of least squares since 1795. This naturally led to a priority dispute with Legendre. However, to Gauss's credit, he went beyond Legendre and succeeded in connecting the method of least squares with the principles of probability and to the normal distribution. He had managed to complete Laplace's program of specifying a mathematical form of the probability density for the observations, depending on a finite number of unknown parameters, and define a method of estimation that minimizes the error of estimation. Gauss showed that the arithmetic mean is indeed the best estimate of the location parameter by changing both the probability density and the method of estimation. He then turned the problem around by asking what form the density should have and what method of estimation should be used to get the arithmetic mean as estimate of the location parameter. In this attempt, he invented the normal distribution.\nThe first clear and concise exposition of the method of least squares was published by Legendre in 1805.[5] The technique is described as an algebraic procedure for fitting linear equations to data and Legendre demonstrates the new method by analyzing the same data as Laplace for the shape of the earth. The value of Legendre's method of least squares was immediately recognized by leading astronomers and geodesists of the time.\nThe method was the culmination of several advances that took place during the course of the eighteenth century:[4]\nThe method of least squares grew out of the fields of astronomy and geodesy, as scientists and mathematicians sought to provide solutions to the challenges of navigating the Earth's oceans during the Age of Exploration.  The accurate description of the behavior of celestial bodies was the key to enabling ships to sail in open seas, where sailors could no longer rely on land sightings for navigation.\nThe least-squares method is usually credited to Carl Friedrich Gauss (1795),[2] but it was first published by Adrien-Marie Legendre (1805).[3]\nThe following discussion is mostly presented in terms of linear functions but the use of least squares is valid and practical for more general families of functions. Also, by iteratively applying local quadratic approximation to the likelihood (through the Fisher information), the least-squares method may be used to fit a generalized linear model.\nWhen the observations come from an exponential family and mild conditions are satisfied, least-squares estimates and maximum-likelihood estimates are identical.[1] The method of least squares can also be derived as a method of moments estimator.\nPolynomial least squares describes the variance in a prediction of the dependent variable as a function of the independent variable and the deviations from the fitted curve.\nLeast-squares problems fall into two categories: linear or ordinary least squares and nonlinear least squares, depending on whether or not the residuals are linear in all unknowns. The linear least-squares problem occurs in statistical regression analysis; it has a closed-form solution. The nonlinear problem is usually solved by iterative refinement; at each iteration the system is approximated by a linear one, and thus the core calculation is similar in both cases.\nThe most important application is in data fitting.  The best fit in the least-squares sense minimizes the sum of squared residuals (a residual being: the difference between an observed value, and the fitted value provided by a model). When the problem has substantial uncertainties in the independent variable (the x variable), then simple regression and least-squares methods have problems; in such cases, the methodology required for fitting errors-in-variables models may be considered instead of that for least squares.\nThe method of least squares is a standard approach in regression analysis to approximate the solution of overdetermined systems, i.e., sets of equations in which there are more equations than unknowns. \"Least squares\" means that the overall solution minimizes the sum of the squares of the residuals made in the results of every single equation.\n",
            "title": "Least squares",
            "url": "https://en.wikipedia.org/wiki/Least_squares"
        },
        {
            "desc_links": [
                "/wiki/Matrix_(mathematics)",
                "/wiki/Row_vector",
                "/wiki/Column_vector",
                "/wiki/Linear_transformation",
                "/wiki/Vector_space",
                "/wiki/Ordered_basis",
                "/wiki/Linear_algebra"
            ],
            "desc_text": "b'In linear algebra, a coordinate vector is a representation of a vector as an ordered list of numbers that describes the vector in terms of a particular ordered basis. Coordinates are always specified relative to an ordered basis. Bases and their associated coordinate representations let one realize vector spaces and linear transformations concretely as column vectors, row vectors, and matrices, hence are useful in calculations.\\n'b'The idea of a coordinate vector can also be used for infinite-dimensional vector spaces, as addressed below.\\n'",
            "links": [
                "/wiki/Matrix_(mathematics)",
                "/wiki/Row_vector",
                "/wiki/Column_vector",
                "/wiki/Linear_transformation",
                "/wiki/Vector_space",
                "/wiki/Ordered_basis",
                "/wiki/Linear_algebra",
                "/wiki/Field_(mathematics)",
                "/wiki/Dimension_(vector_space)",
                "/wiki/Vector_space",
                "/wiki/Coordinates",
                "/wiki/Sequence",
                "/wiki/Row_vector",
                "/wiki/Column_vector",
                "/wiki/Matrix_(mathematics)",
                "/wiki/Polynomials",
                "/wiki/Matrix_(math)",
                "/wiki/Differentiation_operator",
                "/wiki/Eigenvalues",
                "/wiki/Hermitian",
                "/wiki/Invertible_matrix",
                "/wiki/Eigenstate",
                "/wiki/Spin_(physics)",
                "/wiki/Pauli_matrices",
                "/wiki/Automorphism",
                "/wiki/Standard_basis",
                "/wiki/Invertible_matrix",
                "/wiki/Full_linear_ring",
                "/wiki/Infinite_matrix#Infinite_matrices"
            ],
            "text": "The linear transformations between (possibly) infinite-dimensional vector spaces can be modeled, analogously to the finite-dimensional case, with infinite matrices. The special case of the transformations from V into V is described in the full linear ring article.\nSuppose V is an infinite-dimensional vector space over a field F. If the dimension is \u03ba, then there is some basis of \u03ba elements for V. After an order is chosen, the basis can be considered an ordered basis. The elements of V are finite linear combinations of elements in the basis, which give rise to unique coordinate representations exactly as described before. The only change is that the indexing set for the coordinates is not finite. Since a given vector v is a finite linear combination of basis elements, the only nonzero entries of the coordinate vector for v will be the nonzero coefficients of the linear combination representing v. Thus the coordinate vector for v is zero except in finitely many entries.\nThe matrix M is an invertible matrix and M\u22121 is the basis transformation matrix from C to B. In other words,\nUnder the transformation of basis, notice that the superscript on the transformation matrix, M, and the subscript on the coordinate vector, v, are the same, and seemingly cancel, leaving the remaining subscript. While this may serve as a memory aid, it is important to note that no such cancellation, or similar mathematical operation, is taking place.\nwhere \nIf E is the standard basis, the notation can be simplified by omitting it, with the transformation from B to E being represented:\nThis matrix is referred to as the basis transformation matrix from B to C. It can be regarded as an automorphism over V.  Any vector v represented in B can be transformed to a representation in C as follows:\nThe Pauli matrices which represent the spin operator when transforming the spin eigenstates into vector coordinates.\nUsing that method it is easy to explore the properties of the operator: such as invertibility, hermitian or anti-hermitian or none, spectrum and eigenvalues and more.\nAccording to that representation, the differentiation operator d/dx which we shall mark D will be represented by the following matrix:\nis\nthen the coordinate vector corresponding to the polynomial\nmatching\nLet P3 be the space of all the algebraic polynomials in degree at most 3 (i.e. the highest exponent of x can be 3). This space is linear and spanned by the following polynomials:\nor\nCoordinate vectors of finite-dimensional vector spaces can be represented by matrices as column or row vectors. In the above notation, one can write\nThis is also called the representation of v with respect of B, or the B representation of v. The \u03b1-s are called the coordinates of v. The order of the basis becomes important here, since it determines the order in which the coefficients are listed in the coordinate vector.\nThe coordinate vector of v relative to B is the sequence of coordinates\nLet V be a vector space of dimension n over a field F and let \nThe idea of a coordinate vector can also be used for infinite-dimensional vector spaces, as addressed below.\nIn linear algebra, a coordinate vector is a representation of a vector as an ordered list of numbers that describes the vector in terms of a particular ordered basis. Coordinates are always specified relative to an ordered basis. Bases and their associated coordinate representations let one realize vector spaces and linear transformations concretely as column vectors, row vectors, and matrices, hence are useful in calculations.\n",
            "title": "Coordinate vector",
            "url": "https://en.wikipedia.org/wiki/Coordinate_vector"
        },
        {
            "desc_links": [
                "/wiki/Functional_analysis",
                "/wiki/Dimension_(vector_space)",
                "/wiki/Dot_product",
                "/wiki/Euclidean_space",
                "/wiki/Orthogonality",
                "/wiki/Angle",
                "/wiki/Scalar_(mathematics)",
                "/wiki/Mathematical_structure",
                "/wiki/Vector_space",
                "/wiki/Linear_algebra",
                "/wiki/Hilbert_space",
                "/wiki/Complete_space#Completion",
                "/wiki/Hilbert_space",
                "/wiki/Complete_space",
                "/wiki/Normed_vector_space",
                "/wiki/Norm_(mathematics)"
            ],
            "desc_text": "b'In linear algebra, an inner product space is a vector space with an additional structure called an inner product. This additional structure associates each pair of vectors in the space with a scalar quantity known as the inner product of the vectors. Inner products allow the rigorous introduction of intuitive geometrical notions such as the length of a vector or the angle between two vectors. They also provide the means of defining orthogonality between vectors (zero inner product). Inner product spaces generalize Euclidean spaces (in which the inner product is the dot product, also known as the scalar product) to vector spaces of any (possibly infinite) dimension, and are studied in functional analysis. The first usage of the concept of a vector space with an inner product is due to Peano, in 1898.[1]\\n'b'An inner product naturally induces an associated norm, thus an inner product space is also a normed vector space. A complete space with an inner product is called a Hilbert space. An (incomplete) space with an inner product is called a pre-Hilbert space, since its completion with respect to the norm induced by the inner product is a Hilbert space. Inner product spaces over the field of complex numbers are sometimes referred to as unitary spaces.\\n'",
            "links": [
                "/wiki/Functional_analysis",
                "/wiki/Dimension_(vector_space)",
                "/wiki/Dot_product",
                "/wiki/Euclidean_space",
                "/wiki/Orthogonality",
                "/wiki/Angle",
                "/wiki/Scalar_(mathematics)",
                "/wiki/Mathematical_structure",
                "/wiki/Vector_space",
                "/wiki/Linear_algebra",
                "/wiki/Hilbert_space",
                "/wiki/Complete_space#Completion",
                "/wiki/Hilbert_space",
                "/wiki/Complete_space",
                "/wiki/Normed_vector_space",
                "/wiki/Norm_(mathematics)",
                "/wiki/Complex_number",
                "/wiki/Real_number",
                "/wiki/Scalar_(mathematics)",
                "/wiki/Field_(mathematics)",
                "/wiki/Algebra_over_a_field",
                "/wiki/Vector_space",
                "/wiki/Axiom",
                "/wiki/Dual_space",
                "/wiki/Linear_functional",
                "/wiki/Quantum_mechanics",
                "/wiki/Bra%E2%80%93ket_notation",
                "/wiki/Sesquilinear_form",
                "/wiki/Matrix_algebra",
                "/wiki/Physics",
                "/wiki/Hilbert_space",
                "/wiki/Complete_metric_space",
                "/wiki/Quantum_computation",
                "/wiki/Constructible_number#Transformation_into_algebra",
                "/wiki/Algebraic_number",
                "/wiki/Characteristic_(algebra)",
                "/wiki/Ordered_field",
                "/wiki/Basefield",
                "/wiki/Complex_conjugate",
                "/wiki/Sesquilinear",
                "/wiki/Real_numbers",
                "/wiki/Euclidean_space",
                "/wiki/Dot_product",
                "/wiki/Real_coordinate_space",
                "/wiki/Transpose",
                "/wiki/Hermitian_form",
                "/wiki/Weight_function",
                "/wiki/Scale_factor",
                "/wiki/Scaling_(geometry)",
                "/wiki/Conjugate_transpose",
                "/wiki/Positive-definite_matrix",
                "/wiki/Hermitian_matrix",
                "/wiki/Complete_space",
                "/wiki/Hilbert_space",
                "/wiki/Cauchy_sequence",
                "/wiki/Expected_value",
                "/wiki/Random_variable",
                "/wiki/Random_vector",
                "/wiki/Almost_surely",
                "/wiki/Probability",
                "/wiki/Nondegenerate_form",
                "/wiki/Parallelogram_equality#Normed_vector_spaces_satisfying_the_parallelogram_law",
                "/wiki/Normed_space",
                "/wiki/Norm_(mathematics)",
                "/wiki/Gram%E2%80%93Schmidt_process",
                "/wiki/Basis_(linear_algebra)",
                "/wiki/Separable_space",
                "/wiki/Hilbert_space",
                "/wiki/Hausdorff_maximal_principle",
                "/wiki/Hilbert_space",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Parseval%27s_identity",
                "/wiki/Hilbert_space",
                "/wiki/Trigonometric_polynomial",
                "/wiki/Fourier_series",
                "/wiki/Weierstrass_approximation_theorem",
                "/wiki/Linear",
                "/wiki/Normal_operator",
                "/wiki/Spectral_theorem",
                "/wiki/Semi-norm",
                "/wiki/Mercer%27s_theorem",
                "/wiki/Gelfand%E2%80%93Naimark%E2%80%93Segal_construction",
                "/wiki/Sign_convention#Metric_signature",
                "/wiki/Sign_(mathematics)",
                "/wiki/Dimension_(mathematics)",
                "/wiki/Minkowski_space",
                "/wiki/Sylvester%27s_law_of_inertia",
                "/wiki/Pseudo-Riemannian_manifold",
                "/wiki/Riemannian_manifold",
                "/wiki/Differential_geometry",
                "/wiki/Nondegenerate_form",
                "/wiki/Outer_product",
                "/wiki/Simple_tensor",
                "/wiki/Exterior_algebra",
                "/wiki/Differential_form",
                "/wiki/Vector_field",
                "/wiki/Exterior_product",
                "/wiki/Interior_product",
                "/wiki/Clifford_algebra",
                "/wiki/Geometric_algebra"
            ],
            "text": "As a further complication, in geometric algebra the inner product and the exterior (Grassmann) product are combined in the geometric product (the Clifford product in a Clifford algebra) \u2013 the inner product sends two vectors (1-vectors) to a scalar (a 0-vector), while the exterior product sends two vectors to a bivector (2-vector) \u2013 and in this context the exterior product is usually called the \"outer (alternatively, wedge) product\". The inner product is more correctly called a scalar product in this context, as the nondegenerate quadratic form in question need not be positive definite (need not be an inner product).\nThe inner product and outer product should not be confused with the interior product and exterior product, which are instead operations on vector fields and differential forms, or more generally on the exterior algebra.\nMore abstractly, the outer product is the bilinear map W \u00d7 V\u2217 \u2192 Hom(V,W) sending a vector and a covector to a rank 1 linear transformation (simple tensor of type (1,1)), while the inner product is the bilinear evaluation map V\u2217 \u00d7 V \u2192 F given by evaluating a covector on a vector; the order of the domain vector spaces here reflects the covector/vector distinction.\nThe term \"inner product\" is opposed to outer product, which is a slightly more general opposite. Simply, in coordinates, the inner product is the product of a 1 \u00d7 n covector with an n \u00d7 1 vector, yielding a 1\u00a0\u00d7\u00a01 matrix (a scalar), while the outer product is the product of an m \u00d7 1 vector with a 1 \u00d7 n covector, yielding an m \u00d7 n matrix. Note that the outer product is defined for different dimensions, while the inner product requires the same dimension. If the dimensions are the same, then the inner product is the trace of the outer product (trace only being properly defined for square matrices).  In a quip: \"inner is horizontal times vertical and shrinks down, outer is vertical times horizontal and expands out\".\nPurely algebraic statements (ones that do not use positivity) usually only rely on the nondegeneracy (the injective homomorphism V \u2192 V\u2217) and thus hold more generally.\nAlternatively, one may require that the pairing be a nondegenerate form, meaning that for all non-zero x there exists some y such that \u27e8x,y\u27e9 \u2260 0, though y need not equal x; in other words, the induced map to the dual space V \u2192 V\u2217 is injective. This generalization is important in differential geometry: a manifold whose tangent spaces have an inner product is a Riemannian manifold, while if this is related to nondegenerate conjugate symmetric form the manifold is a pseudo-Riemannian manifold. By Sylvester's law of inertia, just as every inner product is similar to the dot product with positive weights on a set of vectors, every nondegenerate conjugate symmetric form is similar to the dot product with nonzero weights on a set of vectors, and the number of positive and negative weights are called respectively the positive index and negative index. Product of vectors in Minkowski space is an example of indefinite inner product, although, technically speaking, it is not an inner product according to the standard definition above. Minkowski space has four dimensions and indices 3 and 1 (assignment of \"+\" and \"\u2212\" to them differs depending on conventions).\nThis construction is used in numerous contexts. The Gelfand\u2013Naimark\u2013Segal construction is a particularly important example of the use of this technique. Another example is the representation of semi-definite kernels on arbitrary sets.\nmakes sense and satisfies all the properties of norm except that ||x|| = 0 does not imply x = 0 (such a functional is then called a semi-norm). We can produce an inner product space by considering the quotient W = V/{x\u00a0: ||x|| = 0}. The sesquilinear form \u27e8\u00b7,\u00b7\u27e9 factors through W.\nIf V is a vector space and \u27e8\u00b7,\u00b7\u00b7\u00b7\u27e9 a semi-definite sesquilinear form, then the function:\nAny of the axioms of an inner product may be weakened, yielding generalized notions. The generalizations that are closest to inner products occur where bilinearity and conjugate symmetry are retained, but positive-definiteness is weakened.\nFrom the point of view of inner product space theory, there is no need to distinguish between two spaces which are isometrically isomorphic. The spectral theorem provides a canonical form for symmetric, unitary and more generally normal operators on finite dimensional inner product spaces. A generalization of the spectral theorem holds for continuous normal operators in Hilbert spaces.\nSeveral types of linear maps A from an inner product space V to an inner product space W are of relevance:\nNormality of the sequence is by design, that is, the coefficients are so chosen so that the norm comes out to 1. Finally the fact that the sequence has a dense algebraic span, in the inner product norm, follows from the fact that the sequence has a dense algebraic span, this time in the space of continuous periodic functions on [\u2212\u03c0,\u03c0] with the uniform norm. This is the content of the Weierstrass theorem on the uniform density of trigonometric polynomials.\nOrthogonality of the sequence {ek}k follows immediately from the fact that if k \u2260 j, then\nis an isometric linear map with dense image.\nis an orthonormal basis of the space C[\u2212\u03c0,\u03c0] with the L2 inner product. The mapping\nTheorem. Let V be the inner product space C[\u2212\u03c0,\u03c0]. Then the sequence (indexed on set of all integers) of continuous functions\nThis theorem can be regarded as an abstract form of Fourier series, in which an arbitrary orthonormal basis plays the role of the sequence of trigonometric polynomials. Note that the underlying index set can be taken to be any countable set (and in fact any set whatsoever, provided l2 is defined appropriately, as is explained in the article Hilbert space). In particular, we obtain the following result in the theory of Fourier series:\nis an isometric linear map V \u2192 l2 with a dense image.\nTheorem. Let V be a separable inner product space and {ek}k an orthonormal basis of\u00a0V. Then the map\nParseval's identity leads immediately to the following theorem:\nThe two previous theorems raise the question of whether all inner product spaces have an orthonormal basis. The answer, it turns out is negative. This is a non-trivial result, and is proved below. The following proof is taken from Halmos's A Hilbert Space Problem Book (see the references).[citation needed]\nTheorem. Any complete inner product space V has an orthonormal basis.\nUsing the Hausdorff maximal principle and the fact that in a complete inner product space orthogonal projection onto linear subspaces is well-defined, one may also show that\nTheorem. Any separable inner product space V has an orthonormal basis.\nUsing an infinite-dimensional analog of the Gram-Schmidt process one may show:\nif \u03b1 \u2260 \u03b2 and \u27e8e\u03b1,e\u03b1\u27e9 = ||e\u03b1|| = 1 for all \u03b1, \u03b2 \u2208 A.\nis a basis for V if the subspace of V generated by finite linear combinations of elements of E is dense in V (in the norm induced by the inner product). We say that E is an orthonormal basis for V if it is a basis and\nThis definition of orthonormal basis generalizes to the case of infinite-dimensional inner product spaces in the following way. Let V be any inner product space. Then a collection\nLet V be a finite dimensional inner product space of dimension n. Recall that every basis of V consists of exactly n linearly independent vectors. Using the Gram\u2013Schmidt process we may start with an arbitrary basis and transform it into an orthonormal basis. That is, into a basis in which all the elements are orthogonal and have unit norm. In symbols, a basis {e1, ..., en} is orthonormal if \u27e8ei,ej\u27e9 = 0 for every i \u2260 j and \u27e8ei,ei\u27e9 = ||ei|| = 1 for each i.\nThis is well defined by the nonnegativity axiom of the definition of inner product space. The norm is thought of as the length of the vector x. Directly from the axioms, we can prove the following:\nHowever, inner product spaces have a naturally defined norm based upon the inner product of the space itself that does satisfy the parallelogram equality:\nis a normed space but not an inner product space, because this norm does not satisfy the parallelogram equality required of a norm to have an inner product associated with it.[9][10]\nA linear space with a norm such as:\nOn an inner product space, or more generally a vector space with a nondegenerate form (so an isomorphism V \u2192 V\u2217) vectors can be sent to covectors (in coordinates, via transpose), so one can take the inner product and outer product of two vectors, not simply of a vector and a covector.\nis an inner product.\nFor real matrices of the same size, \u27e8A,B\u27e9\u00a0:= tr(ABT) with transpose as conjugation\nis an inner product.[6][7][8] In this case, \u27e8X,X\u27e9 = 0 if and only if Pr(X = 0) = 1 (i.e., X = 0 almost surely). This definition of expectation as inner product can be extended to random vectors as well.\nFor real random variables X and Y, the expected value of their product\nThis sequence is a Cauchy sequence for the norm induced by the preceding inner product, which does not converge to a continuous function.\nThis space is not complete; consider for example, for the interval [\u22121,1] the sequence of continuous \"step\" functions, {\u2009fk}k, defined by:\nThe article on Hilbert space has several examples of inner product spaces wherein the metric induced by the inner product yields a complete metric space. An example of an inner product which induces an incomplete metric occurs with the space C([a,b]) of continuous complex valued functions on the interval [a,b]. The inner product is\nwhere M is any Hermitian positive-definite matrix and y\u2020 is the conjugate transpose of y. For the real case this corresponds to the dot product of the results of directionally different scaling of the two vectors, with positive scale factors and orthogonal directions of scaling. Up to an orthogonal transformation it is a weighted-sum version of the dot product, with positive weights.\nThe general form of an inner product on Cn is known as the Hermitian form and is given by\nwhere xT is the transpose of x.\nMore generally, the real n-space Rn with the dot product is an inner product space, an example of a Euclidean n-space.\nA simple example is the real numbers with the standard multiplication as the inner product\nis also known as additivity.\nThe property of an inner product space V that\nAssuming the underlying field to be R, the inner product becomes symmetric, and we obtain\nCombining the linearity of the inner product in its first argument and the conjugate symmetry gives the following important generalization of the familiar square expansion:\nFrom the linearity property it is derived that x = 0 implies \u27e8x,x\u27e9 = 0. while from the positive-definiteness axiom we obtain the converse, \u27e8x,x\u27e9 = 0 implies x = 0. Combining these two, we have the property that \u27e8x,x\u27e9 = 0 if and only if x = 0.\nIn the case of F = R, conjugate-symmetry reduces to symmetry, and sesquilinear reduces to bilinear. So, an inner product on a real vector space is a positive-definite symmetric bilinear form.\nso an inner product is a sesquilinear form. Conjugate symmetry is also called Hermitian symmetry, and a conjugate symmetric sesquilinear form is called a Hermitian form. While the above axioms are more mathematically economical, a compact verbal definition of an inner product is a positive-definite Hermitian form.\nConjugate symmetry and linearity in the first variable gives\nMoreover, sesquilinearity (see below) implies that\nNotice that conjugate symmetry implies that \u27e8x,x\u27e9 is real for all x, since we have:\nWhen F = R, conjugate symmetry reduces to symmetry. That is, \u27e8x,y\u27e9 = \u27e8y,x\u27e9 for F = R; while for F = C, \u27e8x,y\u27e9 is equal to the complex conjugate.\nIn some cases we need to consider non-negative semi-definite sesquilinear forms. This means that \u27e8x,x\u27e9 is only required to be non-negative. We show how to treat these below.\nThere are various technical reasons why it is necessary to restrict the basefield to R and C in the definition. Briefly, the basefield has to contain an ordered subfield in order for non-negativity to make sense,[5] and therefore has to have characteristic equal to 0 (since any ordered field has to have such characteristic). This immediately excludes finite fields. The basefield has to have additional structure, such as a distinguished automorphism. More generally any quadratically closed subfield of R or C will suffice for this purpose, e.g., the algebraic numbers or the constructible numbers. However in these cases when it is a proper subfield (i.e., neither R nor C) even finite-dimensional inner product spaces will fail to be metrically complete. In contrast all finite-dimensional inner product spaces over R or C, such as those used in quantum computation, are automatically metrically complete and hence Hilbert spaces.\nSome authors, especially in physics and matrix algebra, prefer to define the inner product and the sesquilinear form with linearity in the second argument rather than the first. Then the first argument becomes conjugate linear, rather than the second. In those disciplines we would write the product \u27e8x,y\u27e9 as \u27e8y|x\u27e9 (the bra\u2013ket notation of quantum mechanics), respectively y\u2020x (dot product as a case of the convention of forming the matrix product AB as the dot products of rows of A with columns of B). Here the kets and columns are identified with the vectors of V and the bras and rows with the linear functionals (covectors) of the dual space V\u2217, with conjugacy associated with duality. This reverse order is now occasionally followed in the more abstract literature,[4] taking \u27e8x,y\u27e9 to be conjugate linear in x rather than y. A few instead find a middle ground by recognizing both \u27e8\u00b7,\u00b7\u27e9 and \u27e8\u00b7|\u00b7\u27e9 as distinct notations differing only in which argument is conjugate linear.\nthat satisfies the following three axioms for all vectors x, y, z \u2208 V and all scalars a \u2208 F:[2][3]\nFormally, an inner product space is a vector space V over the field F together with an inner product, i.e., with a map\nIn this article, the field of scalars denoted F is either the field of real numbers R or the field of complex numbers C.\nAn inner product naturally induces an associated norm, thus an inner product space is also a normed vector space. A complete space with an inner product is called a Hilbert space. An (incomplete) space with an inner product is called a pre-Hilbert space, since its completion with respect to the norm induced by the inner product is a Hilbert space. Inner product spaces over the field of complex numbers are sometimes referred to as unitary spaces.\nIn linear algebra, an inner product space is a vector space with an additional structure called an inner product. This additional structure associates each pair of vectors in the space with a scalar quantity known as the inner product of the vectors. Inner products allow the rigorous introduction of intuitive geometrical notions such as the length of a vector or the angle between two vectors. They also provide the means of defining orthogonality between vectors (zero inner product). Inner product spaces generalize Euclidean spaces (in which the inner product is the dot product, also known as the scalar product) to vector spaces of any (possibly infinite) dimension, and are studied in functional analysis. The first usage of the concept of a vector space with an inner product is due to Peano, in 1898.[1]\n",
            "title": "Inner product space",
            "url": "https://en.wikipedia.org/wiki/Inner_product"
        },
        {
            "desc_links": [
                "/wiki/Matrix_(mathematics)",
                "/wiki/Linear_algebra",
                "/wiki/Arthur_Cayley"
            ],
            "desc_text": "b'In linear algebra, the transpose of a matrix is an operator which flips a matrix over its diagonal, that is it switches the row and column indices of the matrix by producing another matrix denoted as AT (also written A\\xe2\\x80\\xb2, Atr, tA or At). It is achieved by any one of the following equivalent actions:\\n'b'Formally, the i-th row, j-th column element of AT is the j-th row, i-th column element of A:\\n'b'If A is an m \\xc3\\x97 n matrix, then AT is an n \\xc3\\x97 m matrix.\\n'b'The transpose of a matrix was introduced in 1858 by the British mathematician Arthur Cayley.[1]\\n'",
            "links": [
                "/wiki/Matrix_(mathematics)",
                "/wiki/Linear_algebra",
                "/wiki/Arthur_Cayley",
                "/wiki/Symmetric_matrix",
                "/wiki/Skew-symmetric_matrix",
                "/wiki/Conjugate_transpose",
                "/wiki/Hermitian_matrix",
                "/wiki/Complex_conjugate",
                "/wiki/Complex_number",
                "/wiki/Skew-Hermitian_matrix",
                "/wiki/Complex_number",
                "/wiki/Orthogonal_matrix",
                "/wiki/Unitary_matrix",
                "/wiki/Inner_product",
                "/wiki/Symmetric_matrices",
                "/wiki/Matrix_multiplication",
                "/wiki/Dual_module",
                "/wiki/Module_(mathematics)",
                "/wiki/Linear_map",
                "/wiki/Natural_pairing",
                "/wiki/Basis_(linear_algebra)",
                "/wiki/Double_dual",
                "/wiki/Bilinear_form",
                "/wiki/Nondegenerate_form",
                "/wiki/Vector_space",
                "/wiki/Linear_map",
                "/wiki/Basis_(linear_algebra)",
                "/wiki/Isomorphism",
                "/wiki/Orthogonal_group",
                "/wiki/Hermitian_adjoint",
                "/wiki/Sesquilinear_form",
                "/wiki/BLAS",
                "/wiki/Linear_algebra",
                "/wiki/Software_libraries",
                "/wiki/Random_access_memory",
                "/wiki/Computer",
                "/wiki/Memory_locality",
                "/wiki/Fast_Fourier_transform",
                "/wiki/Row-major_order",
                "/wiki/Computer_science",
                "/wiki/In-place_matrix_transposition",
                "/wiki/Permutation",
                "/wiki/Big_O_notation",
                "/wiki/In-place"
            ],
            "text": "Ideally, one might hope to transpose a matrix with minimal additional storage. This leads to the problem of transposing an n\u00a0\u00d7\u00a0m matrix in-place, with O(1) additional storage or at most storage much less than mn. For n\u00a0\u2260\u00a0m, this involves a complicated permutation of the data elements that is non-trivial to implement in-place. Therefore, efficient in-place matrix transposition has been the subject of numerous research publications in computer science, starting in the late 1950s, and several algorithms have been developed.\nHowever, there remain a number of circumstances in which it is necessary or desirable to physically reorder a matrix in memory to its transposed ordering. For example, with a matrix stored in row-major order, the rows of the matrix are contiguous in memory and the columns are discontiguous. If repeated operations need to be performed on the columns, for example in a fast Fourier transform algorithm, transposing the matrix in memory (to make the columns contiguous) may improve performance by increasing memory locality.\nOn a computer, one can often avoid explicitly transposing a matrix in memory by simply accessing the same data in a different order. For example, software libraries for linear algebra, such as BLAS, typically provide options to specify that certain matrices are to be interpreted in transposed order to avoid the necessity of data movement.\nOver a complex vector space, one often works with sesquilinear forms (conjugate-linear in one argument) instead of bilinear forms. The Hermitian adjoint of a map between such spaces is defined similarly, and the matrix of the Hermitian adjoint is given by the conjugate transpose matrix if the bases are orthonormal.\nThe adjoint allows us to consider whether g\u00a0: W \u2192 V is equal to f\u2009\u22121\u00a0: W \u2192 V. In particular, this allows the orthogonal group over a vector space V with a quadratic form to be defined without reference to matrices (nor the components thereof) as the set of all linear maps V \u2192 V for which the adjoint equals the inverse.\nThese bilinear forms define an isomorphism between V and V\u2217, and between W and W\u2217, resulting in an isomorphism between the transpose and adjoint of f. The matrix of the adjoint of a map is the transposed matrix only if the bases are orthonormal with respect to their bilinear forms. In this context, many authors use the term transpose to refer to the adjoint as defined here.\nIf f\u00a0: V \u2192 W is a linear map between vector spaces V and W, we define g as the adjoint of f if g\u00a0: W \u2192 V satisfies\nIf the vector spaces V and W have respectively nondegenerate bilinear forms BV and BW, a concept known as the adjoint, which is closely related to the transpose, may be defined:\nEvery linear map to the dual space f\u00a0: V \u2192 V\u2217 defines a bilinear form B\u00a0: V \u00d7 V \u2192 F, with the relation B(v, w) = f(v)(w). By defining the transpose of this bilinear form as the bilinear form tB defined by the transpose tf\u00a0: V\u2217\u2217 \u2192 V\u2217 i.e. tB(w, v) = tf(\u03a8(w))(v), we find that B(v, w) = tB(w, v). Here, \u03a8 is the natural homomorphism V \u2192 V\u2217\u2217 into the double dual.\nIf the matrix A describes a linear map with respect to bases of V and W, then the matrix AT describes the transpose of that linear map with respect to the dual bases.\nThe definition of the transpose may be seen to be independent of any bilinear form on the vector spaces, unlike the adjoint (below).\nwhere \u27e8\u00b7,\u00b7\u27e9 is the natural pairing of each dual space with its respective vector space. This definition also applies unchanged to left modules and to vector spaces.[3]\nEquivalently, the transpose tf is defined by the relation\nIf f\u00a0: V \u2192 W is a linear map between right R-modules V and W with respective dual modules V\u2217 and W\u2217, the transpose of f is the linear map\nThe transpose may be defined more generally:\nA quick proof of the symmetry of A AT results from the fact that it is its own transpose:\nIf A is an m \u00d7 n matrix and AT is its transpose, then the result of matrix multiplication with these two matrices gives two square matrices: A AT is m \u00d7 m and AT A is n \u00d7 n. Furthermore, these products are symmetric matrices. Indeed, the matrix product A AT has entries that are the inner product of a row of A with a column of AT. But the columns of AT are the rows of A, so the entry corresponds to the inner product of two rows of A. If pi j is the entry of the product, it is obtained from rows i and j in A. The entry pj i is also obtained from these rows, thus pi j = pj i, and the product matrix (pi j) is symmetric. Similarly, the product AT A is a symmetric matrix.\nA square complex matrix whose transpose is equal to its conjugate inverse is called a unitary matrix; that is, A is unitary if\nA square matrix whose transpose is equal to its inverse is called an orthogonal matrix; that is, A is orthogonal if\nA square complex matrix whose transpose is equal to the negation of its complex conjugate is called a skew-Hermitian matrix; that is, A is skew-Hermitian if\nA square complex matrix whose transpose is equal to the matrix with every entry replaced by its complex conjugate (denoted here with an overline) is called a Hermitian matrix (equivalent to the matrix being equal to its conjugate transpose); that is, A is Hermitian if\nA square matrix whose transpose is equal to its negative is called a skew-symmetric matrix; that is, A is skew-symmetric if\nA square matrix whose transpose is equal to itself is called a symmetric matrix; that is, A is symmetric if\nFor matrices A, B and scalar c we have the following properties of transpose:\nThe transpose of a matrix was introduced in 1858 by the British mathematician Arthur Cayley.[1]\nIf A is an m \u00d7 n matrix, then AT is an n \u00d7 m matrix.\nFormally, the i-th row, j-th column element of AT is the j-th row, i-th column element of A:\nIn linear algebra, the transpose of a matrix is an operator which flips a matrix over its diagonal, that is it switches the row and column indices of the matrix by producing another matrix denoted as AT (also written A\u2032, Atr, tA or At). It is achieved by any one of the following equivalent actions:\n",
            "title": "Transpose",
            "url": "https://en.wikipedia.org/wiki/Transpose"
        },
        {
            "desc_links": [
                "/wiki/Expression_(mathematics)",
                "/wiki/Symbol_(formal)",
                "/wiki/Number",
                "/wiki/Rectangle",
                "/wiki/Mathematics",
                "/wiki/Eigenvalues_and_eigenvectors",
                "/wiki/Geometry",
                "/wiki/Zero",
                "/wiki/If_and_only_if",
                "/wiki/Invertible_matrix",
                "/wiki/Determinant",
                "/wiki/System_of_linear_equations",
                "/wiki/Transformation_(function)",
                "/wiki/Function_composition",
                "/wiki/Transformation_matrices",
                "/wiki/Position_(vector)",
                "/wiki/Column_vector",
                "/wiki/Rotation_matrix",
                "/wiki/Dimension",
                "/wiki/Euclidean_vector",
                "/wiki/Rotation_(mathematics)",
                "/wiki/Linear_functions",
                "/wiki/Linear_transformation",
                "/wiki/Field_(mathematics)",
                "/wiki/Scalar_(mathematics)",
                "/wiki/Matrix_multiplication#Scalar_multiplication",
                "/wiki/Matrix_multiplication",
                "/wiki/Conformable_matrix",
                "/wiki/Matrix_addition",
                "/wiki/Economics",
                "/wiki/Exponentials",
                "/wiki/Derivative",
                "/wiki/Mathematical_analysis",
                "/wiki/Matrix_calculus",
                "/wiki/PageRank",
                "/wiki/Stochastic_matrix",
                "/wiki/Statistics",
                "/wiki/Probability_theory",
                "/wiki/Glossary_of_computer_graphics#screen_space",
                "/wiki/3D_models",
                "/wiki/Computer_graphics",
                "/wiki/Rigid-body_dynamics",
                "/wiki/Quantum_electrodynamics",
                "/wiki/Quantum_mechanics",
                "/wiki/Electromagnetism",
                "/wiki/Optics",
                "/wiki/Classical_mechanics",
                "/wiki/Physics",
                "/wiki/Taylor_series",
                "/wiki/Derivative_(calculus)",
                "/wiki/Finite_element_method",
                "/wiki/Diagonal_matrix",
                "/wiki/Sparse_matrix",
                "/wiki/Matrix_(mathematics)#Decomposition",
                "/wiki/Numerical_analysis"
            ],
            "desc_text": "b'In mathematics, a matrix (plural: matrices) is a rectangular array[1] of numbers, symbols, or expressions, arranged in rows and columns.[2][3] For example, the dimensions of the matrix below are 2 \\xc3\\x97 3 (read \"two by three\"), because there are two rows and three columns:\\n'b\"The individual items in an m \\xc3\\x97 n matrix A, often denoted by ai,j, where max i = m and max j = n, are called its elements or entries.[4] Provided that they have the same size (each matrix has the same number of rows and the same number of columns as the other), two matrices can be added or subtracted element by element (see Conformable matrix). The rule for matrix multiplication, however, is that two matrices can be multiplied only when the number of columns in the first equals the number of rows in the second (i.e., the inner dimensions are the same, n for Am,n \\xc3\\x97 Bn,p). Any matrix can be multiplied element-wise by a scalar from its associated field. A major application of matrices is to represent linear transformations, that is, generalizations of linear functions such as f(x) = 4x. For example, the rotation of vectors in three-dimensional space is a linear transformation, which can be represented by a rotation matrix R: if v is a column vector (a matrix with only one column) describing the position of a point in space, the product Rv is a column vector describing the position of that point after a rotation. The product of two transformation matrices is a matrix that represents the composition of two transformations. Another application of matrices is in the solution of systems of linear equations. If the matrix is square, it is possible to deduce some of its properties by computing its determinant. For example, a square matrix has an inverse if and only if its determinant is not zero. Insight into the geometry of a linear transformation is obtainable (along with other information) from the matrix's eigenvalues and eigenvectors.\\n\"b'Applications of matrices are found in most scientific fields. In every branch of physics, including classical mechanics, optics, electromagnetism, quantum mechanics, and quantum electrodynamics, they are used to study physical phenomena, such as the motion of rigid bodies. In computer graphics, they are used to manipulate 3D models and project them onto a 2-dimensional screen. In probability theory and statistics, stochastic matrices are used to describe sets of probabilities; for instance, they are used within the PageRank algorithm that ranks the pages in a Google search.[5] Matrix calculus generalizes classical analytical notions such as derivatives and exponentials to higher dimensions. Matrices are used in economics to describe systems of economic relationships.\\n'b'A major branch of numerical analysis is devoted to the development of efficient algorithms for matrix computations, a subject that is centuries old and is today an expanding area of research. Matrix decomposition methods simplify computations, both theoretically and practically. Algorithms that are tailored to particular matrix structures, such as sparse matrices and near-diagonal matrices, expedite computations in finite element method and other computations. Infinite matrices occur in planetary theory and in atomic theory. A simple example of an infinite matrix is the matrix representing the derivative operator, which acts on the Taylor series of a function.\\n'",
            "links": [
                "/wiki/Expression_(mathematics)",
                "/wiki/Symbol_(formal)",
                "/wiki/Number",
                "/wiki/Rectangle",
                "/wiki/Mathematics",
                "/wiki/Eigenvalues_and_eigenvectors",
                "/wiki/Geometry",
                "/wiki/Zero",
                "/wiki/If_and_only_if",
                "/wiki/Invertible_matrix",
                "/wiki/Determinant",
                "/wiki/System_of_linear_equations",
                "/wiki/Transformation_(function)",
                "/wiki/Function_composition",
                "/wiki/Transformation_matrices",
                "/wiki/Position_(vector)",
                "/wiki/Column_vector",
                "/wiki/Rotation_matrix",
                "/wiki/Dimension",
                "/wiki/Euclidean_vector",
                "/wiki/Rotation_(mathematics)",
                "/wiki/Linear_functions",
                "/wiki/Linear_transformation",
                "/wiki/Field_(mathematics)",
                "/wiki/Scalar_(mathematics)",
                "/wiki/Matrix_multiplication#Scalar_multiplication",
                "/wiki/Matrix_multiplication",
                "/wiki/Conformable_matrix",
                "/wiki/Matrix_addition",
                "/wiki/Economics",
                "/wiki/Exponentials",
                "/wiki/Derivative",
                "/wiki/Mathematical_analysis",
                "/wiki/Matrix_calculus",
                "/wiki/PageRank",
                "/wiki/Stochastic_matrix",
                "/wiki/Statistics",
                "/wiki/Probability_theory",
                "/wiki/Glossary_of_computer_graphics#screen_space",
                "/wiki/3D_models",
                "/wiki/Computer_graphics",
                "/wiki/Rigid-body_dynamics",
                "/wiki/Quantum_electrodynamics",
                "/wiki/Quantum_mechanics",
                "/wiki/Electromagnetism",
                "/wiki/Optics",
                "/wiki/Classical_mechanics",
                "/wiki/Physics",
                "/wiki/Taylor_series",
                "/wiki/Derivative_(calculus)",
                "/wiki/Finite_element_method",
                "/wiki/Diagonal_matrix",
                "/wiki/Sparse_matrix",
                "/wiki/Matrix_(mathematics)#Decomposition",
                "/wiki/Numerical_analysis",
                "/wiki/Complex_numbers",
                "/wiki/Real_numbers",
                "/wiki/Field_(mathematics)",
                "/wiki/Number",
                "/wiki/Square_matrix",
                "/wiki/Column_vectors",
                "/wiki/Row_vector",
                "/wiki/Parens",
                "/wiki/Box_bracket",
                "/wiki/Set_(mathematics)",
                "/wiki/Commutative",
                "/wiki/Dot_product",
                "/wiki/Distributivity",
                "/wiki/Associativity",
                "/wiki/Commutativity",
                "/wiki/Sylvester_equation",
                "/wiki/Kronecker_product",
                "/wiki/Hadamard_product_(matrices)",
                "/wiki/Matrix_inverse",
                "/wiki/Linear_equation",
                "/wiki/Determinant",
                "/wiki/Minor_(linear_algebra)",
                "/wiki/Independent_equation",
                "/wiki/Generalized_inverse",
                "/wiki/Inverse_matrix",
                "/wiki/Unit_vector",
                "/wiki/2_%C3%97_2_real_matrices",
                "/wiki/Function_composition",
                "/wiki/Bijection",
                "/wiki/Kernel_(matrix)",
                "/wiki/Rank%E2%80%93nullity_theorem",
                "/wiki/Image_(mathematics)",
                "/wiki/Hamel_dimension",
                "/wiki/Linear_independence",
                "/wiki/Rank_of_a_matrix",
                "/wiki/Main_diagonal",
                "/wiki/Square_matrix",
                "/wiki/Diagonal_matrix",
                "/wiki/Triangular_matrix",
                "/wiki/Main_diagonal",
                "/wiki/Diagonal_matrix",
                "/wiki/Complex_conjugate",
                "/wiki/Conjugate_transpose",
                "/wiki/Asterisk",
                "/wiki/Hermitian_matrix",
                "/wiki/Skew-symmetric_matrix",
                "/wiki/Symmetric_matrix",
                "/wiki/Linear_combination",
                "/wiki/Eigenbasis",
                "/wiki/Spectral_theorem",
                "/wiki/Invertible_matrix",
                "/wiki/Invertible_matrix",
                "/wiki/Main_diagonal",
                "/wiki/Identity_matrix",
                "/wiki/Quadratic_form",
                "/wiki/Positive-definite_matrix",
                "/wiki/Positive-definite_matrix#Indefinite",
                "/wiki/Positive-definite_matrix#Negative_definite",
                "/wiki/Bilinear_form",
                "/wiki/Invertible_matrix",
                "/wiki/Transpose",
                "/wiki/Orthonormality",
                "/wiki/Unit_vector",
                "/wiki/Orthogonal",
                "/wiki/Real_number",
                "/wiki/Matrix_(mathematics)#Square_matrices",
                "/wiki/Identity_matrix",
                "/wiki/Reflection_(mathematics)",
                "/wiki/Rotation_(mathematics)",
                "/wiki/Linear_transformation",
                "/wiki/Determinant",
                "/wiki/Determinant",
                "/wiki/Normal_matrix",
                "/wiki/Unitary_matrix",
                "/wiki/Invertible_matrix",
                "/wiki/Unitary_matrix",
                "/wiki/Complex_number",
                "/wiki/Trace_of_a_matrix",
                "/wiki/Cyclic_permutation",
                "/wiki/Absolute_value",
                "/wiki/If_and_only_if",
                "/wiki/Leibniz_formula_for_determinants",
                "/wiki/Rule_of_Sarrus",
                "/wiki/Cramer%27s_rule",
                "/wiki/Linear_system",
                "/wiki/Minor_(linear_algebra)",
                "/wiki/Laplace_expansion",
                "/wiki/Logical_equivalence",
                "/wiki/Zero_matrix",
                "/wiki/Cayley%E2%80%93Hamilton_theorem",
                "/wiki/Degree_of_a_polynomial",
                "/wiki/Monic_polynomial",
                "/wiki/Characteristic_polynomial",
                "/wiki/Indeterminate_(variable)",
                "/wiki/Infinity",
                "/wiki/Limit_of_a_sequence",
                "/wiki/Sequence_(mathematics)",
                "/wiki/Numerical_stability",
                "/wiki/Complexity_analysis",
                "/wiki/Numerical_linear_algebra",
                "/wiki/Strassen_algorithm",
                "/wiki/Matrix_multiplication_algorithm",
                "/wiki/Upper_bound",
                "/wiki/Conjugate_gradient_method",
                "/wiki/Sparse_matrix",
                "/wiki/Adjugate_matrix",
                "/wiki/Condition_number",
                "/wiki/Matrix_norm",
                "/wiki/List_of_numerical_analysis_software",
                "/wiki/APL_(programming_language)",
                "/wiki/HP_9830",
                "/wiki/Computer_language",
                "/wiki/Unitary_matrix",
                "/wiki/Singular_value_decomposition",
                "/wiki/Permutation_matrix",
                "/wiki/Elementary_matrix",
                "/wiki/Row_echelon_form",
                "/wiki/Forward_substitution",
                "/wiki/Triangular_matrix",
                "/wiki/LU_decomposition",
                "/wiki/Jordan_normal_form",
                "/wiki/Diagonalizable_matrix",
                "/wiki/Eigendecomposition",
                "/wiki/Schur_decomposition",
                "/wiki/Condition_number",
                "/wiki/Square_root_of_a_matrix",
                "/wiki/Matrix_logarithm",
                "/wiki/Linear_differential_equation",
                "/wiki/Matrix_exponential",
                "/wiki/Matrix_field",
                "/wiki/Field_(mathematics)",
                "/wiki/Matrix_ring",
                "/wiki/Ring_(mathematics)",
                "/wiki/Group_(mathematics)",
                "/wiki/Tensors",
                "/wiki/Ring_(mathematics)",
                "/wiki/Field_(mathematics)",
                "/wiki/Algebraically_closed_field",
                "/wiki/Eigenvalue",
                "/wiki/Coding_theory",
                "/wiki/Finite_field",
                "/wiki/Rational_number",
                "/wiki/Division_(mathematics)",
                "/wiki/Multiplication",
                "/wiki/Subtraction",
                "/wiki/Addition",
                "/wiki/Set_(mathematics)",
                "/wiki/Field_(mathematics)",
                "/wiki/Complex_number",
                "/wiki/Supermatrix",
                "/wiki/Superring",
                "/wiki/Invertible",
                "/wiki/Leibniz_formula_(determinant)",
                "/wiki/Determinant",
                "/wiki/Associative_algebra",
                "/wiki/Commutative_ring",
                "/wiki/Module_(mathematics)",
                "/wiki/Endomorphism_ring",
                "/wiki/Matrix_ring",
                "/wiki/Ring_(mathematics)",
                "/wiki/Ring_(mathematics)",
                "/wiki/Block_matrix",
                "/wiki/Basis_(linear_algebra)",
                "/wiki/Vector_space",
                "/wiki/Hamel_dimension",
                "/wiki/Dual_space",
                "/wiki/Transpose_of_a_linear_map",
                "/wiki/Matrix_equivalence",
                "/wiki/Endomorphism_ring",
                "/wiki/Matrix_ring",
                "/wiki/General_linear_group",
                "/wiki/Binary_operation",
                "/wiki/Group_(mathematics)",
                "/wiki/Orthogonal_matrix",
                "/wiki/Special_linear_group",
                "/wiki/Subgroup",
                "/wiki/Determinant",
                "/wiki/Orthogonal_group",
                "/wiki/Representation_theory",
                "/wiki/Symmetric_group",
                "/wiki/Regular_representation",
                "/wiki/Isomorphic",
                "/wiki/Finite_group",
                "/wiki/Linear_combination",
                "/wiki/Absolutely_convergent_series",
                "/wiki/Functional_analysis",
                "/wiki/Continuous_function",
                "/wiki/Hilbert_space#Operators_on_Hilbert_spaces",
                "/wiki/Empty_product",
                "/wiki/Computer_algebra_system",
                "/wiki/Zero_vector_space",
                "/wiki/Tf-idf",
                "/wiki/Document-term_matrix",
                "/wiki/Thesaurus",
                "/wiki/Text_mining",
                "/wiki/Payoff_matrix",
                "/wiki/Economics",
                "/wiki/Game_theory",
                "/wiki/Clifford_algebra",
                "/wiki/Quaternion",
                "/wiki/Absolute_value",
                "/wiki/Control_theory",
                "/wiki/Polynomial_ring",
                "/wiki/Rotation_matrix",
                "/wiki/Computer_graphics",
                "/wiki/Hill_cipher",
                "/wiki/Encryption",
                "/wiki/Hartree%E2%80%93Fock",
                "/wiki/Molecular_orbital",
                "/wiki/Roothaan_equations",
                "/wiki/Fock_matrix",
                "/wiki/Overlap_matrix",
                "/wiki/Spectroscopy",
                "/wiki/Chemical_bond",
                "/wiki/Quantum_mechanics",
                "/wiki/Chemistry",
                "/wiki/Network_theory",
                "/wiki/Sparse_matrix",
                "/wiki/Hyperlink",
                "/wiki/Website",
                "/wiki/Distance_matrix",
                "/wiki/Logical_matrix",
                "/wiki/Graph_theory",
                "/wiki/Finite_graph",
                "/wiki/Adjacency_matrix",
                "/wiki/Second_derivative",
                "/wiki/Differentiable_function",
                "/wiki/Hessian_matrix",
                "/wiki/Jacobian_matrix_and_determinant",
                "/wiki/Implicit_function_theorem",
                "/wiki/Elliptic_partial_differential_equation",
                "/wiki/Partial_differential_equation",
                "/wiki/Finite_element_method",
                "/wiki/Absorbing_state",
                "/wiki/Markov_chain",
                "/wiki/Probability_vector",
                "/wiki/Stochastic_matrix",
                "/wiki/Linear_least_squares_(mathematics)",
                "/wiki/Random_variable",
                "/wiki/Variance",
                "/wiki/Covariance_matrix",
                "/wiki/Dimensionality_reduction",
                "/wiki/Data_matrix_(multivariate_statistics)",
                "/wiki/Descriptive_statistics",
                "/wiki/Singular_value_decomposition",
                "/wiki/Physics",
                "/wiki/Number_theory",
                "/wiki/Matrix_normal_distribution",
                "/wiki/Probability_distribution",
                "/wiki/Random_matrix",
                "/wiki/Mass",
                "/wiki/Weak_interaction",
                "/wiki/Cabibbo%E2%80%93Kobayashi%E2%80%93Maskawa_matrix",
                "/wiki/Quantum_chromodynamics",
                "/wiki/Gauge_group",
                "/wiki/Gell-Mann_matrices",
                "/wiki/Special_unitary_group",
                "/wiki/Quark",
                "/wiki/Spinor",
                "/wiki/Fermion",
                "/wiki/Gamma_matrices",
                "/wiki/Pauli_matrices",
                "/wiki/Spin_group",
                "/wiki/Lorentz_group",
                "/wiki/Quantum_field_theory",
                "/wiki/Elementary_particle",
                "/wiki/Symmetry",
                "/wiki/Eigenstates",
                "/wiki/Density_matrix",
                "/wiki/Matrix_mechanics",
                "/wiki/Werner_Heisenberg",
                "/wiki/Quantum_mechanics",
                "/wiki/S-matrix",
                "/wiki/Particle_accelerator",
                "/wiki/Molecules",
                "/wiki/Normal_mode",
                "/wiki/Eigenvector",
                "/wiki/Equation_of_motion",
                "/wiki/Ray_transfer_matrix",
                "/wiki/Lens_(optics)",
                "/wiki/Ray_(geometry)",
                "/wiki/Ray_(optics)",
                "/wiki/Light_wave",
                "/wiki/Geometrical_optics",
                "/wiki/Nodal_analysis",
                "/wiki/Mesh_analysis",
                "/wiki/Dimensionless_quantity",
                "/wiki/Admittance",
                "/wiki/Electrical_impedance",
                "/wiki/Electronics",
                "/wiki/Cramer%27s_rule",
                "/wiki/Gabriel_Cramer",
                "/wiki/Gottfried_Wilhelm_Leibniz",
                "/wiki/Jan_de_Witt",
                "/wiki/Seki_Kowa",
                "/wiki/Japanese_mathematics",
                "/wiki/Gerolamo_Cardano",
                "/wiki/Determinant",
                "/wiki/System_of_linear_equations",
                "/wiki/The_Nine_Chapters_on_the_Mathematical_Art",
                "/wiki/Chinese_mathematics",
                "/wiki/Linear_equations",
                "/wiki/Minor_(linear_algebra)",
                "/wiki/James_Joseph_Sylvester",
                "/wiki/Cayley%E2%80%93Hamilton_theorem",
                "/wiki/Arthur_Cayley",
                "/wiki/Arthur_Cayley",
                "/wiki/Polynomial",
                "/wiki/Augustin-Louis_Cauchy",
                "/wiki/Non-commutative",
                "/wiki/Matrix_product",
                "/wiki/Gotthold_Eisenstein",
                "/wiki/Linear_map",
                "/wiki/Quadratic_form",
                "/wiki/Gauss",
                "/wiki/Number_theory",
                "/wiki/Axiom",
                "/wiki/Karl_Weierstrass",
                "/wiki/Leopold_Kronecker",
                "/wiki/Infinitesimal",
                "/wiki/Jacobian_matrix_and_determinant",
                "/wiki/Carl_Gustav_Jacob_Jacobi",
                "/wiki/Eigenvalue",
                "/wiki/Multiplication",
                "/wiki/Hypercomplex_number",
                "/wiki/Wilhelm_Jordan_(geodesist)",
                "/wiki/Gauss_elimination",
                "/wiki/Gauss%E2%80%93Jordan_elimination",
                "/wiki/Bilinear_form",
                "/wiki/Georg_Frobenius",
                "/wiki/William_Rowan_Hamilton",
                "/wiki/Cayley%E2%80%93Hamilton_theorem",
                "/wiki/Hamel_dimension",
                "/wiki/Euclidean_space",
                "/wiki/Hilbert_space",
                "/wiki/Linear_operator",
                "/wiki/Functional_analysis",
                "/wiki/Mathematical_formulation_of_quantum_mechanics",
                "/wiki/John_von_Neumann",
                "/wiki/Pascual_Jordan",
                "/wiki/Max_Born",
                "/wiki/Werner_Heisenberg",
                "/wiki/Matrix_mechanics",
                "/wiki/Extension_(predicate_logic)",
                "/wiki/Axiom_of_reducibility",
                "/wiki/Alfred_North_Whitehead",
                "/wiki/Bertrand_Russell",
                "/wiki/Truth_table",
                "/wiki/Alfred_Tarski"
            ],
            "text": "Alfred Tarski in his 1946 Introduction to Logic used the word \"matrix\" synonymously with the notion of truth table as used in mathematical logic.[118]\nFor example, a function \u03a6(x, y) of two variables x and y can be reduced to a collection of functions of a single variable, for example, y, by \"considering\" the function for all possible values of \"individuals\" ai substituted in place of variable x. And then the resulting collection of functions of the single variable y, that is, \u2200ai: \u03a6(ai, y), can be reduced to a \"matrix\" of values by \"considering\" the function for all possible values of \"individuals\" bi substituted in place of variable y:\nBertrand Russell and Alfred North Whitehead in their Principia Mathematica (1910\u20131913) use the word \"matrix\" in the context of their axiom of reducibility. They proposed this axiom as a means to reduce any function to one of lower type, successively, so that at the \"bottom\" (0 order) the function is identical to its extension:\nThe word has been used in unusual ways by at least two authors of historical importance.\nThe inception of matrix mechanics by Heisenberg, Born and Jordan led to studying matrices with infinitely many rows and columns.[116] Later, von Neumann carried out the mathematical formulation of quantum mechanics, by further developing functional analytic notions such as linear operators on Hilbert spaces, which, very roughly speaking, correspond to Euclidean space, but with an infinity of independent directions.\nMany theorems were first established for small matrices only, for example the Cayley\u2013Hamilton theorem was proved for 2\u00d72 matrices by Cayley in the aforementioned memoir, and by Hamilton for 4\u00d74 matrices. Frobenius, working on bilinear forms, generalized the theorem to all dimensions (1898). Also at the end of the 19th century the Gauss\u2013Jordan elimination (generalizing a special case now known as Gauss elimination) was established by Jordan. In the early 20th century, matrices attained a central role in linear algebra, [115] partially due to their use in classification of the hypercomplex number systems of the previous century.\nwhere \u03a0 denotes the product of the indicated terms. He also showed, in 1829, that the eigenvalues of symmetric matrices are real.[112] Jacobi studied \"functional determinants\"\u2014later called Jacobi determinants by Sylvester\u2014which can be used to describe geometric transformations at a local (or infinitesimal) level, see above; Kronecker's Vorlesungen \u00fcber die Theorie der Determinanten[113] and Weierstrass' Zur Determinantentheorie,[114] both published in 1903, first treated determinants axiomatically, as opposed to previous more concrete approaches such as the mentioned formula of Cauchy. At that point, determinants were firmly established.\nThe modern study of determinants sprang from several sources.[111] Number-theoretical problems led Gauss to relate coefficients of quadratic forms, that is, expressions such as x2 + xy \u2212 2y2, and linear maps in three dimensions to matrices. Eisenstein further developed these notions, including the remark that, in modern parlance, matrix products are non-commutative. Cauchy was the first to prove general statements about determinants, using as definition of the determinant of a matrix A = [ai,j] the following: replace the powers ajk by ajk in the polynomial\nAn English mathematician named Cullis was the first to use modern bracket notation for matrices in 1913 and he simultaneously demonstrated the first significant use of the notation A = [ai,j] to represent a matrix where ai,j refers to the ith row and the jth column.[103]\nArthur Cayley published a treatise on geometric transformations using matrices that were not rotated versions of the coefficients being investigated as had previously been done. Instead he defined operations such as addition, subtraction, multiplication, and division as transformations of those matrices and showed the associative and distributive properties held true. Cayley investigated and demonstrated the non-commutative property of matrix multiplication as well as the commutative property of matrix addition.[103]  Early matrix theory had limited the use of arrays almost exclusively to determinants and Arthur Cayley's abstract matrix operations were revolutionary. He was instrumental in proposing a matrix concept independent of equation systems. In 1858 Cayley published his A memoir on the theory of matrices[109][110] in which he proposed and demonstrated the Cayley\u2013Hamilton theorem.[103]\nThe term \"matrix\" (Latin for \"womb\", derived from mater\u2014mother[106]) was coined by James Joseph Sylvester in 1850,[107] who understood a matrix as an object giving rise to a number of determinants today called minors, that is to say, determinants of smaller matrices that derive from the original one by removing columns and rows. In an 1851 paper, Sylvester explains:\nMatrices have a long history of application in solving linear equations but they were known as arrays until the 1800s. The Chinese text The Nine Chapters on the Mathematical Art written in 10th\u20132nd century BCE is the first example of the use of array methods to solve simultaneous equations,[102] including the concept of determinants. In 1545 Italian mathematician Gerolamo Cardano brought the method to Europe when he published Ars Magna.[103] The Japanese mathematician Seki used the same array methods to solve simultaneous equations in 1683.[104]  The Dutch Mathematician Jan de Witt represented transformations using arrays in his 1659 book Elements of Curves (1659).[105]  Between 1700 and 1710 Gottfried Wilhelm Leibniz publicized the use of arrays for recording information or solutions and experimented with over 50 different systems of arrays.[103] Cramer presented his rule in 1750.\nThe behaviour of many electronic components can be described using matrices. Let A be a 2-dimensional vector with the component's input voltage v1 and input current i1 as its elements, and let B be a 2-dimensional vector with the component's output voltage v2 and output current i2 as its elements. Then the behaviour of the electronic component can be described by  B = H \u00b7 A, where H is a 2 x 2 matrix containing one impedance element (h12), one admittance element (h21) and two dimensionless elements (h11 and h22). Calculating a circuit now reduces to multiplying matrices.\nTraditional mesh analysis and nodal analysis in electronics lead to a system of linear equations that can be described with a matrix.\nGeometrical optics provides further matrix applications. In this approximative theory, the wave nature of light is neglected. The result is a model in which light rays are indeed geometrical rays. If the deflection of light rays by optical elements is small, the action of a lens or reflective element on a given light ray can be expressed as multiplication of a two-component vector with a two-by-two matrix called ray transfer matrix: the vector's components are the light ray's slope and its distance from the optical axis, while the matrix encodes the properties of the optical element. Actually, there are two kinds of matrices, viz. a refraction matrix describing the refraction at a lens surface, and a translation matrix, describing the translation of the plane of reference to the next refracting surface, where another refraction matrix applies.\nThe optical system, consisting of a combination of lenses and/or reflective elements, is simply described by the matrix resulting from the product of the components' matrices.[101]\nA general application of matrices in physics is to the description of linearly coupled harmonic systems. The equations of motion of such systems can be described in matrix form, with a mass matrix multiplying a generalized velocity to give the kinetic term, and a force matrix multiplying a displacement vector to characterize the interactions. The best way to obtain solutions is to determine the system's eigenvectors, its normal modes, by diagonalizing the matrix equation. Techniques like this are crucial when it comes to the internal dynamics of molecules: the internal vibrations of systems consisting of mutually bound component atoms.[99] They are also needed for describing mechanical vibrations, and oscillations in electrical circuits.[100]\nAnother matrix serves as a key tool for describing the scattering experiments that form the cornerstone of experimental particle physics: Collision reactions such as occur in particle accelerators, where non-interacting particles head towards each other and collide in a small interaction zone, with a new set of non-interacting particles as the result, can be described as the scalar product of outgoing particle states and a linear combination of ingoing particle states.  The linear combination is given by a matrix known as the S-matrix, which encodes all information about the possible interactions between particles.[98]\nThe first model of quantum mechanics (Heisenberg, 1925) represented the theory's operators by infinite-dimensional matrices acting on quantum states.[96] This is also referred to as matrix mechanics. One particular example is the density matrix that characterizes the \"mixed\" state of a quantum system as a linear combination of elementary, \"pure\" eigenstates.[97]\nLinear transformations and the associated symmetries play a key role in modern physics. For example, elementary particles in quantum field theory are classified as representations of the Lorentz group of special relativity and, more specifically, by their behavior under the spin group.  Concrete representations involving the Pauli matrices and more general gamma matrices are an integral part of the physical description of fermions, which behave as spinors.[94] For the three lightest quarks, there is a group-theoretical representation involving the special unitary group SU(3); for their calculations, physicists use a convenient matrix representation known as the Gell-Mann matrices, which are also used for the SU(3) gauge group that forms the basis of the modern description of strong nuclear interactions, quantum chromodynamics. The Cabibbo\u2013Kobayashi\u2013Maskawa matrix, in turn, expresses the fact that the basic quark states that are important for weak interactions are not the same as, but linearly related to the basic quark states that define particles with specific and distinct masses.[95]\nRandom matrices are matrices whose entries are random numbers, subject to suitable probability distributions, such as matrix normal distribution. Beyond probability theory, they are applied in domains ranging from number theory to physics.[92][93]\nwhich can be formulated in terms of matrices, related to the singular value decomposition of matrices.[91]\nStatistics also makes use of matrices in many different forms.[89] Descriptive statistics is concerned with describing data sets, which can often be represented as data matrices, which may then be subjected to dimensionality reduction techniques. The covariance matrix encodes the mutual variance of several random variables.[90] Another technique using matrices are linear least squares, a method that approximates a finite set of pairs (x1, y1), (x2, y2), ..., (xN, yN), by a linear function\nStochastic matrices are square matrices whose rows are probability vectors, that is, whose entries are non-negative and sum up to one. Stochastic matrices are used to define Markov chains with finitely many states.[87] A row of the stochastic matrix gives the probability distribution for the next position of some particle currently in the state that corresponds to the row. Properties of the Markov chain like absorbing states, that is, states that any particle attains eventually, can be read off the eigenvectors of the transition matrices.[88]\nThe finite element method is an important numerical method to solve partial differential equations, widely applied in simulating complex physical systems. It attempts to approximate the solution to some equation by piecewise linear functions, where the pieces are chosen with respect to a sufficiently fine grid, which in turn can be recast as a matrix equation.[86]\nPartial differential equations can be classified by considering the matrix of coefficients of the highest-order differential operators of the equation. For elliptic partial differential equations this matrix is positive definite, which has decisive influence on the set of possible solutions of the equation in question.[85]\nIf n > m, and if the rank of the Jacobi matrix attains its maximal value m, f is locally invertible at that point, by the implicit function theorem.[84]\nAnother matrix frequently used in geometrical situations is the Jacobi matrix of a differentiable map f: Rn \u2192 Rm. If f1, ..., fm denote the components of f, then the Jacobi matrix is defined as [83]\nThe Hessian matrix of a differentiable function \u0192: Rn \u2192 R consists of the second derivatives of \u0192 with respect to the several coordinate directions, that is,[81]\nThe adjacency matrix of a finite graph is a basic notion of graph theory.[79] It records which vertices of the graph are connected by an edge. Matrices containing just two different values (1 and 0 meaning for example \"yes\" and \"no\", respectively) are called logical matrices. The distance (or cost) matrix contains information about distances of the edges.[80] These concepts can be applied to websites connected by hyperlinks or cities connected by roads etc., in which case (unless the connection network is extremely dense) the matrices tend to be sparse, that is, contain few nonzero entries. Therefore, specifically tailored matrix algorithms can be used in network theory.\nChemistry makes use of matrices in various ways, particularly since the use of quantum theory to discuss molecular bonding and spectroscopy. Examples are the overlap matrix and the Fock matrix used in solving the Roothaan equations to obtain the molecular orbitals of the Hartree\u2013Fock method.\nEarly encryption techniques such as the Hill cipher also used matrices. However, due to the linear nature of matrices, these codes are comparatively easy to break.[77] Computer graphics uses matrices both to represent objects and to calculate transformations of objects using affine rotation matrices to accomplish tasks such as projecting a three-dimensional object onto a two-dimensional screen, corresponding to a theoretical camera observation.[78] Matrices over a polynomial ring are important in the study of control theory.\nunder which addition and multiplication of complex numbers and matrices correspond to each other. For example, 2-by-2 rotation matrices represent the multiplication with some complex number of absolute value 1, as above. A similar interpretation is possible for quaternions[76] and Clifford algebras in general.\nComplex numbers can be represented by particular real 2-by-2 matrices via\nThere are numerous applications of matrices, both in mathematics and other sciences. Some of them merely take advantage of the compact representation of a set of numbers in a matrix. For example, in game theory and economics, the payoff matrix encodes the payoff for two players, depending on which out of a given (finite) set of alternatives the players choose.[74] Text mining and automated thesaurus compilation makes use of document-term matrices such as tf-idf to track frequencies of certain words in several documents.[75]\nAn empty matrix is a matrix in which the number of rows or columns (or both) is zero.[72][73] Empty matrices help dealing with maps involving the zero vector space. For example, if A is a 3-by-0 matrix and B is a 0-by-3 matrix, then AB is the 3-by-3 zero matrix corresponding to the null map from a 3-dimensional space V to itself, while BA is a 0-by-0 matrix. There is no common notation for empty matrices, but most computer algebra systems allow creating and computing with them. The determinant of the 0-by-0 matrix is 1 as follows from regarding the empty product occurring in the Leibniz formula for the determinant as 1. This value is also consistent with the fact that the identity map from any finite dimensional space to itself has determinant\u00a01, a fact that is often used as a part of the characterization of determinants.\nIn that vein, infinite matrices can also be used to describe operators on Hilbert spaces, where convergence and continuity questions arise, which again results in certain constraints that must be imposed. However, the explicit point of view of matrices tends to obfuscate the matter,[71] and the abstract and more powerful tools of functional analysis can be used instead.\nIf R is a normed ring, then the condition of row or column finiteness can be relaxed.  With the norm in place, absolutely convergent series can be used instead of finite sums.  For example, the matrices whose column sums are absolutely convergent sequences form a ring.  Analogously of course, the matrices whose row sums are absolutely convergent series also form a ring.\nIf infinite matrices are used to describe linear maps, then only those matrices can be used all of whose columns have but a finite number of nonzero entries, for the following reason. For a matrix A to describe a linear map f: V\u2192W, bases for both spaces must have been chosen; recall that by definition this means that every vector in the space can be written uniquely as a (finite) linear combination of basis vectors, so that written as a (column) vector\u00a0v of coefficients, only finitely many entries vi are nonzero. Now the columns of A describe the images by f of individual basis vectors of V in the basis of W, which is only meaningful if these columns have only finitely many nonzero entries. There is no restriction on the rows of A however: in the product A\u00b7v there are only finitely many nonzero coefficients of v involved, so every one of its entries, even if it is given as an infinite sum of products, involves only finitely many nonzero terms and is therefore well defined. Moreover, this amounts to forming a linear combination of the columns of A that effectively involves only finitely many of them, whence the result has only finitely many nonzero entries, because each of those columns do. One also sees that products of two matrices of the given type is well defined (provided as usual that the column-index and row-index sets match), is again of the same type, and corresponds to the composition of linear maps.\nIt is also possible to consider matrices with infinitely many rows and/or columns[70] even if, being infinite objects, one cannot write down such matrices explicitly. All that matters is that for every element in the set indexing rows, and every element in the set indexing columns, there is a well-defined entry (these index sets need not even be subsets of the natural numbers). The basic operations of addition, subtraction, scalar multiplication and transposition can still be defined without problem; however matrix multiplication may involve infinite summations to define the resulting entries, and these are not defined in general.\nEvery finite group is isomorphic to a matrix group, as one can see by considering the regular representation of the symmetric group.[68] General groups can be studied using matrix groups, which are comparatively well understood, by means of representation theory.[69]\nform the orthogonal group.[67] Every orthogonal matrix has determinant 1 or \u22121. Orthogonal matrices with determinant 1 form a subgroup called special orthogonal group.\nAny property of matrices that is preserved under matrix products and inverses can be used to define further matrix groups. For example, matrices with a given size and with a determinant of 1 form a subgroup of (that is, a smaller group contained in) their general linear group, called a special linear group.[66] Orthogonal matrices, determined by the condition\nA group is a mathematical structure consisting of a set of objects together with a binary operation, that is, an operation combining any two objects to a third, subject to certain requirements.[63] A group in which the objects are matrices and the group operation is matrix multiplication is called a matrix group.[64][65] Since in a group every element must be invertible, the most general matrix groups are the groups of all invertible matrices of a given size, called the general linear groups.\nMore generally, the set of m\u00d7n matrices can be used to represent the R-linear maps between the free modules Rm and Rn for an arbitrary ring R with unity.  When n\u00a0=\u00a0m composition of these maps is possible, and this gives rise to the matrix ring of n\u00d7n matrices representing the endomorphism ring of Rn.\nIn other words, column j of A expresses the image of vj in terms of the basis vectors wi of W; thus this relation uniquely determines the entries of the matrix A. The matrix depends on the choice of the bases: different choices of bases give rise to different, but equivalent matrices.[61] Many of the above concrete notions can be reinterpreted in this light, for example, the transpose matrix AT describes the transpose of the linear map given by A, with respect to the dual bases.[62]\nLinear maps Rn \u2192 Rm are equivalent to m-by-n matrices, as described above. More generally, any linear map f: V \u2192 W between finite-dimensional vector spaces can be described by a matrix A = (aij), after choosing bases v1, ..., vn of V, and w1, ..., wm of W (so n is the dimension of V and m is the dimension of W), which is such that\nMatrices do not always have all their entries in the same ring\u00a0\u2013 or even in any ring at all. One special but common case is block matrices, which may be considered as matrices whose entries themselves are matrices. The entries need not be square matrices, and thus need not be members of any ring; but their sizes must fulfil certain compatibility conditions.\nMore generally, matrices with entries in a ring R are widely used in mathematics.[57] Rings are a more general notion than fields in that a division operation need not exist. The very same addition and multiplication operations of matrices extend to this setting, too. The set M(n, R) of all square n-by-n matrices over R is a ring called matrix ring, isomorphic to the endomorphism ring of the left R-module Rn.[58] If the ring R is commutative, that is, its multiplication is commutative, then M(n, R) is a unitary noncommutative (unless n = 1) associative algebra over R. The determinant of square matrices over a commutative ring R can still be defined using the Leibniz formula; such a matrix is invertible if and only if its determinant is invertible in R, generalising the situation over a field F, where every nonzero element is invertible.[59] Matrices over superrings are called supermatrices.[60]\nThis article focuses on matrices whose entries are real or complex numbers. However, matrices can be considered with much more general types of entries than real or complex numbers. As a first step of generalization, any field, that is, a set where addition, subtraction, multiplication and division operations are defined and well-behaved, may be used instead of R or C, for example rational numbers or finite fields. For example, coding theory makes use of matrices over finite fields. Wherever eigenvalues are considered, as these are roots of a polynomial they may exist only in a larger field than that of the entries of the matrix; for instance they may be complex in case of a matrix with real entries. The possibility to reinterpret the entries of a matrix as elements of a larger field (for example, to view a real matrix as a complex matrix whose entries happen to be all real) then allows considering each square matrix to possess a full set of eigenvalues. Alternatively one can consider only matrices with entries in an algebraically closed field, such as C, from the outset.\nMatrices can be generalized in different ways. Abstract algebra uses matrices with entries in more general fields or even rings, while linear algebra codifies properties of matrices in the notion of linear maps. It is possible to consider matrices with infinitely many columns and rows. Another extension are tensors, which can be seen as higher-dimensional arrays of numbers, as opposed to vectors, which can often be realised as sequences of numbers, while matrices are rectangular or two-dimensional arrays of numbers.[56] Matrices, subject to certain requirements tend to form groups known as matrix groups. Similarly under certain conditions matrices form rings  known as matrix rings. Though the product of matrices is not in general commutative yet certain matrices form fields known as matrix fields.\nand the power of a diagonal matrix can be calculated by taking the corresponding powers of the diagonal entries, which is much easier than doing the exponentiation for A instead. This can be used to compute the matrix exponential eA, a need frequently arising in solving linear differential equations, matrix logarithms and square roots of matrices.[54] To avoid numerically ill-conditioned situations, further algorithms such as the Schur decomposition can be employed.[55]\nThe eigendecomposition or diagonalization expresses A as a product VDV\u22121, where D is a diagonal matrix and V is a suitable invertible matrix.[52]  If A can be written in this form, it is called diagonalizable. More generally, and applicable to all matrices, the Jordan decomposition transforms a matrix into Jordan normal form, that is to say matrices whose only nonzero entries are the eigenvalues \u03bb1 to \u03bbn of A, placed on the main diagonal and possibly entries equal to one directly above the main diagonal, as shown at the right.[53] Given the eigendecomposition, the nth power of A (that is, n-fold iterated matrix multiplication) can be calculated via\nThe LU decomposition factors matrices as a product of lower (L) and an upper triangular matrices (U).[50] Once this decomposition is calculated, linear systems can be solved more efficiently, by a simple technique called forward and back substitution. Likewise, inverses of triangular matrices are algorithmically easier to calculate. The Gaussian elimination is a similar algorithm; it transforms any matrix to row echelon form.[51] Both methods proceed by multiplying the matrix by suitable elementary matrices, which correspond to permuting rows or columns and adding multiples of one row to another row. Singular value decomposition expresses any matrix A as a product UDV\u2217, where U and V are unitary matrices and D is a diagonal matrix.\nThere are several methods to render matrices into a more easily accessible form. They are generally referred to as matrix decomposition or matrix factorization techniques. The interest of all these techniques is that they preserve certain properties of the matrices in question, such as determinant, rank or inverse, so that these quantities can be calculated after applying the transformation, or that certain matrix operations are algorithmically easier to carry out for some types of matrices.\nAlthough most computer languages are not designed with commands or libraries for matrices, as early as the 1970s, some engineering desktop computers such as the HP 9830 had ROM cartridges to add BASIC commands for matrices. Some computer languages such as APL were designed to manipulate matrices, and various mathematical programs can be used to aid computing with matrices.[49]\nmay lead to significant rounding errors if the determinant of the matrix is very small. The norm of a matrix can be used to capture the conditioning of linear algebraic problems, such as computing a matrix's inverse.[48]\nAn algorithm is, roughly speaking, numerically stable, if little deviations in the input values do not lead to big deviations in the result. For example, calculating the inverse of a matrix via Laplace expansion (Adj (A) denotes the adjugate matrix of A)\nIn many practical situations additional information about the matrices involved is known. An important case are sparse matrices, that is, matrices most of whose entries are zero. There are specifically adapted algorithms for, say, solving linear systems Ax = b for sparse matrices A, such as the conjugate gradient method.[47]\nDetermining the complexity of an algorithm means finding upper bounds or estimates of how many elementary operations such as additions and multiplications of scalars are necessary to perform some algorithm, for example, multiplication of matrices. For example, calculating the matrix product of two n-by-n matrix using the definition given above needs n3 multiplications, since for any of the n2 entries of the product, n multiplications are necessary. The Strassen algorithm outperforms this \"naive\" algorithm; it needs only n2.807 multiplications.[46] A refined approach also incorporates specific features of the computing devices.\nTo choose the most appropriate algorithm for each specific problem, it is important to determine both the effectiveness and precision of all the available algorithms. The domain studying these matters is called numerical linear algebra.[45] As with other numerical situations, two main aspects are the complexity of algorithms and their numerical stability.\nMatrix calculations can be often performed with different techniques. Many problems can be solved by both direct algorithms or iterative approaches. For example, the eigenvectors of a square matrix can be obtained by finding a sequence of vectors xn converging to an eigenvector when n tends to infinity.[44]\nThe polynomial pA in an indeterminate X given by evaluation the determinant det(XIn\u2212A) is called the characteristic polynomial of A. It is a monic polynomial of degree n. Therefore the polynomial equation pA(\u03bb)\u00a0=\u00a00 has at most n different solutions, that is, eigenvalues of the matrix.[43] They may be complex even if the entries of A are real. According to the Cayley\u2013Hamilton theorem, pA(A) = 0, that is, the result of substituting the matrix itself into its own characteristic polynomial yields the zero matrix.\nare called an eigenvalue and an eigenvector of A, respectively.[40][41] The number \u03bb is an eigenvalue of an n\u00d7n-matrix A if and only if A\u2212\u03bbIn is not invertible, which is equivalent to\nA number \u03bb and a non-zero vector v satisfying\nAdding a multiple of any row to another row, or a multiple of any column to another column, does not change the determinant. Interchanging two rows or two columns affects the determinant by multiplying it by \u22121.[37] Using these operations, any matrix can be transformed to a lower (or upper) triangular matrix, and for such matrices the determinant equals the product of the entries on the main diagonal; this provides a method to calculate the determinant of any matrix. Finally, the Laplace expansion expresses the determinant in terms of minors, that is, determinants of smaller matrices.[38] This expansion can be used for a recursive definition of determinants (taking as starting case the determinant of a 1-by-1 matrix, which is its unique entry, or even the determinant of a 0-by-0 matrix, which is 1), that can be seen to be equivalent to the Leibniz formula. Determinants can be used to solve linear systems using Cramer's rule, where the division of the determinants of two related square matrices equates to the value of each of the system's variables.[39]\nThe determinant of a product of square matrices equals the product of their determinants: \nThe determinant of 3-by-3 matrices involves 6 terms (rule of Sarrus). The more lengthy Leibniz formula generalises these two formulae to all dimensions.[35]\nThe determinant of 2-by-2 matrices is given by\nThe determinant det(A) or |A| of a square matrix A is a number encoding certain properties of the matrix. A matrix is invertible if and only if its determinant is nonzero. Its absolute value equals the area (in R2) or volume (in R3) of the image of the unit square (or cube), while its sign corresponds to the orientation of the corresponding linear map: the determinant is positive if and only if the orientation is preserved.\nIt follows that the trace of the product of more than two matrices is independent of cyclic permutations of the matrices, however this does not in general apply for arbitrary permutations (for example, tr(ABC) \u2260 tr(BAC), in general). Also, the trace of a matrix is equal to that of its transpose, that is,\nThis is immediate from the definition of matrix multiplication:\nThe trace, tr(A) of a square matrix A is the sum of its diagonal entries. While matrix multiplication is not commutative as mentioned above, the trace of the product of two matrices is independent of the order of the factors: \nThe complex analogue of an orthogonal matrix is a unitary matrix.\nAn orthogonal matrix A is necessarily invertible (with inverse A\u22121 = AT), unitary (A\u22121 = A*), and normal (A*A = AA*). The determinant of any orthogonal matrix is either +1 or \u22121. A special orthogonal matrix is an orthogonal matrix with determinant +1. As a linear transformation, every orthogonal matrix with determinant +1 is a pure rotation, while every orthogonal matrix with determinant -1 is either a pure reflection, or a composition of reflection and rotation.\nwhere I is the identity matrix of size n.\nwhich entails\nAn orthogonal matrix is a square matrix with real entries whose columns and rows are orthogonal unit vectors (that is, orthonormal vectors). Equivalently, a matrix A is orthogonal if its transpose is equal to its inverse:\nAllowing as input two different vectors instead yields the bilinear form associated to A:\nA symmetric matrix is positive-definite if and only if all its eigenvalues are positive, that is, the matrix is positive-semidefinite and it is invertible.[33] The table at the right shows two possibilities for 2-by-2 matrices.\nhas a positive value for every nonzero vector x in Rn. If f\u200a(x) takes only yields negative values then A is negative-definite; if f does produce both negative and positive values then A is indefinite.[32] If the quadratic form f yields only non-negative values (positive or zero), the symmetric matrix is called positive-semidefinite (or if only non-positive values, then negative-semidefinite); hence the matrix is indefinite precisely when it is neither positive-semidefinite nor negative-semidefinite.\nA symmetric n\u00d7n-matrix A is called positive-definite if the associated quadratic form \nwhere In is the n\u00d7n identity matrix with 1s on the main diagonal and 0s elsewhere. If B exists, it is unique and is called the inverse matrix of A, denoted A\u22121.\nA square matrix A is called invertible or non-singular if there exists a matrix B such that\nBy the spectral theorem, real symmetric matrices and complex Hermitian matrices have an eigenbasis; that is, every vector is expressible as a linear combination of eigenvectors. In both cases, all eigenvalues are real.[29] This theorem can be generalized to infinite-dimensional situations related to matrices with infinitely many rows and columns, see below.\nA square matrix A that is equal to its transpose, that is, A = AT, is a symmetric matrix.  If instead, A is equal to the negative of its transpose, that is, A = \u2212AT, then A is a skew-symmetric matrix. In complex matrices, symmetry is often replaced by the concept of Hermitian matrices, which satisfy A\u2217 = A, where the star or asterisk denotes the conjugate transpose of the matrix, that is, the transpose of the complex conjugate of A.\nA nonzero scalar multiple of an identity matrix is called a scalar matrix. If the matrix entries come from a field, the scalar matrices form a group, under matrix multiplication, that is isomorphic to the multiplicative group of nonzero elements of the field.\nIt is a square matrix of order n, and also a special kind of diagonal matrix. It is called an identity matrix because multiplication with it leaves a matrix unchanged: \nThe identity matrix In of size n is the n-by-n matrix in which all the elements on the main diagonal are equal to 1 and all other elements are equal to 0, for example,\nIf all entries of A below the main diagonal are zero, A is called an upper triangular matrix. Similarly if all entries of A above the main diagonal are zero, A is called a lower triangular matrix. If all entries outside the main diagonal are zero, A is called a diagonal matrix.\nA square matrix is a matrix with the same number of rows and columns. An n-by-n matrix is known as a square matrix of order n. Any two square matrices of the same order can be added and multiplied. \nThe entries aii form the main diagonal of a square matrix. They lie on the imaginary line that runs from the top left corner to the bottom right corner of the matrix.\nThe rank of a matrix A is the maximum number of linearly independent row vectors of the matrix, which is the same as the maximum number of linearly independent column vectors.[26] Equivalently it is the dimension of the image of the linear map represented by A.[27] The rank\u2013nullity theorem states that the dimension of the kernel of a matrix plus the rank equals the number of columns of the matrix.[28]\nThe last equality follows from the above-mentioned associativity of matrix multiplication.\nUnder the 1-to-1 correspondence between matrices and linear maps, matrix multiplication corresponds to composition of maps:[25] if a k-by-m matrix B represents another linear map g\u00a0: Rm \u2192 Rk, then the composition g \u2218 f is represented by BA since\nThe following table shows a number of 2-by-2 matrices with the associated linear maps of R2. The blue original is mapped to the green grid and shapes. The origin (0,0) is marked with a black point.\nFor example, the 2\u00d72 matrix\nMatrices and matrix multiplication reveal their essential features when related to linear transformations, also known as linear maps. A real m-by-n matrix A gives rise to a linear transformation Rn \u2192 Rm mapping each vector x in Rn to the (matrix) product Ax, which is a vector in Rm. Conversely, each linear transformation f: Rn \u2192 Rm arises from a unique m-by-n matrix A: explicitly, the (i, j)-entry of A is the ith coordinate of f(ej), where ej = (0,...,0,1,0,...,0) is the unit vector with 1 in the jth position and 0 elsewhere. The matrix A is said to represent the linear map f, and A is called the transformation matrix of f.\nwhere A\u22121 is the inverse matrix of A. If A has no inverse, solutions if any can be found using its generalized inverse.\nUsing matrices, this can be solved more compactly than would be possible by writing out all the equations separately. If n = m and the equations are independent, this can be done by writing\nis equivalent to the system of linear equations\nMatrices can be used to compactly write and work with multiple linear equations, that is, systems of linear equations. For example, if A is an m-by-n matrix, x designates a column vector (that is, n\u00d71-matrix) of n variables x1, x2, ..., xn, and b is an m\u00d71-column vector, then the matrix equation\nA principal submatrix is a square submatrix obtained by removing certain rows and columns.  The definition varies from author to author. According to some authors, a principal submatrix is a submatrix in which the set of row indices that remain is the same as the set of column indices that remain.[20][21] Other authors define a principal submatrix as one in which the first k rows and columns, for some number k, are the ones that remain;[22] this type of submatrix has also been called a leading principal submatrix.[23]\nThe minors and cofactors of a matrix are found by computing the determinant of certain submatrices.[18][19]\nA submatrix of a matrix is obtained by deleting any collection of rows and/or columns.[16][17][18] For example, from the following 3-by-4 matrix, we can construct a 2-by-3 submatrix by removing row 3 and column 2:\nThese operations are used in a number of ways, including solving linear equations and finding matrix inverses.\nThere are three types of row operations:\nBesides the ordinary matrix multiplication just described, there exist other less frequently used operations on matrices that can be considered forms of multiplication, such as the Hadamard product and the Kronecker product.[15] They arise in solving matrix equations such as the Sylvester equation.\nwhereas\nthat is, matrix multiplication is not commutative, in marked contrast to (rational, real, or complex) numbers whose product is independent of the order of the factors. An example of two matrices not commuting with each other is:\nMatrix multiplication satisfies the rules (AB)C = A(BC) (associativity), and (A+B)C = AC+BC as well as C(A+B) = CA+CB (left and right distributivity), whenever the size of the matrices is such that the various products are defined.[14] The product AB may be defined without BA being defined, namely if A and B are m-by-n and n-by-k matrices, respectively, and m \u2260 k. Even if both products are defined, they need not be equal, that is, generally \nwhere 1 \u2264 i \u2264 m and 1 \u2264 j \u2264 p.[13] For example, the underlined entry 2340 in the product is calculated as (2 \u00d7 1000) + (3 \u00d7 100) + (4 \u00d7 10) = 2340:\nMultiplication of two matrices is defined if and only if the number of columns of the left matrix is the same as the number of rows of the right matrix. If A is an m-by-n matrix and B is an n-by-p matrix, then their matrix product AB is the m-by-p matrix whose entries are given by dot product of the corresponding row of A and the corresponding column of B:\nFamiliar properties of numbers extend to these operations of matrices: for example, addition is commutative, that is, the matrix sum does not depend on the order of the summands: A\u00a0+\u00a0B\u00a0=\u00a0B\u00a0+\u00a0A.[12]\nThe transpose is compatible with addition and scalar multiplication, as expressed by (cA)T = c(AT) and (A\u00a0+\u00a0B)T\u00a0=\u00a0AT\u00a0+\u00a0BT. Finally, (AT)T\u00a0=\u00a0A.\nThere are a number of basic operations that can be applied to modify matrices, called matrix addition, scalar multiplication, transposition, matrix multiplication, row operations, and submatrix.[11]\nAn asterisk is occasionally used to refer to whole rows or columns in a matrix. For example, ai,\u2217 refers to the ith row of A, and a\u2217,j refers to the jth column of A. The set of all m-by-n matrices is denoted \ud835\udd44(m, n).\nSome programming languages utilize doubly subscripted arrays (or arrays of arrays) to represent an m-\u00d7-n matrix. Some programming languages start the numbering of array indexes at zero, in which case the entries of an m-by-n matrix are indexed by 0 \u2264 i \u2264 m \u2212 1 and 0 \u2264 j \u2264 n \u2212 1.[9] This article follows the more common convention in mathematical writing where enumeration starts from 1.\nIn this case, the matrix itself is sometimes defined by that formula, within square brackets or double parentheses. For example, the matrix above is defined as A = [i-j], or A = ((i-j)). If matrix size is m \u00d7 n, the above-mentioned formula f(i, j) is valid for any i = 1, ..., m and any j = 1, ..., n. This can be either specified separately, or using m \u00d7 n as a subscript. For instance, the matrix A above is 3 \u00d7 4 and can be defined as A = [i \u2212 j] (i = 1, 2, 3; j = 1, ..., 4), or A = [i \u2212 j]3\u00d74.\nSometimes, the entries of a matrix can be defined by a formula such as ai,j = f(i, j). For example, each of the entries of the following matrix A is determined by aij = i \u2212 j. \nThe entry in the i-th row and j-th column of a matrix A is sometimes referred to as the i,j, (i,j), or (i,j)th entry of the matrix, and most commonly denoted as ai,j, or aij. Alternative notations for that entry are A[i,j] or Ai,j. For example, the (1,3) entry of the following matrix A is 5 (also denoted a13, a1,3, A[1,3] or A1,3):\nMatrices are commonly written in box brackets or parentheses:\nMatrices with a single row are called row vectors, and those with a single column are called column vectors. A matrix with the same number of rows and columns is called a square matrix. A matrix with an infinite number of rows or columns (or both) is called an infinite matrix. In some contexts, such as computer algebra programs, it is useful to consider a matrix with no rows or no columns, called an empty matrix.\nThe size of a matrix is defined by the number of rows and columns that it contains. A matrix with m rows and n columns is called an m\u00a0\u00d7\u00a0n matrix or m-by-n matrix, while m and n are called its dimensions. For example, the matrix A above is a 3\u00a0\u00d7\u00a02 matrix.\nThe numbers, symbols or expressions in the matrix are called its entries or its elements. The horizontal and vertical lines of entries in a matrix are called rows and columns, respectively.\nA matrix is a rectangular array of numbers or other mathematical objects for which operations such as addition and multiplication are defined.[6]  Most commonly, a matrix over a field F is a rectangular array of scalars each of which is a member of F.[7][8] Most of this article focuses on real and complex matrices, that is, matrices whose elements are real numbers or complex numbers, respectively. More general types of entries are discussed below. For instance, this is a real matrix:\nA major branch of numerical analysis is devoted to the development of efficient algorithms for matrix computations, a subject that is centuries old and is today an expanding area of research. Matrix decomposition methods simplify computations, both theoretically and practically. Algorithms that are tailored to particular matrix structures, such as sparse matrices and near-diagonal matrices, expedite computations in finite element method and other computations. Infinite matrices occur in planetary theory and in atomic theory. A simple example of an infinite matrix is the matrix representing the derivative operator, which acts on the Taylor series of a function.\nApplications of matrices are found in most scientific fields. In every branch of physics, including classical mechanics, optics, electromagnetism, quantum mechanics, and quantum electrodynamics, they are used to study physical phenomena, such as the motion of rigid bodies. In computer graphics, they are used to manipulate 3D models and project them onto a 2-dimensional screen. In probability theory and statistics, stochastic matrices are used to describe sets of probabilities; for instance, they are used within the PageRank algorithm that ranks the pages in a Google search.[5] Matrix calculus generalizes classical analytical notions such as derivatives and exponentials to higher dimensions. Matrices are used in economics to describe systems of economic relationships.\nThe individual items in an m \u00d7 n matrix A, often denoted by ai,j, where max i = m and max j = n, are called its elements or entries.[4] Provided that they have the same size (each matrix has the same number of rows and the same number of columns as the other), two matrices can be added or subtracted element by element (see Conformable matrix). The rule for matrix multiplication, however, is that two matrices can be multiplied only when the number of columns in the first equals the number of rows in the second (i.e., the inner dimensions are the same, n for Am,n \u00d7 Bn,p). Any matrix can be multiplied element-wise by a scalar from its associated field. A major application of matrices is to represent linear transformations, that is, generalizations of linear functions such as f(x) = 4x. For example, the rotation of vectors in three-dimensional space is a linear transformation, which can be represented by a rotation matrix R: if v is a column vector (a matrix with only one column) describing the position of a point in space, the product Rv is a column vector describing the position of that point after a rotation. The product of two transformation matrices is a matrix that represents the composition of two transformations. Another application of matrices is in the solution of systems of linear equations. If the matrix is square, it is possible to deduce some of its properties by computing its determinant. For example, a square matrix has an inverse if and only if its determinant is not zero. Insight into the geometry of a linear transformation is obtainable (along with other information) from the matrix's eigenvalues and eigenvectors.\nIn mathematics, a matrix (plural: matrices) is a rectangular array[1] of numbers, symbols, or expressions, arranged in rows and columns.[2][3] For example, the dimensions of the matrix below are 2 \u00d7 3 (read \"two by three\"), because there are two rows and three columns:\n",
            "title": "Matrix (mathematics)",
            "url": "https://en.wikipedia.org/wiki/Matrix_notation"
        },
        {
            "desc_links": [
                "/wiki/Equator",
                "/wiki/Geographical_pole",
                "/wiki/Centrifugal_force",
                "/wiki/Gravity",
                "/wiki/Acceleration",
                "/wiki/Weight",
                "/wiki/General_Conference_on_Weights_and_Measures",
                "/wiki/ISO_80000-3",
                "/wiki/Earth",
                "/wiki/Vacuum",
                "/wiki/Gravitational_acceleration",
                "/wiki/G-force",
                "/wiki/Acceleration",
                "/wiki/Gram",
                "/wiki/Gravitational_constant",
                "/wiki/Earth%27s_gravity",
                "/wiki/Force#Units_of_measurement",
                "/wiki/Kilogram-force",
                "/wiki/Newton_(unit)",
                "/wiki/Conversion_factor",
                "/wiki/Metrological",
                "/wiki/Latitude#Common_\"latitude\""
            ],
            "desc_text": "b'The standard acceleration due to gravity (or standard acceleration of free fall), sometimes abbreviated as standard gravity, usually denoted by \\xc9\\xa10 or \\xc9\\xa1n, is the nominal gravitational acceleration of an object in a vacuum near the surface of the Earth. It is defined by standard as 7000980665000000000\\xe2\\x99\\xa09.80665\\xc2\\xa0m/s2 (about 7000980665044000000\\xe2\\x99\\xa032.17405\\xc2\\xa0ft/s2). This value was established by the 3rd CGPM (1901, CR 70) and used to define the standard weight of an object as the product of its mass and this nominal acceleration.[1][2] The acceleration of a body near the surface of the Earth is due to the combined effects of gravity and centrifugal acceleration from the rotation of the Earth (but which is small enough to be neglected for most purposes); the total (the apparent gravity) is about 0.5% greater at the poles than at the Equator.\\n'b\"Although the symbol \\xc9\\xa1 is sometimes used for standard gravity, \\xc9\\xa1 (without a suffix) can also mean the local acceleration due to local gravity and centrifugal acceleration, which varies depending on one's position on Earth (see Earth's gravity). The symbol \\xc9\\xa1 should not be confused with G, the gravitational constant, or g, the symbol for gram. The \\xc9\\xa1 is also used as a unit for any form of acceleration, with the value defined as above; see g-force.\\n\"b'The value of \\xc9\\xa10 defined above is a nominal midrange value on Earth, originally based on the acceleration of a body in free fall at sea level at a geodetic latitude of 45\\xc2\\xb0. Although the actual acceleration of free fall on Earth varies according to location, the above standard figure is always used for metrological purposes. In particular, it gives the conversion factor between newton and kilogram-force, two units of force.\\n'",
            "links": [
                "/wiki/Equator",
                "/wiki/Geographical_pole",
                "/wiki/Centrifugal_force",
                "/wiki/Gravity",
                "/wiki/Acceleration",
                "/wiki/Weight",
                "/wiki/General_Conference_on_Weights_and_Measures",
                "/wiki/ISO_80000-3",
                "/wiki/Earth",
                "/wiki/Vacuum",
                "/wiki/Gravitational_acceleration",
                "/wiki/G-force",
                "/wiki/Acceleration",
                "/wiki/Gram",
                "/wiki/Gravitational_constant",
                "/wiki/Earth%27s_gravity",
                "/wiki/Force#Units_of_measurement",
                "/wiki/Kilogram-force",
                "/wiki/Newton_(unit)",
                "/wiki/Conversion_factor",
                "/wiki/Metrological",
                "/wiki/Latitude#Common_\"latitude\"",
                "/wiki/Mercury_(element)",
                "/wiki/Atmospheric_pressure",
                "/wiki/Boiling_point",
                "/wiki/Thermometer",
                "/wiki/International_Committee_for_Weights_and_Measures",
                "/wiki/International_Bureau_of_Weights_and_Measures",
                "/wiki/General_Conference_on_Weights_and_Measures",
                "/wiki/Cgs"
            ],
            "text": "The numeric value adopted for \u0261n was, in accordance with the 1887 CIPM declaration, obtained by dividing Defforges's result \u2013 980.991\u00a0cm\u22c5s\u22122 in the cgs system then en vogue \u2013 by  1.0003322 while not taking more digits than warranted considering the uncertainty in the result.\nThis result formed the basis for determining the value still used today for standard gravity. The third General Conference on Weights and Measures, held in 1901, adopted a resolution declaring as follows:\nAll that was needed to obtain a numerical value for standard gravity was now to measure the gravitational strength at the International Bureau. This task was given to Gilbert \u00c9tienne Defforges of the Geographic Service of the French Army. The value he found, based on measurements taken in March and April 1888, was 9.80991(5)\u00a0m\u22c5s\u22122.[4]\nAlready in the early days of its existence, the International Committee for Weights and Measures (CIPM) proceeded to define a standard thermometric scale, using the boiling point of water. Since the boiling point varies with the atmospheric pressure, the CIPM needed to define a standard atmospheric pressure. The definition they chose was based on the weight of a column of mercury of 760\u00a0mm. But since that weight depends on the local gravity, they now also needed a standard gravity. The 1887 CIPM meeting decided as follows:\nThe value of \u02610 defined above is a nominal midrange value on Earth, originally based on the acceleration of a body in free fall at sea level at a geodetic latitude of 45\u00b0. Although the actual acceleration of free fall on Earth varies according to location, the above standard figure is always used for metrological purposes. In particular, it gives the conversion factor between newton and kilogram-force, two units of force.\nAlthough the symbol \u0261 is sometimes used for standard gravity, \u0261 (without a suffix) can also mean the local acceleration due to local gravity and centrifugal acceleration, which varies depending on one's position on Earth (see Earth's gravity). The symbol \u0261 should not be confused with G, the gravitational constant, or g, the symbol for gram. The \u0261 is also used as a unit for any form of acceleration, with the value defined as above; see g-force.\nThe standard acceleration due to gravity (or standard acceleration of free fall), sometimes abbreviated as standard gravity, usually denoted by \u02610 or \u0261n, is the nominal gravitational acceleration of an object in a vacuum near the surface of the Earth. It is defined by standard as 7000980665000000000\u26609.80665\u00a0m/s2 (about 7000980665044000000\u266032.17405\u00a0ft/s2). This value was established by the 3rd CGPM (1901, CR 70) and used to define the standard weight of an object as the product of its mass and this nominal acceleration.[1][2] The acceleration of a body near the surface of the Earth is due to the combined effects of gravity and centrifugal acceleration from the rotation of the Earth (but which is small enough to be neglected for most purposes); the total (the apparent gravity) is about 0.5% greater at the poles than at the Equator.\n",
            "title": "Standard gravity",
            "url": "https://en.wikipedia.org/wiki/Standard_gravity"
        },
        {
            "desc_links": [
                "/wiki/Dataset",
                "/wiki/Dependent_variable",
                "/wiki/Least_squares",
                "/wiki/Explanatory_variable",
                "/wiki/Linear_function",
                "/wiki/Linear_regression",
                "/wiki/Statistical_parameter",
                "/wiki/Linear_least_squares",
                "/wiki/Statistics",
                "/wiki/Regressor",
                "/wiki/Simple_linear_regression",
                "/wiki/Statistical_estimation",
                "/wiki/Maximum_likelihood_estimator",
                "/wiki/Normal_distribution",
                "/wiki/Variance",
                "/wiki/UMVU",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Autocorrelation",
                "/wiki/Homoscedastic",
                "/wiki/Statistical_error",
                "/wiki/Best_linear_unbiased_estimator",
                "/wiki/Exogenous",
                "/wiki/Regressors",
                "/wiki/Consistent_estimator",
                "/wiki/Signal_processing",
                "/wiki/Control_theory",
                "/wiki/Engineering",
                "/wiki/Psychology",
                "/wiki/Political_science",
                "/wiki/Econometrics",
                "/wiki/Economics"
            ],
            "desc_text": "b'In statistics, ordinary least squares (OLS) is a type of linear least squares method for estimating the unknown parameters in a linear regression model. OLS chooses the parameters of a linear function of a set of explanatory variables by the principle of least squares: minimizing the sum of the squares of the differences between the observed dependent variable (values of the variable being predicted) in the given dataset and those predicted by the linear function. \\n'b'Geometrically, this is seen as the sum of the squared distances, parallel to the axis of the dependent variable, between each data point in the set and the corresponding point on the regression surface \\xe2\\x80\\x93 the smaller the differences, the better the model fits the data. The resulting estimator can be expressed by a simple formula, especially in the case of a simple linear regression, in which there is a single regressor on the right side of the regression equation.\\n'b'The OLS estimator is consistent when the regressors are exogenous, and optimal in the class of linear unbiased estimators when the errors are homoscedastic and serially uncorrelated[citation needed]. Under these conditions, the method of OLS provides minimum-variance mean-unbiased estimation when the errors have finite variances. Under the additional assumption that the errors are normally distributed, OLS is the maximum likelihood estimator.\\n'b'OLS is used in fields as diverse as economics (econometrics), political science, psychology and engineering (control theory and signal processing).\\n'",
            "links": [
                "/wiki/Dataset",
                "/wiki/Dependent_variable",
                "/wiki/Least_squares",
                "/wiki/Explanatory_variable",
                "/wiki/Linear_function",
                "/wiki/Linear_regression",
                "/wiki/Statistical_parameter",
                "/wiki/Linear_least_squares",
                "/wiki/Statistics",
                "/wiki/Regressor",
                "/wiki/Simple_linear_regression",
                "/wiki/Statistical_estimation",
                "/wiki/Maximum_likelihood_estimator",
                "/wiki/Normal_distribution",
                "/wiki/Variance",
                "/wiki/UMVU",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Autocorrelation",
                "/wiki/Homoscedastic",
                "/wiki/Statistical_error",
                "/wiki/Best_linear_unbiased_estimator",
                "/wiki/Exogenous",
                "/wiki/Regressors",
                "/wiki/Consistent_estimator",
                "/wiki/Signal_processing",
                "/wiki/Control_theory",
                "/wiki/Engineering",
                "/wiki/Psychology",
                "/wiki/Political_science",
                "/wiki/Econometrics",
                "/wiki/Economics",
                "/wiki/Row_and_column_vectors",
                "/wiki/Design_matrix",
                "/wiki/Overdetermined_system",
                "/wiki/Errors_and_residuals_in_statistics",
                "/wiki/Multicollinearity",
                "/wiki/Moore%E2%80%93Penrose_pseudoinverse",
                "/wiki/Normal_matrix",
                "/wiki/Reduced_chi-squared",
                "/wiki/Coefficient_of_determination",
                "/wiki/Polynomial_least_squares",
                "/wiki/Cram%C3%A9r%E2%80%93Rao_bound",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Karl_Pearson",
                "/wiki/Udny_Yule",
                "/wiki/Proofs_involving_ordinary_least_squares#Maximum_likelihood_approach",
                "/wiki/Maximum_likelihood_estimator",
                "/wiki/Generalized_method_of_moments",
                "/wiki/Iid",
                "/wiki/Gauss%E2%80%93Markov_theorem",
                "/wiki/Linear_regression_model",
                "/wiki/Experiment",
                "/wiki/Design_of_experiments",
                "/wiki/Asymptotic_theory_(statistics)",
                "/wiki/Observational_study",
                "/wiki/Statistical_population",
                "/wiki/Asymptotic_theory_(statistics)",
                "/wiki/Data_collection",
                "/wiki/Random_sample",
                "/wiki/Cross-sectional_data",
                "/wiki/Time_series",
                "/wiki/Nonnegative-definite_matrix",
                "/wiki/Gauss%E2%80%93Markov_theorem",
                "/wiki/Cram%C3%A9r%E2%80%93Rao_bound",
                "/wiki/Chi-squared_distribution",
                "/wiki/Mean_squared_error",
                "/wiki/Cram%C3%A9r%E2%80%93Rao_bound",
                "/wiki/Jackknife_method",
                "/wiki/Annihilator_matrix",
                "/wiki/Interval_estimate",
                "/wiki/Point_estimate",
                "/wiki/Quantile_function",
                "/wiki/Alternative_hypothesis",
                "/wiki/F-test",
                "/wiki/Null_hypothesis",
                "/wiki/Standard_error",
                "/wiki/T-statistic",
                "/wiki/Chow_test",
                "/wiki/Scatterplot",
                "/wiki/List_of_statistical_packages",
                "/wiki/Extrapolation"
            ],
            "text": "This highlights a common error: this example is an abuse of OLS which inherently requires that the errors in the independent variable (in this case height) are zero or at least negligible. The initial rounding to nearest inch plus any actual measurement errors constitute a finite and non-negligible error. As a result, the fitted parameters are not the best estimates they are presumed to be. Though not totally spurious the error in the estimation will depend upon relative size of the x and y errors.\nWhile this may look innocuous in the middle of the data range it could become significant at the extremes or in the case where the fitted model is used to project outside the data range (extrapolation).\nUsing either of these equations to predict the weight of a 5' 6\" (1.6764m) woman gives similar values: 62.94\u00a0kg with rounding vs. 62.98\u00a0kg without rounding. Thus a seemingly small variation in the data has a real effect on the coefficients but a small effect on the results of the equation.\nThis example also demonstrates that coefficients determined by these calculations are sensitive to how the data is prepared. The heights were originally given rounded to the nearest inch and have been converted and rounded to the nearest centimetre. Since the conversion factor is one inch to 2.54\u00a0cm this is not an exact conversion. The original inches can be recovered by Round(x/0.0254) and then re-converted to metric without rounding. If this is done the results become:\nAn important consideration when carrying out statistical inference using regression models is how the data were sampled.  In this example, the data are averages rather than measurements on individual women.  The fit of the model is very good, but this does not imply that the weight of an individual woman can be predicted with high accuracy based only on her height.\nOrdinary least squares analysis often includes the use of diagnostic plots designed to detect departures of the data from the assumed form of the model.  These are some of the common diagnostic plots:\nIn this table:\nThe output from most popular statistical packages will look similar to this:\nWhen only one dependent variable is being modeled, a scatterplot will suggest the form and strength of the relationship between the dependent variable and regressors. It might also reveal outliers, heteroscedasticity, and other aspects of the data that may complicate the interpretation of a fitted regression model.  The scatterplot suggests that the relationship is strong and can be approximated as a quadratic function. OLS can handle non-linear relationships by introducing the regressor HEIGHT2.  The regression model then becomes a multiple linear model:\nThe following data set gives average heights and weights for American women aged 30\u201339 (source: The World Almanac and Book of Facts, 1975).\nIn addition, the Chow test is used to test whether two subsamples both have the same underlying true coefficient values. The sum of squared residuals of regressions on each of the subsets and on the combined data set are compared by computing an F-statistic; if this exceeds a critical value, the null hypothesis of no difference between the two subsets is rejected; otherwise, it is accepted.\nSecond, for each explanatory variable of interest, one wants to know whether its estimated coefficient differs significantly from zero\u2014that is, whether this particular explanatory variable in fact has explanatory power in predicting the response variable. Here the null hypothesis is that the true coefficient is zero. This hypothesis is tested by computing the coefficient's t-statistic, as the ratio of the coefficient estimate to its standard error. If the t-statistic is larger than a predetermined value, the null hypothesis is rejected and the variable is found to have explanatory power, with its coefficient significantly different from zero. Otherwise, the null hypothesis of a zero value of the true coefficient is accepted.\nTwo hypothesis tests are particularly widely used. First, one wants to know if the estimated regression equation is any better than simply predicting that all values of the response variable equal its sample mean (if not, it is said to have no explanatory power). The null hypothesis of no explanatory value of the estimated regression is tested using an F-test. If the calculated F-value is found to be large enough to exceed its critical value for the pre-chosen level of significance, the null hypothesis is rejected and the alternative hypothesis, that the regression has explanatory power, is accepted. Otherwise, the null hypothesis of no explanatory power is accepted.\nSimilarly, the least squares estimator for \u03c32 is also consistent and asymptotically normal (provided that the fourth moment of \u03b5i exists) with limiting distribution\nwhere q denotes the quantile function of standard normal distribution, and [\u00b7]jj is the j-th diagonal element of a matrix.\nThe least squares estimators are point estimates of the linear regression model parameters \u03b2. However, generally we also want to know how close those estimates might be to the true values of parameters. In other words, we want to construct the interval estimates.\nwhere R is a p\u00d7(p\u00a0\u2212\u00a0q) matrix such that the matrix [Q R] is non-singular, and RTQ = 0. Such a matrix can always be found, although generally it is not unique. The second formula coincides with the first in case when XTX is invertible.[32]\nThis expression for the constrained estimator is valid as long as the matrix XTX is invertible. It was assumed from the beginning of this article that this matrix is of full rank, and it was noted that when the rank condition fails, \u03b2 will not be identifiable. However it may happen that adding the restriction A makes \u03b2 identifiable, in which case one would like to find the formula for the estimator. The estimator is equal to [32]\nwhere Q is a p\u00d7q matrix of full rank, and c is a q\u00d71 vector of known constants, where q\u2009<\u2009p. In this case least squares estimation is equivalent to minimizing the sum of squared residuals of the model subject to the constraint A. The constrained least squares (CLS) estimator can be given by an explicit formula:[31]\nSuppose it is known that the coefficients in the regression satisfy a system of linear equations\nThe theorem can be used to establish a number of theoretical results. For example, having a regression with a constant and another regressor is equivalent to subtracting the means from the dependent variable and the regressor and then running the regression for the de-meaned variables but without the constant term.\nwhere M1 is the annihilator matrix for regressors X1.\nwhere X1 and X2 have dimensions n\u00d7p1, n\u00d7p2, and \u03b21, \u03b22 are p1\u00d71 and p2\u00d71 vectors, with p1 + p2 = p.\nSometimes the variables and corresponding parameters in the regression can be logically split into two groups, so that the regression takes form\nFrom the properties of the hat matrix, 0 \u2264 hj \u2264 1, and they sum up to p, so that on average hj \u2248 p/n. These quantities hj are called the leverages, and observations with high hj are called leverage points.[29] Usually the observations with high leverage ought to be scrutinized more carefully, in case they are erroneous, or outliers, or in some other way atypical of the rest of the dataset.\nwhere hj = xjT\u2009(XTX)\u22121xj is the j-th diagonal element of the hat matrix P, and xj is the vector of regressors corresponding to the j-th observation. Similarly, the change in the predicted value for j-th observation resulting from omitting that observation from the dataset will be equal to [28]\nTo analyze which observations are influential we remove a specific j-th observation and consider how much the estimated quantities are going to change (similarly to the jackknife method). It can be shown that the change in the OLS estimator for \u03b2 will be equal to [28]\nThe variance of this estimator is equal to 2\u03c34/(n\u2009\u2212\u2009p), which does not attain the Cram\u00e9r\u2013Rao bound of 2\u03c34/n. However it was shown that there are no unbiased estimators of \u03c32 with variance smaller than that of the estimator s2.[25] If we are willing to allow biased estimators, and consider the class of estimators that are proportional to the sum of squared residuals (SSR) of the model, then the best (in the sense of the mean squared error) estimator in this class will be ~\u03c32 = SSR\u2009/\u2009(n\u2009\u2212\u2009p\u2009+\u20092), which even beats the Cram\u00e9r\u2013Rao bound in case when there is only one regressor (p = 1).[26]\nThe estimator s2 will be proportional to the chi-squared distribution:[24]\nwhere Q is the cofactor matrix. This estimator reaches the Cram\u00e9r\u2013Rao bound for the model, and thus is optimal in the class of all unbiased estimators.[15] Note that unlike the Gauss\u2013Markov theorem, this result establishes optimality among both linear and non-linear estimators, but only in the case of normally distributed error terms.\nThe properties listed so far are all valid regardless of the underlying distribution of the error terms. However, if you are willing to assume that the normality assumption holds (that is, that \u03b5 ~ N(0, \u03c32In)), then additional properties of the OLS estimators can be stated.\nin the sense that this is a nonnegative-definite matrix. This theorem establishes optimality only in the class of linear unbiased estimators, which is quite restrictive. Depending on the distribution of the error terms \u03b5, other, non-linear estimators may provide better results than OLS.\nIf the strict exogeneity does not hold (as is the case with many time series models, where exogeneity is assumed only with respect to the past shocks but not the future ones), then these estimators will be biased in finite samples.\nIn some applications, especially with cross-sectional data, an additional assumption is imposed \u2014 that all observations are independent and identically distributed. This means that all observations are taken from a random sample which makes all the assumptions listed earlier simpler and easier to interpret. Also this framework allows one to state asymptotic results (as the sample size n\u2009\u2192\u2009\u221e), which are understood as a theoretical possibility of fetching new independent observations from the data generating process. The list of assumptions in this case is:\nThe classical model focuses on the \"finite sample\" estimation and inference, meaning that the number of observations n is fixed. This contrasts with the other approaches, which study the asymptotic behavior of OLS, and in which the number of observations is allowed to grow to infinity.\nOne of the lines of difference in interpretation is whether to treat the regressors as random variables, or as predefined constants. In the first case (random design) the regressors xi are random and sampled together with the yi's from some population, as in an observational study. This approach allows for more natural study of the asymptotic properties of the estimators. In the other interpretation (fixed design), the regressors X are treated as known constants set by a design, and y is sampled conditionally on the values of X as in an experiment. For practical purposes, this distinction is often unimportant, since estimation and inference is carried out while conditioning on X. All results stated in this article are within the random design framework.\nThere are several different frameworks in which the linear regression model can be cast in order to make the OLS technique applicable. Each of these settings produces the same formulas and same results. The only difference is the interpretation and the assumptions which have to be imposed in order for the method to give meaningful results. The choice of the applicable framework depends mostly on the nature of data in hand, and on the inference task which has to be performed.\nNote that the original strict exogeneity assumption E[\u03b5i\u2009|\u2009xi] = 0 implies a far richer set of moment conditions than stated above. In particular, this assumption implies that for any vector-function \u0192, the moment condition E[\u0192(xi)\u00b7\u03b5i] = 0 will hold. However it can be shown using the Gauss\u2013Markov theorem that the optimal choice of function \u0192 is to take \u0192(x) = x, which results in the moment equation posted above.\nThese moment conditions state that the regressors should be uncorrelated with the errors. Since xi is a p-vector, the number of moment conditions is equal to the dimension of the parameter vector \u03b2, and thus the system is exactly identified. This is the so-called classical GMM case, when the estimator does not depend on the choice of the weighting matrix.\nIn iid case the OLS estimator can also be viewed as a GMM estimator arising from the moment conditions\nThe OLS estimator is identical to the maximum likelihood estimator (MLE) under the normality assumption for the error terms.[14][proof] This normality assumption has historical importance, as it provided the basis for the early work in linear regression analysis by Yule and Pearson.[citation needed] From the properties of MLE, we can infer that the OLS estimator is asymptotically efficient (in the sense of attaining the Cram\u00e9r\u2013Rao bound for variance) if the normality assumption is satisfied.[15]\nAnother way of looking at it is to consider the regression line to be a weighted average of the lines passing through the combination of any two points in the dataset.[13] Although this way of calculation is more computationally expensive, it provides a better intuition on OLS.\nThe equation and solution of linear least squares are thus described as follows:\nIn other words, the gradient equations at the minimum can be written as:\nFor mathematicians, OLS is an approximate solution to an overdetermined system of linear equations X\u03b2 \u2248 y, where \u03b2 is the unknown. Assuming the system cannot be solved exactly (the number of equations n is much larger than the number of unknowns p), we are looking for a solution that could provide the smallest discrepancy between the right- and left- hand sides. In other words, we are looking for the solution that satisfies\nwhere Var(.) and Cov(.) are sample parameters.\nThe least squares estimates in this case are given by simple formulas\nIf the data matrix X contains only two variables, a constant and a scalar regressor xi, then this is called the \"simple regression model\".[12] This case is often considered in the beginner statistics classes, as it provides much simpler formulas even suitable for manual calculation. The parameters are commonly denoted as (\u03b1, \u03b2):\nThe variance in the prediction of the independent variable as a function of the dependent variable is given in the article Polynomial least squares.\nwhere TSS is the total sum of squares for the dependent variable, L = In \u2212 11T/\u2009n, and 1 is an n\u00d71 vector of ones. (L is a \"centering matrix\" which is equivalent to regression on a constant; it simply subtracts the mean from a variable.) In order for R2 to be meaningful, the matrix X of data on regressors must contain a column vector of ones to represent the constant whose coefficient is the regression intercept. In that case, R2 will always be a number between 0 and 1, with values close to 1 indicating a good degree of fit.\nIt is common to assess the goodness-of-fit of the OLS regression by comparing how much the initial variation in the sample can be reduced by regressing onto X. The coefficient of determination R2 is defined as a ratio of \"explained\" variance to the \"total\" variance of the dependent variable y:[11]\nUsing these residuals we can estimate the value of \u03c3 2, called the reduced chi-squared:\nAfter we have estimated \u03b2, the fitted values (or predicted values) from the regression will be \nThe product N=XT X is a normal matrix and its inverse, Q=N\u20131, is the cofactor matrix of \u03b2,[4][5][6] closely related to its covariance matrix, C\u03b2.\nThe matrix (XT X)\u20131 XT=Q XT is called the Moore\u2013Penrose pseudoinverse matrix of X. This formulation highlights the point that estimation can be carried out if, and only if, there is no perfect multicollinearity between the explanatory variables (which would cause the normal matrix to have no inverse).\nSuppose b is a \"candidate\" value for the parameter vector \u03b2. The quantity yi \u2212 xiTb, called the residual for the i-th observation, measures the vertical distance between the data point (xi yi) and the hyperplane y = xTb, and thus assesses the degree of fit between the actual data and the model. The sum of squared residuals (SSR) (also called the error sum of squares (ESS) or residual sum of squares (RSS))[2] is a measure of the overall model fit:\nwhere the objective function S is given by\nwhere\nConsider an overdetermined system\nThere may be some relationship between the regressors. For instance, the third regressor may be the square of the second regressor. In this case (assuming that the first regressor is constant) we have a quadratic model in the second regressor. But this is still considered a linear model because it is linear in the \u03b2s.\nAs a rule, the constant term is always included in the set of regressors X, say, by taking xi1\u00a0=\u00a01 for all i = 1, \u2026, n. The coefficient \u03b21 corresponding to this regressor is called the intercept.\nwhere y and \u03b5 are n\u00d71 vectors of the values of the response variable and the errors for the various observations, and X is an n\u00d7p matrix of regressors, also sometimes called the design matrix, whose row i is xiT and contains the ith observations on all the explanatory variables.\nor in vector form,\nOLS is used in fields as diverse as economics (econometrics), political science, psychology and engineering (control theory and signal processing).\nThe OLS estimator is consistent when the regressors are exogenous, and optimal in the class of linear unbiased estimators when the errors are homoscedastic and serially uncorrelated[citation needed]. Under these conditions, the method of OLS provides minimum-variance mean-unbiased estimation when the errors have finite variances. Under the additional assumption that the errors are normally distributed, OLS is the maximum likelihood estimator.\nGeometrically, this is seen as the sum of the squared distances, parallel to the axis of the dependent variable, between each data point in the set and the corresponding point on the regression surface \u2013 the smaller the differences, the better the model fits the data. The resulting estimator can be expressed by a simple formula, especially in the case of a simple linear regression, in which there is a single regressor on the right side of the regression equation.\nIn statistics, ordinary least squares (OLS) is a type of linear least squares method for estimating the unknown parameters in a linear regression model. OLS chooses the parameters of a linear function of a set of explanatory variables by the principle of least squares: minimizing the sum of the squares of the differences between the observed dependent variable (values of the variable being predicted) in the given dataset and those predicted by the linear function. \n",
            "title": "Ordinary least squares",
            "url": "https://en.wikipedia.org/wiki/Ordinary_least_squares"
        },
        {
            "desc_links": [],
            "desc_text": "",
            "links": [],
            "text": "",
            "title": "Total derivative",
            "url": "https://en.wikipedia.org/wiki/Total_derivative"
        },
        {
            "desc_links": [
                "/wiki/Straight_line",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Covariate",
                "/wiki/Linear_regression",
                "/wiki/Statistics",
                "/wiki/Deming_regression",
                "/wiki/Median",
                "/wiki/Slope",
                "/wiki/Theil%E2%80%93Sen_estimator",
                "/wiki/Least_absolute_deviations",
                "/wiki/Errors_and_residuals",
                "/wiki/Ordinary_least_squares"
            ],
            "desc_text": "b'In statistics, simple linear regression is a linear regression model with a single explanatory variable.[1][2][3][4] That is, it concerns two-dimensional sample points with one independent variable and one dependent variable (conventionally, the x and y coordinates in a Cartesian coordinate system) and finds a linear function (a non-vertical straight line) that, as accurately as possible, predicts the dependent variable values as a function of the independent variables.\\nThe adjective simple refers to the fact that the outcome variable is related to a single predictor.\\n'b'It is common to make the additional stipulation that the ordinary least squares method should be used: the accuracy of each predicted value is measured by its squared residual (vertical distance between the point of the data set and the fitted line), and the goal is to make the sum of these squared deviations as small as possible. Other regression methods that can be used in place of ordinary least squares include least absolute deviations (minimizing the sum of absolute values of residuals) and the Theil\\xe2\\x80\\x93Sen estimator (which chooses a line whose slope is the median of the slopes determined by pairs of sample points).  Deming regression (total least squares) also finds a line that fits a set of two-dimensional sample points, but (unlike ordinary least squares, least absolute deviations, and median slope regression) it is not really an instance of simple linear regression, because it does not separate the coordinates into one dependent and one independent variable and could potentially return a vertical line as its fit.\\n'b'The remainder of the article assumes an ordinary least squares regression.\\nIn this case, the slope of the fitted line is equal to the correlation between y and x corrected by the ratio of standard deviations of these variables. The intercept of the fitted line is such that the line passes through the center of mass (x, y) of the data points.\\n'",
            "links": [
                "/wiki/Straight_line",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Covariate",
                "/wiki/Linear_regression",
                "/wiki/Statistics",
                "/wiki/Deming_regression",
                "/wiki/Median",
                "/wiki/Slope",
                "/wiki/Theil%E2%80%93Sen_estimator",
                "/wiki/Least_absolute_deviations",
                "/wiki/Errors_and_residuals",
                "/wiki/Ordinary_least_squares",
                "/wiki/Errors_and_residuals",
                "/wiki/Standard_score",
                "/wiki/Wikipedia:Please_clarify",
                "/wiki/Homoscedasticity",
                "/wiki/Statistical_model",
                "/wiki/Central_limit_theorem",
                "/wiki/Student%27s_t-distribution",
                "/wiki/Okun%27s_law",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Standard_normal_distribution",
                "/wiki/Student%27s_t-distribution",
                "/wiki/Central_limit_theorem",
                "/wiki/Law_of_large_numbers",
                "/wiki/Ordinary_least_squares",
                "/wiki/Pearson_product-moment_correlation_coefficient"
            ],
            "text": "Thus a seemingly small variation in the data has a real effect.\nThis example also demonstrates that sophisticated calculations will not overcome the use of badly prepared data. The heights were originally given in inches, and have been converted to the nearest centimetre. Since the conversion has introduced rounding error, this is not an exact conversion. The original inches can be recovered by Round(x/0.0254) and then re-converted to metric without rounding: if this is done, the results become\nThe product-moment correlation coefficient might also be calculated:\nThe 0.975 quantile of Student's t-distribution with 13 degrees of freedom is t*13 = 2.1604, and thus the 95% confidence intervals for \u03b1 and \u03b2 are\nThese quantities would be used to calculate the estimates of the regression coefficients, and their standard errors.\nThere are n = 15 points in this data set. Hand calculations would be started by finding the following five sums:\nThis data set gives average masses for women as a function of their height in a sample of American women of age 30\u201339. Although the OLS article argues that it would be more appropriate to run a quadratic regression for this data, the simple linear regression model is applied here instead.\nThe alternative second assumption states that when the number of points in the dataset is \"large enough\", the law of large numbers and the central limit theorem become applicable, and then the distribution of the estimators is approximately normal. Under this assumption all formulas derived in the previous section remain valid, with the only exception that the quantile t*n\u22122 of Student's t distribution is replaced with the quantile q* of the standard normal distribution. Occasionally the fraction 1/n\u22122 is replaced with 1/n. When n is large such a change does not alter the results appreciably.\nIn order to represent this information graphically, in the form of the confidence bands around the regression line, one has to proceed carefully and account for the joint distribution of the estimators. It can be shown[citation needed] that at confidence level (1 \u2212 \u03b3) the confidence band has hyperbolic form given by the equation\nThe 95% confidence intervals for these estimates are\nThe confidence intervals for \u03b1 and \u03b2 give us the general idea where these regression coefficients are most likely to be. For example, in the Okun's law regression shown here the point estimates are\nat confidence level (1 \u2212 \u03b3), where\nSimilarly, the confidence interval for the intercept coefficient \u03b1 is given by\nThis t-value has a Student's t-distribution with n \u2212 2 degrees of freedom. Using it we can construct a confidence interval for \u03b2:\nwhere\nThe latter case is justified by the central limit theorem.\nThe standard method of constructing confidence intervals for linear regression coefficients relies on the normality assumption, which is justified if either:\nDescription of the statistical properties of estimators from the simple linear regression estimates requires the use of a statistical model. The following is based on assuming the validity of a model under which the estimates are optimal. It is also possible to evaluate the properties under other assumptions, such as inhomogeneity, but this is discussed elsewhere.[clarification needed]\nThe last form above demonstrates how moving the line away from the center of mass of the data points affects the slope.\nwhere Cov and Var refer to the covariance and variance of the sample data (uncorrected for bias).\nSubstituting (x \u2212 h, y \u2212 k) in place of (x, y) gives the regression through (h, k):\nSometimes it is appropriate to force the regression line to pass through the origin, because x and y are assumed to be proportional. For the model without the intercept term, y = \u03b2x, the OLS estimator for \u03b2 simplifies to\nThis notation allows us a concise formula for rxy:\nThis shows that rxy is the slope of the regression line of the standardized data points (and that this line passes through the origin).\nyields\nHere we have introduced\nThis relationship between the true (but unobserved) underlying parameters \u03b1 and \u03b2 and the data points is called a linear regression model.\nwhich describes a line with slope \u03b2 and y-intercept \u03b1. In general such a relationship may not hold exactly for the largely unobserved population of values of the independent and dependent variables; we call the unobserved deviations from the above equation the errors.   Suppose we observe n data pairs and call them {(xi, yi), i = 1, ..., n}. We can describe the underlying relationship between yi and xi involving this error term \u03b5i by\nConsider the model function\nThe remainder of the article assumes an ordinary least squares regression.\nIn this case, the slope of the fitted line is equal to the correlation between y and x corrected by the ratio of standard deviations of these variables. The intercept of the fitted line is such that the line passes through the center of mass (x, y) of the data points.\nIt is common to make the additional stipulation that the ordinary least squares method should be used: the accuracy of each predicted value is measured by its squared residual (vertical distance between the point of the data set and the fitted line), and the goal is to make the sum of these squared deviations as small as possible. Other regression methods that can be used in place of ordinary least squares include least absolute deviations (minimizing the sum of absolute values of residuals) and the Theil\u2013Sen estimator (which chooses a line whose slope is the median of the slopes determined by pairs of sample points).  Deming regression (total least squares) also finds a line that fits a set of two-dimensional sample points, but (unlike ordinary least squares, least absolute deviations, and median slope regression) it is not really an instance of simple linear regression, because it does not separate the coordinates into one dependent and one independent variable and could potentially return a vertical line as its fit.\nIn statistics, simple linear regression is a linear regression model with a single explanatory variable.[1][2][3][4] That is, it concerns two-dimensional sample points with one independent variable and one dependent variable (conventionally, the x and y coordinates in a Cartesian coordinate system) and finds a linear function (a non-vertical straight line) that, as accurately as possible, predicts the dependent variable values as a function of the independent variables.\nThe adjective simple refers to the fact that the outcome variable is related to a single predictor.\n",
            "title": "Simple linear regression",
            "url": "https://en.wikipedia.org/wiki/Simple_linear_regression"
        },
        {
            "desc_links": [
                "/wiki/Francis_Galton",
                "/wiki/Karl_Pearson",
                "/wiki/Cauchy%E2%80%93Schwarz_inequality",
                "/wiki/Correlation",
                "/wiki/Help:IPA/English",
                "/wiki/Statistics"
            ],
            "desc_text": "b\"In statistics, the Pearson correlation coefficient (PCC, pronounced /\\xcb\\x88p\\xc9\\xaa\\xc9\\x99rs\\xc9\\x99n/), also referred to as Pearson's r, the Pearson product-moment correlation coefficient (PPMCC) or the bivariate correlation,[1] is a measure of the linear correlation between two variables X and Y.  Owing to the Cauchy\\xe2\\x80\\x93Schwarz inequality it has a value between +1 and \\xe2\\x88\\x921, where 1 is total positive linear correlation, 0 is no linear correlation, and \\xe2\\x88\\x921 is total negative linear correlation. It is widely used in the sciences. It was developed by Karl Pearson from a related idea introduced by Francis Galton in the 1880s.[2][3][4]\\n\"",
            "links": [
                "/wiki/Francis_Galton",
                "/wiki/Karl_Pearson",
                "/wiki/Cauchy%E2%80%93Schwarz_inequality",
                "/wiki/Correlation",
                "/wiki/Help:IPA/English",
                "/wiki/Statistics",
                "/wiki/Moment_(mathematics)",
                "/wiki/Standard_deviations",
                "/wiki/Covariance",
                "/wiki/Statistical_population",
                "/wiki/Statistical_sample",
                "/wiki/Sample_(statistics)",
                "/wiki/Standard_score",
                "/wiki/Maximum_likelihood",
                "/wiki/Invariant_estimator",
                "/wiki/Line_(mathematics)",
                "/wiki/Absolute_value",
                "/wiki/Anti-correlation",
                "/wiki/Trigonometric_functions",
                "/wiki/Vector_(geometry)",
                "/wiki/Angle",
                "/wiki/Cosine",
                "/wiki/Dot_product",
                "/wiki/Cosine_similarity",
                "/wiki/Two-tailed_test",
                "/wiki/Two-tailed_test",
                "/wiki/P-value",
                "/wiki/Percentile",
                "/wiki/Confidence_interval",
                "/wiki/Sampling_distribution",
                "/wiki/Bootstrapping_(statistics)",
                "/wiki/Student%27s_t-distribution",
                "/wiki/Sampling_distribution",
                "/wiki/Bivariate_normal_distribution",
                "/wiki/Bivariate_normal_distribution",
                "/wiki/Inverse_hyperbolic_function",
                "/wiki/Fisher_transformation",
                "/wiki/Hypothesis_test",
                "/wiki/Confidence_intervals",
                "/wiki/Normal_distribution",
                "/wiki/Standard_score",
                "/wiki/Heavy-tailed_distribution",
                "/wiki/Cauchy_distribution",
                "/wiki/Population_variance",
                "/wiki/Marginal_distribution",
                "/wiki/Covariance",
                "/wiki/Statistical_population",
                "/wiki/Probability_distribution",
                "/wiki/Moment_(mathematics)",
                "/wiki/Statistical_dependence",
                "/wiki/Scatterplot",
                "/wiki/Robust_statistics#Definition",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Outlier",
                "/wiki/Robust_statistics",
                "/wiki/Exchangeable_random_variables",
                "/wiki/Non-parametric_statistics",
                "/wiki/Resampling_(statistics)",
                "/wiki/Bootstrapping_(statistics)",
                "/wiki/Fisher_transformation",
                "/wiki/Bivariate_normal_distribution",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Cosine_similarity",
                "/wiki/Cluster_analysis",
                "/wiki/Sine",
                "/wiki/Directional_statistics",
                "/wiki/Partial_correlation",
                "/wiki/Matrix_inverse",
                "/wiki/Matrix_square_root",
                "/wiki/Principal_components_analysis"
            ],
            "text": "This decorrelation is related to principal components analysis for multivariate data.\nwhere an exponent of \u22121/2 represents the matrix square root of the inverse of a matrix.  The correlation matrix of T will be the identity matrix.  If a new data observation x is a row vector of n elements, then the same transform can be applied to x to get the transformed vectors d and t:\nIt is always possible to remove the correlations between all pairs of an arbitrary number of random variables by using a data transformation, even if the relationship between the variables is nonlinear. A presentation of this result for population distributions is given by Cox & Hinkley.[31]\nIf a population or data-set is characterized by more than two variables, a partial correlation coefficient measures the strength of dependence between a pair of variables that is not accounted for by the way in which they both change in response to variations in a selected subset of the other variables.\nFor variables X = {x1,...,xn} and Y = {y1,...,yn} that are defined on the unit circle [0, 2\u03c0), it is possible to define a circular analog of Pearson's coefficient.[30] This is done by transforming data points in X and Y with a sine function such that the correlation coefficient is given as:\nConsidering that the Pearson correlation coefficient falls between [\u22121, 1], the Pearson distance lies in [0, 2]. The Pearson distance has been used in cluster analysis and data detection for communications and storage with unknown gain and offset[29]\nA distance metric for two variables X and Y known as Pearson's distance can be defined from their correlation coefficient as[28]\nScaled correlation is a variant of Pearson's correlation in which the range of the data is restricted intentionally and in a controlled manner to reveal correlations between fast components in time series.[27] Scaled correlation is defined as average correlation across short segments of data.\nThe weighted version of the sample reflective correlation is\nThe sample reflective correlation is equivalent to cosine similarity:\nThe reflective correlation is symmetric, but it is not invariant under translation:\nThe reflective correlation is a variant of Pearson's correlation in which the data are not centered around their mean values.[citation needed] The population reflective correlation is\nSuppose observations to be correlated have differing degrees of importance that can be expressed with a weight vector w. To calculate the correlation between vectors x and y with the weight vector w (all of length\u00a0n),[25][26]\nNote that radj \u2248 r for large values of\u00a0n.\nAnother proposed[5] adjusted correlation coefficient\nis:[citation needed]\nAn approximate solution[citation needed] to equation (2) is:\nAn approximately unbiased estimator radj can be obtained[citation needed] by truncating E[r] and solving this truncated equation:\nThe unique minimum variance unbiased estimator radj is given by[24]\nThe sample correlation coefficient r is not an unbiased estimate of \u03c1. For data that follows a bivariate normal distribution, the expectation E(r) for the sample correlation coefficient  r of a normal bivariate is[23]\nVariations of the correlation coefficient can be calculated for different purposes. Here are some examples.\nA stratified analysis is one way to either accommodate a lack of bivariate normality, or to isolate the correlation resulting from one factor while controlling for another.  If W represents cluster membership or another factor that it is desirable to control, we can stratify the data based on the value of W, then calculate a correlation coefficient within each stratum.  The stratum-level estimates can then be combined to estimate the overall correlation while controlling for W.[22]\nStatistical inference for Pearson's correlation coefficient is sensitive to the data distribution.  Exact tests, and asymptotic tests based on the Fisher transformation can be applied if the data are approximately normally distributed, but may be misleading otherwise.  In some situations, the bootstrap can be applied to construct confidence intervals, and permutation tests can be applied to carry out hypothesis tests.  These non-parametric approaches may give more meaningful results in some situations where bivariate normality does not hold.  However the standard versions of these approaches rely on exchangeability of the data, meaning that there is no ordering or grouping of the data pairs being analyzed that might affect the behavior of the correlation estimate.\nLike many commonly used statistics, the sample statistic r is not robust,[19] so its value can be misleading if outliers are present.[20][21] Specifically, the PMCC is neither distributionally robust,[citation needed] nor outlier resistant[19] (see Robust statistics#Definition). Inspection of the scatterplot between X and Y will typically reveal a situation where lack of robustness might be an issue, and in such cases it may be advisable to use a robust measure of association. Note however that while most robust estimators of association measure statistical dependence in some way, they are generally not interpretable on the same scale as the Pearson correlation coefficient.\nThe population Pearson correlation coefficient is defined in terms of moments, and therefore exists for any bivariate probability distribution for which the population covariance is defined and the marginal population variances are defined and are non-zero.  Some probability distributions such as the Cauchy distribution have undefined variance and hence \u03c1 is not defined if X or Y follows such a distribution.  In some practical applications, such as those involving data suspected to follow a heavy-tailed distribution, this is an important consideration.  However, the existence of the correlation coefficient is usually not a concern; for instance, if the range of the distribution is bounded, \u03c1 is always defined.\nThat equation can be written as:\nThus\nThe two summands above are the fraction of variance in Y that is explained by X (right) and that is unexplained by X (left).\nFor example, suppose we observe r\u00a0=\u00a00.3 with a sample size of n=50, and we wish to obtain a 95% confidence interval for \u03c1.  The transformed value is artanh(r)\u00a0=\u00a00.30952, so the confidence interval on the transformed scale is 0.30952 \u00b1 1.96/\u221a47, or (0.023624,\u00a00.595415).  Converting back to the correlation scale yields (0.024,\u00a00.534).\nThe inverse Fisher transformation brings the interval back to the correlation scale.\nThus, a z-score is\nIf F(r) is the Fisher transformation of r, and n is the sample size, then F(r) approximately follows a normal distribution with\nIn practice, confidence intervals and hypothesis tests relating to \u03c1 are usually carried out using the Fisher transformation, the inverse hyperbolic function (artanh) of r:\nFor data that follows a bivariate normal distribution, the exact density function f(r) for the sample correlation coefficient  r of a normal bivariate is\n[16]\n[17]\n[18]\nAnother early paper[15] provides graphs and tables for general values of \u03c1, for small sample sizes, and discusses computational approaches.\nAlternatively, large sample approaches can be used.\nhas a Student's t-distribution in the null case (zero correlation).[13] This also holds approximately even if the observed values are non-normal, provided sample sizes are not very small.[14] For determining the critical values for r the inverse of this transformation is also needed:\nFor pairs from an uncorrelated bivariate normal distribution, the sampling distribution of a certain function of Pearson's correlation coefficient follows Student's t-distribution with degrees of freedom n\u00a0\u2212\u00a02.  Specifically, if the underlying variables have a bivariate normal distribution, the variable\nThe bootstrap can be used to construct confidence intervals for Pearson's correlation coefficient.  In the \"non-parametric\" bootstrap, n pairs (xi,\u00a0yi) are resampled \"with replacement\" from the observed set of n pairs, and the correlation coefficient r is calculated based on the resampled data.  This process is repeated a large number of times, and the empirical distribution of the resampled r values are used to approximate the sampling distribution of the statistic.  A 95% confidence interval for \u03c1 can be defined as the interval spanning from the 2.5th to the 97.5th percentile of the resampled r values.\nTo perform the permutation test, repeat steps\u00a0(1) and (2) a large number of times.  The p-value for the permutation test is the proportion of the r values generated in step\u00a0(2) that are larger than the Pearson correlation coefficient that was calculated from the original data.  Here \"larger\" can mean either that the value is larger in magnitude, or larger in signed value, depending on whether a two-sided or one-sided test is desired.\nPermutation tests provide a direct approach to performing hypothesis tests and constructing confidence intervals.  A permutation test for Pearson's correlation coefficient involves the following two steps: \nWe discuss methods of achieving one or both of these aims below.\nStatistical inference based on Pearson's correlation coefficient often focuses on one of the following two aims:  \nSeveral authors have offered guidelines for the interpretation of a correlation coefficient.[11][12] However, all such criteria are in some ways arbitrary.[12] The interpretation of a correlation coefficient depends on the context and purposes.  A correlation of 0.8 may be very low if one is verifying a physical law using high-quality instruments, but may be regarded as very high in the social sciences where there may be a greater contribution from complicating factors.\nas expected.\nThis uncentred correlation coefficient is identical with the cosine similarity.\nNote that the above data were deliberately chosen to be perfectly correlated: y = 0.10 + 0.01 x. The Pearson correlation coefficient must therefore be exactly one. Centering the data (shifting x by E(x) = 3.8 and y by E(y) = 0.138) yields x = (\u22122.8, \u22121.8, \u22120.8, 1.2, 4.2) and y = (\u22120.028, \u22120.018, \u22120.008, 0.012, 0.042), from which\nBy the usual procedure for finding the angle \u03b8 between two vectors (see dot product), the uncentered correlation coefficient is:\nBoth the uncentered (non-Pearson-compliant) and centered correlation coefficients can be determined for a dataset. As an example, suppose five countries are found to have gross national products of 1, 2, 3, 5, and 8 billion dollars, respectively. Suppose these same five countries (in the same order) are found to have 11%, 12%, 13%, 15%, and 18% poverty. Then let x and y be ordered 5-element vectors containing the above data: x = (1, 2, 3, 5, 8) and y = (0.11, 0.12, 0.13, 0.15, 0.18).\nFor centered data (i.e., data which have been shifted by the sample means of their respective variables so as to have an average of zero for each variable), the correlation coefficient can also be viewed as the cosine of the angle \u03b8 between the two observed vectors in N-dimensional space (for N observations of each variable)[10]:ch. 5 (as illustrated for a special case in the next paragraph).\nFor uncentered data, there is a relation between the correlation coefficient and the angle \u03c6 between the two regression lines, y = gx(x) and x = gy(y), obtained by regressing y on x and x on y respectively. (Here \u03c6 is measured counterclockwise within the first quadrant formed around the lines' intersection point if r > 0, or counterclockwise from the fourth to the second quadrant if r < 0.) One can show[9] that if the standard deviations are equal, then r = sec \u03c6 \u2212 tan \u03c6, where sec and tan are trigonometric functions.\nRogers and Nicewander \n[8]\ncataloged thirteen ways of interpreting correlation:\nMore generally, note that (Xi\u00a0\u2212\u00a0X)(Yi\u00a0\u2212\u00a0Y) is positive if and only if Xi and Yi lie on the same side of their respective means.  Thus the correlation coefficient is positive if Xi and Yi tend to be simultaneously greater than, or simultaneously less than, their respective means.  The correlation coefficient is negative (anti-correlation) if Xi and Yi tend to lie on opposite sides of their respective means. Moreover, the stronger is either tendency, the larger is the absolute value of the correlation coefficient.\nThe correlation coefficient ranges from \u22121 to 1. A value of 1 implies that a linear equation describes the relationship between X and Y perfectly, with all data points lying on a line for which Y increases as X increases. A value of \u22121 implies that all data points lie on a line for which Y decreases as X increases. A value of 0 implies that there is no linear correlation between the variables.\nA key mathematical property of the Pearson correlation coefficient is that it is invariant under separate changes in location and scale in the two variables.  That is, we may transform X to a\u00a0+\u00a0bX and transform Y to c\u00a0+\u00a0dY, where a, b, c, and d are constants with b, d > 0, without changing the correlation coefficient. (This holds for both the population and sample Pearson correlation coefficients.) Note that more general linear transformations do change the correlation: see \u00a7\u00a0Decorrelation of n random variables for an application of this.\nThe absolute values of both the sample and population Pearson correlation coefficients are less than or equal to 1.  Correlations equal to 1 or \u22121 correspond to data points lying exactly on a line (in the case of the sample correlation), or to a bivariate distribution entirely supported on a line (in the case of the population correlation).  The Pearson correlation coefficient is symmetric: corr(X,Y)\u00a0=\u00a0corr(Y,X).\nIn case of missing data, Garren derived the maximum likelihood estimator.[7]\nUnder heavy noise conditions, extracting the correlation coefficient between two sets of stochastic variables is nontrivial, in particular where Canonical Correlation Analysis reports degraded correlation values due to the heavy noise contributions. A generalization of the approach is given elsewhere.[6]\nAlternative formulae for r are also available. One can use the following formula for r:\nAn equivalent expression gives the formula for r as the mean of the products of the standard scores as follows:\nRearranging again gives us this[5] formula for r:\nRearranging gives us this formula for r:\nPearson's correlation coefficient when applied to a sample is commonly represented by the letter r and may be referred to as the sample correlation coefficient or the sample Pearson correlation coefficient. We can obtain a formula for r by substituting estimates of the covariances and variances based on a sample into the formula above. So if we have one dataset {x1,...,xn} containing n values and another dataset {y1,...,yn} containing n values then that formula for r is:\nthe formula for \u03c1 can also be written as\nThe formula for \u03c1 can be expressed in terms of uncentered moments.  Since\nthe formula for \u03c1 can also be written as\nThe formula for \u03c1 can be expressed in terms of mean and expectation.  Since\nPearson's correlation coefficient when applied to a population is commonly represented by the Greek letter \u03c1 (rho) and may be referred to as the population correlation coefficient or the population Pearson correlation coefficient. The formula for \u03c1[5] is:\nPearson's correlation coefficient is the covariance of the two variables divided by the product of their standard deviations. The form of the definition involves a \"product moment\", that is, the mean (the first moment about the origin) of the product of the mean-adjusted random variables; hence the modifier product-moment in the name.\nIn statistics, the Pearson correlation coefficient (PCC, pronounced /\u02c8p\u026a\u0259rs\u0259n/), also referred to as Pearson's r, the Pearson product-moment correlation coefficient (PPMCC) or the bivariate correlation,[1] is a measure of the linear correlation between two variables X and Y.  Owing to the Cauchy\u2013Schwarz inequality it has a value between +1 and \u22121, where 1 is total positive linear correlation, 0 is no linear correlation, and \u22121 is total negative linear correlation. It is widely used in the sciences. It was developed by Karl Pearson from a related idea introduced by Francis Galton in the 1880s.[2][3][4]\n",
            "title": "Pearson correlation coefficient",
            "url": "https://en.wikipedia.org/wiki/Pearson_correlation"
        },
        {
            "desc_links": [
                "/wiki/Differential_geometry",
                "/wiki/Vector_calculus",
                "/wiki/Total_derivative",
                "/wiki/Derivative",
                "/wiki/Function_(mathematics)#MULTIVARIATE_FUNCTION",
                "/wiki/Mathematics",
                "/wiki/Carl_Gustav_Jacob_Jacobi",
                "/wiki/Adrien-Marie_Legendre",
                "/wiki/Marquis_de_Condorcet",
                "/wiki/%E2%88%82"
            ],
            "desc_text": "b'In mathematics, a partial derivative of a function of several variables is its derivative with respect to one of those variables, with the others held constant (as opposed to the total derivative, in which all variables are allowed to vary). Partial derivatives are used in vector calculus and differential geometry.\\n'b'The partial derivative of a function \\n  \\n    \\n      \\n        f\\n        (\\n        x\\n        ,\\n        y\\n        ,\\n        \\xe2\\x80\\xa6\\n        )\\n      \\n    \\n    {\\\\displaystyle f(x,y,\\\\dots )}\\n  \\n with respect to the variable \\n  \\n    \\n      \\n        x\\n      \\n    \\n    {\\\\displaystyle x}\\n  \\n is variously denoted by\\n'b'Sometimes, for \\n  \\n    \\n      \\n        z\\n        =\\n        f\\n        (\\n        x\\n        ,\\n        y\\n        ,\\n        \\xe2\\x80\\xa6\\n        )\\n        ,\\n      \\n    \\n    {\\\\displaystyle z=f(x,y,\\\\dots ),}\\n  \\n the partial derivative of \\n  \\n    \\n      \\n        z\\n      \\n    \\n    {\\\\displaystyle z}\\n  \\n with respect to \\n  \\n    \\n      \\n        x\\n      \\n    \\n    {\\\\displaystyle x}\\n  \\n is denoted as \\n  \\n    \\n      \\n        \\n          \\n            \\xe2\\x88\\x82\\n            z\\n          \\n        \\n        \\n          \\n            \\xe2\\x88\\x82\\n            x\\n          \\n          .\\n        \\n      \\n    \\n    {\\\\displaystyle {\\\\partial z} \\\\over {\\\\partial x}.}\\n  \\n  Since a partial derivative generally has the same arguments as the original function, its functional dependence is sometimes explicitly signified by the notation, such as in:\\n'b'The symbol used to denote partial derivatives is \\xe2\\x88\\x82. One of the first known uses of this symbol in mathematics is by Marquis de Condorcet from 1770, who used it for partial differences. The modern partial derivative notation was created by Adrien-Marie Legendre (1786), though he later abandoned it; Carl Gustav Jacob Jacobi reintroduced the symbol again in 1841.[1]\\n'",
            "links": [
                "/wiki/Differential_geometry",
                "/wiki/Vector_calculus",
                "/wiki/Total_derivative",
                "/wiki/Derivative",
                "/wiki/Function_(mathematics)#MULTIVARIATE_FUNCTION",
                "/wiki/Mathematics",
                "/wiki/Carl_Gustav_Jacob_Jacobi",
                "/wiki/Adrien-Marie_Legendre",
                "/wiki/Marquis_de_Condorcet",
                "/wiki/%E2%88%82",
                "/wiki/Slope",
                "/wiki/Tangent_line",
                "/wiki/Euclidean_space",
                "/wiki/Surface_(topology)",
                "/wiki/Graph_of_a_function",
                "/wiki/Arity",
                "/wiki/Vector_field",
                "/wiki/Gradient",
                "/wiki/Open_set",
                "/wiki/Limit_of_a_function",
                "/wiki/Total_derivative",
                "/wiki/Neighborhood_(topology)",
                "/wiki/Continuous_function",
                "/wiki/Radius",
                "/wiki/Height",
                "/wiki/Cone_(geometry)",
                "/wiki/Volume",
                "/wiki/Total_derivative",
                "/wiki/System_of_equations",
                "/wiki/First_order_condition",
                "/wiki/Profit_(economics)",
                "/wiki/Economics",
                "/wiki/Optimization",
                "/wiki/Mole_fraction",
                "/wiki/Mathematical_physics",
                "/wiki/Gibbs-Duhem_equation",
                "/wiki/Mole_fraction",
                "/wiki/Partial_differential_equation",
                "/wiki/Gradient",
                "/wiki/Algorithm",
                "/wiki/Pixel",
                "/wiki/Seam_carving",
                "/wiki/Marginal_propensity_to_consume",
                "/wiki/Consumption_function",
                "/wiki/Economics",
                "/wiki/Mixed_derivatives",
                "/wiki/Antiderivative",
                "/wiki/Conservative_vector_field",
                "/wiki/Gradient",
                "/wiki/Schwarz_theorem",
                "/wiki/Optimization",
                "/wiki/Second_order_condition",
                "/wiki/Hessian_matrix"
            ],
            "text": "Own and cross partial derivatives appear in the Hessian matrix which is used in the second order conditions in optimization problems.\nSchwarz's theorem states that if the second derivatives are continuous the expression for the cross partial derivative is unaffected by which variable the partial derivative is taken with respect to first and which is taken second. That is,\nThe cross partial derivative with respect to x and y is obtained by taking the partial derivative of f with respect to x, and then taking the partial derivative of the result with respect to y, to obtain\nIf all the partial derivatives of a function are known (for example, with the gradient), then the antiderivatives can be matched via the above process to reconstruct the original function up to a constant. Unlike in the single-variable case, however, not every set of functions can be the set of all (first) partial derivatives of a single function. In other words, not every vector field is conservative.\nThere is a concept for partial derivatives that is analogous to antiderivatives for regular derivatives. Given a partial derivative, it allows for the partial recovery of the original function.\nHigher-order partial and mixed derivatives:\nSecond-order mixed derivatives:\nSecond-order partial derivatives:\nFirst-order partial derivatives:\nPartial derivatives play a prominent role in economics, in which most functions describing economic behaviour posit that the behaviour depends on more than one variable. For example, a societal consumption function may describe the amount spent on consumer goods as depending on both income and wealth; the marginal propensity to consume is then the partial derivative of the consumption function with respect to income.\nPartial derivatives are key to target-aware image resizing algorithms. Widely known as seam carving, these algorithms require each pixel in an image to be assigned a numerical 'energy' to describe their dissimilarity against orthogonal adjacent pixels. The algorithm then progressively removes rows or columns with the lowest energy. The formula established to determine a pixel's energy (magnitude of gradient at a pixel) depends heavily on the constructs of partial derivatives.\nThis equality can be rearranged to have differential quotient of mole fractions on one side.\nwhich can be used for solving partial differential equations like:\nRatios X, Y, Z of mole fractions can be written for ternary and multicomponent systems:\nDifferential quotients can be formed at constant ratios like those above:\nExpress mole fractions of a component as functions of other components mole fraction and binary mole ratios:\nPartial derivatives appear in thermodynamic equations like Gibbs-Duhem equation as well in other equations from mathematical physics. Here the variables being held constant in partial derivatives can be ratio of simple variables like mole fractions xi in the following example involving the Gibbs energies in a ternary mixture system:\nPartial derivatives appear in any calculus-based optimization problem with more than one choice variable. For example, in economics a firm may wish to maximize profit \u03c0(x, y)  with respect to the choice of the quantities x and y of two different types of output. The first order conditions for this optimization are \u03c0x = 0 = \u03c0y. Since both partial derivatives \u03c0x and \u03c0y will generally themselves be functions of both arguments x and y, these two first order conditions form a system of two equations in two unknowns.\nSimilarly, the total derivative with respect to h is:\nwhich simplifies to:\nThis gives the total derivative with respect to r:\nIf (for some arbitrary reason) the cone's proportions have to stay the same, and the height and radius are in a fixed ratio k,\nThe difference between the total and partial derivative is the elimination of indirect dependencies between variables in partial derivatives.\nand\nBy contrast, the total derivative of V with respect to r and h are respectively\nwhich represents the rate with which the volume changes if its height is varied and its radius is kept constant.\nThe partial derivative of V with respect to r is\nThe volume V of a cone depends on the cone's height h and its radius r according to the formula\nEven if all partial derivatives \u2202f/\u2202xi(a) exist at a given point a, the function need not be continuous there. However, if all partial derivatives exist in a neighborhood of a and are continuous there, then f is totally differentiable in that neighborhood and the total derivative is continuous. In this case, it is said that f is a C1 function. This can be used to generalize for vector valued functions (f\u00a0: U \u2192 R'm) by carefully using a componentwise argument.\nLike ordinary derivatives, the partial derivative is defined as a limit. Let U be an open subset of Rn and f\u00a0: U \u2192 R a function. The partial derivative of f at the point a = (a1, ..., an) \u2208 U with respect to the i-th variable xi is defined as\nThis vector is called the gradient of f at a. If f is differentiable at every point in some domain, then the gradient is a vector-valued function \u2207f which takes the point a to the vector \u2207f(a). Consequently, the gradient produces a vector field.\nIn other words, the different choices of a index a family of one-variable functions just as in the example above. This expression also shows that the computation of partial derivatives reduces to the computation of one-variable derivatives.\nand by definition,\nIn the above difference quotient, all the variables except xi are held fixed. That choice of fixed values determines a function of one variable\nIn general, the partial derivative of an n-ary function f(x1,...,xn) in the direction xi at the point (a1,...,an) is defined to be:\nThis is the partial derivative of f with respect to x. Here \u2202 is a rounded d called the partial derivative symbol. To distinguish it from the letter d, \u2202 is sometimes pronounced \"tho\" or \"partial\".\nThe above procedure can be performed for any choice of a. Assembling the derivatives together into a function gives a function which describes the variation of f in the x direction:\nIn this expression, a is a constant, not a variable, so fa is a function of only one real variable, that being x. Consequently, the definition of the derivative for a function of one variable applies:\nOnce a value of y is chosen, say a, then f(x,y) determines a function fa which traces a curve x2 + ax + a2 on the xz plane:\nNote that in this section the subscript notation fy  denotes a function contingent on a fixed value of y, and not a partial derivative.\nIn other words, every value of y defines a function, denoted fy , which is a function of one variable x.[a] That is,\nThe function f can be reinterpreted as a family of functions of one variable indexed by the other variables:\nThe graph of this function defines a surface in euclidean space. To every point on this surface, there are an infinite number of tangent lines. Partial differentiation is the act of choosing one of these lines and finding its slope. Usually, the lines of most interest are those that are parallel to the xz-plane, and those that are parallel to the yz-plane (which result from holding either y or x constant, respectively.)\nSuppose that f is a function of more than one variable. For instance,\nThe symbol used to denote partial derivatives is \u2202. One of the first known uses of this symbol in mathematics is by Marquis de Condorcet from 1770, who used it for partial differences. The modern partial derivative notation was created by Adrien-Marie Legendre (1786), though he later abandoned it; Carl Gustav Jacob Jacobi reintroduced the symbol again in 1841.[1]\nIn mathematics, a partial derivative of a function of several variables is its derivative with respect to one of those variables, with the others held constant (as opposed to the total derivative, in which all variables are allowed to vary). Partial derivatives are used in vector calculus and differential geometry.\n",
            "title": "Partial derivative",
            "url": "https://en.wikipedia.org/wiki/Partial_derivative"
        },
        {
            "desc_links": [
                "/wiki/Almost_surely",
                "/wiki/Arithmetic_mean",
                "/wiki/Law_of_large_numbers",
                "/wiki/Dice",
                "/wiki/Random_variable",
                "/wiki/Probability_theory",
                "/wiki/Probability_measure",
                "/wiki/Probability_density_function",
                "/wiki/Lebesgue_integral",
                "/wiki/Absolute_continuity#Absolute_continuity_of_measures",
                "/wiki/Weighted_average",
                "/wiki/Discrete_random_variable",
                "/wiki/Cauchy_distribution",
                "/wiki/Heavy-tailed_distribution",
                "/wiki/Probability_distribution",
                "/wiki/Statistical_dispersion",
                "/wiki/Variance",
                "/wiki/Location_parameter",
                "/wiki/Probability_distribution",
                "/wiki/Unbiased_estimator",
                "/wiki/Dependent_variable",
                "/wiki/Explanatory_variable",
                "/wiki/Regression_analysis",
                "/wiki/Security_breach",
                "/wiki/Gordon-Loeb_Model",
                "/wiki/Von_Neumann%E2%80%93Morgenstern_utility_function",
                "/wiki/Objective_function",
                "/wiki/Risk_aversion",
                "/wiki/Risk_neutrality",
                "/wiki/Expected_utility_hypothesis#Expected_value_and_choice_under_risk",
                "/wiki/Decision_theory"
            ],
            "desc_text": "b'In probability theory, the expected value of a random variable, intuitively, is the long-run average value of repetitions of the experiment it represents. For example, the expected value in rolling a six-sided die is 3.5, because the average of all the numbers that come up in an extremely large number of rolls is close to 3.5. Less roughly, the law of large numbers states that the arithmetic mean of the values almost surely converges to the expected value as the number of repetitions approaches infinity. The expected value is also known as the expectation, mathematical expectation, EV, average, mean value, mean, or first moment.\\n'b'More practically, the expected value of a discrete random variable is the probability-weighted average of all possible values. In other words, each possible value the random variable can assume is multiplied by its probability of occurring, and the resulting products are summed to produce the expected value. The same principle applies to an absolutely continuous random variable, except that an integral of the variable with respect to its probability density replaces the sum. The formal definition subsumes both of these and also works for distributions which are  neither discrete nor absolutely continuous; the expected value of a random variable is the integral of the random variable with respect to its probability measure.[1][2]\\n'b'The expected value does not exist for random variables having some distributions with large \"tails\", such as the Cauchy distribution.[3]  For random variables such as these, the long-tails of the distribution prevent the sum or integral from converging.\\n'b\"The expected value is a key aspect of how one characterizes a probability distribution; it is one type of location parameter. By contrast, the variance is a measure of dispersion of the possible values of the random variable around the expected value. The variance itself is defined in terms of two expectations: it is the expected value of the squared deviation of the variable's value from the variable's expected value.\\n\"b'The expected value plays important roles in a variety of contexts. In regression analysis, one desires a formula in terms of observed data that will give a \"good\" estimate of the parameter giving the effect of some explanatory variable upon a dependent variable. The formula will give different estimates using different samples of data, so the estimate it gives is itself a random variable. A formula is typically considered good in this context if it is an unbiased estimator\\xe2\\x80\\x94 that is if the expected value of the estimate (the average value it would give over an arbitrarily large number of separate samples) can be shown to equal the true value of the desired parameter.\\n'b'In decision theory, and in particular in choice under uncertainty, an agent is described as making an optimal choice in the context of incomplete information. For risk neutral agents, the choice involves using the expected values of uncertain quantities, while for risk averse agents it involves maximizing the expected value of some objective function such as a von Neumann\\xe2\\x80\\x93Morgenstern utility function. One example of using expected value in reaching optimal decisions is the Gordon\\xe2\\x80\\x93Loeb model of information security investment. According to the model, one can conclude that the amount a firm spends to protect information should generally be only a small fraction of the expected loss (i.e., the expected value of the loss resulting from a cyber or information security breach).[4]\\n'",
            "links": [
                "/wiki/Almost_surely",
                "/wiki/Arithmetic_mean",
                "/wiki/Law_of_large_numbers",
                "/wiki/Dice",
                "/wiki/Random_variable",
                "/wiki/Probability_theory",
                "/wiki/Probability_measure",
                "/wiki/Probability_density_function",
                "/wiki/Lebesgue_integral",
                "/wiki/Absolute_continuity#Absolute_continuity_of_measures",
                "/wiki/Weighted_average",
                "/wiki/Discrete_random_variable",
                "/wiki/Cauchy_distribution",
                "/wiki/Heavy-tailed_distribution",
                "/wiki/Probability_distribution",
                "/wiki/Statistical_dispersion",
                "/wiki/Variance",
                "/wiki/Location_parameter",
                "/wiki/Probability_distribution",
                "/wiki/Unbiased_estimator",
                "/wiki/Dependent_variable",
                "/wiki/Explanatory_variable",
                "/wiki/Regression_analysis",
                "/wiki/Security_breach",
                "/wiki/Gordon-Loeb_Model",
                "/wiki/Von_Neumann%E2%80%93Morgenstern_utility_function",
                "/wiki/Objective_function",
                "/wiki/Risk_aversion",
                "/wiki/Risk_neutrality",
                "/wiki/Expected_utility_hypothesis#Expected_value_and_choice_under_risk",
                "/wiki/Decision_theory",
                "/wiki/Riemann_rearrangement_theorem",
                "/wiki/Conditional_convergence",
                "/wiki/Absolute_convergence",
                "/wiki/Lebesgue%E2%80%93Stieltjes_integration",
                "/wiki/Cauchy_distribution",
                "/wiki/Covariance",
                "/wiki/Statistical_frequency",
                "/wiki/Indicator_function",
                "/wiki/Moment_generating_function",
                "/wiki/Moment_about_the_mean",
                "/wiki/Moment_(mathematics)",
                "/wiki/Estimator",
                "/wiki/Variance",
                "/wiki/Statistical_sample",
                "/wiki/Sample_size",
                "/wiki/Law_of_large_numbers",
                "/wiki/Estimator",
                "/wiki/Errors_and_residuals_in_statistics",
                "/wiki/Estimator_bias",
                "/wiki/Arithmetic_mean",
                "/wiki/Estimation_theory",
                "/wiki/Center_of_mass",
                "/wiki/Classical_mechanics",
                "/wiki/Computational_formula_for_the_variance",
                "/wiki/Variance",
                "/wiki/Pierre_de_Fermat",
                "/wiki/Antoine_Gombaud",
                "/wiki/Blaise_Pascal",
                "/wiki/Problem_of_points",
                "/wiki/Theory_of_probability",
                "/wiki/Christiaan_Huygens",
                "/wiki/De_M%C3%A9r%C3%A9%27s_Problem",
                "/wiki/Pierre-Simon_Laplace",
                "/wiki/William_Allen_Whitworth"
            ],
            "text": "The use of the letter E to denote expected value goes back to W.A. Whitworth in 1901,[8] who used a script E. The symbol has become popular since for English writers it meant \"Expectation\", for Germans \"Erwartungswert\", for Spanish \"Esperanza matem\u00e1tica\" and for French \"Esp\u00e9rance math\u00e9matique\".[9]\nNeither Pascal nor Huygens used the term \"expectation\" in its modern sense. In particular, Huygens writes: \"That my Chance or Expectation to win any thing is worth just such a Sum, as wou'd procure me in the same Chance and Expectation at a fair Lay. ... If I expect a or b, and have an equal Chance of gaining them, my Expectation is worth a+b/2.\" More than a hundred years later, in 1814, Pierre-Simon Laplace published his tract \"Th\u00e9orie analytique des probabilit\u00e9s\", where the concept of expected value was defined explicitly:\nIn the foreword to his book, Huygens wrote: \"It should be said, also, that for some time some of the best mathematicians of France have occupied themselves with this kind of calculus so that no one should attribute to me the honour of the first invention. This does not belong to me. But these savants, although they put each other to the test by proposing to each other many questions difficult to solve, have hidden their methods. I have had therefore to examine and go deeply for myself into this matter by beginning with the elements, and it is impossible for me for this reason to affirm that I have even started from the same principle. But finally I have found that my answers in many cases do not differ from theirs.\" (cited by Edwards (2002)). Thus, Huygens learned about de M\u00e9r\u00e9's Problem in 1655 during his visit to France; later on in 1656 from his correspondence with Carcavi he learned that his method was essentially the same as Pascal's; so that before his book went to press in 1657 he knew about Pascal's priority in this subject.\nThree years later, in 1657, a Dutch mathematician Christiaan Huygens, who had just visited Paris, published a treatise (see Huygens (1657)) \"De ratiociniis in ludo ale\u00e6\" on probability theory. In this book he considered the problem of points and presented a solution based on the same principle as the solutions of Pascal and Fermat. Huygens also extended the concept of expectation by adding rules for how to calculate expectations in more complicated situations than the original problem (e.g., for three or more players). In this sense this book can be seen as the first successful attempt at laying down the foundations of the theory of probability.\nThe idea of the expected value originated in the middle of the 17th century from the study of the so-called problem of points, which seeks to divide the stakes in a fair way between two players who have to end their game before it's properly finished. This problem had been debated for centuries, and many conflicting proposals and solutions had been suggested over the years, when it was posed in 1654 to Blaise Pascal by French writer and amateur mathematician Chevalier de M\u00e9r\u00e9. de M\u00e9r\u00e9 claimed that this problem couldn't be solved and that it showed just how flawed mathematics was when it came to its application to the real world. Pascal, being a mathematician, was provoked and determined to solve the problem once and for all. He began to discuss the problem in a now famous series of letters to Pierre de Fermat. Soon enough they both independently came up with a solution. They solved the problem in different computational ways but their results were identical because their computations were based on the same fundamental principle. The principle is that the value of a future gain should be directly proportional to the chance of getting it. This principle seemed to have come naturally to both of them. They were very pleased by the fact that they had found essentially the same solution and this in turn made them absolutely convinced they had solved the problem conclusively. However, they did not publish their findings. They only informed a small circle of mutual scientific friends in Paris about it.[7]\nand\nand\nExpected values can also be used to compute the variance, by means of the computational formula for the variance\n In classical mechanics, the center of mass is an analogous concept to expectation. For example, suppose X is a discrete random variable with values xi and corresponding probabilities pi. Now consider a weightless rod on which are placed weights, at locations xi along the rod and having masses pi (whose sum is one). The point at which the rod balances is E[X].\nTo empirically estimate the expected value of a random variable, one repeatedly measures observations of the variable and computes the arithmetic mean of the results. If the expected value exists, this procedure estimates the true expected value in an unbiased manner and has the property of minimizing the sum of the squares of the residuals (the sum of the squared differences between the observations and the estimate). The law of large numbers demonstrates (under fairly mild conditions) that, as the size of the sample gets larger, the variance of this estimate gets smaller.\nThe expected values of the powers of X are called the moments of X; the moments about the mean of X are expected values of powers of X \u2212 E[X]. The moments of some random variables can be used to specify their distributions, via their moment generating functions.\nIt is possible to construct an expected value equal to the probability of an event by taking the expectation of an indicator function that is one if the event has occurred and zero otherwise. This relationship can be used to translate properties of expected values into properties of probabilities, e.g. using the law of large numbers to justify estimating probabilities by frequencies.\nwhere\nCorollary. Let\nFatou's lemma states that\nThe monotone convergence theorem states that\nCorollary.\nThe Cauchy\u2013Bunyakovsky\u2013Schwarz inequality states that\nBy finite additivity,\nand a random variable\nThe amount by which the multiplicativity fails is called the covariance:\nand\nNote that this result can also be proved based on Jensen's inequality.\nProof. By definition of Lebesgue integral,\nwhence the extremal property follows.\nThe properties below replicate or follow immediately from those of Lebesgue integral.\nRemark 4. For multidimensional random variables, their expected value is defined per component, i.e.\nRemark 3. An example of a distribution for which there is no expected value is Cauchy distribution.\nwhere the integral is interpreted in the sense of Lebesgue\u2013Stieltjes.\nThe following scenarios are possible:\nthen the values (whether finite or infinite) of both integrals agree.\nRemark 2. Due to absolute convergence, the expected value does not depend on the order in which the outcomes are presented. By contrast, a conditionally convergent series can be made to converge or diverge arbitrarily, via the Riemann rearrangement theorem.\nIn decision theory, and in particular in choice under uncertainty, an agent is described as making an optimal choice in the context of incomplete information. For risk neutral agents, the choice involves using the expected values of uncertain quantities, while for risk averse agents it involves maximizing the expected value of some objective function such as a von Neumann\u2013Morgenstern utility function. One example of using expected value in reaching optimal decisions is the Gordon\u2013Loeb model of information security investment. According to the model, one can conclude that the amount a firm spends to protect information should generally be only a small fraction of the expected loss (i.e., the expected value of the loss resulting from a cyber or information security breach).[4]\nThe expected value plays important roles in a variety of contexts. In regression analysis, one desires a formula in terms of observed data that will give a \"good\" estimate of the parameter giving the effect of some explanatory variable upon a dependent variable. The formula will give different estimates using different samples of data, so the estimate it gives is itself a random variable. A formula is typically considered good in this context if it is an unbiased estimator\u2014 that is if the expected value of the estimate (the average value it would give over an arbitrarily large number of separate samples) can be shown to equal the true value of the desired parameter.\nThe expected value is a key aspect of how one characterizes a probability distribution; it is one type of location parameter. By contrast, the variance is a measure of dispersion of the possible values of the random variable around the expected value. The variance itself is defined in terms of two expectations: it is the expected value of the squared deviation of the variable's value from the variable's expected value.\nThe expected value does not exist for random variables having some distributions with large \"tails\", such as the Cauchy distribution.[3]  For random variables such as these, the long-tails of the distribution prevent the sum or integral from converging.\nMore practically, the expected value of a discrete random variable is the probability-weighted average of all possible values. In other words, each possible value the random variable can assume is multiplied by its probability of occurring, and the resulting products are summed to produce the expected value. The same principle applies to an absolutely continuous random variable, except that an integral of the variable with respect to its probability density replaces the sum. The formal definition subsumes both of these and also works for distributions which are  neither discrete nor absolutely continuous; the expected value of a random variable is the integral of the random variable with respect to its probability measure.[1][2]\nIn probability theory, the expected value of a random variable, intuitively, is the long-run average value of repetitions of the experiment it represents. For example, the expected value in rolling a six-sided die is 3.5, because the average of all the numbers that come up in an extremely large number of rolls is close to 3.5. Less roughly, the law of large numbers states that the arithmetic mean of the values almost surely converges to the expected value as the number of repetitions approaches infinity. The expected value is also known as the expectation, mathematical expectation, EV, average, mean value, mean, or first moment.\n",
            "title": "Expected value",
            "url": "https://en.wikipedia.org/wiki/Expected_value"
        },
        {
            "desc_links": [
                "/wiki/Truth_value",
                "/wiki/Strike_action",
                "/wiki/Time_series_analysis",
                "/wiki/Econometrics",
                "/wiki/Mutually_exclusive_events",
                "/wiki/Regression_analysis",
                "/wiki/Econometrics",
                "/wiki/Statistics",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Coefficient",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Regression_analysis",
                "/wiki/Qualitative_data",
                "/wiki/Credit_score",
                "/wiki/Economic_forecasting",
                "/wiki/Time_series_analysis"
            ],
            "desc_text": "b'In statistics and econometrics, particularly in regression analysis, a dummy variable (also known as an indicator variable, design variable, Boolean indicator, binary variable, or qualitative variable[1][2]) is one that takes the value 0 or 1 to indicate the absence or presence of some categorical effect that may be expected to shift the outcome.[3][4] Dummy variables are used as devices to sort data into mutually exclusive categories (such as smoker/non-smoker, etc.).[2]  For example, in econometric time series analysis, dummy variables may be used to indicate the occurrence of wars or major strikes. A dummy variable can thus be thought of as a truth value represented as a numerical value 0 or 1 (as is sometimes done in computer programming).\\n'b'Dummy variables are \"proxy\" variables or numeric stand-ins for qualitative facts in a regression model. In regression analysis, the dependent variables may be influenced not only by quantitative variables (income, output, prices, etc.), but also by qualitative variables (gender, religion, geographic region, etc.). A dummy independent variable (also called a dummy explanatory variable) which for some observation has a value of 0 will cause that variable\\'s coefficient to have no role in influencing the dependent variable, while when the dummy takes on a value 1 its coefficient acts to alter the intercept. For example, suppose membership in a group is one of the qualitative variables relevant to a regression. If group membership is arbitrarily assigned the value of 1, then all others would get the value 0. Then the intercept (the value of the dependent variable if all other explanatory variables hypothetically took on the value zero) would be the constant term for non-members but would be the constant term plus the coefficient of the membership dummy in the case of group members.[1]\\n'b'Dummy variables are used frequently in time series analysis with regime switching, seasonal analysis and  qualitative data applications. Dummy variables are involved in studies for economic forecasting, bio-medical studies, credit scoring, response modelling, etc. Dummy variables may be incorporated in traditional regression methods or newly developed modeling paradigms.[1]\\n'",
            "links": [
                "/wiki/Truth_value",
                "/wiki/Strike_action",
                "/wiki/Time_series_analysis",
                "/wiki/Econometrics",
                "/wiki/Mutually_exclusive_events",
                "/wiki/Regression_analysis",
                "/wiki/Econometrics",
                "/wiki/Statistics",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Coefficient",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Regression_analysis",
                "/wiki/Qualitative_data",
                "/wiki/Credit_score",
                "/wiki/Economic_forecasting",
                "/wiki/Time_series_analysis",
                "/wiki/Mincer_earnings_function",
                "/wiki/Multicollinearity",
                "/wiki/Analysis_of_variance",
                "/wiki/Expected_value",
                "/wiki/Least_squares",
                "/wiki/P_value",
                "/wiki/T-statistic",
                "/wiki/Standard_error_(statistics)",
                "/wiki/Statistical_significance",
                "/wiki/Analysis_of_covariance",
                "/wiki/Interaction_(statistics)",
                "/wiki/Dichotomy",
                "/wiki/Polychotomy",
                "/wiki/Probit_model",
                "/wiki/Logistic_regression",
                "/wiki/Linear_probability_model",
                "/wiki/Least_squares",
                "/wiki/Linear_probability_model",
                "/wiki/Cumulative_distribution_function",
                "/wiki/Probit_model",
                "/wiki/Logistic_regression",
                "/wiki/Normal_distribution",
                "/wiki/Logistic_distribution"
            ],
            "text": "Another model that was developed to offset the disadvantages of the LPM is the probit model. The probit model uses the same approach to non-linearity as does the logit model; however, it uses the normal CDF instead of the logistic CDF.[8]\nThis relationship shows that Li is linear in relation to Xi, but the probabilities are not linear in terms of Xi.[9]\nThe shortcomings of the LPM led to the development of a more refined and improved model called the logit model. In the logit model, the cumulative distribution of the error term in the regression equation is logistic.[8] The regression is more realistic in that it is non-linear.\nTwo alternative CDFs can be used: the logistic and normal CDFs. The logistic CDF gives rise to the logit model and the normal CDF give rises to the probit model\n.[2]\nFor this purpose, a cumulative distribution function (CDF) can be used to estimate the dependent dummy variable regression. Figure 4 shows an 'S'-shaped curve, which resembles the CDF of a random variable. In this model, the probability is between 0 and 1 and the non-linearity has been captured. The choice of the CDF to be used is now the question.\nTo avoid the limitations of the LPM, what is needed is a model that has the feature that as the explanatory variable, Xi, increases, Pi = E (Yi = 1 | Xi) should remain within the range between 0 and 1. Thus the relationship between the independent and dependent variables is necessarily non-linear.\nSome problems are inherent in the LPM model:\nwhere\nAn ordinary least squares model in which the dependent variable Y is a dichotomous dummy, taking the values of 0 and 1, is the linear probability model (LPM).[8] Suppose we consider the following regression:\nAnalysis of dependent dummy variable models can be done through different methods. One such method is the usual OLS method, which in this context is called the linear probability model. An alternative method is to assume that there is an unobservable continuous latent variable Y* and that the observed dichotomous variable Y = 1 if Y* > 0, 0 otherwise. This is the underlying concept of the logit and probit models. These models are discussed in brief below.[8]\nWhen the qualitative dependent dummy variable has more than two values (such as affiliation to many political parties), it becomes a multiresponse or a multinomial or polychotomous model.[7]\nDecision: Retirement.      Dependent Dummy: Retired = 1 if retired, 0 if not retired.\nDecision: Affiliation to a Political Party.      Dependent Dummy: Affiliation = 1 if affiliated to the party, 0 if not affiliated.\nDecision: Choice of Occupation.      Dependent Dummy: Supervisory = 1 if supervisor, 0 if not supervisor.\nFor example, the decision of a worker to be a part of the labour force becomes a dummy dependent variable. The decision is dichotomous, i.e., the decision has two possible outcomes: yes and no. So the dependent dummy variable Participation would take on the value 1 if participating, 0 if not participating.[2] Some other examples of dichotomous dependent dummies are cited below:\nA model with a dummy dependent variable (also known as a qualitative dependent variable)  is one in which the dependent variable, as influenced by the explanatory variables, is qualitative in nature. Some decisions regarding 'how much' of an act must be performed involve a prior decision making on whether to perform the act or not. For example, the amount of output to produce, the cost to be incurred, etc. involve prior decisions on whether to produce or not, whether to spend or not, etc. Such \"prior decisions\" become dependent dummies in the regression model.[7]\nThen with zero shock term the value of the dependent variable is \u03b41+ \u03b1Xi for the base category unmarried males, \u03b41 + \u03b44+ \u03b1Xi for unmarried females, \u03b41 + \u03b45+ \u03b1Xi for married males, and \u03b41 + \u03b46+ \u03b1Xi for married females. This specification involves the same number of right-side variables as does the previous specification with an interaction term, and the regression results for the predicted value of the dependent variable contingent on Xi, for any combination of qualitative traits, are identical between this specification and the interaction specification.\nthen it suffices to specify the regression\nHowever, the use of products of dummy variables to capture interactions can be avoided by using a different scheme for categorizing the data\u2014one that specifies categories in terms of combinations of characteristics. If we let\nThus, an interaction dummy (product of two dummies) can alter the dependent variable from the value that it gets when the two dummies are considered individually.[2]\nBy this equation, in the absence of a non-zero error the wage of an unmarried male is \u03b21+ \u03b1Xi, that of an unmarried female is \u03b21+ \u03b22 + \u03b1Xi, that of being a married male is \u03b21+ \u03b23 + \u03b1Xi, and that of being a married female is \u03b21+\u03b22+ \u03b23 + \u03b24+ \u03b1Xi (where any of the estimates of the coefficients of the dummies could turn out to be positive, zero, or negative).\nHere,\nThis specification does not allow for the possibility that there may be an interaction that occurs between the two qualitative variables, D2 and D3. For example, a female who is married may earn wages that differ from those of an unmarried male by an amount that is not the same as the sum of the differentials for solely being female and solely being married. Then the effect of the interacting dummies on the mean of Y is not simply additive as in the case of the above specification, but multiplicative also, and the determination of wages can be specified as:\nwhere\nWith the two qualitative variables being gender and marital status and with the quantitative explanator being years of education, a regression that is purely linear in the explanators would be\nQuantitative regressors in regression models often have an interaction among each other. In the same way, qualitative regressors, or dummies, can also have interaction effects between each other, and these interactions can be depicted in the regression model. For example, in a regression involving determination of wages, if two qualitative variables are considered, namely, gender and marital status, there could be an interaction between marital status and gender.[5] These interactions can be shown in the regression equation as illustrated by the example below.\nThe result suggests that, for every $1 increase in State expenditure per pupil on public schools, a public school teacher's average salary goes up by about $3.29. Further, for a state in the North region, the mean salary of the teachers is lower than that of West region by about $1673 and for a state in the South region, the mean salary of teachers is lower than that of the West region by about $1144. Figure 3 depicts this model diagrammatically. The average salary lines are parallel to each other by the assumption of the model that the coefficient of expenditure does not vary by state. The trade off shown separately in the graph for each category is between the two quantitative variables: public school teachers' salaries (Y) in relation to State expenditure per pupil on public schools (X).[2]\nSay the regression output for this model is\nwhere,\nTo illustrate how qualitative and quantitative regressors are included to form ANCOVA models, suppose we consider the same example used in the ANOVA model with one qualitative variable: average annual salary of public school teachers in three geographical regions of Country A. If we include a quantitative variable, State Government expenditure on public schools per pupil, in this regression, we get the following model:\nA regression model that contains a mixture of both quantitative and qualitative variables is called an Analysis of Covariance (ANCOVA) model. ANCOVA models are extensions of ANOVA models. They statistically control for the effects of quantitative explanatory variables (also called covariates or control variables).[2]\nThus, if more than one qualitative variable is included in the regression, it is important to note that the omitted category should be chosen as the benchmark category and all comparisons will be made in relation to that category. The intercept term will show the expectation of the benchmark category and the slope coefficients will show by how much the other categories differ from the benchmark (omitted) category.[2]\nHere, the base group is the omitted category: Unmarried, Non-North region (Unmarried people who do not live in the North region). All comparisons would be made in relation to this base group or omitted category. The mean hourly wage in the base category is about $8.81 (intercept term). In comparison, the mean hourly wage of those who are married is higher by about $1.10 and is equal to about $9.91 ($8.81 + $1.10). In contrast, the mean hourly wage of those who live in the North is lower by about $1.67 and is about $7.14 ($8.81 \u2212 $1.67).\nIn this model, a single dummy is assigned to each qualitative variable, one less than the number of categories included in each.\nwhere,\nSay the regression output on the basis of some given data appears as follows:\nSuppose we consider an ANOVA model having two qualitative variables, each with two categories: Hourly Wages  are to be explained in terms of the qualitative variables Marital Status (Married / Unmarried) and Geographical Region (North / Non-North). Here, Marital Status and Geographical Region are the two explanatory dummy variables.[2]\nTo find out if the mean salaries of the teachers in the North and South are statistically different from that of the teachers in the West (the comparison category), we have to find out if the slope coefficients of the regression result are statistically significant. For this, we need to consider the p values. The estimated slope coefficient for the North is not statistically significant as its p value is 23 percent; however, that of the South is statistically significant at the 5% level as its p value is only around 3.5 percent. Thus the overall result is that the mean salaries of the teachers in the West and North are not statistically different from each other, but the mean salary of the teachers in the South is statistically lower than that in the West by around $3265. The model is diagrammatically shown in Figure 2. This model is an ANOVA model with one qualitative variable having 3 categories.[2]\nThe regression result can be interpreted as: The mean salary of the teachers in the West (base group) is about $26,158, the salary of the teachers in the North is lower by about $1734 ($26,158.62 \u2212 $1734.473 = $24,424.14, which is the average salary of the teachers in the North) and that of the teachers in the South is lower by about $3265 ($26,158.62 \u2212 $3264.615 = $22,894, which is the average salary of the teachers in the South).\nwhere, se = standard error, t = t-statistics, p = p value\nR2 = 0.0901\np  =             (0.0000)     (0.2330)                 (0.0349)\nt  =            (23.1759)    (\u22121.2078)                (\u22122.1776)\nse =           (1128.523)   (1435.953)               (1499.615)\nUsing the given data, the result of the regression would be:\nThe expected values can be interpreted as follows: The mean salary of public school teachers in the West is equal to the intercept term \u03b11 in the multiple regression equation and the differential intercept coefficients, \u03b12 and \u03b13, explain by how much the mean salaries of teachers in the North and South Regions vary from that of the teachers in the West. Thus, the mean salaries of teachers in the North and South is compared against the mean salary of the teachers in the West. Hence, the West Region becomes the base group or the benchmark group,i.e., the group against which the comparisons are made. The omitted category, i.e., the category to which no dummy is assigned, is taken as the base group category.\n(The error term does not get included in the expectation values as it is assumed that it satisfies the usual OLS conditions, i.e., E(ui) = 0)\nE(Yi|D2i = 0, D3i = 0) = \u03b11 \nMean salary of public school teachers in the West Region:\nE(Yi|D2i = 0, D3i = 1) = \u03b11 + \u03b13\nMean salary of public school teachers in the South Region:\nE(Yi|D2i = 1, D3i = 0) = \u03b11 + \u03b12\nMean salary of public school teachers in the North Region:\nNow, taking the expectation of both sides, we obtain the following:\nIn this model, we have only qualitative regressors, taking the value of 1 if the observation belongs to a specific category and 0 if it belongs to any other category. This makes it an ANOVA model.\nwhere\nSuppose we want to run a regression to find out if the average annual salary of public school teachers differs among three geographical regions in Country A with 51 states: (1) North (21 states) (2) South (17 states) (3) West (13 states). Say that the simple arithmetic average salaries are as follows: $24,424.14 (North), $22,894 (South), $26,158.62 (West). The arithmetic averages are different, but are they statistically different from each other? To compare the mean values, Analysis of Variance techniques can be used.\nThe regression model can be defined as:\nA regression model in which the dependent variable is quantitative in nature but all the explanatory variables are dummies (qualitative in nature) is called an Analysis of Variance (ANOVA) model.[2]\nThe constant term in all regression equations is a coefficient multiplied by a regressor equal to one. When the regression is expressed as a matrix equation, the matrix of regressors then consists of a column of ones (the constant term), vectors of zeros and ones (the dummies), and possibly other regressors. If one includes both male and female dummies, say, the sum of these vectors is a vector of ones, since every observation is categorized as either male or female. This sum is thus equal to the constant term's regressor, the first vector of ones. As result, the regression equation will be unsolvable, even by the typical pseudoinverse method. In other words: if both the vector-of-ones (constant term) regressor and an exhaustive set of dummies are present, perfect multicollinearity occurs,[6] and the system of equations formed by the regression does not have a unique solution. This is referred to as the dummy variable trap. The trap can be avoided by removing either the constant term or one of the offending dummies. The removed dummy then becomes the base category against which the other categories are compared.\nDummy variables are incorporated in the same way as quantitative variables are included (as explanatory variables) in regression models. For example, if we consider a Mincer-type regression model of wage determination, wherein wages are dependent on gender (qualitative) and years of education (quantitative):\nDummy variables are used frequently in time series analysis with regime switching, seasonal analysis and  qualitative data applications. Dummy variables are involved in studies for economic forecasting, bio-medical studies, credit scoring, response modelling, etc. Dummy variables may be incorporated in traditional regression methods or newly developed modeling paradigms.[1]\nDummy variables are \"proxy\" variables or numeric stand-ins for qualitative facts in a regression model. In regression analysis, the dependent variables may be influenced not only by quantitative variables (income, output, prices, etc.), but also by qualitative variables (gender, religion, geographic region, etc.). A dummy independent variable (also called a dummy explanatory variable) which for some observation has a value of 0 will cause that variable's coefficient to have no role in influencing the dependent variable, while when the dummy takes on a value 1 its coefficient acts to alter the intercept. For example, suppose membership in a group is one of the qualitative variables relevant to a regression. If group membership is arbitrarily assigned the value of 1, then all others would get the value 0. Then the intercept (the value of the dependent variable if all other explanatory variables hypothetically took on the value zero) would be the constant term for non-members but would be the constant term plus the coefficient of the membership dummy in the case of group members.[1]\nIn statistics and econometrics, particularly in regression analysis, a dummy variable (also known as an indicator variable, design variable, Boolean indicator, binary variable, or qualitative variable[1][2]) is one that takes the value 0 or 1 to indicate the absence or presence of some categorical effect that may be expected to shift the outcome.[3][4] Dummy variables are used as devices to sort data into mutually exclusive categories (such as smoker/non-smoker, etc.).[2]  For example, in econometric time series analysis, dummy variables may be used to indicate the occurrence of wars or major strikes. A dummy variable can thus be thought of as a truth value represented as a numerical value 0 or 1 (as is sometimes done in computer programming).\n",
            "title": "Dummy variable (statistics)",
            "url": "https://en.wikipedia.org/wiki/Dummy_variable_(statistics)"
        },
        {
            "desc_links": [
                "/wiki/Line_segment",
                "/wiki/Vector_algebra",
                "/wiki/Direction_(geometry)",
                "/wiki/Euclidean_norm",
                "/wiki/Magnitude_(mathematics)",
                "/wiki/Engineering",
                "/wiki/Physics",
                "/wiki/Mathematics",
                "/wiki/Vector_space",
                "/wiki/Euclidean_space",
                "/wiki/Distributivity",
                "/wiki/Associativity",
                "/wiki/Commutativity",
                "/wiki/Additive_inverse",
                "/wiki/Multiplication",
                "/wiki/Subtraction",
                "/wiki/Addition",
                "/wiki/Real_number",
                "/wiki/Algebraic_operation",
                "/wiki/Tensor",
                "/wiki/Pseudovector",
                "/wiki/Coordinate_system",
                "/wiki/Displacement_(vector)",
                "/wiki/Position_(vector)",
                "/wiki/Force",
                "/wiki/Acceleration",
                "/wiki/Velocity",
                "/wiki/Physics"
            ],
            "desc_text": "b'In mathematics, physics, and engineering, a Euclidean vector (sometimes called a geometric[1] or spatial vector,[2] or\\xe2\\x80\\x94as here\\xe2\\x80\\x94simply a vector) is a geometric object that has magnitude (or length) and direction. Vectors can be added to other vectors according to vector algebra. A Euclidean vector is frequently represented by a line segment with a definite direction, or graphically as an arrow, connecting an initial point A with a terminal point B,[3] and denoted by \\n  \\n    \\n      \\n        \\n          \\n            \\n              A\\n              B\\n            \\n            \\xe2\\x86\\x92\\n          \\n        \\n        .\\n      \\n    \\n    {\\\\displaystyle {\\\\overrightarrow {AB}}.}\\n  \\n\\n'b'A vector is what is needed to \"carry\" the point A to the point B; the Latin word vector means \"carrier\".[4] It was first used by 18th century astronomers investigating planet rotation around the Sun.[5]  The magnitude of the vector is the distance between the two points and the direction refers to the direction of displacement from A to B. Many algebraic operations on real numbers such as addition, subtraction, multiplication, and negation have close analogues for vectors, operations which obey the familiar algebraic laws of commutativity, associativity, and distributivity. These operations and associated laws qualify Euclidean vectors as an example of the more generalized concept of vectors defined simply as elements of a vector space.\\n'b'Vectors play an important role in physics: the velocity and acceleration of a moving object and the forces acting on it can all be described with vectors. Many other physical quantities can be usefully thought of as vectors. Although most of them do not represent distances (except, for example, position or displacement), their magnitude and direction can still be represented by the length and direction of an arrow. The mathematical representation of a physical vector depends on the coordinate system used to describe it. Other vector-like objects that describe physical quantities and transform in a similar way under changes of the coordinate system include pseudovectors and tensors.\\n'",
            "links": [
                "/wiki/Vector_space",
                "/wiki/Euclidean_space",
                "/wiki/Distributivity",
                "/wiki/Associativity",
                "/wiki/Commutativity",
                "/wiki/Additive_inverse",
                "/wiki/Multiplication",
                "/wiki/Subtraction",
                "/wiki/Addition",
                "/wiki/Real_number",
                "/wiki/Algebraic_operation",
                "/wiki/Tensor",
                "/wiki/Pseudovector",
                "/wiki/Coordinate_system",
                "/wiki/Displacement_(vector)",
                "/wiki/Position_(vector)",
                "/wiki/Force",
                "/wiki/Acceleration",
                "/wiki/Velocity",
                "/wiki/Physics",
                "/wiki/Equivalence_relation",
                "/wiki/Equipollence_(geometry)",
                "/wiki/Giusto_Bellavitis",
                "/wiki/Real_line",
                "/wiki/Imaginary_unit",
                "/wiki/Complex_number",
                "/wiki/Equivalence_class",
                "/wiki/Real_number",
                "/wiki/Quaternion",
                "/wiki/William_Rowan_Hamilton",
                "/wiki/Matthew_O%27Brien_(mathematician)",
                "/wiki/Comte_de_Saint-Venant",
                "/wiki/August_M%C3%B6bius",
                "/wiki/Hermann_Grassmann",
                "/wiki/Augustin_Cauchy",
                "/wiki/Del",
                "/wiki/Peter_Guthrie_Tait",
                "/wiki/Cross_product",
                "/wiki/Dot_product",
                "/wiki/William_Kingdon_Clifford",
                "/wiki/Elements_of_Dynamic",
                "/wiki/Vector_Analysis",
                "/wiki/Edwin_Bidwell_Wilson",
                "/wiki/James_Clerk_Maxwell",
                "/wiki/Josiah_Willard_Gibbs",
                "/wiki/Euclidean_space",
                "/wiki/Vector_space",
                "/wiki/Pure_mathematics",
                "/wiki/Euclidean_space",
                "/wiki/Line_segment",
                "/wiki/Magnitude_(mathematics)",
                "/wiki/Engineering",
                "/wiki/Physics",
                "/wiki/Meter_(unit)",
                "/wiki/Axis_(mathematics)",
                "/wiki/Newton_(unit)",
                "/wiki/Force_(physics)",
                "/wiki/Vector_field",
                "/wiki/Magnetic_field",
                "/wiki/Electric_field",
                "/wiki/Angular_momentum",
                "/wiki/Linear_momentum",
                "/wiki/Angular_acceleration",
                "/wiki/Displacement_(vector)",
                "/wiki/Force",
                "/wiki/Speed",
                "/wiki/Velocity",
                "/wiki/Parallelepiped#Parallelotope",
                "/wiki/Exterior_product",
                "/wiki/Parallelogram",
                "/wiki/Orientation_(geometry)",
                "/wiki/Area",
                "/wiki/Cross_product",
                "/wiki/Dot_product",
                "/wiki/Thermodynamics",
                "/wiki/Special_relativity",
                "/wiki/Minkowski_space",
                "/wiki/Affine_space",
                "/wiki/Vector_space",
                "/wiki/Tensor",
                "/wiki/Tensor",
                "/wiki/Covariance_and_contravariance_of_vectors",
                "/wiki/Kelvin",
                "/wiki/Gradient",
                "/wiki/Basis_vector",
                "/wiki/Tuple",
                "/wiki/Coordinate_vector",
                "/wiki/Field_(mathematics)",
                "/wiki/Vector_space",
                "/wiki/Mathematics",
                "/wiki/Magnitude_(mathematics)",
                "/wiki/Line_segment",
                "/wiki/Arrow_(weapon)",
                "/wiki/Plane_(mathematics)",
                "/wiki/Perpendicular",
                "/wiki/Scalar_component",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Cartesian_coordinate",
                "/wiki/Tuple",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Coordinate_vector",
                "/wiki/Matrix_(mathematics)",
                "/wiki/Row_vector",
                "/wiki/Column_vector",
                "/wiki/Standard_basis",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Scalar_component",
                "/wiki/Vector_component",
                "/wiki/Summation_convention",
                "/wiki/Index_notation",
                "/wiki/Vector_projection",
                "/wiki/Euclidean_vector#Representations",
                "/wiki/Perpendicular",
                "/wiki/Parallel_(geometry)",
                "/wiki/Rotation",
                "/wiki/Radius",
                "/wiki/Tangential_component",
                "/wiki/Orientation_(geometry)",
                "/wiki/Inertial_reference_frame",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Parallelogram",
                "/wiki/Vector_analysis",
                "/wiki/Real_number",
                "/wiki/Distributivity",
                "/wiki/Absolute_value",
                "/wiki/Norm_(mathematics)",
                "/wiki/Magnitude_(mathematics)",
                "/wiki/Length",
                "/wiki/Euclidean_norm",
                "/wiki/Pythagorean_theorem",
                "/wiki/Dot_product",
                "/wiki/Inner_product_space",
                "/wiki/Trigonometric_function",
                "/wiki/Angle",
                "/wiki/Seven-dimensional_cross_product",
                "/wiki/Right-hand_rule",
                "/wiki/Perpendicular",
                "/wiki/Right-hand_rule",
                "/wiki/Orthogonal",
                "/wiki/Pseudovector",
                "/wiki/Linear_independence",
                "/wiki/Parallelepiped",
                "/wiki/Matrix_(mathematics)",
                "/wiki/Determinant",
                "/wiki/Direction_cosine_matrix",
                "/wiki/Cosine",
                "/wiki/Direction_cosine#Cartesian_coordinates",
                "/wiki/Matrix_transpose",
                "/wiki/Matrix_inverse",
                "/wiki/Rotation_matrix",
                "/wiki/Rotation_matrix",
                "/wiki/Transformation_matrix",
                "/wiki/Quaternion",
                "/wiki/Euler_angles",
                "/wiki/Pseudoscalar",
                "/wiki/Bivector",
                "/wiki/Exterior_algebra#Areas_in_the_plane",
                "/wiki/Seven-dimensional_cross_product",
                "/wiki/Proportionality_constant",
                "/wiki/Dimensional_analysis",
                "/wiki/Scale_(measurement)",
                "/wiki/Dimensionless_number",
                "/wiki/Calculus",
                "/wiki/Integral",
                "/wiki/Derivative",
                "/wiki/Parametric_equation",
                "/wiki/Position_vector",
                "/wiki/Length",
                "/wiki/Displacement_(vector)",
                "/wiki/Speed",
                "/wiki/Velocity",
                "/wiki/Euclidean_vector#Ordinary_derivative",
                "/wiki/Euclidean_vector#Ordinary_derivative",
                "/wiki/Acceleration",
                "/wiki/Newton%27s_second_law",
                "/wiki/Force",
                "/wiki/Displacement_(vector)",
                "/wiki/Force",
                "/wiki/Chain_rule",
                "/wiki/Tangent_space",
                "/wiki/Covariance_and_contravariance_of_vectors",
                "/wiki/Tensor",
                "/wiki/Differential_geometry",
                "/wiki/Cross_product",
                "/wiki/Pseudovector",
                "/wiki/Orientation_(mathematics)",
                "/wiki/Torque",
                "/wiki/Magnetic_field",
                "/wiki/Wheel",
                "/wiki/Car",
                "/wiki/Angular_velocity",
                "/wiki/Parity_(physics)",
                "/wiki/Symmetry"
            ],
            "text": "This distinction between vectors and pseudovectors is often ignored, but it becomes important in studying symmetry properties. See parity (physics).\nOne example of a pseudovector is angular velocity. Driving in a car, and looking forward, each of the wheels has an angular velocity vector pointing to the left. If the world is reflected in a mirror which switches the left and right side of the car, the reflection of this angular velocity vector points to the right, but the actual angular velocity vector of the wheel still points to the left, corresponding to the minus sign. Other examples of pseudovectors include magnetic field, torque, or more generally any cross product of two (true) vectors.\nSome vectors transform like contravariant vectors, except that when they are reflected through a mirror, they flip and gain a minus sign. A transformation that switches right-handedness to left-handedness and vice versa like a mirror does is said to change the orientation of space. A vector which gains a minus sign when the orientation of space changes is called a pseudovector or an axial vector. Ordinary vectors are sometimes called true vectors or polar vectors to distinguish them from pseudovectors. Pseudovectors occur most frequently as the cross product of two ordinary vectors.\nIn the language of differential geometry, the requirement that the components of a vector transform according to the same matrix of the coordinate transition is equivalent to defining a contravariant vector to be a tensor of contravariant rank one. Alternatively, a contravariant vector is defined to be a tangent vector, and the rules for transforming a contravariant vector follow from the chain rule.\nTherefore, any directional derivative can be identified with a corresponding vector, and any vector can be identified with a corresponding directional derivative. A vector can therefore be defined precisely as\nWork is the dot product of force and displacement\nForce is a vector with dimensions of mass\u00d7length/time2 and Newton's second law is the scalar multiplication\nAcceleration a of a point is vector which is the time derivative of velocity. Its dimensions are length/time2.\nwhere x0 is the position at time t = 0. Velocity is the time derivative of position. Its dimensions are length/time.\nThe velocity v of a point or particle is a vector, its length gives the speed. For constant velocity the position at time t will be\nwhich specifies the position of y relative to x. The length of this vector gives the straight-line distance from x to y. Displacement has the dimensions of length.\nGiven two points x = (x1, x2, x3), y = (y1, y2, y3) their displacement is a vector\nThe position vector has dimensions of length.\nThe position of a point x = (x1, x2, x3) in three-dimensional space can be represented as a position vector whose base point is the origin\nOften in areas of physics and mathematics, a vector evolves in time, meaning that it depends on a time parameter t. For instance, if r represents the position vector of a particle, then r(t) gives a parametric representation of the trajectory of the particle. Vector-valued functions can be differentiated and integrated by differentiating or integrating the components of the vector, and many of the familiar rules from calculus continue to hold for the derivative and integral of vector-valued functions.\nIn abstract vector spaces, the length of the arrow depends on a dimensionless scale. If it represents, for example, a force, the \"scale\" is of physical dimension length/force. Thus there is typically consistency in scale among quantities of the same dimension, but otherwise scale ratios may vary; for example, if \"1 newton\" and \"5 m\" are both represented with an arrow of 2 cm, the scales are 1 m:50 N and 1:250 respectively. Equal length of vectors of different dimension has no particular significance unless there is some proportionality constant inherent in the system that the diagram represents. Also length of a unit vector (of dimension length, not length/force, etc.) has no coordinate-system-invariant significance.\nVectors have many uses in physics and other sciences.\nA seven-dimensional cross product is similar to the cross product in that its result is a vector orthogonal to the two arguments; there is however no natural way of selecting one of the possible such products.\nThe cross product does not readily generalise to other dimensions, though the closely related exterior product does, whose result is a bivector. In two dimensions this is simply a pseudoscalar\nand in four dimensions as\nWith the exception of the cross and triple products, the above formulae generalise to two dimensions and higher dimensions. For example, addition generalises to two dimensions as\nBy applying several matrix multiplications in succession, any vector can be expressed in any basis so long as the set of direction cosines is known relating the successive bases.[13]\nThe advantage of this method is that a direction cosine matrix can usually be obtained independently by using Euler angles or a quaternion to relate the two vector bases, so the basis conversions can be performed directly, without having to work out all the dot products described above.\nThe properties of a direction cosine matrix, C are[14]:\nBy referring collectively to e1, e2, e3 as the e basis and to n1, n2, n3 as the n basis, the matrix containing all the cjk is known as the \"transformation matrix from e to n\", or the \"rotation matrix from e to n\" (because it can be imagined as the \"rotation\" of a vector from one basis to another), or the \"direction cosine matrix from e to n\"[13] (because it contains direction cosines).  The properties of a rotation matrix are such that its inverse is equal to its transpose. This means that the \"rotation matrix from e to n\" is the transpose of \"rotation matrix from n to e\".\nThis matrix equation relates the scalar components of a in the n basis (u,v, and w) with those in the e basis (p, q, and r).  Each matrix element cjk is the direction cosine relating nj to ek.[13] The term direction cosine refers to the cosine of the angle between two unit vectors, which is also equal to their dot product.[13] Therefore,\nand these equations can be expressed as the single matrix equation\nReplacing each dot product with a unique scalar gives\nDistributing the dot-multiplication gives\nThe values of p, q, r, and u, v, w relate to the unit vectors in such a way that the resulting vector sum is exactly the same physical vector a in both cases.  It is common to encounter vectors known in terms of different bases (for example, one basis fixed to the Earth and a second basis fixed to a moving vehicle).  In such a case it is necessary to develop a method to convert between bases so the basic vector operations such as addition and subtraction can be performed.  One way to express u, v, w in terms of p, q, r is to use column matrices along with a direction cosine matrix containing the information that relates the two bases.  Such an expression can be formed by substitution of the above equations to form\nand the scalar components in the n basis are, by definition,\nIn another orthnormal basis n = {n1, n2, n3} that is not necessarily aligned with e, the vector a is expressed as\nThe scalar components in the e basis are, by definition,\nAll examples thus far have dealt with vectors expressed in terms of the same basis, namely, the e basis {e1, e2, e3}. However, a vector can be expressed in terms of any number of different bases that are not necessarily aligned with each other, and still remain the same vector.  In the e basis, a vector a is expressed, by definition, as\nThe scalar triple product is linear in all three entries and anti-symmetric in the following sense:\nIn components (with respect to a right-handed orthonormal basis), if the three vectors are thought of as rows (or columns, but in the same order), the scalar triple product is simply the determinant of the 3-by-3 matrix having the three vectors as rows\nIt has three primary uses. First, the absolute value of the box product is the volume of the parallelepiped which has edges that are defined by the three vectors. Second, the scalar triple product is zero if and only if the three vectors are linearly dependent, which can be easily proved by considering that in order for the three vectors to not make a volume, they must all lie in the same plane. Third, the box product is positive if and only if the three vectors a, b and c are right-handed.\nThe scalar triple product (also called the box product or mixed triple product) is not really a new operator, but a way of applying the other two multiplication operators to three vectors. The scalar triple product is sometimes denoted by (a b c) and defined as:\nFor arbitrary choices of spatial orientation (that is, allowing for left-handed as well as right-handed coordinate systems) the cross product of two vectors is a pseudovector instead of a vector (see below).\nThe cross product can be written as\nThe length of a\u00a0\u00d7\u00a0b can be interpreted as the area of the parallelogram having a and b as sides.\nThe cross product a\u00a0\u00d7\u00a0b is defined so that a, b, and a\u00a0\u00d7\u00a0b also becomes a right-handed system (but note that a and b are not necessarily orthogonal). This is the right-hand rule.\nwhere \u03b8 is the measure of the angle between a and b, and n is a unit vector perpendicular to both a and b which completes a right-handed system. The right-handedness constraint is necessary because there exist two unit vectors that are perpendicular to both a and b, namely, n and (\u2013n).\nThe cross product (also called the vector product or outer product) is only meaningful in three or seven dimensions. The cross product differs from the dot product primarily in that the result of the cross product of two vectors is a vector. The cross product, denoted a\u00a0\u00d7\u00a0b, is a vector perpendicular to both a and b and is defined as\nThe dot product can also be defined as the sum of the products of the components of each vector as\nwhere \u03b8 is the measure of the angle between a and b (see trigonometric function for an explanation of cosine). Geometrically, this means that a and b are drawn with a common start point and then the length of a is multiplied with the length of the component of b that points in the same direction as a.\nThe dot product of two vectors a and b (sometimes called the inner product, or, since its result is a scalar, the scalar product) is denoted by a\u00a0\u2219\u00a0b and is defined as:\nTo normalize a vector a = (a1, a2, a3), scale the vector by the reciprocal of its length \u2016a\u2016. That is:\nA unit vector is any vector with a length of one; normally unit vectors are used simply to indicate direction. A vector of arbitrary length can be divided by its length to create a unit vector. This is known as normalizing a vector. A unit vector is often indicated with a hat as in \u00e2.\nThis happens to be equal to the square root of the dot product, discussed below, of the vector with itself:\nwhich is a consequence of the Pythagorean theorem since the basis vectors e1, e2, e3 are orthogonal unit vectors.\nThe length of the vector a can be computed with the Euclidean norm\nThe length or magnitude or norm of the vector a is denoted by \u2016a\u2016 or, less commonly, |a|, which is not to be confused with the absolute value (a scalar \"norm\").\nScalar multiplication is distributive over vector addition in the following sense: r(a + b) = ra + rb for all vectors a and b and all scalars r. One can also show that a \u2212 b = a + (\u22121)b.\nIf r is negative, then the vector changes direction: it flips around by an angle of 180\u00b0. Two examples (r = \u22121 and r = 2) are given below:\nIntuitively, multiplying by a scalar r stretches a vector out by a factor of r. Geometrically, this can be visualized (at least in the case when r is an integer) as placing r copies of the vector in a line where the endpoint of one vector is the initial point of the next vector.\nA vector may also be multiplied, or re-scaled, by a real number r. In the context of conventional vector algebra, these real numbers are often called scalars (from scale) to distinguish them from vectors. The operation of multiplying a vector by a scalar is called scalar multiplication. The resulting vector is\nSubtraction of two vectors can be geometrically defined as follows: to subtract b from a, place the tails of a and b at the same point, and then draw an arrow from the head of b to the head of a. This new arrow represents the vector a \u2212 b, as illustrated below:\nThe difference of a and b is\nThis addition method is sometimes called the parallelogram rule because a and b form the sides of a parallelogram and a + b is one of the diagonals. If a and b are bound vectors that have the same base point, this point will also be the base point of a + b. One can check geometrically that a + b = b + a and (a + b) + c = a + (b + c).\nThe addition may be represented graphically by placing the tail of the arrow b at the head of the arrow a, and then drawing an arrow from the tail of a to the head of b. The new arrow drawn represents the vector a + b, as illustrated below:\nAssume now that a and b are not necessarily equal vectors, but that they may have different magnitudes and directions. The sum of a and b is\nTwo vectors are parallel if they have the same direction but not necessarily the same magnitude, or antiparallel if they have opposite direction but not necessarily the same magnitude.\nare opposite if\nand\nTwo vectors are opposite if they have the same magnitude but opposite direction.  So two vectors\nare equal if\nand\nTwo vectors are said to be equal if they have the same magnitude and direction. Equivalently they will be equal if their coordinates are equal. So two vectors\nand assumes that all vectors have the origin as a common base point. A vector a will be written as\nThe following section uses the Cartesian coordinate system with basis vectors\nIn these cases, each of the components may be in turn decomposed with respect to a fixed coordinate system or basis set (e.g., a global coordinate system, or inertial reference frame).\nA vector can also be broken up with respect to \"non-fixed\" basis vectors that change their orientation as a function of time or space. For example, a vector in three-dimensional space can be decomposed with respect to two axes, respectively normal, and tangent to a surface (see figure). Moreover, the radial and tangential components of a vector relate to the radius of rotation of an object. The former is parallel to the radius and the latter is orthogonal to it.[12]\nThe choice of a basis does not affect the properties of a vector or its behaviour under transformations.\nThe decomposition or resolution[11] of a vector into components is not unique, because it depends on the choice of the axes on which the vector is projected.\nAs explained above a vector is often described by a set of vector components that add up to form the given vector. Typically, these components are the projections of the vector on a set of mutually perpendicular reference axes (basis vectors). The vector is said to be decomposed or resolved with respect to that set.\nThe notation ei is compatible with the index notation and the summation convention commonly used in higher level mathematics, physics, and engineering.\nwhere a1, a2, a3 are called the vector components (or vector projections) of a on the basis vectors or, equivalently, on the corresponding Cartesian axes x, y, and z (see figure), while a1, a2, a3 are the respective scalar components (or scalar projections).\nor\nThese have the intuitive interpretation as vectors of unit length pointing up the x-, y-, and z-axis of a Cartesian coordinate system, respectively. In terms of these, any vector a in R3 can be expressed in the form:\nAnother way to represent a vector in n-dimensions is to introduce the standard basis vectors. For instance, in three dimensions, there are three of them:\nThese numbers are often arranged into a column vector or row vector, particularly when dealing with matrices, as follows:\nThis can be generalised to n-dimensional Euclidean space (or Rn).\nIn three dimensional Euclidean space (or R3), vectors are identified with triples of scalar components:\nAs an example in two dimensions (see figure), the vector from the origin O = (0, 0) to the point A = (2, 3) is simply written as\nIn order to calculate with vectors, the graphical representation may be too cumbersome. Vectors in an n-dimensional Euclidean space can be represented as coordinate vectors in a Cartesian coordinate system. The endpoint of a vector can be identified with an ordered list of n real numbers (n-tuple). These numbers are the coordinates of the endpoint of the vector, with respect to a given Cartesian coordinate system, and are typically called the scalar components (or scalar projections) of the vector on the axes of the coordinate system.\nOn a two-dimensional diagram, sometimes a vector perpendicular to the plane of the diagram is desired. These vectors are commonly shown as small circles. A circle with a dot at its centre (Unicode U+2299 \u2299) indicates a vector pointing out of the front of the diagram, toward the viewer. A circle with a cross inscribed in it (Unicode U+2297 \u2297) indicates a vector pointing into and behind the diagram. These can be thought of as viewing the tip of an arrow head on and viewing the flights of an arrow from the back.\nVectors are usually shown in graphs or other diagrams as arrows (directed line segments), as illustrated in the figure. Here the point A is called the origin, tail, base, or initial point; point B is called the head, tip, endpoint, terminal point or final point. The length of the arrow is proportional to the vector's magnitude, while the direction in which the arrow points indicates the vector's direction.\nIn pure mathematics, a vector is any element of a vector space over some field and is often represented as a coordinate vector. The vectors described in this article are a very special case of this general definition because they are contravariant with respect to the ambient space. Contravariance captures the physical intuition behind the idea that a vector has \"magnitude and direction\".\nIn physics, as well as mathematics, a vector is often identified with a tuple of components, or list of numbers, that act as scalar coefficients for a set of basis vectors. When the basis is transformed, for example by rotation or stretching, then the components of any vector in terms of that basis also transform in an opposite sense. The vector itself has not changed, but the basis has, so the components of the vector must change to compensate. The vector is called covariant or contravariant depending on how the transformation of the vector's components is related to the transformation of the basis. In general, contravariant vectors are \"regular vectors\" with units of distance (such as a displacement) or distance times some other unit (such as velocity or acceleration); covariant vectors, on the other hand, have units of one-over-distance such as gradient. If you change units (a special case of a change of basis) from meters to millimeters, a scale factor of 1/1000, a displacement of 1\u00a0m becomes 1000\u00a0mm\u2014a contravariant change in numerical value. In contrast, a gradient of 1\u00a0K/m becomes 0.001\u00a0K/mm\u2014a covariant change in value. See covariance and contravariance of vectors. Tensors are another type of quantity that behave in this way; a vector is one type of tensor.\nHowever, it is not always possible or desirable to define the length of a vector in a natural way. This more general type of spatial vector is the subject of vector spaces (for free vectors) and affine spaces (for bound vectors, as each represented by an ordered pair of \"points\"). An important example is Minkowski space that is important to our understanding of special relativity, where there is a generalization of length that permits non-zero vectors to have zero length. Other physical examples come from thermodynamics, where many of the quantities of interest can be considered vectors in a space with no notion of length or angle.[10]\nIn the geometrical and physical settings, sometimes it is possible to associate, in a natural way, a length or magnitude and a direction to vectors. In addition, the notion of direction is strictly associated with the notion of an angle between two vectors. If the dot product of two vectors is defined\u2014a scalar-valued product of two vectors\u2014then it is also possible to define a length; the dot product gives a convenient algebraic characterization of both angle (a function of the dot product between any two non-zero vectors) and length (the square root of the dot product of a vector by itself). In three dimensions, it is further possible to define the cross product, which supplies an algebraic characterization of the area and orientation in space of the parallelogram defined by two vectors (used as sides of the parallelogram). In any dimension (and, in particular, higher dimensions), it's possible to define the exterior product, which (among other things) supplies an algebraic characterization of the area and orientation in space of the n-dimensional parallelotope defined by n vectors.\nThis coordinate representation of free vectors allows their algebraic features to be expressed in a convenient numerical fashion. For example, the sum of the two (free) vectors (1, 2, 3) and (\u22122, 0, 4) is the (free) vector\nIn Cartesian coordinates a free vector may be thought of in terms of a corresponding bound vector, in this sense, whose initial point has the coordinates of the origin O = (0, 0, 0). It is then determined by the coordinates of that bound vector's terminal point. Thus the free vector represented by (1, 0, 0) is a vector of unit length pointing along the direction of the positive x-axis.\nVectors are fundamental in the physical sciences. They can be used to represent any quantity that has magnitude, has direction, and which adheres to the rules of vector addition. An example is velocity, the magnitude of which is speed. For example, the velocity 5 meters per second upward could be represented by the vector (0, 5) (in 2 dimensions with the positive y-axis as 'up'). Another quantity represented by a vector is force, since it has a magnitude and direction and follows the rules of vector addition. Vectors also describe many other physical quantities, such as linear displacement, displacement, linear acceleration, angular acceleration, linear momentum, and angular momentum. Other physical vectors, such as the electric and magnetic field, are represented as a system of vectors at each point of a physical space; that is, a vector field. Examples of quantities that have magnitude and direction but fail to follow the rules of vector addition are angular displacement and electric current. Consequently, these are not vectors.\nSince the physicist's concept of force has a direction and a magnitude, it may be seen as a vector. As an example, consider a rightward force F of 15 newtons. If the positive axis is also directed rightward, then F is represented by the vector 15 N, and if positive points leftward, then the vector for F is \u221215 N. In either case, the magnitude of the vector is 15 N. Likewise, the vector representation of a displacement \u0394s of 4 meters would be 4 m or \u22124 m, depending on its direction, and its magnitude would be 4 m regardless.\nThe term vector also has generalizations to higher dimensions and to more formal approaches with much wider applications.\nThis article is about vectors strictly defined as arrows in Euclidean space. When it becomes necessary to distinguish these special vectors from vectors as defined in pure mathematics, they are sometimes referred to as geometric, spatial, or Euclidean vectors.\nIn physics and engineering, a vector is typically regarded as a geometric entity characterized by a magnitude and a direction. It is formally defined as a directed line segment, or arrow, in a Euclidean space.[8] In pure mathematics, a vector is defined more generally as any element of a vector space. In this context, vectors are abstract entities which may or may not be characterized by a magnitude and a direction. This generalized definition implies that the above-mentioned geometric entities are a special kind of vectors, as they are elements of a special kind of vector space called Euclidean space.\nJosiah Willard Gibbs, who was exposed to quaternions through James Clerk Maxwell's Treatise on Electricity and Magnetism, separated off their vector part for independent treatment. The first half of Gibbs's Elements of Vector Analysis, published in 1881, presents what is essentially the modern system of vector analysis.[6] In 1901 Edwin Bidwell Wilson published Vector Analysis, adapted from Gibb's lectures, which banished any mention of quaternions in the development of vector calculus.\nIn 1878 Elements of Dynamic was published by William Kingdon Clifford. Clifford simplified the quaternion study by isolating the dot product and cross product of two vectors from the complete quaternion product. This approach made vector calculations available to engineers and others working in three dimensions and skeptical of the fourth.\nPeter Guthrie Tait carried the quaternion standard after Hamilton. His 1867 Elementary Treatise of Quaternions included extensive treatment of the nabla or del operator \u2207.\nSeveral other mathematicians developed vector-like systems in the middle of the nineteenth century,  including Augustin Cauchy, Hermann Grassmann, August M\u00f6bius, Comte de Saint-Venant, and Matthew O'Brien. Grassmann's 1840 work Theorie der Ebbe und Flut (Theory of the Ebb and Flow) was the first system of spatial analysis similar to today's system and had ideas corresponding to the cross product, scalar product and vector differentiation. Grassmann's work was largely neglected until the 1870s.[6]\nThe term vector was introduced by William Rowan Hamilton as part of a quaternion, which is a sum q = s + v of a Real number s (also called scalar) and a 3-dimensional vector. Like Bellavitis, Hamilton viewed vectors as representative of classes of equipollent directed segments. As complex numbers use an imaginary unit to complement the real line, Hamilton considered the vector v to be the imaginary part of a quaternion:\nGiusto Bellavitis abstracted the basic idea in 1835 when he established the concept of equipollence. Working in a Euclidean plane, he made equipollent any pair of line segments of the same length and orientation. Essentially he realized an equivalence relation on the pairs of points (bipoints) in the plane and thus erected the first space of vectors in the plane.[6]:52\u20134\nThe concept of vector, as we know it today, evolved gradually over a period of more than 200 years. About a dozen people made significant contributions.[6]\nVectors play an important role in physics: the velocity and acceleration of a moving object and the forces acting on it can all be described with vectors. Many other physical quantities can be usefully thought of as vectors. Although most of them do not represent distances (except, for example, position or displacement), their magnitude and direction can still be represented by the length and direction of an arrow. The mathematical representation of a physical vector depends on the coordinate system used to describe it. Other vector-like objects that describe physical quantities and transform in a similar way under changes of the coordinate system include pseudovectors and tensors.\nA vector is what is needed to \"carry\" the point A to the point B; the Latin word vector means \"carrier\".[4] It was first used by 18th century astronomers investigating planet rotation around the Sun.[5]  The magnitude of the vector is the distance between the two points and the direction refers to the direction of displacement from A to B. Many algebraic operations on real numbers such as addition, subtraction, multiplication, and negation have close analogues for vectors, operations which obey the familiar algebraic laws of commutativity, associativity, and distributivity. These operations and associated laws qualify Euclidean vectors as an example of the more generalized concept of vectors defined simply as elements of a vector space.\n",
            "title": "Euclidean vector",
            "url": "https://en.wikipedia.org/wiki/Euclidean_vector"
        },
        {
            "desc_links": [
                "/wiki/Straight_line",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Covariate",
                "/wiki/Linear_regression",
                "/wiki/Statistics",
                "/wiki/Deming_regression",
                "/wiki/Median",
                "/wiki/Slope",
                "/wiki/Theil%E2%80%93Sen_estimator",
                "/wiki/Least_absolute_deviations",
                "/wiki/Errors_and_residuals",
                "/wiki/Ordinary_least_squares"
            ],
            "desc_text": "b'In statistics, simple linear regression is a linear regression model with a single explanatory variable.[1][2][3][4] That is, it concerns two-dimensional sample points with one independent variable and one dependent variable (conventionally, the x and y coordinates in a Cartesian coordinate system) and finds a linear function (a non-vertical straight line) that, as accurately as possible, predicts the dependent variable values as a function of the independent variables.\\nThe adjective simple refers to the fact that the outcome variable is related to a single predictor.\\n'b'It is common to make the additional stipulation that the ordinary least squares method should be used: the accuracy of each predicted value is measured by its squared residual (vertical distance between the point of the data set and the fitted line), and the goal is to make the sum of these squared deviations as small as possible. Other regression methods that can be used in place of ordinary least squares include least absolute deviations (minimizing the sum of absolute values of residuals) and the Theil\\xe2\\x80\\x93Sen estimator (which chooses a line whose slope is the median of the slopes determined by pairs of sample points).  Deming regression (total least squares) also finds a line that fits a set of two-dimensional sample points, but (unlike ordinary least squares, least absolute deviations, and median slope regression) it is not really an instance of simple linear regression, because it does not separate the coordinates into one dependent and one independent variable and could potentially return a vertical line as its fit.\\n'b'The remainder of the article assumes an ordinary least squares regression.\\nIn this case, the slope of the fitted line is equal to the correlation between y and x corrected by the ratio of standard deviations of these variables. The intercept of the fitted line is such that the line passes through the center of mass (x, y) of the data points.\\n'",
            "links": [
                "/wiki/Straight_line",
                "/wiki/Cartesian_coordinate_system",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Covariate",
                "/wiki/Linear_regression",
                "/wiki/Statistics",
                "/wiki/Deming_regression",
                "/wiki/Median",
                "/wiki/Slope",
                "/wiki/Theil%E2%80%93Sen_estimator",
                "/wiki/Least_absolute_deviations",
                "/wiki/Errors_and_residuals",
                "/wiki/Ordinary_least_squares",
                "/wiki/Errors_and_residuals",
                "/wiki/Standard_score",
                "/wiki/Wikipedia:Please_clarify",
                "/wiki/Homoscedasticity",
                "/wiki/Statistical_model",
                "/wiki/Central_limit_theorem",
                "/wiki/Student%27s_t-distribution",
                "/wiki/Okun%27s_law",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Standard_normal_distribution",
                "/wiki/Student%27s_t-distribution",
                "/wiki/Central_limit_theorem",
                "/wiki/Law_of_large_numbers",
                "/wiki/Ordinary_least_squares",
                "/wiki/Pearson_product-moment_correlation_coefficient"
            ],
            "text": "Thus a seemingly small variation in the data has a real effect.\nThis example also demonstrates that sophisticated calculations will not overcome the use of badly prepared data. The heights were originally given in inches, and have been converted to the nearest centimetre. Since the conversion has introduced rounding error, this is not an exact conversion. The original inches can be recovered by Round(x/0.0254) and then re-converted to metric without rounding: if this is done, the results become\nThe product-moment correlation coefficient might also be calculated:\nThe 0.975 quantile of Student's t-distribution with 13 degrees of freedom is t*13 = 2.1604, and thus the 95% confidence intervals for \u03b1 and \u03b2 are\nThese quantities would be used to calculate the estimates of the regression coefficients, and their standard errors.\nThere are n = 15 points in this data set. Hand calculations would be started by finding the following five sums:\nThis data set gives average masses for women as a function of their height in a sample of American women of age 30\u201339. Although the OLS article argues that it would be more appropriate to run a quadratic regression for this data, the simple linear regression model is applied here instead.\nThe alternative second assumption states that when the number of points in the dataset is \"large enough\", the law of large numbers and the central limit theorem become applicable, and then the distribution of the estimators is approximately normal. Under this assumption all formulas derived in the previous section remain valid, with the only exception that the quantile t*n\u22122 of Student's t distribution is replaced with the quantile q* of the standard normal distribution. Occasionally the fraction 1/n\u22122 is replaced with 1/n. When n is large such a change does not alter the results appreciably.\nIn order to represent this information graphically, in the form of the confidence bands around the regression line, one has to proceed carefully and account for the joint distribution of the estimators. It can be shown[citation needed] that at confidence level (1 \u2212 \u03b3) the confidence band has hyperbolic form given by the equation\nThe 95% confidence intervals for these estimates are\nThe confidence intervals for \u03b1 and \u03b2 give us the general idea where these regression coefficients are most likely to be. For example, in the Okun's law regression shown here the point estimates are\nat confidence level (1 \u2212 \u03b3), where\nSimilarly, the confidence interval for the intercept coefficient \u03b1 is given by\nThis t-value has a Student's t-distribution with n \u2212 2 degrees of freedom. Using it we can construct a confidence interval for \u03b2:\nwhere\nThe latter case is justified by the central limit theorem.\nThe standard method of constructing confidence intervals for linear regression coefficients relies on the normality assumption, which is justified if either:\nDescription of the statistical properties of estimators from the simple linear regression estimates requires the use of a statistical model. The following is based on assuming the validity of a model under which the estimates are optimal. It is also possible to evaluate the properties under other assumptions, such as inhomogeneity, but this is discussed elsewhere.[clarification needed]\nThe last form above demonstrates how moving the line away from the center of mass of the data points affects the slope.\nwhere Cov and Var refer to the covariance and variance of the sample data (uncorrected for bias).\nSubstituting (x \u2212 h, y \u2212 k) in place of (x, y) gives the regression through (h, k):\nSometimes it is appropriate to force the regression line to pass through the origin, because x and y are assumed to be proportional. For the model without the intercept term, y = \u03b2x, the OLS estimator for \u03b2 simplifies to\nThis notation allows us a concise formula for rxy:\nThis shows that rxy is the slope of the regression line of the standardized data points (and that this line passes through the origin).\nyields\nHere we have introduced\nThis relationship between the true (but unobserved) underlying parameters \u03b1 and \u03b2 and the data points is called a linear regression model.\nwhich describes a line with slope \u03b2 and y-intercept \u03b1. In general such a relationship may not hold exactly for the largely unobserved population of values of the independent and dependent variables; we call the unobserved deviations from the above equation the errors.   Suppose we observe n data pairs and call them {(xi, yi), i = 1, ..., n}. We can describe the underlying relationship between yi and xi involving this error term \u03b5i by\nConsider the model function\nThe remainder of the article assumes an ordinary least squares regression.\nIn this case, the slope of the fitted line is equal to the correlation between y and x corrected by the ratio of standard deviations of these variables. The intercept of the fitted line is such that the line passes through the center of mass (x, y) of the data points.\nIt is common to make the additional stipulation that the ordinary least squares method should be used: the accuracy of each predicted value is measured by its squared residual (vertical distance between the point of the data set and the fitted line), and the goal is to make the sum of these squared deviations as small as possible. Other regression methods that can be used in place of ordinary least squares include least absolute deviations (minimizing the sum of absolute values of residuals) and the Theil\u2013Sen estimator (which chooses a line whose slope is the median of the slopes determined by pairs of sample points).  Deming regression (total least squares) also finds a line that fits a set of two-dimensional sample points, but (unlike ordinary least squares, least absolute deviations, and median slope regression) it is not really an instance of simple linear regression, because it does not separate the coordinates into one dependent and one independent variable and could potentially return a vertical line as its fit.\nIn statistics, simple linear regression is a linear regression model with a single explanatory variable.[1][2][3][4] That is, it concerns two-dimensional sample points with one independent variable and one dependent variable (conventionally, the x and y coordinates in a Cartesian coordinate system) and finds a linear function (a non-vertical straight line) that, as accurately as possible, predicts the dependent variable values as a function of the independent variables.\nThe adjective simple refers to the fact that the outcome variable is related to a single predictor.\n",
            "title": "Simple linear regression",
            "url": "https://en.wikipedia.org/wiki/Simple_linear_regression"
        },
        {
            "desc_links": [
                "/wiki/Vector_(mathematics_and_physics)",
                "/wiki/Vector_space",
                "/wiki/Field_(mathematics)",
                "/wiki/Complex_number",
                "/wiki/Field_(mathematics)",
                "/wiki/Scalar_multiplication",
                "/wiki/Linear_algebra",
                "/wiki/Inner_product_space",
                "/wiki/Scalar_multiplication",
                "/wiki/Inner_product",
                "/wiki/Quaternion",
                "/wiki/Tensor",
                "/wiki/Matrix_(mathematics)",
                "/wiki/Identity_matrix",
                "/wiki/Scalar_matrix"
            ],
            "desc_text": "b'A scalar is an element of a field which is used to define a vector space. A quantity described by multiple scalars, such as having both direction and magnitude, is called a vector.[1]\\n'b'In linear algebra, real numbers or other elements of a field are called scalars and relate to vectors in a vector space through the operation of scalar multiplication, in which a vector can be multiplied by a number to produce another vector.[2][3][4] More generally, a vector space may be defined by using any field instead of real numbers, such as complex numbers. Then the scalars of that vector space will be the elements of the associated field.\\n'b'A scalar product operation \\xe2\\x80\\x93\\xc2\\xa0not to be confused with scalar multiplication\\xc2\\xa0\\xe2\\x80\\x93 may be defined on a vector space, allowing two vectors to be multiplied to produce a scalar. A vector space equipped with a scalar product is called an inner product space.\\n'b'The real component of a quaternion is also called its scalar part.\\n'b'The term is also sometimes used informally to mean a vector, matrix, tensor, or other usually \"compound\" value that is actually reduced to a single component.  Thus, for example, the product of a 1\\xc3\\x97n matrix and an n\\xc3\\x971 matrix, which is formally a 1\\xc3\\x971 matrix, is often said to be a scalar.\\n'b'The term scalar matrix is used to denote a matrix of the form kI where k is a scalar and I is the identity matrix.\\n'",
            "links": [
                "/wiki/Vector_(mathematics_and_physics)",
                "/wiki/Vector_space",
                "/wiki/Field_(mathematics)",
                "/wiki/Complex_number",
                "/wiki/Field_(mathematics)",
                "/wiki/Scalar_multiplication",
                "/wiki/Linear_algebra",
                "/wiki/Inner_product_space",
                "/wiki/Scalar_multiplication",
                "/wiki/Inner_product",
                "/wiki/Quaternion",
                "/wiki/Tensor",
                "/wiki/Matrix_(mathematics)",
                "/wiki/Identity_matrix",
                "/wiki/Scalar_matrix",
                "/wiki/Wikipedia:Citing_sources",
                "/wiki/Fran%C3%A7ois_Vi%C3%A8te",
                "/wiki/Latin_language",
                "/wiki/Quaternion",
                "/wiki/William_Rowan_Hamilton",
                "/wiki/Oxford_English_Dictionary",
                "/wiki/Finite_field",
                "/wiki/Algebraic_number",
                "/wiki/Rational_number",
                "/wiki/Dimension_(vector_space)",
                "/wiki/Coordinate_vector_space",
                "/wiki/Isomorphism",
                "/wiki/Basis_(linear_algebra)",
                "/wiki/Normed_vector_space",
                "/wiki/Norm_(mathematics)",
                "/wiki/Module_(mathematics)",
                "/wiki/Commutative",
                "/wiki/Ring_(mathematics)",
                "/wiki/Algebra",
                "/wiki/Tangent_bundle",
                "/wiki/Section_(fiber_bundle)",
                "/wiki/Manifold",
                "/wiki/Linear_transformation",
                "/wiki/Scaling_(geometry)"
            ],
            "text": "Operations that apply to a single value at a time.\nThe scalar multiplication of vector spaces and modules is a special case of scaling, a kind of linear transformation.\nIn this case the \"scalars\" may be complicated objects.  For instance, if R is a ring, the vectors of the product space Rn can be made into a module with the n\u00d7n matrices with entries from R as the scalars. Another example comes from manifold theory, where the space of sections of the tangent bundle forms a module over the algebra of real functions on the manifold.\nWhen the requirement that the set of scalars form a field is relaxed so that it need only form a ring (so that, for example, the division of scalars need not be defined, or the scalars need not be commutative), the resulting more general algebraic structure is called a module.\nThe norm is usually defined to be an element of V's scalar field K, which restricts the latter to fields that support the notion of sign. Moreover, if V has dimension 2 or more, K must be closed under square root, as well as the four arithmetic operations; thus the rational numbers Q are excluded, but the surd field is acceptable.  For this reason, not every scalar product space is a normed vector space.\nAlternatively, a vector space V can be equipped with a norm function that assigns to every vector v in V a scalar ||v||. By definition, multiplying v by a scalar k also multiplies its norm by |k|. If ||v|| is interpreted as the length of v, this operation can be described as scaling the length of v by k.  A vector space equipped with a norm is called a normed vector space (or normed linear space).\nAccording to a fundamental theorem of linear algebra, every vector space has a basis.  It follows that every vector space over a scalar field K is isomorphic to a coordinate vector space where the coordinates are elements of K.  For example, every real vector space of dimension n is isomorphic to n-dimensional real space Rn.\nThe scalars can be taken from any field, including the rational, algebraic, real, and complex numbers, as well as finite fields.\nAccording to a citation in the Oxford English Dictionary the first recorded usage of the term \"scalar\" in English came with W. R. Hamilton in 1846, referring to the real part of a quaternion:\nThe word scalar derives from the Latin  word scalaris, an adjectival form of scala (Latin for \"ladder\"), from which the English word scale also comes. The first recorded usage of the word \"scalar\" in mathematics occurs in Fran\u00e7ois Vi\u00e8te's Analytic Art (In artem analyticem isagoge) (1591):[5][page\u00a0needed][6]\nThe term scalar matrix is used to denote a matrix of the form kI where k is a scalar and I is the identity matrix.\nThe term is also sometimes used informally to mean a vector, matrix, tensor, or other usually \"compound\" value that is actually reduced to a single component.  Thus, for example, the product of a 1\u00d7n matrix and an n\u00d71 matrix, which is formally a 1\u00d71 matrix, is often said to be a scalar.\nThe real component of a quaternion is also called its scalar part.\nA scalar product operation \u2013\u00a0not to be confused with scalar multiplication\u00a0\u2013 may be defined on a vector space, allowing two vectors to be multiplied to produce a scalar. A vector space equipped with a scalar product is called an inner product space.\nIn linear algebra, real numbers or other elements of a field are called scalars and relate to vectors in a vector space through the operation of scalar multiplication, in which a vector can be multiplied by a number to produce another vector.[2][3][4] More generally, a vector space may be defined by using any field instead of real numbers, such as complex numbers. Then the scalars of that vector space will be the elements of the associated field.\nA scalar is an element of a field which is used to define a vector space. A quantity described by multiple scalars, such as having both direction and magnitude, is called a vector.[1]\n",
            "title": "Scalar (mathematics)",
            "url": "https://en.wikipedia.org/wiki/Scalar_(mathematics)"
        },
        {
            "desc_links": [
                "/wiki/Halbert_White",
                "/wiki/Peter_J._Huber",
                "/wiki/Friedhelm_Eicker",
                "/wiki/Time_series_analysis",
                "/wiki/Linear_regression",
                "/wiki/Econometrics",
                "/wiki/Statistics",
                "/wiki/GARCH",
                "/wiki/Time-series",
                "/wiki/Heteroscedasticity"
            ],
            "desc_text": "b'The topic of heteroscedasticity-consistent (HC) standard errors arises in statistics and econometrics in the context of linear regression as well as time series analysis. These are also known as Eicker\\xe2\\x80\\x93Huber\\xe2\\x80\\x93White standard errors (also Huber\\xe2\\x80\\x93White standard errors or White standard errors),[1] to recognize the contributions of Friedhelm Eicker,[2] Peter J. Huber,[3] and Halbert White.[4]\\n'b'In regression and time-series modelling, basic forms of models make use of the assumption that the errors or disturbances ui have the same variance across all observation points.  When this is not the case, the errors are said to be heteroscedastic, or to have heteroscedasticity, and this behaviour will be reflected in the residuals \\n  \\n    \\n      \\n        \\n          \\n            \\n              \\n                \\n                  u\\n                  \\n                    i\\n                  \\n                \\n                ^\\n              \\n            \\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\scriptstyle {\\\\widehat {u_{i}}}}\\n  \\n estimated from a fitted model. Heteroscedasticity-consistent standard errors are used to allow the fitting of a model that does contain heteroscedastic residuals. The first such approach was proposed by Huber (1967), and further improved procedures have been produced since for cross-sectional data, time-series data and  GARCH estimation.\\n'",
            "links": [
                "/wiki/Halbert_White",
                "/wiki/Peter_J._Huber",
                "/wiki/Friedhelm_Eicker",
                "/wiki/Time_series_analysis",
                "/wiki/Linear_regression",
                "/wiki/Econometrics",
                "/wiki/Statistics",
                "/wiki/Ordinary_least_squares",
                "/wiki/BLUE",
                "/wiki/Uncorrelated",
                "/wiki/Errors_and_residuals_in_statistics",
                "/wiki/William_Greene_(economist)",
                "/wiki/Maximum_likelihood_estimation",
                "/wiki/Probit",
                "/wiki/Logit",
                "/wiki/Leverage_(statistics)"
            ],
            "text": "Alternative estimators have been proposed in MacKinnon & White (1985) that correct for unequal variances of regression residuals due to different leverage.[7] Unlike the asymptotic White's estimator, their estimators are unbiased when the data are homoscedastic.\nPrecisely which covariance matrix is of concern should be a matter of context.\nand\nThus,\nand\nwhere,\nFor any non-linear model (for instance Logit and Probit models), however, heteroscedasticity has more severe consequences: the maximum likelihood estimates of the parameters will be biased (in an unknown direction), as well as inconsistent (unless the likelihood function is modified to correctly take into account the precise form of heteroscedasticity).[5] As pointed out by Greene, \u201csimply computing a robust covariance matrix for an otherwise inconsistent estimator does not give it redemption.\u201d[6]\nIf the sample errors have equal variance \u03c32 and are uncorrelated, then the least-squares estimate of \u03b2 is BLUE (best linear unbiased estimator), and its variance is easily estimated with\nThe ordinary least squares (OLS) estimator is\nwhere X is the vector of explanatory variables and \u03b2 is a k \u00d7 1 column vector of parameters to be estimated.\nAssume that we are studying the linear regression model\nThe topic of heteroscedasticity-consistent (HC) standard errors arises in statistics and econometrics in the context of linear regression as well as time series analysis. These are also known as Eicker\u2013Huber\u2013White standard errors (also Huber\u2013White standard errors or White standard errors),[1] to recognize the contributions of Friedhelm Eicker,[2] Peter J. Huber,[3] and Halbert White.[4]\n",
            "title": "Heteroscedasticity-consistent standard errors",
            "url": "https://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors"
        },
        {
            "desc_links": [
                "/wiki/Alexander_Aitken",
                "/wiki/Statistical_inference",
                "/wiki/Efficiency_(statistics)",
                "/wiki/Weighted_least_squares",
                "/wiki/Ordinary_least_squares",
                "/wiki/Regression_model",
                "/wiki/Statistical_residual",
                "/wiki/Correlation",
                "/wiki/Linear_regression",
                "/wiki/Parameter",
                "/wiki/Statistics"
            ],
            "desc_text": "b'In statistics, generalized least squares (GLS) is a technique for estimating the unknown parameters in a linear regression model when there is a certain degree of correlation between the residuals in a regression model. In these cases, ordinary least squares and weighted least squares can be statistically inefficient, or even give misleading inferences. GLS was first described by Alexander Aitken in 1934.[1]\\n'",
            "links": [
                "/wiki/Alexander_Aitken",
                "/wiki/Statistical_inference",
                "/wiki/Efficiency_(statistics)",
                "/wiki/Weighted_least_squares",
                "/wiki/Ordinary_least_squares",
                "/wiki/Regression_model",
                "/wiki/Statistical_residual",
                "/wiki/Correlation",
                "/wiki/Linear_regression",
                "/wiki/Parameter",
                "/wiki/Statistics",
                "/wiki/Asymptotic_distribution",
                "/wiki/Efficiency_(statistics)",
                "/wiki/Consistent_estimator",
                "/wiki/Bias_of_an_estimator",
                "/wiki/Blue_(statistics)",
                "/wiki/Gauss%E2%80%93Markov_theorem",
                "/wiki/Heteroscedasticity",
                "/wiki/Heteroscedasticity-consistent_standard_errors",
                "/wiki/Ordinary_least_squares"
            ],
            "text": "here p-lim means limit in probability\nwhere n is the sample size and\nUnder regularity conditions any of the FGLS estimator (or that of any of its iterations, if we iterate a finite number of times) is asymptotically distributed as\nThe procedure can be iterated. The first iteration is given by\nIt is important to notice that the squared residuals cannot be used in the previous expression; we need an estimator of the errors variances. To do so, we can use a parametric heteroskedasticity model, or a nonparametric estimator. Once this step is fulfilled, we can proceed:\nThe ordinary least squares (OLS) estimator is calculated as usual by\n(which is inconsistent in this framework) and using a HAC (Heteroskedasticity and Autocorrelation Consistent) estimator. For example, in autocorrelation context we can use the Bartlett estimator (often known as Newey-West estimator since these authors popularized the use of this estimator among econometricians in their 1987 Econometrica article), and in heteroskedastic context we can use the Eicker\u2013White estimator (Eicker\u2013White). This approach is much safer, and it is the appropriate path to take unless the sample is large, and \"large\" is sometimes a slippery issue (e.g. if the errors distribution is asymmetric the required sample would be much larger).\nIn general this estimator has different properties than GLS. For large samples (i.e., asymptotically) all properties are (under appropriate conditions) common with respect to GLS, but for finite samples the properties of FGLS estimators are unknown: they vary dramatically with each particular model, and as a general rule their exact distributions cannot be derived analytically. For finite samples, FGLS may be even less efficient than OLS in some cases. Thus, while GLS can be made feasible, it is not always wise to apply this method when the sample is small.\nA method sometimes used to improve the accuracy of the estimators in finite samples is to iterate, i.e. taking the residuals from FGLS to update the errors covariance estimator, and then updating the FGLS estimation, applying the same idea iteratively until the estimators vary less than some tolerance. But this method does not necessarily improve the efficiency of the estimator very much if the original sample was small.\nA reasonable option when samples are not too large is to apply OLS, but throwing away the classical variance estimator\nWhereas GLS is more efficient than OLS under heteroscedasticity or autocorrelation, this is not true for FGLS. The feasible estimator is, provided the errors covariance matrix is consistently estimated, asymptotically more efficient, but for a small or medium size sample, it can be actually less efficient than OLS. This is why, some authors prefer to use OLS, and reformulate their inferences by simply considering an alternative estimator for the variance of the estimator robust to heteroscedasticity or serial autocorrelation.\nBut for large samples FGLS is preferred over OLS under heteroskedasticity or serial correlation.[3] [4] A cautionary note is that the FGLS estimator is not always consistent. One case in which FGLS might be inconsistent is if there are individual specific fixed effects.[5]\nA special case of GLS called weighted least squares (WLS) occurs when all the off-diagonal entries of \u03a9 are 0.  This situation arises when the variances of the observed values are unequal (i.e.\u00a0heteroscedasticity is present), but where no correlations exist among the observed variances.  The weight for unit i is proportional to the reciprocal of the variance of the response for unit i.[2]\nThis has the effect of standardizing the scale of the errors and \u201cde-correlating\u201d them. Since OLS is applied to data with homoscedastic errors, the Gauss\u2013Markov theorem applies, and therefore the GLS estimate is the best linear unbiased estimator for \u03b2.\nThe GLS estimator is unbiased, consistent, efficient, and asymptotically normal:\nIn statistics, generalized least squares (GLS) is a technique for estimating the unknown parameters in a linear regression model when there is a certain degree of correlation between the residuals in a regression model. In these cases, ordinary least squares and weighted least squares can be statistically inefficient, or even give misleading inferences. GLS was first described by Alexander Aitken in 1934.[1]\n",
            "title": "Generalized least squares",
            "url": "https://en.wikipedia.org/wiki/Generalized_least_squares"
        },
        {
            "desc_links": [
                "/wiki/Numerical_methods_for_linear_least_squares",
                "/wiki/Residuals_(statistics)",
                "/wiki/Generalized_least_squares",
                "/wiki/Weighted_least_squares",
                "/wiki/Ordinary_least_squares",
                "/wiki/Linear_regression",
                "/wiki/Linear_functions",
                "/wiki/Least_squares_approximation"
            ],
            "desc_text": "b'Linear least squares is the least squares approximation of linear functions to data.\\nIt is a set of formulations for solving statistical problems involved in linear regression, including variants for \\nordinary (unweighted),\\nweighted, and \\ngeneralized (correlated) residuals.\\nNumerical methods for linear least squares include inverting the matrix of the normal equations and orthogonal decomposition methods.\\n'",
            "links": [
                "/wiki/Numerical_methods_for_linear_least_squares",
                "/wiki/Residuals_(statistics)",
                "/wiki/Generalized_least_squares",
                "/wiki/Weighted_least_squares",
                "/wiki/Ordinary_least_squares",
                "/wiki/Linear_regression",
                "/wiki/Linear_functions",
                "/wiki/Least_squares_approximation",
                "/wiki/Constrained_least_squares",
                "/wiki/Objective_function",
                "/wiki/Mathematical_optimization",
                "/wiki/Goodness_of_fit",
                "/wiki/Prediction",
                "/wiki/Descriptive_statistics",
                "/wiki/Parameter",
                "/wiki/Data",
                "/wiki/Statistical_model",
                "/wiki/Mathematical_model",
                "/wiki/Mathematics",
                "/wiki/Statistics",
                "/wiki/Minimum_mean_square_error",
                "/wiki/Iterative_method",
                "/wiki/Non-linear_least_squares",
                "/wiki/Closed-form_expression",
                "/wiki/Convex_function",
                "/wiki/Overdetermined_system",
                "/wiki/Outline_of_regression_analysis",
                "/wiki/Statistical_inference",
                "/wiki/Ordinary_least_squares",
                "/wiki/Regression_analysis",
                "/wiki/Linear_regression",
                "/wiki/Statistical_model",
                "/wiki/Arithmetic_mean",
                "/wiki/Maximum_likelihood",
                "/wiki/Errors-in-variables_models",
                "/wiki/Total_least_squares",
                "/wiki/Maxima_and_minima",
                "/wiki/Least_squares"
            ],
            "text": "and solved\nThe partial derivatives with respect to the parameters (this time there is only one) are again computed and set to 0:\nThis results in a system of two equations in two unknowns, called the normal equations, which when solved give\nThe \"error\", at each point, between the curve fit and the data is the difference between the right- and left-hand sides of the equations above. The least squares approach to solving this problem is to try to make the sum of the squares of these errors as small as possible; that is, to find the minimum of the function\nof four equations in two unknowns in some \"best\" sense.\nand the best fit can be found by solving the normal equations.\nso to minimize the function\nIdeally, the model function fits the data exactly, so\nAn assumption underlying the treatment given above is that the independent variable, x, is free of error. In practice, the errors on the measurements of the independent variable are usually much smaller than the errors on the dependent variable and can therefore be ignored. When this is not the case, total least squares or more generally errors-in-variables models, or rigorous least squares, should be used. This can be done by adjusting the weighting scheme to take into account errors on both the dependent and independent variables and then following the standard procedure.[10][11]\nThese properties underpin the use of the method of least squares for all types of data fitting, even when the assumptions are not strictly valid.\nHowever, in the case that the experimental errors do belong to a normal distribution, the least-squares estimator is also a maximum likelihood estimator.[9]\nFor example, it is easy to show that the arithmetic mean of a set of measurements of a quantity is the least-squares estimator of the value of that quantity. If the conditions of the Gauss\u2013Markov theorem apply, the arithmetic mean is optimal, whatever the distribution of errors of the measurements might be.\nIn statistics, linear least squares problems correspond to a particularly important type of statistical model called linear regression which arises as a particular form of regression analysis. One basic form of such a model is an ordinary least squares model. The present article concentrates on the mathematical aspects of linear least squares problems, with discussion of the formulation and interpretation of statistical regression models and statistical inferences related to these being dealt with in the articles just mentioned. See outline of regression analysis for an outline of the topic.\nMathematically, linear least squares is the problem of approximately solving an overdetermined system of linear equations, where the best approximation is defined as that which minimizes the sum of squared differences between the data values and their corresponding modeled values.  The approach is called linear least squares since the assumed function is linear in the parameters to be estimated. Linear least squares problems are convex and have a closed-form solution that is unique, provided that the number of data points used for fitting equals or exceeds the number of unknown parameters, except in special degenerate situations.  In contrast, non-linear least squares problems generally must be solved by an iterative procedure, and the problems can be non-convex with multiple optima for the objective function. If prior distributions are available, then even an underdetermined system can be solved using the Bayesian MMSE estimator.\nIn statistics and mathematics, linear least squares is an approach to fitting a mathematical or statistical model to data in cases where the idealized value provided by the model for any data point is expressed linearly in terms of the unknown parameters of the model.  The resulting fitted model can be used to summarize the data, to predict unobserved values from the same system, and to understand the mechanisms that may underlie the system.\nFor WLS, the ordinary objective function above is replaced for a weighted average of residuals.\nThese values can be used for a statistical criterion as to the goodness of fit. When unit weights are used, the numbers should be divided by the variance of an observation.\nIn OLS (i.e., assuming unweighted observations), the optimal value of the objective function is found by substituting in the optimal expression for the coefficient vector, can be written as:\nIn constrained least squares, one is interested in solving a linear least squares problem with an additional constraint on the solution.\nIn addition, percentage least squares focuses on reducing percentage errors, which is useful in the field of forecasting or time series analysis. It is also useful in situations where the dependent variable has a wide range without constant variance, as here the larger residuals at the upper end of the range would dominate if OLS were used. When the percentage or relative error is normally distributed, least squares percentage regression provides maximum likelihood estimates. Percentage regression is linked to a multiplicative error model, whereas OLS is linked to models containing an additive error term.[6]\nOther formulations include:\nThe three main linear least squares formulations are:\nLinear least squares is the least squares approximation of linear functions to data.\nIt is a set of formulations for solving statistical problems involved in linear regression, including variants for \nordinary (unweighted),\nweighted, and \ngeneralized (correlated) residuals.\nNumerical methods for linear least squares include inverting the matrix of the normal equations and orthogonal decomposition methods.\n",
            "title": "Linear least squares",
            "url": "https://en.wikipedia.org/wiki/Linear_least_squares_(mathematics)#Weighted_linear_least_squares"
        },
        {
            "desc_links": [
                "/wiki/Identity_matrix",
                "/wiki/Ordinary_least_squares",
                "/wiki/Diagonal_matrix",
                "/wiki/Covariance_matrix",
                "/wiki/Generalized_least_squares"
            ],
            "desc_text": "b'Weighted least squares (WLS) is a specialization of generalized least squares in which the errors covariance matrix is diagonal.\\nWLS is also a generalization of ordinary least squares in which the above matrix is allowed to be different to an identity matrix.\\n'",
            "links": [
                "/wiki/Identity_matrix",
                "/wiki/Ordinary_least_squares",
                "/wiki/Diagonal_matrix",
                "/wiki/Covariance_matrix",
                "/wiki/Generalized_least_squares",
                "/wiki/Heteroscedasticity",
                "/wiki/Variance",
                "/wiki/Generalized_least_squares",
                "/wiki/Variance-covariance_matrix",
                "/wiki/Entrywise_division",
                "/wiki/Whitening_transformation",
                "/wiki/Non-linear_least_squares",
                "/wiki/Feasible_generalized_least_squares",
                "/wiki/Diagonal_matrix",
                "/wiki/Iteratively_reweighted_least_squares",
                "/wiki/Error_propagation",
                "/wiki/Variance-covariance_matrix",
                "/wiki/Sampling_error",
                "/wiki/Degrees_of_freedom_(statistics)",
                "/wiki/Student%27s_t-distribution",
                "/wiki/Chebychev%27s_inequality",
                "/wiki/Errors_and_residuals_in_statistics",
                "/wiki/Hat_matrix",
                "/wiki/Idempotent_matrix",
                "/wiki/Identity_matrix",
                "/wiki/Outlier",
                "/wiki/Studentized_residual",
                "/wiki/Student%27s_t-distribution",
                "/wiki/Normal_distribution"
            ],
            "text": "If experimental error follows a normal distribution, then, because of the linear relationship between residuals and observations, so should residuals,[3] but since the observations are only a sample of the population of all possible observations, the residuals should belong to a Student's t-distribution. Studentized residuals are useful in making a statistical test for an outlier when a particular residual appears to be excessively large.\nThus, in the motivational example, above, the fact that the sum of residual values is equal to zero is not accidental, but is a consequence of the presence of the constant term, \u03b1, in the model.\nThe sum of residual values is equal to zero whenever the model function contains a constant term. Left-multiply the expression for the residuals by XT:\nThus the residuals are correlated, even if the observations are not.\nand I is the identity matrix. The variance-covariance matrix of the residuals, M r is given by\nwhere H is the idempotent matrix known as the hat matrix:\nThe residuals  are related to the observations by\nWhen the number of observations is relatively small, Chebychev's inequality can be used for an upper bound on probabilities, regardless of any assumptions about the distribution of experimental errors: the maximum probabilities that a parameter will be more than 1, 2 or 3 standard deviations away from its expectation value are 100%, 25% and 11% respectively.\nThe assumption is not unreasonable when m\u00a0>>\u00a0n. If the experimental errors are normally distributed the parameters will belong to a Student's t-distribution with m\u00a0\u2212\u00a0n degrees of freedom. When m\u00a0>>\u00a0n Student's t-distribution approximates a normal distribution. Note, however, that these confidence limits cannot take systematic error into account. Also, parameter errors should be quoted to one significant figure only, as they are subject to sampling error.[2]\nwhere S is the minimum value of the (weighted) objective function:\nWhen W = M\u22121, this simplifies to\nTherefore, an expression for the estimated variance-covariance matrix of the parameter estimates can be obtained by error propagation from the errors in the observations. Let the variance-covariance matrix for the observations be denoted by M and that of the estimated parameters by M\u03b2. Then\nThe estimated parameter values are linear combinations of the observed values\nThis method is used in iteratively reweighted least squares.\nwhere wi > 0 is the weight of the ith observation, and W is the diagonal matrix of such weights.\nIn some cases the observations may be weighted\u2014for example, they may not be equally reliable. In this case, one can minimize the weighted sum of squares:\nIf the uncertainty of the observations is not known from external sources, then the weights could be estimated from the given observations. This can be useful, for example, to identify outliers. After the outliers have been removed from the data set, the weights should be reset to one.[1]\nNote that for empirical tests, the appropriate W is not known for sure and must be estimated.  For this feasible generalized least squares (FGLS) techniques may be used; in this case it is specialized for a diagonal covariance matrix, thus yielding a feasible weighted least squares solution.\nFor non-linear least squares systems a similar argument shows that the normal equations should be modified as follows.\nThis is a type of whitening transformation; the last expression involves an entrywise division.\nwhere we define the following scaled matrix and vector:\nIf the errors are correlated, the resulting estimator is the BLUE if the weight matrix is equal to the inverse of the variance-covariance matrix of the observations.\nWhen the observational errors are uncorrelated and the weight matrix, W, is diagonal, these may be written as\nwhich, in a linear least squares system give the modified normal equations,\nThe gradient equations for this sum of squares are\nA special case of generalized least squares called weighted least squares occurs when all the off-diagonal entries of \u03a9 (the correlation matrix of the residuals) are null; the variances of the observations (along the covariance matrix diagonal) may still be unequal (heteroscedasticity).\nWeighted least squares (WLS) is a specialization of generalized least squares in which the errors covariance matrix is diagonal.\nWLS is also a generalization of ordinary least squares in which the above matrix is allowed to be different to an identity matrix.\n",
            "title": "Weighted least squares",
            "url": "https://en.wikipedia.org/wiki/Weighted_least_squares"
        },
        {
            "desc_links": [],
            "desc_text": "",
            "links": [
                "/wiki/Covariance",
                "/wiki/Cantor_distribution",
                "/wiki/Continuous_random_variable",
                "/wiki/Discrete_random_variable",
                "/wiki/Algorithms_for_calculating_variance",
                "/wiki/Catastrophic_cancellation",
                "/wiki/Floating_point_arithmetic",
                "/wiki/Weighted_variance",
                "/wiki/Central_limit_theorem",
                "/wiki/Data_set",
                "/wiki/Location_parameter",
                "/wiki/Invariant_(mathematics)",
                "/wiki/Linear_combination",
                "/wiki/Uncorrelated",
                "/wiki/Statistical_independence",
                "/wiki/Ir%C3%A9n%C3%A9e-Jules_Bienaym%C3%A9",
                "/wiki/Central_limit_theorem",
                "/wiki/Standard_error_(statistics)",
                "/wiki/Covariance",
                "/wiki/Correlated",
                "/wiki/Classical_test_theory",
                "/wiki/Cronbach%27s_alpha",
                "/wiki/Covariance",
                "/wiki/Standard_error",
                "/wiki/Spearman%E2%80%93Brown_prediction_formula",
                "/wiki/Law_of_large_numbers",
                "/wiki/Covariance",
                "/wiki/Independence_(probability_theory)",
                "/wiki/Analysis_of_variance",
                "/wiki/Algorithms_for_calculating_variance",
                "/wiki/Catastrophic_cancellation",
                "/wiki/Cumulative_distribution_function",
                "/wiki/Probability_density_function",
                "/wiki/Root_mean_square_deviation",
                "/wiki/Standard_deviation",
                "/wiki/Heavy-tailed_distribution",
                "/wiki/Measurement_error",
                "/wiki/Outlier",
                "/wiki/Robust_statistics",
                "/wiki/Covariance",
                "/wiki/Taylor_expansions_for_the_moments_of_functions_of_random_variables",
                "/wiki/Taylor_expansion",
                "/wiki/Delta_method",
                "/wiki/Statistical_population",
                "/wiki/Observations",
                "/wiki/Sample_(statistics)",
                "/wiki/Estimator",
                "/wiki/Estimation_theory",
                "/wiki/Unbiased_estimation_of_standard_deviation",
                "/wiki/Mean_squared_error",
                "/wiki/Squared_deviations",
                "/wiki/Consistent_estimator",
                "/wiki/Bessel%27s_correction",
                "/wiki/Biased_estimator",
                "/wiki/Shrinkage_estimator",
                "/wiki/Mean_squared_error#Variance",
                "/wiki/Excess_kurtosis",
                "/wiki/Mean_squared_error",
                "/wiki/Statistical_population",
                "/wiki/Sample_(statistics)",
                "/wiki/Squared_deviations",
                "/wiki/Statistical_sample",
                "/wiki/Unbiased_estimation_of_standard_deviation",
                "/wiki/Jensen%27s_inequality",
                "/wiki/Concave_function",
                "/wiki/Sample_standard_deviation",
                "/wiki/Sample_covariance",
                "/wiki/Bessel%27s_correction",
                "/wiki/U-statistic",
                "/wiki/Chi-squared_distribution",
                "/wiki/Cochran%27s_theorem",
                "/wiki/Normal_distribution",
                "/wiki/Random_variable",
                "/wiki/Central_moment",
                "/wiki/Kurtosis",
                "/wiki/Consistent_estimator",
                "/wiki/Law_of_large_numbers",
                "/wiki/Chi_square_test",
                "/wiki/F_test",
                "/wiki/Median",
                "/wiki/Resampling_(statistics)",
                "/wiki/Bootstrapping_(statistics)",
                "/wiki/The_Correlation_Between_Relatives_on_the_Supposition_of_Mendelian_Inheritance",
                "/wiki/Ronald_Fisher",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Investment#In_finance",
                "/wiki/Downside_risk",
                "/wiki/Chebyshev%27s_inequality#Semivariances"
            ],
            "text": "For inequalities associated with the semivariance, see Chebyshev's inequality \u00a7\u00a0Semivariances.\nThe semivariance is calculated in the same manner as the variance but only those observations that fall below the mean are included in the calculation. It is sometimes described as a measure of downside risk in an investments context. For skewed distributions, the semivariance can provide additional information that a variance does not.[citation needed]\nThat is, there is the most variance in the x direction.  Physicists would consider this to have a low moment about the x axis so the moment-of-inertia tensor is\nThis difference between moment of inertia in physics and in statistics is clear for points that are gathered along a line. Suppose many points are close to the x axis and distributed along it. The covariance matrix might look like\nThe term variance was first introduced by Ronald Fisher in his 1918 paper The Correlation Between Relatives on the Supposition of Mendelian Inheritance:[20]\nResampling methods, which include the bootstrap and the jackknife, may be used to test the equality of variances.\nThe Lehmann test is a parametric test of two variances. Of this test there are several variants known. Other tests of the equality of variances include the Box test, the Box\u2013Anderson test and the Moses test.\nSeveral non parametric tests have been proposed: these include the Barton\u2013David\u2013Ansari\u2013Freund\u2013Siegel\u2013Tukey test, the Capon test, Mood test, the Klotz test and the Sukhatme test. The Sukhatme test applies to two variances and requires that both medians be known and equal to zero. The Mood, Klotz, Capon and Barton\u2013David\u2013Ansari\u2013Freund\u2013Siegel\u2013Tukey tests also apply to two variances. They allow the median to be unknown but do require that the two medians are equal.\nTesting for the equality of two or more variances is difficult. The F test and chi square tests are both adversely affected by non-normality and are not recommended for this purpose.\nwhere ymin is the minimum of the sample.[19]\nThis bound has been improved, and it is known that variance is bounded by\nIt has been shown[18] that for a sample {yi} of real numbers,\nIf the conditions of the law of large numbers hold for the squared observations, s2 is a consistent estimator of\u00a0\u03c32. One can see indeed that the variance of the estimator tends asymptotically to zero.  An asymptotically equivalent formula was given in Kenney and Keeping (1951:164), Rose and Smith (2002:264), and Weisstein (n.d.).[14][15][16]\nwhere \u03ba is the kurtosis of the distribution and \u03bc4 is the fourth central moment.\nIf the yi are independent and identically distributed, but not necessarily normally distributed, then[12][13]\nand[11]\nAs a direct consequence, it follows that \nBeing a function of random variables, the sample variance is itself a random variable, and it is natural to study its distribution. In the case that yi are independent observations from a normal distribution, Cochran's theorem shows that s2 follows a scaled chi-squared distribution:[10]\nThe unbiased sample variance is a U-statistic for the function \u0192(y1,\u00a0y2) =\u00a0(y1\u00a0\u2212\u00a0y2)2/2, meaning that it is obtained by averaging a 2-sample statistic over 2-element subsets of the population.\nThe use of the term n\u00a0\u2212\u00a01 is called Bessel's correction, and it is also used in sample covariance and the sample standard deviation (the square root of variance). The square root is a concave function and thus introduces negative bias (by Jensen's inequality), which depends on the distribution, and thus the corrected sample standard deviation (using Bessel's correction) is biased. The unbiased estimation of standard deviation is a technically involved problem, though for the normal distribution using the term n\u00a0\u2212\u00a01.5 yields an almost unbiased estimator.\nEither estimator may be simply referred to as the sample variance when the version can be determined by context. The same proof is also applicable for samples taken from a continuous probability distribution.\nWe take a  sample with replacement of n values y1,\u00a0...,\u00a0yn from the population, where n\u00a0<\u00a0N, and estimate the variance on the basis of this sample.[9] Directly taking the variance of the sample data gives the average of the squared deviations:\nIn many practical situations, the true variance of a population is not known a priori and must be computed somehow.  When dealing with extremely large populations, it is not possible to count every object in the population, so the computation must be performed on a sample of the population.[8] Sample variance can also be applied to the estimation of the variance of a continuous distribution from a sample of that distribution.\nThe population variance matches the variance of the generating probability distribution. In this sense, the concept of population can be extended to continuous random variables with infinite populations.\nThis is true because\nThe population variance can also be computed using\nwhere the population mean is\nIn general, the population variance of a finite population of size N with values xi is given by\nSecondly, the sample variance does not generally minimize mean squared error between sample variance and population variance. Correcting for bias often makes this worse: one can always choose a scale factor that performs better than the corrected sample variance, though the optimal scale factor depends on the excess kurtosis of the population (see mean squared error: variance), and introduces bias. This always consists of scaling down the unbiased estimator (dividing by a number larger than n\u00a0\u2212\u00a01), and is a simple example of a shrinkage estimator: one \"shrinks\" the unbiased estimator towards zero. For the normal distribution, dividing by n\u00a0+\u00a01 (instead of n\u00a0\u2212\u00a01 or n) minimizes mean squared error. The resulting estimator is biased, however, and is known as the biased sample variation.\nFirstly, if the omniscient mean is unknown (and is computed as the sample mean), then the sample variance is a biased estimator: it underestimates the variance by a factor of (n\u00a0\u2212\u00a01) / n; correcting by this factor (dividing by n\u00a0\u2212\u00a01 instead of n) is called Bessel's correction. The resulting estimator is unbiased, and is called the (corrected) sample variance or unbiased sample variance. For example, when n\u00a0=\u00a01 the variance of a single observation about the sample mean (itself) is obviously zero regardless of the population variance. If the mean is determined in some other way than from the same samples used to estimate the variance then this bias does not arise and the variance can safely be estimated as that of the samples about the (independently known) mean.\nThe simplest estimators for population mean and population variance are simply the mean and variance of the sample, the sample mean and (uncorrected) sample variance \u2013 these are consistent estimators (they converge to the correct value as the number of samples increases), but can be improved. Estimating the population variance by taking the sample's variance is close to optimal in general, but can be improved in two  ways. Most simply, the sample variance is computed as an average of squared deviations about the (sample) mean, by dividing by n. However, using values other than n improves the estimator in various ways. Four common values for the denominator are n, n\u00a0\u2212\u00a01, n\u00a0+\u00a01, and n\u00a0\u2212\u00a01.5: n is the simplest (population variance of the sample), n\u00a0\u2212\u00a01 eliminates bias, n\u00a0+\u00a01 minimizes mean squared error for the normal distribution, and n\u00a0\u2212\u00a01.5 mostly eliminates bias in unbiased estimation of standard deviation for the normal distribution.\nReal-world observations such as the measurements of yesterday's rain throughout the day typically cannot be complete sets of all possible observations that could be made. As such, the variance calculated from the finite set will in general not match the variance that would have been calculated from the full population of possible observations.  This means that one estimates the mean and variance that would have been calculated from an omniscient set of observations by using an estimator equation.  The estimator is a function of the sample of n observations drawn without observational bias from the whole population of potential observations. In this example that sample would be the set of actual measurements of yesterday's rainfall from available rain gauges within the geography of interest.\n\nprovided that f is twice differentiable and that the mean and variance of X are finite.\nThe delta method uses second-order Taylor expansions to approximate the variance of a function of one or more random variables: see Taylor expansions for the moments of functions of random variables. For example, the approximate variance of a function of one variable is given by\nThe standard deviation and the expected absolute deviation can both be used as an indicator of the \"spread\" of a distribution.  The standard deviation is more amenable to algebraic manipulation than the expected absolute deviation, and, together with variance and its generalization covariance, is used frequently in theoretical statistics; however the expected absolute deviation tends to be more robust as it is less sensitive to outliers arising from measurement anomalies or an unduly heavy-tailed distribution.\nUnlike expected  absolute deviation, the variance of a variable has units that are the square of the units of the variable itself.  For example, a variable measured in meters will have a variance measured in meters squared.  For this reason, describing data sets via their standard deviation or root mean square deviation is often preferred over using the variance.  In the dice example the standard deviation is \u221a2.9\u00a0\u2248\u00a01.7, slightly larger than the expected absolute deviation of\u00a01.5.\nThis expression can be used to calculate the variance in situations where the CDF, but not the density, can be conveniently expressed.\nThe population variance for a non-negative random variable can be expressed in terms of the cumulative distribution function F using\nThis formula is also sometimes used in connection with the sample variance. While useful for hand calculations, it is not advised for computer calculations as it suffers from catastrophic cancellation if the two components of the equation are similar in magnitude and floating point arithmetic is used. This is discussed in the article Algorithms for calculating variance.\nThis will be useful when it is possible to derive formulae for the expected value and for the expected value of the square.\nA formula often used for deriving the variance of a theoretical distribution is as follows:\nThis can also be derived from the additivity of variances, since the total (observed) score is the sum of the predicted score and the error score, where the latter two are uncorrelated.\nA similar formula is applied in analysis of variance, where the corresponding formula is\nIn general, if two variables are statistically dependent, the variance of their product is given by:\nEquivalently, using the basic properties of expectation, it is given by\nIf two variables X and Y are independent, the variance of their product is given by[6]\nThe expression above can be extended to a weighted sum of multiple variables:\nThis implies that in a weighted sum of variables, the variable with the largest weight will have a disproportionally large weight in the variance of the total. For example, if X and Y are uncorrelated and the weight of X is two times the weight of Y, then the weight of the variance of X will be four times the weight of the variance of Y.\nThe scaling property and the Bienaym\u00e9 formula, along with the property of the covariance Cov(aX,\u00a0bY) = ab Cov(X,\u00a0Y)  jointly imply that\nTherefore, the variance of the mean of a large number of standardized variables is approximately equal to their average correlation. This makes clear that the sample mean of correlated variables does not generally converge to the population mean, even though the law of large numbers states that the sample mean will converge for independent variables.\nThis formula is used in the Spearman\u2013Brown prediction formula of classical test theory. This converges to \u03c1 if n goes to infinity, provided that the average correlation remains constant or converges too. So for the variance of the mean of standardized variables with equal correlations or converging average correlation we have\nThis implies that the variance of the mean increases with the average of the correlations. In other words, additional correlated observations are not as effective as additional independent observations at reducing the uncertainty of the mean. Moreover, if the variables have unit variance, for example if they are standardized, then this simplifies to\nSo if the variables have equal variance \u03c32 and the average correlation of distinct variables is \u03c1, then the variance of their mean is\nHere Cov(\u22c5, \u22c5) is the covariance, which is zero for independent random variables (if it exists). The formula states that the variance of a sum is equal to the sum of all elements in the covariance matrix of the components. The next expression states equivalently that the variance of the sum is the sum of the diagonal of covariance matrix plus two times the sum of its upper triangular elements (or its lower triangular elements); this emphasizes that the covariance matrix is symmetric. This formula is used in the theory of Cronbach's alpha in classical test theory.\n(Note: The second equality comes from the fact that Cov(Xi,Xi) = Var(Xi).)\nIn general, if the variables are correlated, then the variance of their sum is the sum of their covariances:\nUsing the linearity of the expectation operator and the assumption of independence (or uncorrelatedness) of X and Y, this further simplifies as follows:\nThe general result then follows by induction.  Starting with the definition,\nTo prove the initial statement, it suffices to show that\nThat is, the variance of the mean decreases when n increases. This formula for the variance of the mean is used in the definition of the standard error of the sample mean, which is used in the central limit theorem.\nThis statement is called the Bienaym\u00e9 formula[2] and was discovered in 1853.[3][4] It is often made with the stronger condition that the variables are independent, but being uncorrelated suffices. So if all the variables have the same variance \u03c32, then, since division by n is a linear transformation, this formula immediately implies that the variance of their mean is\nOne reason for the use of the variance in preference to other measures of dispersion is that the variance of the sum (or the difference) of uncorrelated random variables is the sum of their variances:\nThese results lead to the variance of a linear combination as:\nThe variance of a sum of two random variables is given by\nIf all values are scaled by a constant, the variance is scaled by the square of that constant:\nVariance is invariant with respect to changes in a location parameter.  That is, if a constant is added to all values of the variable, the variance is unchanged:\nThe variance of a constant random variable is zero, and if the variance of a variable in a data set is 0, then all the entries have the same value:\nVariance is non-negative because the squares are positive or zero:\nThe general formula for the variance of the outcome, X, of an n-sided die is\nThe role of the normal distribution in the central limit theorem is in part responsible for the prevalence of the variance in probability and statistics.\nor equivalently and conventionally, \n(When such a discrete weighted variance is specified by weights whose sum is not\u00a01, then one divides by the sum of the weights.)\nor equivalently\nA mnemonic for the above expression is \"mean of square minus square of mean\". This equation should not be used for computations using floating point arithmetic because it suffers from catastrophic cancellation if the two components of the equation are similar in magnitude. There exist numerically stable alternatives.\nThis definition encompasses random variables that are generated by processes that are discrete, continuous, neither, or mixed. The variance can also be thought of as the covariance of a random variable with itself:\n",
            "title": "Variance",
            "url": "https://en.wikipedia.org/wiki/Variance"
        },
        {
            "desc_links": [],
            "desc_text": "",
            "links": [],
            "text": "",
            "title": "Heteroscedasticity",
            "url": "https://en.wikipedia.org/wiki/Heteroscedasticity"
        },
        {
            "desc_links": [
                "/wiki/Normal_distribution",
                "/wiki/Response_variable",
                "/wiki/Linear_regression",
                "/wiki/Statistics",
                "/wiki/Variance-stabilizing_transformation",
                "/wiki/Least_squares",
                "/wiki/Bayesian_statistics",
                "/wiki/Maximum_likelihood",
                "/wiki/Iterative_method",
                "/wiki/Iteratively_reweighted_least_squares",
                "/wiki/Poisson_regression",
                "/wiki/Logistic_regression",
                "/wiki/Linear_regression",
                "/wiki/Robert_Wedderburn_(statistician)",
                "/wiki/John_Nelder"
            ],
            "desc_text": "b'In statistics, the generalized linear model (GLM) is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution.  The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\\n'b'Generalized linear models were formulated by John Nelder and Robert Wedderburn as a way of unifying various other statistical models, including linear regression, logistic regression and Poisson regression.[1] They proposed an iteratively reweighted least squares method for maximum likelihood estimation of the model parameters. Maximum-likelihood estimation remains popular and is the default method on many statistical computing packages.  Other approaches, including Bayesian approaches and least squares fits to variance stabilized responses, have been developed.\\n'",
            "links": [
                "/wiki/Normal_distribution",
                "/wiki/Response_variable",
                "/wiki/Linear_regression",
                "/wiki/Statistics",
                "/wiki/Variance-stabilizing_transformation",
                "/wiki/Least_squares",
                "/wiki/Bayesian_statistics",
                "/wiki/Maximum_likelihood",
                "/wiki/Iterative_method",
                "/wiki/Iteratively_reweighted_least_squares",
                "/wiki/Poisson_regression",
                "/wiki/Logistic_regression",
                "/wiki/Linear_regression",
                "/wiki/Robert_Wedderburn_(statistician)",
                "/wiki/John_Nelder",
                "/wiki/Normal_distribution",
                "/wiki/Linear_combination",
                "/wiki/Random_variable",
                "/wiki/Expected_value",
                "/wiki/Logarithm",
                "/wiki/Log-linear_model",
                "/wiki/Logistic_regression",
                "/wiki/Odds_ratio",
                "/wiki/Bernoulli_distribution",
                "/wiki/Logit",
                "/wiki/Binomial_distribution",
                "/wiki/Bernoulli_distribution",
                "/wiki/Poisson_distribution",
                "/wiki/Normal_distribution",
                "/wiki/Gamma_distribution",
                "/wiki/Poisson_distribution",
                "/wiki/Binomial_distribution",
                "/wiki/Normal_distribution",
                "/wiki/Probability_distributions",
                "/wiki/Exponential_family",
                "/wiki/Probability_distribution",
                "/wiki/Dependent_variable",
                "/wiki/Expected_value",
                "/wiki/Bayesian_probability",
                "/wiki/Quasi-likelihood",
                "/wiki/Maximum_likelihood",
                "/wiki/Expected_value",
                "/wiki/Eta_(letter)",
                "/wiki/Greek_alphabet",
                "/wiki/Probit_model#Gibbs_sampling",
                "/wiki/Range_(mathematics)",
                "/wiki/Domain_of_a_function",
                "/wiki/Density_function",
                "/wiki/Expected_value",
                "/wiki/Expected_value",
                "/wiki/Newton%E2%80%93Raphson_method",
                "/wiki/Iteratively_reweighted_least_squares",
                "/wiki/Maximum_likelihood",
                "/wiki/Gibbs_sampling",
                "/wiki/Markov_chain_Monte_Carlo",
                "/wiki/Laplace_approximation",
                "/wiki/Closed-form_expression",
                "/wiki/Posterior_distribution",
                "/wiki/Asymptotic",
                "/wiki/General_linear_model",
                "/wiki/Gauss%E2%80%93Markov_theorem",
                "/wiki/Least-squares",
                "/wiki/Linear_regression",
                "/wiki/Closed-form_expression",
                "/wiki/Closed-form_expression",
                "/wiki/Bernoulli_distribution",
                "/wiki/Logit",
                "/wiki/Logistic_regression",
                "/wiki/Gibbs_sampling",
                "/wiki/Probit_model",
                "/wiki/Prior_distribution",
                "/wiki/Poisson_distribution",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Linear_probability_model",
                "/wiki/Variance_function",
                "/wiki/Overdispersion",
                "/wiki/Quasi-likelihood",
                "/wiki/Multinomial_distribution",
                "/wiki/Level_of_measurement#Ordinal_measurement",
                "/wiki/Ordered_probit",
                "/wiki/Ordered_logit",
                "/wiki/Level_of_measurement#Nominal_scale",
                "/wiki/Multinomial_probit",
                "/wiki/Multinomial_logit",
                "/wiki/Poisson_distribution",
                "/wiki/Count_data",
                "/wiki/Poisson_regression",
                "/wiki/Overdispersion",
                "/wiki/Quasi-likelihood",
                "/wiki/Longitudinal_studies",
                "/wiki/Correlation",
                "/wiki/Uncorrelated",
                "/wiki/Smoothing",
                "/wiki/Generalized_additive_model",
                "/wiki/John_Nelder"
            ],
            "text": "The term \"generalized linear model\", and especially its abbreviation GLM, are sometimes confused with general linear model. Co-originator John Nelder has expressed regret over this terminology.[8]\nThe smoothing functions fi are estimated from the data. In general this requires a large number of data points and is computationally intensive.[6][7]\nGeneralized additive models (GAMs) are another extension to GLMs in which the linear predictor \u03b7 is not restricted to be linear in the covariates X but is the sum of smoothing functions applied to the xis:\nThe standard GLM assumes that the observations are uncorrelated. Extensions have been developed to allow for correlation between observations, as occurs for example in longitudinal studies and clustered designs:\nwhere the dispersion parameter \u03c4 is typically fixed at exactly one. When it is not, the resulting quasi-likelihood model is often described as poisson with overdispersion or quasipoisson.\nThe variance function is proportional to the mean\nAnother example of generalized linear models includes Poisson regression which models count data using the Poisson distribution.  The link is typically the logarithm, the canonical link.\nfor m > 2. Different links g lead to multinomial logit or multinomial probit models.  These are more general than the ordered response models, and more parameters are estimated. \nIf the response variable is a nominal measurement, or the data do not satisfy the assumptions of an ordered model, one may fit a model of the following form:\nfor m > 2. Different links g lead to proportional odds models or ordered probit models.\nIf the response variable is an ordinal measurement, then one may fit a model function of the form:\nThe binomial case may be easily extended to allow for a multinomial distribution as the response (also, a Generalized Linear Model for counts, with a constrained total). There are two ways in which this is usually done:\nwhere the dispersion parameter \u03c4 is exactly 1 for the binomial distribution. Indeed, the standard binomial likelihood omits \u03c4.  When it is present, the model is called \"quasibinomial\", and the modified likelihood is called a quasi-likelihood, since it is not generally the likelihood corresponding to any real probability distribution.  If \u03c4 exceeds 1, the model is said to exhibit overdispersion.\nThe variance function for \"quasibinomial\" data is:\nThe identity link g(p) = p is also sometimes used for binomial data to yield a linear probability model.  However, the identity link can predict nonsense \"probabilities\" less than zero or greater than one.  This can be avoided by using a transformation like cloglog, probit or logit (or any inverse cumulative distribution function).  A primary merit of the identity link is that it can be estimated using linear math\u2014and other standard link functions are approximately linear matching the identity link near p = 0.5.\nA linear model requires the response variable to take values over the entire real line. Since \u03bc must be positive, we can enforce that by taking the logarithm, and letting log(\u03bc) be a linear model.  This produces the \"cloglog\" transformation\nand then\nwhere \u03bc is a positive number denoting the inverse of the expected number of events.  If p represents the proportion of observations with at least one event, its complement\nThis link function is asymmetric and will often produce different results from the logit and probit link functions.[citation needed] The cloglog model corresponds to applications where we observe either zero events (e.g., defects) or one or more, where the number of events is assumed to follow the Poisson distribution. The Poisson assumption means that\nThe complementary log-log function may also be used:\nThe reason for the use of the probit model is that a constant scaling of the input variable to a normal CDF (which can be absorbed through equivalent scaling of all of the parameters) yields a function that is practically identical to the logit function, but probit models are more tractable in some situations than logit models. (In a Bayesian setting in which normally distributed prior distributions are placed on the parameters, the relationship between the normal priors and the normal CDF link function means that a probit model can be computed using Gibbs sampling, while a logit model generally cannot.)\nGLMs with this setup are logistic regression models (or logit models).\nThe most typical link function is the canonical logit link:\nThere are several popular link functions for binomial functions.\nWhen the response data, Y, are binary (taking on only values 0 and 1), the distribution function is generally chosen to be the Bernoulli distribution and the interpretation of \u03bci is then the probability, p, of Yi taking on the value one.\nFor the normal distribution, the generalized linear model has a closed form expression for the maximum-likelihood estimates, which is convenient. Most other GLMs lack closed form estimates.\nFrom the perspective of generalized linear models, however, it is useful to suppose that the distribution function is the normal distribution with constant variance and the link function is the identity, which is the canonical link if the variance is known.\nA simple, very important example of a generalized linear model (also an example of a general linear model) is linear regression. In linear regression, the use of the least-squares estimator is justified by the Gauss\u2013Markov theorem, which does not assume that the distribution is normal.\nA possible point of confusion has to do with the distinction between generalized linear models and the general linear model, two broad statistical models.  The general linear model may be viewed as a special case of the generalized linear model with identity link and responses normally distributed.  As most exact results of interest are obtained only for the general linear model, the general linear model has undergone a somewhat longer historical development.  Results for the generalized linear model with non-identity link are asymptotic (tending to work well with large samples).\nIn general, the posterior distribution cannot be found in closed form and so must be approximated, usually using Laplace approximations or some type of Markov chain Monte Carlo method such as Gibbs sampling.\nThe maximum likelihood estimates can be found using an iteratively reweighted least squares algorithm or a Newton\u2013Raphson method with updates of the form:\nFor categorical and multinomial distributions, the parameter to be predicted is a K-vector of probabilities, with the further restriction that all probabilities must add up to 1.  Each probability indicates the likelihood of occurrence of one of the K possible values.  For the multinomial distribution, and for the vector form of the categorical distribution, the expected values of the elements of the vector can be related to the predicted probabilities similarly to the binomial and Bernoulli distributions.\nFor the Bernoulli and binomial distributions, the parameter is a single probability, indicating the likelihood of occurrence of a single event.  The Bernoulli still satisfies the basic condition of the generalized linear model in that, even though a single outcome will always be either 0 or 1, the expected value will nonetheless be a real-valued probability, i.e. the probability of occurrence of a \"yes\" (or 1) outcome.  Similarly, in a binomial distribution, the expected value is Np, i.e. the expected proportion of \"yes\" outcomes will be the probability to be predicted.\nIn the cases of the exponential and gamma distributions, the domain of the canonical link function is not the same as the permitted range of the mean. In particular, the linear predictor may be positive, which would give an impossible negative mean.  When maximizing the likelihood, precautions must be taken to avoid this.  An alternative is to use a noncanonical link function.\nFollowing is a table of several exponential-family distributions in common use and the data they are typically used for, along with the canonical link functions and their inverses (sometimes referred to as the mean function, as done here).\nThe link function provides the relationship between the linear predictor and the mean of the distribution function.  There are many commonly used link functions, and their choice is informed by several considerations. There is always a well-defined canonical link function which is derived from the exponential  of the response's density function. However, in some cases it makes sense to try to match the domain of the link function to the range of the distribution function's mean, or use a non-canonical link function for algorithmic purposes, for example Bayesian probit regression.\n\u03b7 is expressed as linear combinations (thus, \"linear\") of unknown parameters \u03b2.  The coefficients of the linear combination are represented as the matrix of independent variables X.  \u03b7 can thus be expressed as\nThe linear predictor is the quantity which incorporates the information about the independent variables into the model.  The symbol \u03b7 (Greek \"eta\") denotes a linear predictor.  It is related to the expected value of the data through the link function.\nUnder this scenario, the variance of the distribution can be shown to be[2]\nThe GLM consists of three elements:\nThe unknown parameters, \u03b2, are typically estimated with maximum likelihood, maximum quasi-likelihood, or Bayesian techniques.\nIt is convenient if V follows from the exponential family distribution, but it may simply be that the variance is a function of the predicted value.\nIn this framework, the variance is typically a function, V, of the mean:\nwhere E(Y) is the expected value of Y; X\u03b2 is the linear predictor, a linear combination of unknown parameters \u03b2; g is the link function.\nIn a generalized linear model (GLM), each outcome Y of the dependent variables is assumed to be generated from a particular distribution in the exponential family, a large range of probability distributions that includes the normal, binomial, Poisson and gamma distributions, among others. The mean, \u03bc, of the distribution depends on the independent variables, X, through:\nGeneralized linear models cover all these situations by allowing for response variables that have arbitrary distributions (rather than simply normal distributions), and for an arbitrary function of the response variable (the link function) to vary linearly with the predicted values (rather than assuming that the response itself must vary linearly).  For example, the case above of predicted number of beach attendees would typically be modeled with a Poisson distribution and a log link, while the case of predicted probability of beach attendance would typically be modeled with a Bernoulli distribution (or binomial distribution, depending on exactly how the problem is phrased) and a log-odds (or logit) link function.\nSimilarly, a model that predicts a probability of making a yes/no choice (a Bernoulli variable) is even less suitable as a linear-response model, since probabilities are bounded on both ends (they must be between 0 and 1).  Imagine, for example, a model that predicts the likelihood of a given person going to the beach as a function of temperature.  A reasonable model might predict, for example, that a change in 10 degrees makes a person two times more or less likely to go to the beach.  But what does \"twice as likely\" mean in terms of a probability? It cannot literally mean to double the probability value (e.g. 50% becomes 100%, 75% becomes 150%, etc.).  Rather, it is the odds that are doubling: from 2:1 odds, to 4:1 odds, to 8:1 odds, etc. Such a model is a log-odds or logistic model.\nHowever, these assumptions are inappropriate for some types of response variables.  For example, in cases where the response variable is expected to be always positive and varying over a wide range, constant input changes lead to geometrically varying, rather than constantly varying, output changes. As an example, a prediction model might predict that 10 degree temperature decrease would lead to 1,000 fewer people visiting the beach is unlikely to generalize well over both small beaches (e.g. those where the expected attendance was 50 at a particular temperature) and large beaches (e.g. those where the expected attendance was 10,000 at a low temperature).  The problem with this kind of prediction model would imply a temperature drop of 10 degrees would lead to 1,000 fewer people visiting the beach, a beach whose expected attendance was 50 at a higher temperature would now be predicted to have the impossible attendance value of \u2212950. Logically, a more realistic model would instead predict a constant rate of increased beach attendance (e.g. an increase in 10 degrees leads to a doubling in beach attendance, and a drop in 10 degrees leads to a halving in attendance).  Such a model is termed an exponential-response model (or log-linear model, since the logarithm of the response is predicted to vary linearly).\nOrdinary linear regression predicts the expected value of a given unknown quantity (the response variable, a random variable) as a linear combination of a set of observed values (predictors).  This implies that a constant change in a predictor leads to a constant change in the response variable (i.e. a linear-response model).  This is appropriate when the response variable has a normal distribution (intuitively, when a response variable can vary essentially indefinitely in either direction with no fixed \"zero value\", or more generally for any quantity that only varies by a relatively small amount, e.g. human heights).\nGeneralized linear models were formulated by John Nelder and Robert Wedderburn as a way of unifying various other statistical models, including linear regression, logistic regression and Poisson regression.[1] They proposed an iteratively reweighted least squares method for maximum likelihood estimation of the model parameters. Maximum-likelihood estimation remains popular and is the default method on many statistical computing packages.  Other approaches, including Bayesian approaches and least squares fits to variance stabilized responses, have been developed.\nIn statistics, the generalized linear model (GLM) is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution.  The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n",
            "title": "Generalized linear model",
            "url": "https://en.wikipedia.org/wiki/Generalized_linear_model"
        },
        {
            "desc_links": [],
            "desc_text": "b'\\n'b'The aim of this page is to describe ways to clarify text or request such clarification. There are inline cleanup tags to flag specific wording that is likely to be confusing to the average reader.\\n'",
            "links": [
                "/wiki/Wikipedia:Template_messages",
                "/wiki/Parameters_(computer_science)"
            ],
            "text": "There are some common situations where use of a more specific clarification template might make the desired clarification clearer. A common case is an article citing a scientific measurement without indicating how the measurement was taken. For example, the following statement about solar intensity at the earth's surface without specifying the sun's elevation could be annotated with the following tag:\nThe templates' pages will almost always have additional documentation on usage and parameters. If not, you can leave a message on the template's talk page requesting such information be added.\nWhen using these templates, be specific: mark individual phrases, sentences, and sections in preference to entire articles.  Also be sure to leave specific suggestions for improvement on the article's talk-page.\nIt is always best to take care of something when you notice it, but that is not always possible. You can choose one of these templates that tag text with inline messages to request specific clarifications that you cannot provide yourself:\nThe aim of this page is to describe ways to clarify text or request such clarification. There are inline cleanup tags to flag specific wording that is likely to be confusing to the average reader.\n\n",
            "title": "Wikipedia:Please clarify",
            "url": "https://en.wikipedia.org/wiki/Wikipedia:Please_clarify"
        },
        {
            "desc_links": [
                "/wiki/Linear_regression",
                "/wiki/Linear_model",
                "/wiki/Parameter",
                "/wiki/Statistical_model",
                "/wiki/ANCOVA",
                "/wiki/Growth_curve_(statistics)",
                "/wiki/Repeated_measures",
                "/wiki/Multivariate_analysis",
                "/wiki/Nested_data"
            ],
            "desc_text": "b'Multilevel models (also known as hierarchical linear models, nested data models, mixed models, random coefficient, random-effects models, random parameter models, or split-plot designs) are statistical models of parameters that vary at more than one level.[1] An example could be a model of student performance that contains measures for individual students as well as measures for classrooms within which the students are grouped. These models can be seen as generalizations of linear models (in particular, linear regression), although they can also extend to non-linear models.  These models became much more popular after sufficient computing power and software became available.[1]\\n'b'Multilevel models are particularly appropriate for research designs where data for participants are organized at more than one level (i.e., nested data).[2] The units of analysis are usually individuals (at a lower level) who are nested within contextual/aggregate units (at a higher level).[3] While the lowest level of data in multilevel models is usually an individual, repeated measurements of individuals may also be examined.[2] As such, multilevel models provide an alternative type of analysis for univariate or multivariate analysis of repeated measures. Individual differences in growth curves may be examined.[2] Furthermore, multilevel models can be used as an alternative to ANCOVA, where scores on the dependent variable are adjusted for covariates (e.g. individual differences) before testing treatment differences.[4] Multilevel models are able to analyze these experiments without the assumptions of homogeneity-of-regression slopes that is required by ANCOVA.[2]\\n'b'Multilevel models can be used on data with many levels, although 2-level models are the most common and the rest of this article deals only with these. The dependent variable must be examined at the lowest level of analysis.[1]\\n'",
            "links": [
                "/wiki/Linear_regression",
                "/wiki/Linear_model",
                "/wiki/Parameter",
                "/wiki/Statistical_model",
                "/wiki/ANCOVA",
                "/wiki/Growth_curve_(statistics)",
                "/wiki/Repeated_measures",
                "/wiki/Multivariate_analysis",
                "/wiki/Nested_data",
                "/wiki/Model_selection",
                "/wiki/Bayesian_information_criterion",
                "/wiki/Akaike_information_criterion",
                "/wiki/Statistical_model#Nested_models",
                "/wiki/Likelihood-ratio_test",
                "/wiki/Linear_regression_model",
                "/wiki/ANOVA",
                "/wiki/Talk:Multilevel_model",
                "/wiki/Wikipedia:Disputed_statement",
                "/wiki/Homoscedasticity",
                "/wiki/T-test",
                "/wiki/Z-test",
                "/wiki/Educational_research",
                "/wiki/Variable_(mathematics)",
                "/wiki/Categorical_variable",
                "/wiki/Independent_variable",
                "/wiki/Hyperparameter",
                "/wiki/Mobile,_Alabama",
                "/wiki/Seattle",
                "/wiki/Latent_class_model",
                "/wiki/Structural_equation_modeling",
                "/wiki/Random_variable",
                "/wiki/Hierarchical_Bayesian_model",
                "/wiki/Industrial_and_organizational_psychology",
                "/wiki/Ecological_fallacy"
            ],
            "text": "Multilevel models have two error terms, which are also known as disturbances. The individual components are all independent, but there are also group components, which are independent between groups but correlated within groups. However, variance components can differ, as some groups are more homogeneous than others.[11]\nAnother way to analyze hierarchical data would be through a random-coefficients model. This model assumes that each group has a different regression model\u2014with its own intercept and slope.[4] Because groups are sampled, the model assumes that the intercepts and slopes are also randomly sampled from a population of group intercepts and slopes. This allows for an analysis in which one can assume that slopes are fixed but intercepts are allowed to vary.[4] However this presents a problem, as individual components are independent but group components are independent between groups, but dependent within groups. This also allows for an analysis in which the slopes are random; however, the correlations of the error terms (disturbances) are dependent on the values of the individual-level variables.[4] Thus, the problem with using a random-coefficients model in order to analyze hierarchical data is that is still not possible to incorporate higher order variables.\nThere are several alternative ways of analyzing hierarchical data, although most of them have some problems. First, traditional statistical techniques can be used. One could disaggregate higher-order variables to the individual level, and thus conduct an analysis on this individual level (for example, assign class variables to the individual level). The problem with this approach is that it would violate the assumption of independence, and thus could bias our results. This is known as atomistic fallacy.[10]  Another way to analyze the data using traditional statistical approaches is to aggregate individual level variables to higher-order variables and then to conduct an analysis on this higher level. The problem with this approach is that it discards all within-group information (because it takes the average of the individual level variables). As much as 80\u201390% of the variance could be wasted, and the relationship between aggregated variables is inflated, and thus distorted.[11] This is known as ecological fallacy, and statistically, this type of analysis results in decreased power in addition to the loss of information.[2]\nCross-level interactions may also be of substantive interest; for example, when a slope is allowed to vary randomly, a level-2 predictor may be included in the slope formula for the level-1 covariate. For example, one may estimate the interaction of race and neighborhood so that an estimate of the interaction between an individual's characteristics and the context.\nDifferent covariables may be relevant on different levels.  They can be used for longitudinal studies, as with growth studies, to separate changes within one individual and differences between individuals.\nMultilevel models have been used in education research or geographical research, to estimate separately the variance between pupils within the same school, and the variance between schools.  In psychological applications, the multiple levels are items in an instrument, individuals, and families. In sociological applications, multilevel models are used to examine individuals embedded within regions or countries. In organizational psychology research, data from individuals must often be nested within teams or other functional units.\nMultilevel models are a subclass of hierarchical Bayesian models, which are general models with multiple levels of random variables and arbitrary relationships among the different variables.  Multilevel analysis has been extended to include multilevel structural equation modeling, multilevel latent class modeling, and other more general models.\nIn other words, a simple linear regression model might, for example, predict that a given randomly sampled person in Seattle would have an average yearly income $10,000 higher than a similar person in Mobile, Alabama.  However, it would also predict, for example, that a white person might have an average income $7,000 above a black person, and a 65-year-old might have an income $3,000 below a 45-year-old, in both cases regardless of location.  A multilevel model, however, would allow for different regression coefficients for each predictor in each location.  Essentially, it would assume that people in a given location have correlated incomes generated by a single set of regression coefficients, whereas people in another location have incomes generated by a different set of coefficients.  Meanwhile, the coefficients themselves are assumed to be correlated and generated from a single set of hyperparameters.  Additional levels are possible: For example, people might be grouped by cities, and the city-level regression coefficients grouped by state, and the state-level coefficients generated from a single hyper-hyperparameter.\nAs a simple example, consider a basic linear regression model that predicts income as a function of age, class, gender and race.  It might then be observed that income levels also vary depending on the city and state of residence.  A simple way to incorporate this into the regression model would be to add an additional independent categorical variable to account for the location (i.e. a set of additional binary predictors and associated regression coefficients, one per location).  This would have the effect of shifting the mean income up or down\u2014but it would still assume, for example, that the effect of race and gender on income is the same everywhere.  In reality, this is unlikely to be the case\u2014different local laws, different retirement policies, differences in level of racial prejudice, etc. are likely to cause all of the predictors to have different sorts of effects in different locales.\nThe researcher must establish for each variable the level at which it was measured. In this example \"test score\" might be measured at pupil level, \"teacher experience\" at class level, \"school funding\" at school level, and \"urban\" at district level.\nHowever, if one were studying multiple schools and multiple school districts, a 4-level model could be:\nThe concept of level is the keystone of this approach. In an educational research example, the levels for a 2-level model might be:\nStatistical power for multilevel models differs depending on whether it is level 1 or level 2 effects that are being examined. Power for level 1 effects is dependent upon the number of individual observations, whereas the power for level 2 effects is dependent upon the number of groups.[9] To conduct research with sufficient power, large sample sizes are required in multilevel models. However, the number of individual observations in groups is not as important as the number of groups in a study. In order to detect cross-level interactions, given that the group sizes are not too small, recommendations have been made that at least 20 groups are needed.[9] The issue of statistical power in multilevel models is complicated by the fact that power varies as a function of effect size and intraclass correlations, it differs for fixed effects versus random effects, and it changes depending on the number of groups and the number of individual observations per group.[9]\nThe type of statistical tests that are employed in multilevel models depend on whether one is examining fixed effects or variance components. When examining fixed effects, the tests are compared with the standard error of the fixed effect, which results in a Z-test.[4] A t-test can also be computed. When computing a t-test, it is important to keep in mind the degrees of freedom, which will depend on the level of the predictor (e.g., level 1 predictor or level 2 predictor).[4] For a level 1 predictor, the degrees of freedom are based on the number of level 1 predictors, the number of groups and the number of individual observations. For a level 2 predictor, the degrees of freedom are based on the number of level 2 predictors and the number of groups.[4]\nIndependence is an assumption of general linear models, which states that cases are random samples from the population and that scores on the dependent variable are independent of each other.[6]  One of the main purposes of multilevel models is to deal with cases where the assumption of independence is violated; multilevel models do, however, assume that 1) the level 1 and level 2 residuals are uncorrelated and 2) The errors (as measured by the residuals) at the highest level are uncorrelated. [8]\nThe assumption of homoscedasticity, also known as homogeneity of variance, assumes equality of population variances.[6] However, different variance-correlation matrix can be specified to account for this, and the heterogeneity of variance can itself be modeled.\nThe assumption of normality states that the error terms at every level of the model are normally distributed.[6][disputed  \u2013 discuss]. However, most statistical software allows one to specify different distributions for the variance terms, such as a Poisson, binomial, logistic. The multilevel modelling approach can be used for all forms of Generalized Linear models. \nThe assumption of linearity states that there is a rectilinear (straight-line, as opposed to non-linear or U-shaped) relationship between variables.[6] However, the model can be extended to nonlinear relationships.[7]\nMultilevel models have the same assumptions as other major general linear models (e.g., ANOVA, regression), but some of the assumptions are modified for the hierarchical nature of the design (i.e., nested data).\nIn order to assess models, different model fit statistics would be examined.[2] One such statistic is the chi-square likelihood-ratio test, which assesses the difference between models. The likelihood-ratio test can be employed for model building in general, for examining what happens when effects in a model are allowed to vary, and when testing a dummy-coded categorical variable as a single effect.[2] However, the test can only be used when models are nested (meaning that a more complex model includes all of the effects of a simpler model). When testing non-nested models, comparisons between models can be made using the Akaike information criterion (AIC) or the Bayesian information criterion (BIC), among others.[1][2][4]  See further Model selection.\nIn order to conduct a multilevel model analysis, one would start with fixed coefficients (slopes and intercepts). One aspect would be allowed to vary at a time (that is, would be changed), and compared with the previous model in order to assess better model fit.[1] There are three different questions that a researcher would ask in assessing a model. First, is it a good model? Second, is a more complex model better? Third, what contribution do individual predictors make to the model?\nA model that includes both random intercepts and random slopes is likely the most realistic type of model, although it is also the most complex. In this model, both intercepts and slopes are allowed to vary across groups, meaning that they are different in different contexts.[4]\nA random slopes model is a model in which slopes are allowed to vary, and therefore, the slopes are different across groups. This model assumes that intercepts are fixed (the same across different contexts).[4]\nA random intercepts model is a model in which intercepts are allowed to vary, and therefore, the scores on the dependent variable for each individual observation are predicted by the intercept that varies across groups.[4][5] This model assumes that slopes are fixed (the same across different contexts). In addition, this model provides information about intraclass correlations, which are helpful in determining whether multilevel models are required in the first place.[2]\nBefore conducting a multilevel model analysis, a researcher must decide on several aspects, including which predictors are to be included in the analysis, if any. Second, the researcher must decide whether parameter values (i.e., the elements that will be estimated) will be fixed or random.[2][4] Fixed parameters are composed of a constant over all the groups, whereas a random parameter has a different value for each of the groups. Additionally, the researcher must decide whether to employ a maximum likelihood estimation or a restricted maximum likelihood estimation type.[2]\nThe dependent variables are the intercepts and the slopes for the independent variables at Level 1 in the groups of Level 2.\nWhen there are multiple level 1 independent variables, the model can be expanded by substituting vectors and matrices in the equation.\nAt Level 1, both the intercepts and slopes in the groups can be either fixed (meaning that all groups have the same values, although in the real world this would be a rare occurrence), non-randomly varying (meaning that the intercepts and/or slopes are predictable from an independent variable at Level 2), or randomly varying (meaning that the intercepts and/or slopes are different in the different groups, and that each have their own overall mean and variance).[2]\nWhen there is a single level 1 independent variable, the level 1 model is:\nMultilevel models can be used on data with many levels, although 2-level models are the most common and the rest of this article deals only with these. The dependent variable must be examined at the lowest level of analysis.[1]\nMultilevel models are particularly appropriate for research designs where data for participants are organized at more than one level (i.e., nested data).[2] The units of analysis are usually individuals (at a lower level) who are nested within contextual/aggregate units (at a higher level).[3] While the lowest level of data in multilevel models is usually an individual, repeated measurements of individuals may also be examined.[2] As such, multilevel models provide an alternative type of analysis for univariate or multivariate analysis of repeated measures. Individual differences in growth curves may be examined.[2] Furthermore, multilevel models can be used as an alternative to ANCOVA, where scores on the dependent variable are adjusted for covariates (e.g. individual differences) before testing treatment differences.[4] Multilevel models are able to analyze these experiments without the assumptions of homogeneity-of-regression slopes that is required by ANCOVA.[2]\nMultilevel models (also known as hierarchical linear models, nested data models, mixed models, random coefficient, random-effects models, random parameter models, or split-plot designs) are statistical models of parameters that vary at more than one level.[1] An example could be a model of student performance that contains measures for individual students as well as measures for classrooms within which the students are grouped. These models can be seen as generalizations of linear models (in particular, linear regression), although they can also extend to non-linear models.  These models became much more popular after sufficient computing power and software became available.[1]\n",
            "title": "Multilevel model",
            "url": "https://en.wikipedia.org/wiki/Hierarchical_linear_models"
        },
        {
            "desc_links": [],
            "desc_text": "",
            "links": [],
            "text": "",
            "title": "Errors-in-variables models",
            "url": "https://en.wikipedia.org/wiki/Errors-in-variables_model"
        },
        {
            "desc_links": [],
            "desc_text": "",
            "links": [],
            "text": "",
            "title": "Efficiency (statistics)",
            "url": "https://en.wikipedia.org/wiki/Efficiency_(statistics)"
        },
        {
            "desc_links": [
                "/wiki/Convergence_in_probability",
                "/wiki/Estimator",
                "/wiki/Statistics",
                "/wiki/Sample_size",
                "/wiki/Bias_of_an_estimator",
                "/wiki/Almost_sure_convergence"
            ],
            "desc_text": "b'In statistics, a consistent estimator or asymptotically  consistent estimator is an estimator\\xe2\\x80\\x94a rule for computing estimates of a parameter \\xce\\xb80\\xe2\\x80\\x94having the property that as the number of data points used increases indefinitely, the resulting sequence of estimates converges in probability to \\xce\\xb80. This means that the distributions of the estimates become more and more concentrated near the true value of the parameter being estimated, so that the probability of the estimator being arbitrarily close to \\xce\\xb80 converges to one.\\n'b'In practice one constructs an estimator as a function of an available sample of size n, and then imagines being able to keep collecting data and expanding the sample ad infinitum. In this way one would obtain a sequence of estimates indexed by n, and consistency is a property of what occurs as the sample size \\xe2\\x80\\x9cgrows to infinity\\xe2\\x80\\x9d. If the sequence of estimates can be mathematically shown to converge in probability to the true value \\xce\\xb80, it is called a consistent estimator; otherwise the estimator is said to be inconsistent.\\n'b'Consistency as defined here is sometimes referred to as weak consistency. When we replace convergence in probability with almost sure convergence, then the estimator is said to be strongly consistent. Consistency is related to bias; see bias versus consistency.\\n'",
            "links": [
                "/wiki/Convergence_in_probability",
                "/wiki/Estimator",
                "/wiki/Statistics",
                "/wiki/Sample_size",
                "/wiki/Bias_of_an_estimator",
                "/wiki/Almost_sure_convergence",
                "/wiki/Convergence_in_probability",
                "/wiki/Estimator",
                "/wiki/Statistical_sample",
                "/wiki/Parametric_model",
                "/wiki/Sample_mean",
                "/wiki/Normal_distribution",
                "/wiki/Chebyshev%27s_inequality",
                "/wiki/Markov_inequality",
                "/wiki/Iid",
                "/wiki/Biased_estimator",
                "/wiki/Degrees_of_freedom_(statistics)",
                "/wiki/Bessel%27s_correction",
                "/wiki/Sample_standard_deviation",
                "/wiki/Sample_variance"
            ],
            "text": "Important examples include the sample variance and sample standard deviation. Without Bessel's correction (that is, when using the sample size n instead of the degrees of freedom n\u00a0\u2212\u00a01), these are both negatively biased but consistent estimators. With the correction, the corrected sample variance is unbiased, while the corrected sample standard deviation is still biased, but less so, and both are still consistent: the correction factor converges to 1 as sample size grows.\nHowever, if a sequence of estimators is unbiased and converges to a value, then it is consistent, as it must converge to the correct value.\nAn estimator can be unbiased but not consistent. For example, for an iid sample {x1,..., xn} one can use T(X) = x1 as the estimator of the mean E[x]. Note that here the sampling distribution of T is the same as the underlying distribution (for any n, as it ignores all points but the first), so E[T(X)] = E[x] and it is unbiased, but it does not converge to any value.\nthe most common choice for function h being either the absolute value (in which case it is known as Markov inequality), or the quadratic function (respectively Chebyshev's inequality).\nThe notion of asymptotic consistency is very close, almost synonymous to the notion of convergence in probability. As such, any theorem, lemma, or property which establishes convergence in probability may be used to prove the consistency. Many such tools exist:\nSuppose one has a sequence of observations {X1, X2, ...} from a normal N(\u03bc,\u2009\u03c32) distribution. To estimate \u03bc based on the first n observations, one can use the sample mean: Tn\u00a0=\u00a0(X1 + ... + Xn)/n. This defines a sequence of estimators, indexed by the sample size n.\nThis definition uses g(\u03b8) instead of simply \u03b8, because often one is interested in estimating a certain function or a sub-vector of the underlying parameter. In the next example we estimate the location parameter of the model, but not the scale:\nA more rigorous definition takes into account the fact that \u03b8 is actually unknown, and thus the convergence in probability must take place for every possible value of this parameter. Suppose {p\u03b8: \u03b8\u2009\u2208\u2009\u0398} is a family of distributions (the parametric model), and X\u03b8 = {X1, X2, \u2026\u00a0: Xi ~ p\u03b8} is an infinite sample from the distribution p\u03b8. Let {\u2009Tn(X\u03b8)\u2009} be a sequence of estimators for some parameter g(\u03b8). Usually Tn will be based on the first n observations of a sample. Then this sequence {Tn} is said to be (weakly) consistent if [2]\nLoosely speaking, an estimator Tn of parameter \u03b8 is said to be consistent, if it converges in probability to the true value of the parameter:[1]\nConsistency as defined here is sometimes referred to as weak consistency. When we replace convergence in probability with almost sure convergence, then the estimator is said to be strongly consistent. Consistency is related to bias; see bias versus consistency.\nIn practice one constructs an estimator as a function of an available sample of size n, and then imagines being able to keep collecting data and expanding the sample ad infinitum. In this way one would obtain a sequence of estimates indexed by n, and consistency is a property of what occurs as the sample size \u201cgrows to infinity\u201d. If the sequence of estimates can be mathematically shown to converge in probability to the true value \u03b80, it is called a consistent estimator; otherwise the estimator is said to be inconsistent.\nIn statistics, a consistent estimator or asymptotically  consistent estimator is an estimator\u2014a rule for computing estimates of a parameter \u03b80\u2014having the property that as the number of data points used increases indefinitely, the resulting sequence of estimates converges in probability to \u03b80. This means that the distributions of the estimates become more and more concentrated near the true value of the parameter being estimated, so that the probability of the estimator being arbitrarily close to \u03b80 converges to one.\n",
            "title": "Consistent estimator",
            "url": "https://en.wikipedia.org/wiki/Consistent_estimator"
        },
        {
            "desc_links": [
                "/wiki/System",
                "/wiki/Ancient_Greek_language",
                "/wiki/Attribute_(disambiguation)",
                "/wiki/Function_(disambiguation)#Math,_computing_and_engineering",
                "/wiki/Variable_(disambiguation)",
                "/wiki/Axiom",
                "/wiki/Property_(disambiguation)#Philosophy_and_science",
                "/wiki/Argument",
                "/wiki/Linguistics",
                "/wiki/Logic",
                "/wiki/Statistics",
                "/wiki/Engineering",
                "/wiki/Computer_programming",
                "/wiki/Computing",
                "/wiki/Mathematics"
            ],
            "desc_text": "b'A parameter (from the Ancient Greek \\xcf\\x80\\xce\\xb1\\xcf\\x81\\xce\\xac, para: \"beside\", \"subsidiary\"; and \\xce\\xbc\\xce\\xad\\xcf\\x84\\xcf\\x81\\xce\\xbf\\xce\\xbd, metron: \"measure\"), generally, is any characteristic that can help in defining or classifying a particular system (meaning an event, project, object, situation, etc.). That is, a parameter is an element of a system that is useful, or critical, when identifying the system, or when evaluating its performance, status, condition, etc.\\n'b'Parameter has more specific meanings within various disciplines, including mathematics, computing and computer programming, engineering, statistics, logic and linguistics. Within and across these fields, careful distinction must be maintained of the different usages of the term parameter and of other terms often associated with it, such as argument,  property, axiom, variable, function, attribute, etc.[1]\\n'",
            "links": [
                "/wiki/System",
                "/wiki/Ancient_Greek_language",
                "/wiki/Attribute_(disambiguation)",
                "/wiki/Function_(disambiguation)#Math,_computing_and_engineering",
                "/wiki/Variable_(disambiguation)",
                "/wiki/Axiom",
                "/wiki/Property_(disambiguation)#Philosophy_and_science",
                "/wiki/Argument",
                "/wiki/Linguistics",
                "/wiki/Logic",
                "/wiki/Statistics",
                "/wiki/Engineering",
                "/wiki/Computer_programming",
                "/wiki/Computing",
                "/wiki/Mathematics",
                "/wiki/Quadratic_function",
                "/wiki/Variable_(mathematics)",
                "/wiki/Argument_of_a_function",
                "/wiki/Mathematical_function",
                "/wiki/Falling_factorial_power",
                "/wiki/Polynomial#Polynomial_functions",
                "/wiki/Currying",
                "/wiki/Indexed_family",
                "/wiki/Probability_distribution",
                "/wiki/Mathematical_model",
                "/wiki/Curve",
                "/wiki/Analytic_geometry",
                "/wiki/Independent_variable",
                "/wiki/Parametric_equations",
                "/wiki/Mathematical_analysis",
                "/wiki/Bound_variable",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Bayesian_probability",
                "/wiki/Frequentist_inference",
                "/wiki/Hypothesis_testing",
                "/wiki/Statistical_estimation",
                "/wiki/Econometrics",
                "/wiki/Statistics",
                "/wiki/Statistical_population",
                "/wiki/Statistic",
                "/wiki/Estimand",
                "/wiki/Estimator",
                "/wiki/Estimation_theory",
                "/wiki/Correlation_and_dependence",
                "/wiki/Pearson_product-moment_correlation_coefficient",
                "/wiki/Spearman%27s_rank_correlation_coefficient",
                "/wiki/Parametric_statistics",
                "/wiki/Non-parametric_statistics",
                "/wiki/Probability_distribution",
                "/wiki/Probability_mass_function",
                "/wiki/Poisson_distribution",
                "/wiki/Probability_distribution",
                "/wiki/Random_variable",
                "/wiki/Probability_distribution",
                "/wiki/Probability_theory",
                "/wiki/Radioactivity",
                "/wiki/Normal_distribution",
                "/wiki/Statistical_parameter",
                "/wiki/Cumulant",
                "/wiki/Moment_(mathematics)",
                "/wiki/Parameter_(computer_programming)#Parameters_and_arguments",
                "/wiki/Parameter_(computer_programming)",
                "/wiki/Computer_programming",
                "/wiki/Parameter_(computer_programming)#Alternative_convention_in_Eiffel",
                "/wiki/Eiffel_(programming_language)",
                "/wiki/C_(programming_language)",
                "/wiki/Combinatory_logic",
                "/wiki/Lambda_calculus",
                "/wiki/Functional_programming",
                "/wiki/Engineering",
                "/wiki/Percentile",
                "/wiki/Statistics",
                "/wiki/Microbiology",
                "/wiki/Chemistry",
                "/wiki/Principles_and_Parameters",
                "/wiki/Universal_Grammar",
                "/wiki/Bound_variable",
                "/wiki/Free_variable",
                "/wiki/Lawrence_Paulson",
                "/wiki/Dag_Prawitz",
                "/wiki/Logic",
                "/wiki/George_Perle",
                "/wiki/Paul_Lansky",
                "/wiki/Serial_music",
                "/wiki/Timbre",
                "/wiki/Duration_(music)",
                "/wiki/Loudness",
                "/wiki/Pitch_(music)"
            ],
            "text": "In music theory, a parameter denotes an element which may be manipulated (composed), separately from the other elements. The term is used particularly for pitch, loudness, duration, and timbre, though theorists or composers have sometimes considered other musical aspects as parameters. The term is particularly used in serial music, where each parameter may follow some specified series. Paul Lansky and George Perle criticized the extension of the word \"parameter\" to this sense, since it is not closely related to its mathematical sense,[4] but it remains common.  The term is also common in music production, as the functions of audio processing units (such as the attack, release, ratio, threshold, and other variables on a compressor) are defined by parameters specific to the type of unit (compressor, equalizer, delay, etc.).\nIn logic, the parameters passed to (or operated on by) an open predicate are called parameters by some authors (e.g., Prawitz, \"Natural Deduction\"; Paulson, \"Designing a theorem prover\"). Parameters locally defined within the predicate are called variables. This extra distinction pays off when defining substitution (without this distinction special provision must be made to avoid variable capture). Others (maybe most) just call parameters passed to (or operated on by) an open predicate variables, and when defining substitution have to distinguish between free variables and bound variables.\nWithin linguistics, the word \"parameter\" is almost exclusively used to denote a binary switch in a Universal Grammar within a Principles and Parameters framework.\nIn environmental science and particularly in chemistry and microbiology, a parameter is used to describe a discrete chemical or microbiological entity that can be assigned a value: commonly a concentration, but may also be a logical entity (present or absent), a statistical result such as a 95%ile value or in some cases a subjective value.\nThe term can also be used in engineering contexts, however, as it is typically used in the physical sciences.\n\"Speaking generally, properties are those physical quantities which directly describe the physical attributes of the system; parameters are those combinations of the properties which suffice to determine the response of the system. Properties can have all sorts of dimensions, depending upon the system being considered; parameters are dimensionless, or have the dimension of time or its reciprocal.\"[3]\nIn engineering (especially involving data acquisition) the term parameter sometimes loosely refers to an individual measured item. This usage isn't consistent, as sometimes the term channel refers to an individual measured item, with parameter referring to the setup information about that channel.\nThese concepts are discussed in a more precise way in functional programming and its foundational disciplines, lambda calculus and combinatory logic. Terminology varies between languages; some computer languages such as C define parameter and argument as given here, while Eiffel uses an alternative convention.\n3 is the actual parameter (the argument) for evaluation by the defined function; it is a given value (actual value) that is substituted for the formal parameter of the defined function. (In casual usage the terms parameter and argument might inadvertently be interchanged, and thereby used incorrectly.)\nWhen the function is evaluated for a given value, as in\nx is the formal parameter (the parameter) of the defined function.\nFor example, in the definition of a function such as\nIn computer programming, two notions of parameter are commonly used, and are referred to as parameters and arguments\u2014or more formally as a formal parameter and an actual parameter.\nIn computing, a parameter is defined as  \"a reference or value that is passed to a function, procedure, subroutine, command, or program\".[1]  For example, the name of a file, (a parameter), is passed to a computer program, which then performs a specific function; that is, a program may be passed the name of a file on which it will perform the specific function.\nIt is possible to use the sequence of moments (mean, mean square, ...) or cumulants (mean, variance, ...) as parameters for a probability distribution: see Statistical parameter.\nIn these above examples, the distributions of the random variables are completely specified by the type of distribution, i.e. Poisson or normal, and the parameter values, i.e. mean and variance.  In such a case, we have a parameterized distribution.\nAnother common distribution is the normal distribution, which has as parameters the mean \u03bc and the variance \u03c3\u00b2.\nFor instance, suppose we have a radioactive sample that emits, on average, five particles every ten minutes.  We take measurements of how many particles the sample emits over ten-minute periods.  The measurements exhibit different values of k, and if the sample behaves according to Poisson statistics, then each value of k will come up in a proportion given by the probability mass function above.  From measurement to measurement, however, \u03bb remains constant at 5.  If we do not alter the system, then the parameter \u03bb is unchanged from measurement to measurement; if, on the other hand, we modulate the system by replacing the sample with a more radioactive one, then the parameter \u03bb would increase.\nIn probability theory, one may describe the distribution of a random variable as belonging to a family of probability distributions, distinguished from each other by the values of a finite number of parameters. For example, one talks about \"a Poisson distribution with mean value \u03bb\".  The function defining the distribution (the probability mass function) is:\nIt is possible to make statistical inferences without assuming a particular parametric family of probability distributions. In that case, one speaks of non-parametric statistics as opposed to the parametric statistics just described. For example, a test based on Spearman's rank correlation coefficient would be called non-parametric since the statistic is computed from the rank-order of the data disregarding their actual values (and thus regardless of the distribution they were sampled from), whereas those based on the Pearson product-moment correlation coefficient are parametric tests since it is computed directly from the data values and thus estimates the parameter known as the population correlation.\nIn estimation theory of statistics, \"statistic\" or estimator refers to samples, whereas \"parameter\" or estimand refers to populations, where the samples are taken from. A statistic is a numerical characteristic of a sample that can be used as an estimate of the corresponding parameter, the numerical characteristic of the population from which the sample was drawn.\nIn statistics and econometrics, the probability framework above still holds, but attention shifts to estimating the parameters of a distribution based on observed data, or testing hypotheses about them. In frequentist estimation parameters are considered \"fixed but unknown\", whereas in Bayesian estimation they are treated as random variables, and their uncertainty is described as a distribution.[citation needed]\nIn this formula, t is the argument of the function F, and on the right-hand side the parameter on which the integral depends. When evaluating the integral, t is held constant, and so it is considered to be a parameter.  If we are interested in the value of F for different values of t, we then consider t to be a variable. The quantity x is a dummy variable or variable of integration (confusingly, also sometimes called a parameter of integration).\nIn mathematical analysis, integrals dependent on a parameter are often considered. These are of the form\nHence these equations, which might be called functions elsewhere are in analytic geometry characterized as parametric equations and the independent variables are considered as parameters.\nIn analytic geometry, curves are often given as the image of some function. The argument of the function is invariably called \"the parameter\". A circle of radius 1 centered at the origin can be specified in more than one form:\nIn the context of a mathematical model, such as a probability distribution, the distinction between variables and parameters was described by Bard as follows:\nSometimes it is useful to consider all functions with certain parameters as parametric family, i.e. as an indexed family of functions. Examples from probability theory are given further below.\nas the most fundamental object being considered, then defining functions with fewer variables from the main one by means of currying.\ndefines a polynomial function of n (when k is considered a parameter), but is not a polynomial function of k (when n is considered a parameter). Indeed, in the latter case, it is only defined for non-negative integer arguments. More formal presentations of such situations typically start out with a function of several variables (including all those that might sometimes be called \"parameters\") such as\nIn some informal situations it is a matter of convention (or historical accident) whether some or all of the symbols in a function definition are called parameters. However, changing the status of symbols between parameter and variable changes the function as a mathematical object. For instance, the notation for the falling factorial power\nHere, the variable x designates the function's argument, but a, b, and c are parameters that determine which particular quadratic function is being considered. A parameter could be incorporated into the function name to indicate its dependence on the parameter. For instance, one may define the base-b logarithm by the formula\nMathematical functions have one or more arguments that are designated in the definition by variables. A function definition can also contain parameters, but unlike variables, parameters are not listed among the arguments that the function takes. When parameters are present, the definition actually defines a whole family of functions, one for every valid set of values of the parameters. For instance, one could define a general quadratic function by declaring\nParameter has more specific meanings within various disciplines, including mathematics, computing and computer programming, engineering, statistics, logic and linguistics. Within and across these fields, careful distinction must be maintained of the different usages of the term parameter and of other terms often associated with it, such as argument,  property, axiom, variable, function, attribute, etc.[1]\nA parameter (from the Ancient Greek \u03c0\u03b1\u03c1\u03ac, para: \"beside\", \"subsidiary\"; and \u03bc\u03ad\u03c4\u03c1\u03bf\u03bd, metron: \"measure\"), generally, is any characteristic that can help in defining or classifying a particular system (meaning an event, project, object, situation, etc.). That is, a parameter is an element of a system that is useful, or critical, when identifying the system, or when evaluating its performance, status, condition, etc.\n",
            "title": "Parameter",
            "url": "https://en.wikipedia.org/wiki/Parameter"
        },
        {
            "desc_links": [
                "/wiki/Dow_Jones_Industrial_Average",
                "/wiki/Sunspots",
                "/wiki/Tides",
                "/wiki/Discrete-time",
                "/wiki/Sequence",
                "/wiki/Data_point",
                "/wiki/Time",
                "/wiki/Engineering",
                "/wiki/Applied_science",
                "/wiki/Communications_engineering",
                "/wiki/Astronomy",
                "/wiki/Control_engineering",
                "/wiki/Electroencephalography",
                "/wiki/Earthquake_prediction",
                "/wiki/Weather_forecasting",
                "/wiki/Mathematical_finance",
                "/wiki/Econometrics",
                "/wiki/Pattern_recognition",
                "/wiki/Signal_processing",
                "/wiki/Statistics",
                "/wiki/Line_chart",
                "/wiki/Interrupted_time_series",
                "/wiki/Regression_analysis",
                "/wiki/Model_(abstract)",
                "/wiki/Time_reversibility",
                "/wiki/Stochastic",
                "/wiki/Spatial_data_analysis",
                "/wiki/Cross-sectional_study",
                "/wiki/English_language",
                "/wiki/Data_type#Numeric_types",
                "/wiki/Real_number"
            ],
            "desc_text": "b'A time series is a series of data points indexed (or listed or graphed) in time order.  Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data. Examples of time series are heights of ocean tides, counts of sunspots, and the daily closing value of the Dow Jones Industrial Average.\\n'b'Time series are very frequently plotted via line charts. Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and largely in any domain of applied science and engineering which involves temporal measurements.\\n'b'Time series analysis comprises methods for analyzing time series data in order to extract meaningful statistics and other characteristics of the data. Time series forecasting is the use of a model to predict future values based on previously observed values. While regression analysis is often employed in such a way as to test theories that the current values of one or more independent time series affect the current value of another time series, this type of analysis of time series is not called \"time series analysis\", which focuses on comparing values of a single time series or multiple dependent time series at different points in time.[1] Interrupted time series analysis is the analysis of interventions on a single time series.\\n'b\"Time series data have a natural temporal ordering.  This makes time series analysis distinct from cross-sectional studies, in which there is no natural ordering of the observations (e.g. explaining people's wages by reference to their respective education levels, where the individuals' data could be entered in any order).  Time series analysis is also distinct from spatial data analysis where the observations typically relate to geographical locations (e.g. accounting for house prices by the location as well as the intrinsic characteristics of the houses). A stochastic model for a time series will generally reflect the fact that observations close together in time will be more closely related than observations further apart. In addition, time series models will often make use of the natural one-way ordering of time so that values for a given period will be expressed as deriving in some way from past values, rather than from future values (see time reversibility.)\\n\"b'Time series analysis can be applied to real-valued, continuous data, discrete numeric data, or discrete symbolic data (i.e. sequences of characters, such as letters and words in the English language[2]).\\n'",
            "links": [
                "/wiki/Dow_Jones_Industrial_Average",
                "/wiki/Sunspots",
                "/wiki/Tides",
                "/wiki/Discrete-time",
                "/wiki/Sequence",
                "/wiki/Data_point",
                "/wiki/Time",
                "/wiki/Engineering",
                "/wiki/Applied_science",
                "/wiki/Communications_engineering",
                "/wiki/Astronomy",
                "/wiki/Control_engineering",
                "/wiki/Electroencephalography",
                "/wiki/Earthquake_prediction",
                "/wiki/Weather_forecasting",
                "/wiki/Mathematical_finance",
                "/wiki/Econometrics",
                "/wiki/Pattern_recognition",
                "/wiki/Signal_processing",
                "/wiki/Statistics",
                "/wiki/Line_chart",
                "/wiki/Interrupted_time_series",
                "/wiki/Regression_analysis",
                "/wiki/Model_(abstract)",
                "/wiki/Time_reversibility",
                "/wiki/Stochastic",
                "/wiki/Spatial_data_analysis",
                "/wiki/Cross-sectional_study",
                "/wiki/English_language",
                "/wiki/Data_type#Numeric_types",
                "/wiki/Real_number",
                "/wiki/Scaled_correlation",
                "/wiki/Cross-correlation",
                "/wiki/Auto-correlation",
                "/wiki/Wavelet_analysis",
                "/wiki/Frequency_spectrum#Spectrum_analysis",
                "/wiki/Time-domain",
                "/wiki/Frequency-domain",
                "/wiki/Spectrum",
                "/wiki/Covariance",
                "/wiki/Non-parametric_statistics",
                "/wiki/Moving_average",
                "/wiki/Autoregressive",
                "/wiki/Stationary_process",
                "/wiki/Parametric_estimation",
                "/wiki/Non-parametric_statistics",
                "/wiki/Parametric_estimation",
                "/wiki/Multivariate_analysis",
                "/wiki/Univariate_analysis",
                "/wiki/Nonlinear_regression",
                "/wiki/Linear_regression",
                "/wiki/Cross-sectional_data",
                "/wiki/Panel_data",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Forecasting",
                "/wiki/Anomaly_detection",
                "/wiki/Statistical_classification",
                "/wiki/Cluster_analysis",
                "/wiki/Machine_learning",
                "/wiki/Pattern_recognition",
                "/wiki/Data_mining",
                "/wiki/Estimation",
                "/wiki/Communication_engineering",
                "/wiki/Control_engineering",
                "/wiki/Signal_processing",
                "/wiki/Forecasting",
                "/wiki/Geophysics",
                "/wiki/Meteorology",
                "/wiki/Seismology",
                "/wiki/Quantitative_finance",
                "/wiki/Econometrics",
                "/wiki/Statistics",
                "/wiki/Line_chart",
                "/wiki/Uncertainty",
                "/wiki/Range_(mathematics)",
                "/wiki/Extrapolation",
                "/wiki/Statistical_inference",
                "/wiki/Regression_analysis",
                "/wiki/Smoothing",
                "/wiki/Interpolation",
                "/wiki/Data",
                "/wiki/Function_(mathematics)",
                "/wiki/Curve",
                "/wiki/Polynomial_regression",
                "/wiki/Polynomial",
                "/wiki/Spline_interpolation",
                "/wiki/Polynomial_interpolation",
                "/wiki/Interpolation",
                "/wiki/Uncertainty",
                "/wiki/Interpolation",
                "/wiki/Extrapolation",
                "/wiki/Rational_function",
                "/wiki/Polynomial",
                "/wiki/Special_function",
                "/wiki/Numerical_analysis",
                "/wiki/Approximation_theory",
                "/wiki/Function_(mathematics)",
                "/wiki/Statistical_classification",
                "/wiki/Codomain",
                "/wiki/Curve_fitting",
                "/wiki/Regression_analysis",
                "/wiki/Extrapolation",
                "/wiki/Interpolation",
                "/wiki/Real_number",
                "/wiki/Codomain",
                "/wiki/Domain_of_a_function",
                "/wiki/Supervised_learning",
                "/wiki/Statistical_learning_theory",
                "/wiki/Fitness_approximation",
                "/wiki/Statistical_classification",
                "/wiki/Regression_analysis",
                "/wiki/Forecasting",
                "/wiki/Predictive_inference",
                "/wiki/Statistical_inference",
                "/wiki/Prediction",
                "/wiki/Statistics",
                "/wiki/Sign_language",
                "/wiki/Digital_signal_processing",
                "/wiki/Estimation_theory",
                "/wiki/Kalman_filter",
                "/wiki/Dennis_Gabor",
                "/wiki/Rudolf_E._K%C3%A1lm%C3%A1n",
                "/wiki/Norbert_Wiener",
                "/wiki/World_War_II",
                "/wiki/Spectral_density_estimation",
                "/wiki/Fourier_transform",
                "/wiki/Frequency_domain",
                "/wiki/Harmonic_analysis",
                "/wiki/Change_detection",
                "/wiki/Vector_autoregression",
                "/wiki/Autoregressive_fractionally_integrated_moving_average",
                "/wiki/Autoregressive_integrated_moving_average",
                "/wiki/Autoregressive_moving_average",
                "/wiki/Moving_average_model",
                "/wiki/Autoregressive",
                "/wiki/Stochastic_processes",
                "/wiki/Nonlinear_autoregressive_exogenous_model",
                "/wiki/Chaos_theory",
                "/wiki/Doubly_stochastic_model",
                "/wiki/GARCH",
                "/wiki/Autoregressive_conditional_heteroskedasticity",
                "/wiki/Heteroskedasticity",
                "/wiki/Markov_switching_multifractal",
                "/wiki/Speech_recognition",
                "/wiki/Dynamic_Bayesian_network",
                "/wiki/Hidden_Markov_model",
                "/wiki/Natural_number",
                "/wiki/Index_set",
                "/wiki/Stationary_process#Weaker_forms_of_stationarity",
                "/wiki/Strict_stationarity",
                "/wiki/Time%E2%80%93frequency_representation",
                "/wiki/Time-frequency_analysis",
                "/wiki/Cyclostationary_process",
                "/wiki/Regression_analysis",
                "/wiki/Classification_(machine_learning)",
                "/wiki/Features_(pattern_recognition)"
            ],
            "text": "Working with Time Series data is a relatively common use for statistical analysis software. As a result of this, there are many offerings both commercial and open source. Some examples include:\nTime series can be visualized with two categories of chart: Overlapping Charts and Separated Charts. Overlapping Charts display all-time series on the same layout while Separated Charts presents them on different layouts (but aligned for comparison purpose)[36]\nTime series metrics or features that can be used for time series classification or regression analysis:[32]\nTools for investigating time-series data include:\nIn addition, time-series analysis can be applied where the series are seasonally stationary or non-stationary. Situations where the amplitudes of frequency components change with time can be dealt with in time-frequency analysis which makes use of a time\u2013frequency representation of a time-series or signal.[28]\nHowever, ideas of stationarity must be expanded to consider two important ideas: strict stationarity and second-order stationarity. Both models and applications can be developed under each of these conditions, although the models in the latter case might be considered as only partly specified.\nThere are two sets of conditions under which much of the theory is built:\nwhere T is the index set.\nAnother common notation is\nA number of different notations are in use for time-series analysis. A common notation specifying a time series X that is indexed by the natural numbers is written\nA Hidden Markov model (HMM) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (hidden) states. An HMM can be considered as the simplest dynamic Bayesian network. HMM models are widely used in speech recognition, for translating a time series of spoken words into text.\nIn recent work on model-free analyses, wavelet transform based methods (for example locally stationary wavelets and wavelet decomposed neural networks) have gained favor. Multiscale (often referred to as multiresolution) techniques decompose a given time series, attempting to illustrate time dependence at multiple scales. See also Markov switching multifractal (MSMF) techniques for modeling volatility evolution.\nAmong other types of non-linear time series models, there are models to represent the changes of variance over time (heteroskedasticity). These models represent autoregressive conditional heteroskedasticity (ARCH) and the collection comprises a wide variety of representation (GARCH, TARCH, EGARCH, FIGARCH, CGARCH, etc.). Here changes in variability are related to, or predicted by, recent past values of the observed series. This is in contrast to other possible representations of locally varying variability, where the variability might be modelled as being driven by a separate time-varying process, as in a doubly stochastic model.\nNon-linear dependence of the level of a series on previous data points is of interest, partly because of the possibility of producing a chaotic time series. However, more importantly, empirical investigations can indicate the advantage of using predictions derived from non-linear models, over those from linear models, as for example in nonlinear autoregressive exogenous models. Further references on nonlinear time series analysis: (Kantz and Schreiber),[26] and (Abarbanel)[27]\nModels for time series data can have many forms and represent different stochastic processes. When modeling variations in the level of a process, three broad classes of practical importance are the autoregressive (AR) models, the integrated (I) models, and the moving average (MA) models. These three classes depend linearly on previous data points.[25] Combinations of these ideas produce autoregressive moving average (ARMA) and autoregressive integrated moving average (ARIMA) models. The autoregressive fractionally integrated moving average (ARFIMA) model generalizes the former three. Extensions of these classes to deal with vector-valued data are available under the heading of multivariate time-series models and sometimes the preceding acronyms are extended by including an initial \"V\" for \"vector\", as in VAR for vector autoregression. An additional set of extensions of these models is available for use where the observed time-series is driven by some \"forcing\" time-series (which may not have a causal effect on the observed series): the distinction from the multivariate case is that the forcing series may be deterministic or under the experimenter's control. For these models, the acronyms are extended with a final \"X\" for \"exogenous\".\nSplitting a time-series into a sequence of segments. It is often the case that a time-series can be represented as a sequence of individual segments, each with its own characteristic properties. For example, the audio signal from a conference call can be partitioned into pieces corresponding to the times during which each person was speaking. In time-series segmentation, the goal is to identify the segment boundary points in the time-series, and to characterize the dynamical properties associated with each segment. One can approach this problem using change-point detection, or by modeling the time-series as a more sophisticated system, such as a Markov jump linear system.\nThis approach is based on harmonic analysis and filtering of signals in the frequency domain using the Fourier transform, and spectral density estimation, the development of which was significantly accelerated during World War II by mathematician Norbert Wiener, electrical engineers Rudolf E. K\u00e1lm\u00e1n, Dennis Gabor and others for filtering signals from noise and predicting signal values at a certain point in time. See Kalman filter, Estimation theory, and Digital signal processing\nAssigning time series pattern to a specific category, for example identify a word based on series of hand movements in sign language.\nIn statistics, prediction is a part of statistical inference. One particular approach to such inference is known as predictive inference, but the prediction can be undertaken within any of the several approaches to statistical inference. Indeed, one description of statistics is that it provides a means of transferring knowledge about a sample of a population to the whole population, and to other related populations, which is not necessarily the same as prediction over time. When information is transferred across time, often to specific points in time, the process is known as forecasting.\nTo some extent the different problems (regression, classification, fitness approximation) have received a unified treatment in statistical learning theory, where they are viewed as supervised learning problems.\nSecond, the target function, call it g, may be unknown; instead of an explicit formula, only a set of points (a time series) of the form (x, g(x)) is provided.  Depending on the structure of the domain and codomain of g, several techniques for approximating g may be applicable.  For example, if g is an operation on the real numbers, techniques of interpolation, extrapolation, regression analysis, and curve fitting can be used.  If the codomain (range or target set) of g is a finite set, one is dealing with a classification problem instead. A related problem of online time series approximation[24] is to summarize the data in one-pass and construct an approximate representation that can support a variety of time series queries with bounds on worst-case error.\nIn general, a function approximation problem asks us to select a function among a well-defined class that closely matches (\"approximates\") a target function in a task-specific way.\nOne can distinguish two major classes of function approximation problems: First, for known target functions approximation theory  is the branch of numerical analysis that investigates how certain known functions (for example, special functions) can be approximated by a specific class of functions (for example, polynomials or rational functions) that often have desirable properties (inexpensive computation, continuity, integral and limit values, etc.).\nExtrapolation is the process of estimating, beyond the original observation range, the value of a variable on the basis of its relationship with another variable. It is similar to interpolation, which produces estimates between known observations, but extrapolation is subject to greater uncertainty and a higher risk of producing meaningless results.\nThe construction of economic time series involves the estimation of some components for some dates by interpolation between values (\"benchmarks\") for earlier and later dates. Interpolation is estimation of an unknown quantity between two known quantities (historical data), or drawing conclusions about missing information from the available information (\"reading between the lines\").[22] Interpolation is useful where the data surrounding the missing data is available and its trend, seasonality, and longer-term cycles are known. This is often done by using a related series known for all relevant dates.[23] Alternatively polynomial interpolation or spline interpolation is used where piecewise polynomial functions are fit into time intervals such that they fit smoothly together. A different problem which is closely related to interpolation is the approximation of a complicated function by a simple function (also called regression).The main difference between regression and interpolation is that polynomial regression gives a single polynomial that models the entire data set.  Spline interpolation, however, yield a piecewise continuous function composed of many polynomials to model the data set.\nCurve fitting[5][6] is the process of constructing a curve, or mathematical function, that has the best fit to a series of data points,[7] possibly subject to constraints.[8][9] Curve fitting can involve either interpolation,[10][11] where an exact fit to the data is required, or smoothing,[12][13] in which a \"smooth\" function is constructed that approximately fits the data.  A related topic is regression analysis,[14][15] which focuses more on questions of statistical inference such as how much uncertainty is present in a curve that is fit to data observed with random errors. Fitted curves can be used as an aid for data visualization,[16][17] to infer values of a function where no data are available,[18] and to summarize the relationships among two or more variables.[19] Extrapolation refers to the use of a fitted curve beyond the range of the observed data,[20] and is subject to a degree of uncertainty[21] since it may reflect the method used to construct the curve as much as it reflects the observed data.\nOther techniques include:\nThe clearest way to examine a regular time series manually is with a line chart such as the one shown for tuberculosis in the United States, made with a spreadsheet program. The number of cases was standardized to a rate per 100,000 and the percent change per year in this rate was calculated. The nearly steadily dropping line shows that the TB incidence was decreasing in most years, but the percent change in this rate varied by as much as +/- 10%, with 'surges' in 1975 and around the early 1990s. The use of both vertical axes allows the comparison of two time series in one graphic.\nIn the context of statistics, econometrics, quantitative finance, seismology, meteorology, and geophysics the primary goal of time series analysis is forecasting. In the context of signal processing, control engineering and communication engineering it is used for signal detection and estimation, while in the context of data mining, pattern recognition and machine learning  time series analysis can be used for clustering, classification, query by content, anomaly detection as well as forecasting[citation needed].\nThere are several types of motivation and data analysis available for time series which are appropriate for different purposes and etc.\nA time series is one type of panel data. Panel data is the general class, a multidimensional data set, whereas a time series data set is a one-dimensional panel (as is a cross-sectional dataset).  A data set may exhibit characteristics of both panel data and time series data.  One way to tell is to ask what makes one data record unique from the other records.  If the answer is the time data field, then this is a time series data set candidate.  If determining a unique record requires a time data field and an additional identifier which is unrelated to time (student ID, stock symbol, country code), then it is panel data candidate.  If the differentiation lies on the non-time identifier, then the data set is a cross-sectional data set candidate.\nMethods of time series analysis may also be divided into linear and non-linear, and univariate and multivariate.\nAdditionally, time series analysis techniques may be divided into parametric and non-parametric methods. The parametric approaches assume that the underlying stationary stochastic process has a certain structure which can be described using a small number of parameters (for example, using an autoregressive or moving average model). In these approaches, the task is to estimate the parameters of the model that describes the stochastic process. By contrast, non-parametric approaches explicitly estimate the covariance or the spectrum of the process without assuming that the process has any particular structure.\nMethods for time series analysis may be divided into two classes: frequency-domain methods and time-domain methods. The former include spectral analysis and wavelet analysis; the latter include auto-correlation and cross-correlation analysis. In the time domain, correlation and analysis can be made in a filter-like manner using scaled correlation, thereby mitigating the need to operate in the frequency domain.\nTime series analysis can be applied to real-valued, continuous data, discrete numeric data, or discrete symbolic data (i.e. sequences of characters, such as letters and words in the English language[2]).\nTime series data have a natural temporal ordering.  This makes time series analysis distinct from cross-sectional studies, in which there is no natural ordering of the observations (e.g. explaining people's wages by reference to their respective education levels, where the individuals' data could be entered in any order).  Time series analysis is also distinct from spatial data analysis where the observations typically relate to geographical locations (e.g. accounting for house prices by the location as well as the intrinsic characteristics of the houses). A stochastic model for a time series will generally reflect the fact that observations close together in time will be more closely related than observations further apart. In addition, time series models will often make use of the natural one-way ordering of time so that values for a given period will be expressed as deriving in some way from past values, rather than from future values (see time reversibility.)\nTime series analysis comprises methods for analyzing time series data in order to extract meaningful statistics and other characteristics of the data. Time series forecasting is the use of a model to predict future values based on previously observed values. While regression analysis is often employed in such a way as to test theories that the current values of one or more independent time series affect the current value of another time series, this type of analysis of time series is not called \"time series analysis\", which focuses on comparing values of a single time series or multiple dependent time series at different points in time.[1] Interrupted time series analysis is the analysis of interventions on a single time series.\nTime series are very frequently plotted via line charts. Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and largely in any domain of applied science and engineering which involves temporal measurements.\nA time series is a series of data points indexed (or listed or graphed) in time order.  Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data. Examples of time series are heights of ocean tides, counts of sunspots, and the daily closing value of the Dow Jones Industrial Average.\n",
            "title": "Time series",
            "url": "https://en.wikipedia.org/wiki/Time_series"
        },
        {
            "desc_links": [],
            "desc_text": "",
            "links": [],
            "text": "",
            "title": "Instrumental variables estimation",
            "url": "https://en.wikipedia.org/wiki/Instrumental_variables"
        },
        {
            "desc_links": [],
            "desc_text": "",
            "links": [
                "/wiki/Random_assignment",
                "/wiki/Adverse_drug_reactions",
                "/wiki/Health_intervention",
                "/wiki/Effectiveness",
                "/wiki/Efficacy#Medicine",
                "/wiki/Clinical_trial",
                "/wiki/Gold_standard_(test)",
                "/wiki/Scientific_control",
                "/wiki/Selection_bias",
                "/wiki/Randomized_experiment",
                "/wiki/Tossing_a_coin",
                "/wiki/Conceptually",
                "/wiki/Clinical_research",
                "/wiki/Clinical_trial",
                "/wiki/Scientific_literature",
                "/wiki/Scientific_control#Positive",
                "/wiki/Placebo-controlled_study",
                "/wiki/Scientific_control",
                "/wiki/Ronald_A._Fisher",
                "/wiki/Jerzy_Neyman",
                "/wiki/School_of_education",
                "/wiki/Charles_Sanders_Peirce",
                "/wiki/Experimental_psychology",
                "/wiki/Randomized_experiment",
                "/wiki/Scurvy",
                "/wiki/James_Lind",
                "/wiki/Clinical_trial",
                "/wiki/Austin_Bradford_Hill",
                "/wiki/Medical_Research_Council_(UK)",
                "/wiki/Tuberculosis",
                "/wiki/Streptomycin",
                "/wiki/Consolidated_Standards_of_Reporting_Trials",
                "/wiki/Cochrane_Library",
                "/wiki/Screening_(medicine)",
                "/wiki/Zelen%27s_design",
                "/wiki/Ethics",
                "/wiki/Clinical_equipoise",
                "/wiki/Therapeutic_misconception",
                "/wiki/Informed_consent",
                "/wiki/Study_design",
                "/wiki/PubMed",
                "/wiki/Effectiveness#Usage",
                "/wiki/Efficacy#Medicine",
                "/wiki/Statistical_significance",
                "/wiki/Randomized_experiment",
                "/wiki/Robust_statistics",
                "/wiki/Restricted_randomization",
                "/wiki/Lurking_variable",
                "/wiki/Objectivity_(philosophy)",
                "/wiki/Subjectivity",
                "/wiki/Meta-analysis",
                "/wiki/Clinical_trial_protocol",
                "/wiki/Null_hypothesis",
                "/wiki/Statistical_hypothesis_testing",
                "/wiki/Physical_therapy",
                "/wiki/Blind_experiment",
                "/wiki/Consolidated_Standards_of_Reporting_Trials",
                "/wiki/Multiple_sclerosis",
                "/wiki/Open-label_trial",
                "/wiki/Consolidated_Standards_of_Reporting_Trials",
                "/wiki/Consolidated_Standards_of_Reporting_Trials",
                "/wiki/Journal_of_the_American_Medical_Association",
                "/wiki/Observational_study",
                "/wiki/The_New_England_Journal_of_Medicine",
                "/wiki/Sample_size",
                "/wiki/Type_I_and_type_II_errors",
                "/wiki/Evidence-based_practice",
                "/wiki/Systematic_review",
                "/wiki/Hierarchy_of_evidence",
                "/wiki/Scientific_method",
                "/wiki/Gross_domestic_product",
                "/wiki/Per_capita",
                "/wiki/Quality-adjusted_life_year",
                "/wiki/Return_on_investment",
                "/wiki/Mean",
                "/wiki/National_Institute_of_Neurological_Disorders_and_Stroke",
                "/wiki/Phase_III",
                "/wiki/Sudden_infant_death_syndrome",
                "/wiki/Psychosocial",
                "/wiki/Diagnosis",
                "/wiki/Physical_examination",
                "/wiki/Patient_history",
                "/wiki/Medicine",
                "/wiki/Case_report",
                "/wiki/Randomized_controlled_trials",
                "/wiki/Cochrane_Collaboration",
                "/wiki/Publication_bias",
                "/wiki/Pharmaceutical_industry",
                "/wiki/Innovations_for_Poverty_Action",
                "/wiki/Abdul_Latif_Jameel_Poverty_Action_Lab",
                "/wiki/Development_economics",
                "/wiki/Political_corruption",
                "/wiki/Quasi-experimental_design",
                "/wiki/Critical_appraisal"
            ],
            "text": "Mock randomised controlled trials, or simulations using confectionery, can conducted in the classroom to teach students and health professionals the principles of RCT design and critical appraisal.[108]\nRCTs have been used in evaluating a number of educational interventions. Between 1980 and 2016, over 1,000 reports of RCTs have been published.[105]For example, a 2009 study randomized 260 elementary school teachers' classrooms to receive or not receive a program of behavioral screening, classroom intervention, and parent training, and then measured the behavioral and academic performance of their students.[106] Another 2009 study randomized classrooms for 678 first-grade children to receive a classroom-centered intervention, a parent-centered intervention, or no intervention, and then followed their academic outcomes through age 19.[107]\nA 2005 review found 83 randomized experiments in criminology published in 1982-2004, compared with only 35 published in 1957-1981.[103] The authors classified the studies they found into five categories: \"policing\", \"prevention\", \"corrections\", \"court\", and \"community\".[103]  Focusing only on offending behavior programs, Hollin (2008) argued that RCTs may be difficult to implement (e.g., if an RCT required \"passing sentences that would randomly assign offenders to programmes\") and therefore that experiments with quasi-experimental design are still necessary.[104]\nFor some development economists, the main benefit to using RCTs compared to other research methods is that randomization guards against selection bias, a problem present in many current studies of development policy. In one notable example of a cluster RCT in the field of development economics, Olken (2007) randomized 608 villages in Indonesia in which roads were about to be built into six groups (no audit vs. audit, and no invitations to accountability meetings vs. invitations to accountability meetings vs. invitations to accountability meetings along with anonymous comment forms).[102] After estimating \"missing expenditures\" (a measure of corruption), Olken concluded that government audits were more effective than \"increasing grassroots participation in monitoring\" in reducing corruption.[102] Overall, it is important in social sciences to account for the intended as well as the unintended consequences of interventions for policy evaluations.\nRCTs are currently being used by a number of international development experts to measure the impact of development interventions worldwide.  Development economists at research organizations including Abdul Latif Jameel Poverty Action Lab (J-PAL)[98][99][100] and Innovations for Poverty Action[101] have used RCTs to measure the effectiveness of poverty, health, and education programs in the developing world. While RCTs can be useful in policy evaluation, it is necessary to exercise care in interpreting the results in social science settings. For example, interventions can inadvertently induce socioeconomic and behavioral changes that can confound the relationships (Bhargava, 2008).\nAnd the causal mechanisms:\nThe intervention:\nDr. Steve Melia[97] took issue with these conclusions, arguing that claims about the advantages of RCTs, in establishing causality and avoiding bias, have been exaggerated.  He proposed the following 8 criteria for the use of RCTs in contexts where interventions must change human behaviour to be effective:\nResearchers in transport science argue that public spending on programmes such as school travel plans could not be justified unless their efficacy is demonstrated by randomized controlled trials.[95]  Graham-Rowe and colleagues[96]  reviewed 77 evaluations of transport interventions found in the literature, categorising them into 5 \"quality levels\".  They concluded that most of the studies were of low quality and advocated the use of randomized controlled trials wherever possible in future transport research.\nDue to the recent emergence of RCTs in social science, the use of RCTs in social sciences is a contested issue.  Some writers from a medical or health background have argued that existing research in a range of social science disciplines lacks rigour, and should be improved by greater use of randomized control trials.\nHistorical control trials (HCT) exploit the data of previous RCTs to reduce the sample size; however, these approaches are controversial in the scientific community and must be handled with care.[94]\nIf a 'disruptive' innovation in medical (or other) technology is developed, it may be difficult to test this ethically in an RCT if it becomes 'obvious' that the control subjects have poorer outcomes\u2014either due to other foregoing testing, or within the initial phase of the RCT itself.  Ethically it may be necessary to abort the RCT prematurely, and getting ethics approval (and patient agreement) to withhold the innovation from the control group in future RCT's may not be feasible.\nSome RCTs are fully or partly funded by the health care industry (e.g., the pharmaceutical industry) as opposed to government, nonprofit, or other sources. A systematic review published in 2003 found four 1986\u20132002 articles comparing industry-sponsored and nonindustry-sponsored RCTs, and in all the articles there was a correlation of industry sponsorship and positive study outcome.[90] A 2004 study of 1999\u20132001 RCTs published in leading medical and surgical journals determined that industry-funded RCTs \"are more likely to be associated with statistically significant pro-industry findings.\"[91] These results have been mirrored in trials in surgery, where although industry funding did not affect the rate of trial discontinuation it was however associated with a lower odds of publication for completed trials.[92] One possible reason for the pro-industry results in industry-funded published RCTs is publication bias.[91]  Other authors have cited the differing goals of academic and industry sponsored research as contributing to the difference. Commercial sponsors may be more focused on performing trials of drugs that have already shown promise in early stage trials, and on replicating previous positive results to fulfill regulatory requirements for drug approval.[93]\nA 2011 study done to disclose possible conflicts of interests in underlying research studies used for medical meta-analyses  reviewed 29 meta-analyses and found that conflicts of interests in the studies underlying the meta-analyses were rarely disclosed.  The 29 meta-analyses included 11 from general medicine journals; 15 from specialty medicine journals, and 3 from the Cochrane Database of Systematic Reviews. The 29 meta-analyses reviewed an aggregate of 509 randomized controlled trials (RCTs). Of these, 318 RCTs reported funding sources with 219 (69%) industry funded. 132 of the 509 RCTs reported author conflict of interest disclosures, with 91 studies (69%) disclosing industry financial ties with one or more authors. The information was, however, seldom reflected in the meta-analyses. Only two (7%) reported RCT funding sources and none reported RCT author-industry ties. The authors concluded \"without acknowledgment of COI due to industry funding or author industry financial ties from RCTs included in meta-analyses, readers' understanding and appraisal of the evidence from the meta-analysis may be compromised.\"[89]\nDue to the costs of running RCTs, these usually only inspect one variable or very few variables, rarely reflecting the full picture of a complicated medical situation; whereas the case report, for example, can detail many aspects of the patient's medical situation (e.g. patient history, physical examination, diagnosis, psychosocial aspects, follow up).[88]\nInterventions to prevent events that occur only infrequently (e.g., sudden infant death syndrome) and uncommon adverse outcomes (e.g., a rare side effect of a drug) would require RCTs with extremely large sample sizes and may therefore best be assessed by observational studies.[68]\nIt is costly to maintain RCTs for the years or decades that would be ideal for evaluating some interventions.[68][86]\nThe conduct of an RCT takes several years until being published, thus data is restricted from the medical community for long years and may be of less relevance at time of publication.[88]\nRCTs can be expensive;[86] one study found 28 Phase III RCTs funded by the National Institute of Neurological Disorders and Stroke prior to 2000 with a total cost of US$335 million,[87] for a mean cost of US$12 million per RCT.  Nevertheless, the return on investment of RCTs may be high, in that the same study projected that the 28 RCTs produced a \"net benefit to society at 10-years\" of 46 times the cost of the trials program, based on evaluating a quality-adjusted life year as equal to the prevailing mean per capita gross domestic product.[87]\nMany papers discuss the disadvantages of RCTs.[68][85][86]   Among the most frequently cited drawbacks are:\nNotable RCTs with unexpected results that contributed to changes in clinical practice include:\nRCTs are considered to be the most reliable form of scientific evidence in the hierarchy of evidence that influences healthcare policy and practice because RCTs reduce spurious causality and bias. Results of RCTs may be combined in systematic reviews which are increasingly being used in the conduct of evidence-based practice. Some examples of scientific organizations' considering RCTs or systematic reviews of RCTs to be the highest-quality evidence available are:\nLike all statistical methods, RCTs are subject to both type I (\"false positive\") and type II (\"false negative\") statistical errors.  Regarding Type I errors, a typical RCT will use 0.05 (i.e., 1 in 20) as the probability that the RCT will falsely find two equally effective treatments significantly different.[71] Regarding Type II errors, despite the publication of a 1978 paper noting that the sample sizes of many \"negative\" RCTs were too small to make definitive conclusions about the negative results,[72] by 2005-2006 a sizeable proportion of RCTs still had inaccurate or incompletely reported sample size calculations.[73]\nTwo other lines of reasoning question RCTs' contribution to scientific knowledge beyond other types of studies:\nTwo studies published in The New England Journal of Medicine in 2000 found that observational studies and RCTs overall produced similar results.[64][65] The authors of the 2000 findings questioned the belief that \"observational studies should not be used for defining evidence-based medical care\" and that RCTs' results are \"evidence of the highest grade.\"[64][65] However, a 2001 study published in Journal of the American Medical Association concluded that \"discrepancies beyond chance do occur and differences in estimated magnitude of treatment effect are very common\" between observational studies and RCTs.[66]\nFor other RCT study designs, \"CONSORT extensions\" have been published, some examples are:\nThe CONSORT 2010 Statement is \"an evidence-based, minimum set of recommendations for reporting RCTs.\"[60] The CONSORT 2010 checklist contains 25 items (many with sub-items) focusing on \"individually randomised, two group, parallel trials\" which are the most common type of RCT.[1]\nRegardless of the statistical methods used, important considerations in the analysis of RCT data include:\nThe types of statistical methods used in RCTs depend on the characteristics of the data and include:\nRCTs without blinding are referred to as \"unblinded\",[52] \"open\",[53] or (if the intervention is a medication) \"open-label\".[54] In 2008 a study concluded that the results of unblinded RCTs tended to be biased toward beneficial effects only if the RCTs' outcomes were subjective as opposed to objective;[48] for example, in an RCT of treatments for multiple sclerosis, unblinded neurologists (but not the blinded neurologists) felt that the treatments were beneficial.[55] In pragmatic RCTs, although the participants and providers are often unblinded, it is \"still desirable and often possible to blind the assessor or obtain an objective source of data for evaluation of outcomes.\"[35]\nTraditionally, blinded RCTs have been classified as \"single-blind\", \"double-blind\", or \"triple-blind\"; however, in 2001 and 2006 two studies showed that these terms have different meanings for different people.[50][51]  The 2010 CONSORT Statement specifies that authors and editors should not use the terms \"single-blind\", \"double-blind\", and \"triple-blind\"; instead, reports of blinded RCT should discuss \"If done, who was blinded after assignment to interventions (for example, participants, care providers, those assessing outcomes) and how.\"[3]\nAn RCT may be blinded, (also called \"masked\") by \"procedures that prevent study participants, caregivers, or outcome assessors from knowing which intervention was received.\"[48] Unlike allocation concealment, blinding is sometimes inappropriate or impossible to perform in an RCT; for example, if an RCT involves a treatment in which active participation of the patient is necessary (e.g., physical therapy), participants cannot be blinded to the intervention.\nThe number of treatment units (subjects or groups of subjects) assigned to control and treatment groups, affects an RCT's reliability. If the effect of the treatment is small, the number of treatment units in either group may be insufficient for rejecting the null hypothesis in the respective statistical test. The failure to reject the null hypothesis would imply that the treatment shows no statistically significant effect on the treated in a given test. But as the sample size increases, the same RCT may be able to demonstrate a significant effect of the treatment, even if this effect is small.[49]\nSome standard methods of ensuring allocation concealment include sequentially numbered, opaque, sealed envelopes (SNOSE); sequentially numbered containers; pharmacy controlled randomization; and central randomization.[38] It is recommended that allocation concealment methods be included in an RCT's protocol, and that the allocation concealment methods should be reported in detail in a publication of an RCT's results; however, a 2005 study determined that most RCTs have unclear allocation concealment in their protocols, in their publications, or both.[47] On the other hand, a 2008 study of 146 meta-analyses concluded that the results of RCTs with inadequate or unclear allocation concealment tended to be biased toward beneficial effects only if the RCTs' outcomes were subjective as opposed to objective.[48]\n\"Allocation concealment\" (defined as \"the procedure for protecting the randomization process so that the treatment to be allocated is not known before the patient is entered into the study\") is important in RCTs.[46] In practice, clinical investigators in RCTs often find it difficult to maintain impartiality. Stories abound of investigators holding up sealed envelopes to lights or ransacking offices to determine group assignments in order to dictate the assignment of their next patient.[38] Such practices introduce selection bias and confounders (both of which should be minimized by randomization), possibly distorting the results of the study.[38] Adequate allocation concealment should defeat patients and investigators from discovering treatment allocation once a study is underway and after the study has concluded.  Treatment related side-effects or adverse events may be specific enough to reveal allocation to investigators or patients thereby introducing bias or influencing any subjective parameters collected by investigators or requested from subjects.\nAt least two types of \"adaptive\" randomization procedures have been used in RCTs, but much less frequently than simple or restricted randomization:\nTo balance group sizes in smaller RCTs, some form of \"restricted\" randomization is recommended.[44]  The major types of restricted randomization used in RCTs are:\nThis is a commonly used and intuitive procedure, similar to \"repeated fair coin-tossing.\"[37] Also known as \"complete\" or \"unrestricted\" randomization, it is robust against both selection and accidental biases. However, its main drawback is the possibility of imbalanced group sizes in small RCTs.  It is therefore recommended only for RCTs with over 200 subjects.[44]\nHowever, no single randomization procedure meets those goals in every circumstance, so researchers must select a procedure for a given study based on its advantages and disadvantages.\nAn ideal randomization procedure would achieve the following goals:[40]\nThe treatment allocation is the desired proportion of patients in each treatment arm.\nHowever empirical evidence that adequate randomization changes outcomes relative to inadequate randomization has been difficult to detect.[39]\nThere are two processes involved in randomizing patients to different interventions. First is choosing a randomization procedure to generate an unpredictable sequence of allocations; this may be a simple random assignment of patients to any of the groups at equal probabilities, may be \"restricted\", or may be \"adaptive.\" A second and more practical issue is allocation concealment, which refers to the stringent precautions taken to ensure that the group assignment of patients are not revealed prior to definitively allocating them to their respective groups. Non-random \"systematic\" methods of group assignment, such as alternating subjects between one group and the other, can cause \"limitless contamination possibilities\" and can cause a breach of allocation concealment.[38]\nThe advantages of proper randomization in RCTs include:[37]\nAnother classification of RCTs categorizes them as \"superiority trials\", \"noninferiority trials\", and \"equivalence trials\", which differ in methodology and reporting.[36] Most RCTs are superiority trials, in which one intervention is hypothesized to be superior to another in a statistically significant way.[36] Some RCTs are noninferiority trials \"to determine whether a new treatment is no worse than a reference treatment.\"[36] Other RCTs are equivalence trials in which the hypothesis is that two interventions are indistinguishable from each other.[36]\nRCTs can be classified as \"explanatory\" or \"pragmatic.\"[35] Explanatory RCTs test efficacy in a research setting with highly selected participants and under highly controlled conditions.[35] In contrast, pragmatic RCTs (pRCTs) test effectiveness in everyday practice with relatively unselected participants and under flexible conditions; in this way, pragmatic RCTs can \"inform decisions about practice.\"[35]\nAn analysis of the 616 RCTs indexed in PubMed during December 2006 found that 78% were parallel-group trials, 16% were crossover, 2% were split-body, 2% were cluster, and 2% were factorial.[32]\nOne way to classify RCTs is by study design.  From most to least common in the healthcare literature, the major categories of RCT study designs are:[32]\nIn 2004, the International Committee of Medical Journal Editors (ICMJE) announced that all trials starting enrolment after July 1, 2005 must be registered prior to consideration for publication in one of the 12 member journals of the committee.[28] However, trial registration may still occur late or not at all.[29][30]\nMedical journals have been slow in adapting policies requiring mandatory clinical trial registration as a prerequisite for publication.[31]\nThe RCT method variations may also create cultural effects that have not been well understood.[27] For example, patients with terminal illness may join trials in the hope of being cured, even when treatments are unlikely to be successful.\nAlthough subjects almost always provide informed consent for their participation in an RCT, studies since 1982 have documented that RCT subjects may believe that they are certain to receive treatment that is best for them personally; that is, they do not understand the difference between research and treatment.[25][26] Further research is necessary to determine the prevalence of and ways to address this \"therapeutic misconception\".[26]\nAlthough the principle of clinical equipoise (\"genuine uncertainty within the expert medical community... about the preferred treatment\") common to clinical trials[20] has been applied to RCTs, the ethics of RCTs have special considerations.  For one, it has been argued that equipoise itself is insufficient to justify RCTs.[21]  For another, \"collective equipoise\" can conflict with a lack of personal equipoise (e.g., a personal belief that an intervention is effective).[22]  Finally, Zelen's design, which has been used for some RCTs, randomizes subjects before they provide informed consent, which may be ethical for RCTs of screening and selected therapies, but is likely unethical \"for most therapeutic trials.\"[23][24]\nBy the late 20th century, RCTs were recognized as the standard method for \"rational therapeutics\" in medicine.[19]  As of 2004, more than 150,000 RCTs were in the Cochrane Library.[18]  To improve the reporting of RCTs in the medical literature, an international group of scientists and editors published Consolidated Standards of Reporting Trials (CONSORT) Statements in 1996, 2001 and 2010, and these have become widely accepted.[1][3] Randomization is the process of assigning trial subjects to treatment or control groups using an element of chance to determine the assignments in order to reduce the bias.\nThe first published RCT in medicine appeared in the 1948 paper entitled \"Streptomycin treatment of pulmonary tuberculosis\", which described a Medical Research Council investigation.[15][16][17] One of the authors of that paper was Austin Bradford Hill, who is credited as having conceived the modern RCT.[18]\nThe first reported clinical trial was conducted by James Lind in 1747 to identify treatment for scurvy.[8] Randomized experiments appeared in psychology, where they were introduced by Charles Sanders Peirce,[9] and in education.[10][11][12] Later, randomized experiments appeared in agriculture, due to Jerzy Neyman[13] and Ronald A. Fisher. Fisher's experimental research and his writings popularized randomized experiments.[14]\nThe terms \"RCT\" and randomized trial are sometimes used synonymously, but the methodologically sound practice is to reserve the \"RCT\" name only for trials that contain control groups, in which  groups receiving the experimental treatment are compared with control groups receiving no treatment (a placebo-controlled study) or a previously tested treatment (a positive-control study). The term \"randomized trials\" omits mention of controls and can describe studies that compare multiple treatment groups with each other (in the absence of a control group).[4] Similarly, although the \"RCT\" name is sometimes expanded as \"randomized clinical trial\" or \"randomized comparative trial\", the methodologically sound practice, to avoid ambiguity in the scientific literature, is to retain \"control\" in the definition of \"RCT\" and thus reserve that name only for trials that contain controls. Not all randomized clinical trials are randomized controlled trials (and some of them could never be, in cases where controls would be impractical or unethical to institute). The term randomized controlled clinical trials is a methodologically sound alternate expansion for \"RCT\" in RCTs that concern clinical research;[5][6][7] however, RCTs are also employed in other research areas, including many of the social sciences.\nRandom allocation in real trials is complex, but conceptually the process is like tossing a coin. After randomization, the two (or more) groups of subjects are followed in exactly the same way and the only differences between them is the care they receive. For example, in terms of procedures, tests, outpatient visits, and follow-up calls, should be those intrinsic to the treatments being compared.  The most important advantage of proper randomization is that it minimizes allocation bias, balancing both known and unknown prognostic factors, in the assignment of treatments.[3]\nA randomized controlled trial (or randomized control trial;[2] RCT) is a type of scientific (often medical) experiment which aims to reduce bias when testing a new treatment. The people participating in the trial are randomly allocated to either the group receiving the treatment under investigation or to a group receiving standard treatment (or placebo treatment) as the control. Randomization minimises selection bias and the different comparison groups allow the researchers to determine any effects of the treatment when compared with the no treatment (control) group, while other variables are kept constant. The RCT is often considered the gold standard for a clinical trial. RCTs are often used to test the efficacy or effectiveness of various types of medical intervention and may provide information about adverse effects, such as drug reactions. Random assignment of intervention is done after subjects have been assessed for eligibility and recruited, but before the intervention to be studied begins.\n",
            "title": "Randomized controlled trial",
            "url": "https://en.wikipedia.org/wiki/Randomized_controlled_trial"
        },
        {
            "desc_links": [
                "/wiki/Causality",
                "/wiki/Dependent_and_independent_variables"
            ],
            "desc_text": "b'In statistics, a confounder (also confounding variable, confounding factor or lurking variable) is a variable that influences both the dependent variable and independent variable causing a spurious association.  Confounding is a causal concept, and as such, cannot be described in terms of correlations or associations.[1][2][3]\\n'",
            "links": [
                "/wiki/Causality",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Cause",
                "/wiki/Bayesian_network",
                "/wiki/Berkson%27s_paradox",
                "/wiki/Leslie_Kish",
                "/wiki/Ronald_Fisher",
                "/wiki/Medieval_Latin",
                "/wiki/Judea_Pearl",
                "/wiki/Donald_Rubin",
                "/wiki/Jerzy_Neyman",
                "/wiki/Epidemiology",
                "/wiki/Experiment",
                "/wiki/Pesticide",
                "/wiki/Health",
                "/wiki/Human",
                "/wiki/Risk_assessment",
                "/wiki/Random_assignment",
                "/wiki/Observational_studies",
                "/wiki/Epidemiology",
                "/wiki/Risk_assessment",
                "/wiki/Multiple_comparisons",
                "/wiki/Replication_(statistics)",
                "/wiki/Peer_review",
                "/wiki/Wikipedia:Citation_needed"
            ],
            "text": "All these methods have their drawbacks:\nDepending on the type of study design in place, there are various ways to modify that design to actively exclude or control confounding variables:[22]\nConfounding effects may be less likely to occur and act similarly at multiple times and locations.[citation needed] In selecting study sites, the environment can be characterized in detail at the study sites to ensure sites are ecologically similar and therefore less likely to have confounding variables. Lastly, the relationship between the environmental variables that possibly confound the analysis and the measured parameters can be studied. The information pertaining to environmental variables can then be used in site-specific models to identify residual variance that may be due to real effects.[21]\nPeer review is a process that can assist in reducing instances of confounding, either before study implementation or after analysis has occurred. Peer review relies on collective expertise within a discipline to identify potential weaknesses in study design and analysis, including ways in which results may depend on confounding. Similarly, replication can test for the robustness of findings from one study under alternative study conditions or alternative analyses (e.g., controlling for potential confounds not identified in the initial study).\nA reduction in the potential for the occurrence and effect of confounding factors can be obtained by increasing the types and numbers of comparisons performed in an analysis. If measures or manipulations of core constructs are confounded (i.e. operational or procedural confounds exist), subgroup analysis may not reveal problems in the analysis. Additionally, increasing the number of comparisons can create other problems (see multiple comparisons).\nIn risk assessments, factors such as age, gender, and educational levels often affect health status and so should be controlled.  Beyond these factors, researchers may not consider or have access to data on other causal factors.  An example is on the study of smoking tobacco on human health.  Smoking, drinking alcohol, and diet are lifestyle activities that are related.  A risk assessment that looks at the effects of smoking but does not control for alcohol consumption or diet may overestimate the risk of smoking.[19]   Smoking and confounding are reviewed in occupational risk assessments such as the safety of coal mining.[20]    When there is not a large sample population of non-smokers or non-drinkers in a particular occupation, the risk assessment may be biased towards finding a negative effect on health.\nIn another concrete example, say one is studying the relation between birth order (1st child, 2nd child, etc.) and the presence of Down's Syndrome in the child. In this scenario, maternal age would be a confounding variable:\nConfounding variables may also be categorised according to their source. The choice of measurement instrument (operational confound), situational characteristics (procedural confound), or inter-individual differences (person confound).\nIn some disciplines, confounding is categorized into different types. In epidemiology, one type is \"confounding by indication\",[16] which relates to confounding from observational studies. Because prognostic factors may influence treatment decisions (and bias estimates of treatment effects), controlling for known prognostic factors may reduce this problem, but it is always possible that a forgotten or unknown factor was not included or that factors interact complexly. Confounding by indication has been described as the most important limitation of observational studies. Randomized trials are not affected by confounding by indication due to random assignment.\nIn the case of risk assessments evaluating the magnitude and nature of risk to human health, it is important to control for confounding to isolate the effect of a particular hazard such as a food additive, pesticide, or new drug. For prospective studies, it is difficult to recruit and screen for volunteers with the same background (age, diet, education, geography, etc.), and in historical studies, there can be similar variability.  Due to the inability to control for variability of volunteers and human studies, confounding is a particular challenge. For these reasons, experiments offer a way to avoid most forms of confounding.\nGraphical criteria were shown to be formally equivalent to the counterfactual definition,[15] but more transparent to researchers relying on process models.\nFormal conditions defining what makes certain groups \"comparable\" and others \"incomparable\" were later developed in epidemiology by Greenland and Robins (1986)[12] using the counterfactual language of Neyman (1935)[13] and Rubin (1974).[14] These were later supplemented by graphical criteria such as the Back-Door condition (Pearl 1993; Greenland, Pearl and Robins, 1999).[3][4]\nAccording to Morabia (2011),[8] the word derives from the Medieval Latin verb \"confudere\", which meant \"mixing\", and was probably chosen to represent the confusion (from Latin: con=with + fusus=mix or fuse together) between the cause one wishes to assess and other causes that may affect the outcome and thus confuse, or stand in the way of the desired assessment. Fisher used the word \"confounding\" in his 1935 book \"The Design of Experiments\"[9] to denote any source of error in his ideal of randomized experiment. According to Vandenbroucke (2004)[10] it was Kish[11] who used the word \"confounding\" in the modern sense of the word, to mean \"incomparability\" of two or more groups (e.g., exposed and unexposed) in an observational study.\nIn general, confounding can be controlled by adjustment if and only if there is a set of observed covariates that satisfies the Back-Door condition. Moreover, if Z is such a set, then the adjustment formula of Eq. (3) is valid <4,5>. Pearl's do-calculus provide additional conditions under which P(y|do(x)) can be estimated, not necessarily by adjustment.[7]\nContrary to common beliefs, adding covariates to the adjustment set Z can introduce bias. A typical counterexample occurs when Z is a common effect of X and Y,[6] a case in which Z is not a confounder (i.e., the null set is Back-door admissible) and adjusting for Z would create bias known as \"collider bias\" or \"Berkson's paradox.\"\nIn this way the physician can predict the likely effect of administering the drug from observational studies in which the conditional probabilities appearing on the right-hand side of the equation can be estimated by regression.\nwhich gives an unbiased estimate for the causal effect of X on Y. The same adjustment formula works when there are multiple confounders except, in this case, the choice of a set Z of variables that would guarantee unbiased estimates must be done with caution. The criterion for a proper choice of variables is called the Back-Door [4][5] and requires that the chosen set Z \"blocks\" (or intercepts) every path from X to Y that ends with an arrow into X. Such sets are called \"Back-Door admissible\" and may include variables which are not common causes of X and Y, but merely proxies thereof.\nWe have that\nConsider a researcher attempting to assess the effectiveness of drug X, from population data in which drug usage was a patient's choice. The data shows that gender (Z) differences influence a patient's choice of drug as well as their chances of recovery (Y). In this scenario, gender Z confounds the relation between X and Y since Z is a cause of both X and Y:\nIn principle, the defining equality P(y\u00a0|\u00a0do(x)) = P(y\u00a0|\u00a0x) can be verified from the data generating model assuming we have all the equations and probabilities associated with the model. This is done by simulating an intervention do(X = x) (see Bayesian network) and checking whether the resulting probability of Y equals the conditional probability P(y\u00a0|\u00a0x). It turns out, however, that graph structure alone is sufficient for verifying the equality P(y\u00a0|\u00a0do(x)) = P(y\u00a0|\u00a0x).\nConfounding is defined in terms of the data generating model (as in the Figure above). Let X be some independent variable, Y some dependent variable. To estimate the effect of X on Y, the statistician must suppress the effects of extraneous variables that influence both X and Y. We say that, X and Y are confounded by some other variable Z whenever Z is a cause of both X and Y.\nIn statistics, a confounder (also confounding variable, confounding factor or lurking variable) is a variable that influences both the dependent variable and independent variable causing a spurious association.  Confounding is a causal concept, and as such, cannot be described in terms of correlations or associations.[1][2][3]\n",
            "title": "Confounding",
            "url": "https://en.wikipedia.org/wiki/Confounding"
        },
        {
            "desc_links": [
                "/wiki/Education",
                "/wiki/Education",
                "/wiki/Income",
                "/wiki/Schizophrenia",
                "/wiki/Arthritis",
                "/wiki/Obesity",
                "/wiki/Drug_abuse",
                "/wiki/Unwanted_pregnancy"
            ],
            "desc_text": "b'\\n'b\"Socioeconomic status (SES) is an economic and sociological combined total measure of a person's work experience and of an individual's or family's economic and social position in relation to others, based on income, education, and occupation. When analyzing a family's SES, the household income, earners' education, and occupation are examined, as well as combined income, whereas for an individual's SES only their own attributes are assessed. However, SES is more commonly used to depict an economic difference in society as a whole.[1]\\n\"b'Socioeconomic status is typically broken into three levels (high, middle, and low) to describe the three places a family or an individual may fall into. When placing a family or individual into one of these categories, any or all of the three variables (income, education, and occupation) can be assessed.\\n'b\"Additionally, low income and education have been shown to be strong predictors of a range of physical and mental health problems, including respiratory viruses, arthritis, coronary disease, and schizophrenia. These problems may be due to environmental conditions in their workplace, or, in the case of disabilities or mental illnesses, may be the entire cause of that person's social predicament to begin with.[2][3][4][5]\\n\"b'Education in higher socioeconomic families is typically stressed as much more important, both within the household as well as the local community. In poorer areas, where food, shelter and safety are priority, education can take a backseat. Youth audiences are particularly at risk for many health and social problems in the United States, such as unwanted pregnancies, drug abuse, and obesity.[6]\\n'",
            "links": [
                "/wiki/Education",
                "/wiki/Education",
                "/wiki/Income",
                "/wiki/Schizophrenia",
                "/wiki/Arthritis",
                "/wiki/Obesity",
                "/wiki/Drug_abuse",
                "/wiki/Unwanted_pregnancy",
                "/wiki/Unemployment",
                "/wiki/Renting",
                "/wiki/Profit_(accounting)",
                "/wiki/Salaries",
                "/wiki/Wage",
                "/wiki/Relative_poverty",
                "/wiki/John_Maynard_Keynes",
                "/wiki/Wealth",
                "/wiki/Gini_coefficient",
                "/wiki/Income_inequality",
                "/wiki/Education",
                "/wiki/Middle_class",
                "/wiki/Concerted_cultivation",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Educational_attainment",
                "/wiki/Occupational_prestige",
                "/wiki/Redlining",
                "/wiki/Employment_discrimination",
                "/wiki/Thomas_Shapiro",
                "/wiki/Racial_inequality_in_the_United_States",
                "/wiki/Premature_aging",
                "/wiki/Cancer",
                "/wiki/Rheumatoid_arthritis",
                "/wiki/Type_2_diabetes",
                "/wiki/Peptic_ulcer",
                "/wiki/Heart_disease",
                "/wiki/Stress_(medicine)",
                "/wiki/Homosexuals",
                "/wiki/Health_equity",
                "/wiki/Population_health",
                "/wiki/Economic_inequality",
                "/wiki/Epidemiology",
                "/wiki/Social_status",
                "/wiki/Rheumatoid_arthritis",
                "/wiki/Type_2_diabetes",
                "/wiki/Alcoholic_beverage",
                "/wiki/Tobacco_smoking",
                "/wiki/Exercise",
                "/wiki/London",
                "/wiki/Civil_servants",
                "/wiki/Whitehall_Study",
                "/wiki/Richard_G._Wilkinson",
                "/wiki/Joint_attention",
                "/wiki/Imperative_mood",
                "/wiki/Authoritarian_Parent",
                "/wiki/Permissive_Parenting",
                "/wiki/Authoritative_Parenting",
                "/wiki/Parenting_styles",
                "/wiki/Authoritarian_Parent",
                "/wiki/Hierarchy",
                "/wiki/Verb_phrase",
                "/wiki/Complex_sentence",
                "/wiki/Simple_sentence",
                "/wiki/Syntax",
                "/wiki/Verb_phrase",
                "/wiki/Noun_phrase",
                "/wiki/Rapport"
            ],
            "text": "Michael Kraus and Dacher Keltner, in their study published in the December 2008 issue of Psychological Science, found that children of parents with a high SES tended to express more disengagement behaviors than their peers of low SES. In this context, disengagement behaviors included self-grooming, fidgeting with nearby objects, and doodling while being addressed. In contrast, engagement behaviors included head nods, eyebrow raises, laughter and gazes at one\u2019s partner. These cues indicated an interest in one\u2019s partner and the desire to deepen and enhance the relationship. Participants of low SES tended to express more engagement behaviors toward their conversational partners, while their high SES counterparts displayed more disengagement behaviors. Authors hypothesized that, as SES rises, the capacity to fulfill one\u2019s needs also increases. This may lead to greater feelings of independence, making individuals of high SES less inclined to gain rapport with conversational partners because they are less likely to need their assistance in the future.[41]\nSchool characteristics, including characteristics of peers and teachers, contribute to reading disparities between low and high SES children. For instance, peers play a role in influencing early reading proficiency. In low SES schools, there are higher concentrations of less skilled, lower SES, and minority peers who have lower gains in reading. The number of children reading below grade and the presence of low-income peers were consistently associated with initial achievement and growth rates. Low SES peers tend to have limited skills and fewer economic resources than high SES children, which makes it difficult for children to grow in their reading ability. The most rapid growth of reading ability happens between the spring of kindergarten and the spring of first grade. Teacher experience (number of years teaching  at a particular school and the number of years teaching a particular grade level), teacher preparation to teach (based on the number of courses taken on early education, elementary education, and child development), the highest degree earned, and the number of courses taken on teaching reading all determine whether or not a reading teacher is qualified. Low SES students are more likely to have less qualified teachers, which is associated with their reading growth rates being significantly lower than the growth rates of their high SES counterparts.[38]\nIn a study by M. Keels, it was determined that when low-income families are moved from poor neighborhoods to suburban neighborhoods, there are reductions in delinquency in children.[40]  When comparing different social statuses of families, the environment of a neighborhood turns out to be major factor in contributing to the growth of a child.\nThe neighborhood setting in which children grow up contributes to reading disparities between low and high SES children. These neighborhood qualities include but are not limited to garbage or litter in the street, individuals selling or using drugs in the street, burglary or robbery in the area, violent crime in the area, vacant homes in the area, and how safe it is to play in the neighborhood. Low SES children are more likely to grow up in such neighborhood conditions than their high SES peers. Community support for the school and poor physical conditions surrounding the school are also associated with children\u2019s reading. Neighborhood factors help explain the variation in reading scores in school entry, and especially as children move on to higher grades. As low SES children in poor neighborhood environments get older, they fall further behind their high SES peers in reading growth and thus have a more difficult time developing reading skills at grade level.[38]\nFamily SES is also associated with reading achievement growth during the summer. Students from high SES families continue to grow in their ability to read after kindergarten and students from low SES families fall behind in their reading growth at a comparable amount. Additionally, the summer setback disproportionately affects African American and Hispanic students because they are more likely than White students to come from low SES families. Also, low SES families typically lack the appropriate resources to continue reading growth when school is not in session.[37]\nThe home environment makes the largest contribution to the prediction of initial kindergarten reading disparities. Characteristics of the home environment include home literacy environment and parental involvement in school. Home literacy environment is characterized by the frequency with which parents engage in joint book reading with the child, the frequency with which children read books outside of school, and the frequency with which household members visited the library with the child. Parental involvement in school is characterized by attending a parent\u2013teacher conference, attending a parent\u2013teacher association (PTA) meeting, attending an open house, volunteering, participating in fundraising, and attending a school event. Resources, experiences, and relationships associated with the family are most closely associated with reading gaps when students reading levels are first assessed in kindergarten. The influence of family factors on initial reading level may be due to children experiencing little schooling before kindergarten\u2014they mainly have their families to rely on for their reading growth.[38]\nHome environment is one of the leading factors of a child's well being. Children living in a poor home with inadequate living conditions are more likely to be susceptible to illness and injuries.[19] The disparities in experiences in the home environment children of high and low SES affect reading outcomes. The home environment is considered the main contributor to SES reading outcomes.[38] Children of low SES status are read to less often and have fewer books in the home than their high SES peers, which suggests an answer to why children of low SES status have lower initial reading scores than their high SES counterparts upon entering kindergarten.[38] [39]\nA gap in reading growth exists between low SES and high SES children, which widens as children move on to higher grades. Reading assessments that test reading growth include measures on basic reading skills (i.e., print familiarity, letter recognition, beginning and ending sounds, rhyming sounds, word recognition), vocabulary (receptive vocabulary), and reading comprehension skills (i.e., listening comprehension, words in context).[37] The reading growth gap is apparent between the spring of kindergarten and the spring of first-grade, the time when children rely more on the school for reading growth and less on their parents. Initially, high SES children begin as better readers than their low SES counterparts. As children get older, high SES children progress more rapidly in reading growth rates than low SES children. These early reading outcomes affect later academic success. The further children fall behind, the more difficult it is to catch up and the more likely they will continue to fall behind. By the time students enter high school in the United States, low SES children are considerably behind their high SES peers in reading growth.[38]\nGiven the large amount of research on the setbacks children of low SES face, there is a push by child developmental researchers to steer research to a more positive direction regarding low SES. The goal is to highlight the strengths and assets low income families possess in raising children. For example, African American preschoolers of low SES exhibit strengths in oral narrative, or storytelling, that may promote later success in reading. These children have better narrative comprehension when compared to peers of higher SES.[36]\nPhonological awareness, the ability to recognize that words are made up different sound units, is also affected by SES. Children of low SES between the second and sixth grades are found to have low phonological awareness. The gap in phonological awareness increases by grade level.[34] This gap is even more problematic if children of low SES are already born with low levels of phonological awareness and their environment does not foster its growth. Children who have high phonological awareness from an early age are not affected by SES.[35]\nChildren\u2019s grasp of morphology, the study of how words are formed, is affected by SES. Children of high SES have advantages in applying grammatical rules, such as the pluralization of nouns and adjectives compared to children of low SES. Pluralizing nouns consists of understanding that some nouns are regular and -s denotes more than one, but also understanding how to apply different rules to irregular nouns. Learning and understanding how to use plural rules is an important tool in conversation and writing. In order to communicate successfully that there is more than one dog running down the street, an -s must be added to dog. Research also finds that the gap in ability to pluralize nouns and adjectives does not diminish by age or schooling because low SES children\u2019s reaction times to pluralize nouns and adjectives do not decrease.[33]\nThis lag in the sentence formation abilities of low SES children may be caused by less frequent exposure to complex syntax through parental speech. Low SES parents ask fewer response-coaxing questions of their children which limits the opportunities of these children to practice more complex speech patterns.[26] Instead, these parents give their children more direct orders, which has been found to negatively influence the acquisition of more difficult noun and verb phrases.[27] In contrast, high SES households ask their children broad questions to cultivate speech development. Exposure to more questions positively contributes to children\u2019s vocabulary growth and complex noun phrase constructions.[27]\nSyntax refers to the arrangement of words and phrases to form sentences. SES affects the production of sentence structures. Although 22- to 44-month-old children\u2019s production of simple sentence structures does not vary by SES, low SES does contribute to difficulty with complex sentence structures. Complex sentences include sentences that have more than one verb phrase. An example of a complex sentence is, \"I want you to sit there\".[32] The emergence of simple sentence structures is seen as a structure that is obligatory in everyday speech. Complex sentence structures are optional and can only be mastered if the environment fosters its development.[32]\nSemantics is the study of the meaning of words and phrases. Semantics covers vocabulary, which is affected by SES. \nChildren of high SES have larger expressive vocabularies by the age of 24 months due to more efficient processing of familiar words. By age 3, there are significant differences in the amount of dialogue and vocabulary growth between children of low and high SES.[30] A lack of joint attention in children contributes to poor vocabulary growth when compared to their high SES peers. Joint attention and book reading are important factors that affect children\u2019s vocabulary growth.[31] With joint attention, a child and adult can focus on the same object, allowing the child to map out words. For example, a child sees an animal running outside and the mom points to it and says, \"Look, a dog.\" The child will focus its attention to where its mother is pointing and map the word dog to the pointed animal. Joint attention thus facilitates word learning for children.\nThe linguistic environment of low and high SES children differs substantially, which affects many aspects of language and literacy development such as semantics, syntax, morphology, and phonology.\nConversely, high SES individuals occupy high power positions that call for greater expressivity. High SES parents encourage their children to question the world around them.[28] In addition to asking their children more questions, these parents push their children to create questions of their own.[26] In contrast with low SES parents, these individuals often view the power disparity between parent and child as detrimental to the family. Opting instead to treat children as equals, high SES conversations are characterized by a give and take between parent and child.[29] These interactions help prepare these children for occupations that require greater expressivity.\nParental differences in addressing children may be traced to the position of their respective groups within society. Working class individuals often hold low power, subordinate positions in the occupational world. This standing in the social hierarchy requires a personality and interaction style that is relational and capable of adjusting to circumstances.[28] An authoritarian style of address prepares children for these types of roles, which require a more accommodating and compliant personality. Therefore, low SES parents see the family as more hierarchical, with the parents at the top of the power structure, which shapes verbal interaction.[29] This power differential emulates the circumstances of the working class world, where individuals are ranked and discouraged from questioning authority.\nIn addition to the amount of language input from parents, SES heavily influences the type of parenting style a family chooses to practice. These different parenting styles shape the tone and purpose of verbal interactions between parent and child. For example, parents of high SES tend toward more authoritative or permissive parenting styles.[26] These parents pose more open-ended questions to their children to encourage the latter\u2019s speech growth.[27] In contrast, parents of low SES tend toward more authoritarian styles of address. Their conversations with their children contain more imperatives and yes/no questions that inhibits child responses and speech development.[27]\nChildren from lower income households had greater media access in their bedrooms but lower access to portable play equipment compared to higher income children.[25] This eventually leads children from lower socioeconomic backgrounds to be at a disadvantage when comparing them with their counterparts in terms of access to physical activities.\nLanguage ability differs sharply as a function of SES, for example, the average vocabulary size of 3-year-old children from professional families was more than twice as large as for those on welfare.[24]\nThe environment of low SES children is characterized by less dialogue from parents, minimal amounts of book reading, and few instances of joint attention, the shared focus of the child and adult on the same object or event, when compared to the environment of high SES children. In contrast, infants from high SES families experience more child-directed speech. At 10 months, children of high SES hear on average 400 more words than their low SES peers.[23]\nPolitical scientists have established a consistent relationship between SES and political participation.\nThere is no significant relationship between SES and stress during pregnancy, while there is a significant relationship with a husband's occupational status[22]. Also, there is no significant relationship between income and mother's education and the rate of pregnancy stress[22]\nOther researchers such as Richard G. Wilkinson, J. Lynch, and G.A. Kaplan have found that socioeconomic status strongly affects health even when controlling for economic resources and access to health care.[21] Most famous for linking social status with health are the Whitehall studies\u2014a series of studies conducted on civil servants in London. The studies found that although all civil servants in England have the same access to health care, there was a strong correlation between social status and health. The studies found that this relationship remained strong even when controlling for health-affecting habits such as exercise, smoking and drinking. Furthermore, it has been noted that no amount of medical attention will help decrease the likelihood of someone getting type 2 diabetes or rheumatoid arthritis\u2014yet both are more common among populations with lower socioeconomic status.\nThere is debate regarding the cause of the SES Gradient. Researchers see a definite link between economic status and mortality due to the greater economic resources of the wealthy, but they find little correlation due to social status differences.[20]\nRecently, there has been increasing interest from epidemiologists on the subject of economic inequality and its relation to the health of populations.  Socioeconomic status has long been related to health, those higher in the social hierarchy typically enjoy better health than do those below.[18] Socioeconomic status is an important source of health inequity, as there is a very robust positive correlation between socioeconomic status and health, other than for male homosexuals. This correlation suggests that it is not only the poor who tend to be sick when everyone else is healthy, but that there is a continual gradient, from the top to the bottom of the socio-economic ladder, relating status to health. Parents with a low socioeconomic status cannot afford many of the health care resources which is the reason that their children may have a more advanced illness because of the lack of treatment.[19] This phenomenon is often called the \"SES Gradient\" or according to the World Health Organisation the \"Social Gradient\". Lower socioeconomic status has been linked to chronic stress, heart disease, ulcers, type 2 diabetes, rheumatoid arthritis, certain types of cancer, and premature aging.\nThe wealth gap, like income inequality, is very large in the United States. There exists a racial wealth gap due in part to income disparities and differences in achievement resulting from institutional discrimination. According to Thomas Shapiro, differences in savings (due to different rates of incomes), inheritance factors, and discrimination in the housing market lead to the racial wealth gap. Shapiro claims that savings increase with increasing income, but African Americans cannot participate in this, because they make significantly less than Americans of European descent (whites). Additionally, rates of inheritance dramatically differ between African Americans and Americans of European descent. The amount a person inherits, either during a lifetime or after death, can create different starting points between two different individuals or families. These different starting points also factor into housing, education, and employment discrimination. A third reason Shapiro offers for the racial wealth gap are the various discriminations African Americans must face, like redlining and higher interest rates in the housing market. These types of discrimination feed into the other reasons why African Americans end up having different starting points and therefore fewer assets.[17]\nIncome, age, marital status, family size, religion, occupation, and education are all predictors for wealth attainment.\nWealth, a set of economic reserves or assets, presents a source of security providing a measure of a household's ability to meet emergencies, absorb economic shocks, or provide the means to live comfortably. Wealth reflects intergenerational transitions as well as accumulation of income and savings.[5][16]\nIn sum, the majority of researchers agree that income, education and occupation together best represent SES, while some others feel that changes in family structure should also be considered.[14]  With the definition of SES more clearly defined, it is now important to discuss the effects of SES on students' cognitive abilities and academic success.[14] Several researchers have found that SES affects students' abilities.[14]\nOccupation is the most difficult factor to measure because so many exist, and there are so many competing scales. Many scales rank occupations based on the level of skill involved, from unskilled to skilled manual labor to professional, or use a combined measure using the education level needed and income involved.\nOccupations are ranked by the Census (among other organizations) and opinion polls from the general population are surveyed. Some of the most prestigious occupations are physicians and surgeons, lawyers, chemical and biomedical engineers, university professors, and communications analysts. These jobs, considered to be grouped in the high SES classification, provide more challenging work and greater control over working conditions but require more ability. The jobs with lower rankings include food preparation workers, counter attendants, bartenders and helpers, dishwashers, janitors, maids and housekeepers, vehicle cleaners, and parking lot attendants. The jobs that are less valued also offer significantly lower wages, and often are more laborious, very hazardous, and provide less autonomy.[5][13]\nOccupational prestige, as one component of SES, encompasses both income and educational attainment. Occupational status reflects the educational attainment required to obtain the job and income levels that vary with different jobs and within ranks of occupations. Additionally, it shows achievement in skills required for the job. Occupational status measures social position by describing job characteristics, decision making ability and control, and psychological demands on the job[citation needed].\nResearch shows that lower SES students have lower and slower academic achievement as compared with students of higher SES.[10] When teachers make judgments about students based on their class and SES, they are taking the first step in preventing students from having an equal opportunity for academic achievement.  Educators need to help overcome the stigma of poverty.  A student of low SES and low self-esteem should not be reinforced by educators.  Teachers need to view students as individuals and not as a member of an SES group.  Teachers looking at students in this manner will help them to not be prejudiced towards students of certain SES groups.[11] Raising the level of instruction can help to create equality in student achievement.  Teachers relating the content taught to students' prior knowledge and relating it to real world experiences can improve achievement.[11] Educators also need to be open and discuss class and SES differences.  It is important that all are educated, understand, and be able to speak openly about SES.[12]\nEducation plays a major role in skill sets for acquiring jobs, as well as specific qualities that stratify people with higher SES from lower SES. Annette Lareau speaks on the idea of concerted cultivation, where middle class parents take an active role in their children\u2019s education and development by using controlled organized activities and fostering a sense of entitlement through encouraged discussion. Laureau argues that families with lower income do not participate in this movement, causing their children to have a sense of constraint.  An interesting observation that studies have noted is that parents from lower SES households are more likely to give orders to their children in their interactions while parents with a higher SES are more likely to interact and play with their children.  A division in education attainment is thus born out of these two differences in child rearing.  Research has shown how children who are born in lower SES households have weaker language skills compared to children raised in higher SES households.  These language skills affect their abilities to learn and thus exacerbate the problem of education disparity between low and high SES neighborhoods.  Lower income families can have children who do not succeed to the levels of the middle income children, who can have a greater sense of entitlement, be more argumentative, or be better prepared for adult life.[9]\nEducation also plays a role in income. Median earnings increase with each level of education. As conveyed in the chart, the highest degrees, professional and doctoral degrees, make the highest weekly earnings while those without a high school diploma earn less. Higher levels of education are associated with better economic and psychological outcomes (i.e.: more income, more control, and greater social support and networking).[5]\nIncome inequality is most commonly measured around the world by the Gini coefficient, where 0 corresponds to perfect equality and 1 means perfect inequality. Low income families focus on meeting immediate needs and do not accumulate wealth that could be passed on to future generations, thus increasing inequality. Families with higher and expendable income can accumulate wealth and focus on meeting immediate needs while being able to consume and enjoy luxuries and weather crises.[8]\nIncome can be looked at in two terms, relative and absolute. Absolute income, as theorized by economist John Maynard Keynes, is the relationship in which as income increases, so will consumption, but not at the same rate.[7] Relative income dictates a person or family\u2019s savings and consumption based on the family\u2019s income in relation to others. Income is a commonly used measure of SES because it is relatively easy to figure for most individuals.\nIncome refers to wages, salaries, profits, rents, and any flow of earnings received. Income can also come in the form of unemployment or worker's compensation, social security, pensions, interests or dividends, royalties, trusts, alimony, or other governmental, public, or family financial assistance.\nEducation in higher socioeconomic families is typically stressed as much more important, both within the household as well as the local community. In poorer areas, where food, shelter and safety are priority, education can take a backseat. Youth audiences are particularly at risk for many health and social problems in the United States, such as unwanted pregnancies, drug abuse, and obesity.[6]\nAdditionally, low income and education have been shown to be strong predictors of a range of physical and mental health problems, including respiratory viruses, arthritis, coronary disease, and schizophrenia. These problems may be due to environmental conditions in their workplace, or, in the case of disabilities or mental illnesses, may be the entire cause of that person's social predicament to begin with.[2][3][4][5]\nSocioeconomic status is typically broken into three levels (high, middle, and low) to describe the three places a family or an individual may fall into. When placing a family or individual into one of these categories, any or all of the three variables (income, education, and occupation) can be assessed.\nSocioeconomic status (SES) is an economic and sociological combined total measure of a person's work experience and of an individual's or family's economic and social position in relation to others, based on income, education, and occupation. When analyzing a family's SES, the household income, earners' education, and occupation are examined, as well as combined income, whereas for an individual's SES only their own attributes are assessed. However, SES is more commonly used to depict an economic difference in society as a whole.[1]\n\n",
            "title": "Socioeconomic status",
            "url": "https://en.wikipedia.org/wiki/Socioeconomic_status"
        },
        {
            "desc_links": [
                "/wiki/Lurking_variable",
                "/wiki/Mathematical_relationship",
                "/wiki/Statistics"
            ],
            "desc_text": "b'In statistics, a spurious relationship or spurious correlation[1][2]    is a mathematical relationship in which two or more events or variables are not causally related to each other, yet it may be wrongly inferred that they are, due to either coincidence or the presence of a certain third, unseen factor (referred to as a \"common response variable\", \"confounding factor\", or \"lurking variable\").\\n'",
            "links": [
                "/wiki/Lurking_variable",
                "/wiki/Mathematical_relationship",
                "/wiki/Statistics",
                "/wiki/Spurious_correlation_of_ratios",
                "/wiki/Price_level",
                "/wiki/Real_versus_nominal_value_(economics)",
                "/wiki/Real_versus_nominal_value_(economics)",
                "/wiki/Unit_root",
                "/wiki/Non-stationary",
                "/wiki/Correlation_and_dependence",
                "/wiki/Time-series",
                "/wiki/Confounding_variable",
                "/wiki/Heat_wave",
                "/wiki/Swimming_pool",
                "/wiki/Ice_cream",
                "/wiki/Type_I_error",
                "/wiki/Causality",
                "/wiki/Correlation",
                "/wiki/Experimental_techniques",
                "/wiki/Statistics",
                "/wiki/Control_variable",
                "/wiki/Regression_analysis",
                "/wiki/Econometrics",
                "/wiki/Economics",
                "/wiki/Omitted_variable_bias",
                "/wiki/Granger_causality"
            ],
            "text": "There are several other relationships defined in statistical analysis as follows.\nIn addition to regression analysis, the data can be examined to determine if Granger causality exists. The presence of Granger causality indicates both that x precedes y, and that x contains unique information about\u00a0y.\nJust as an experimenter must be careful to employ an experimental design that controls for every confounding factor, so also must the user of multiple regression be careful to control for all confounding factors by including them among the regressors. If a confounding factor is omitted from the regression, its effect is captured in the error term by default, and if the resulting error term is correlated with one (or more) of the included regressors, then the estimated regression may be biased or inconsistent (see omitted variable bias).\nRegression analysis controls for other relevant variables by including them as regressors (explanatory variables). This helps to avoid mistaken inference of causality due to the presence of a third, underlying, variable that influences both the potentially causative variable and the potentially caused variable: its effect on the potentially caused variable is captured by directly including it in the regression, so that effect will not be picked up as a spurious effect of the potentially causative variable of interest. In addition, the use of multivariate regression helps to avoid wrongly inferring that an indirect effect of, say x1 (e.g., x1 \u2192 x2 \u2192 y) is a direct effect (x1 \u2192 y).\nDisciplines whose data are mostly non-experimental, such as economics, usually employ observational data to establish causal relationships. The body of statistical techniques used in economics is called econometrics. The main statistical method in econometrics is multivariable regression analysis.  Typically a linear relationship such as\nIn experiments, spurious relationships can often be identified by controlling for other factors, including those that have been theoretically identified as possible confounding factors. For example, consider a researcher trying to determine whether a new drug kills bacteria; when the researcher applies the drug to a bacterial culture, the bacteria die. But to help in ruling out the presence of a confounding variable, another culture is subjected to conditions that are as nearly identical as possible to those facing the first-mentioned culture, but the second culture is not subjected to the drug. If there is an unseen confounding factor in those conditions, this control culture will die as well, so that no conclusion of efficacy of the drug can be drawn from the results of the first culture. On the other hand, if the control culture does not die, then the researcher cannot reject the hypothesis that the drug is efficacious.\nThe term \"spurious relationship\" is commonly used in statistics and in particular in experimental research techniques, both of which attempt to understand and predict direct causal relationships (X \u2192 Y). A non-causal correlation can be spuriously created by an antecedent which causes both (W \u2192 X and W \u2192 Y).  Intervening variables (X \u2192 W \u2192 Y), if undetected, may make indirect causation look direct.  Because of this, experimentally identified correlations do not represent causal relationships unless spurious relationships can be ruled out.\nOften one tests a null hypothesis of no correlation between two variables, and chooses in advance to reject the hypothesis if the correlation computed from a data sample would have occurred in less than (say) 5% of data samples if the null hypothesis were true. While a true null hypothesis will be accepted 95% of the time, the other 5% of the times having a true null of no correlation a zero correlation will be wrongly rejected, causing acceptance of a correlation which is spurious (an event known as Type I error). Here the spurious correlation in the sample resulted from random selection of a sample that did not reflect the true properties of the underlying population.\nAnother commonly noted example is a series of Dutch statistics showing a positive correlation between the number of storks nesting in a series of springs and the number of human babies born at that time.  Of course there was no causal connection; they were correlated with each other only because they were correlated with the weather nine months before the observations.[5] However H\u00f6fer et al. (2004) showed the correlation to be stronger than just weather variations as he could show in post reunification Germany that, while the number of clinical deliveries was not linked with the rise in stork population, out of hospital deliveries correlated with the stork population.[6]\nAn example of a spurious relationship can be seen by examining a city's ice cream sales. These sales are highest when the rate of drownings in city swimming pools is highest. To allege that ice cream sales cause drowning, or vice versa, would be to imply a spurious relationship between the two. In reality, a heat wave may have caused both. The heat wave is an example of a hidden or unseen variable, also known as a confounding variable.\nA well-known case of a spurious relationship can be found in the time-series literature, where a spurious regression is a regression that provides misleading statistical evidence of a linear relationship between independent non-stationary variables. In fact, the non-stationarity may be due to the presence of a unit root in both variables.[3][4] In particular, any two nominal economic variables are likely to be correlated with each other, even when neither has a causal effect on the other, because each equals a real variable times the price level, and the common presence of the price level in the two data series imparts correlation to them. (See also Spurious correlation of ratios.)\nIn statistics, a spurious relationship or spurious correlation[1][2]    is a mathematical relationship in which two or more events or variables are not causally related to each other, yet it may be wrongly inferred that they are, due to either coincidence or the presence of a certain third, unseen factor (referred to as a \"common response variable\", \"confounding factor\", or \"lurking variable\").\n",
            "title": "Spurious relationship",
            "url": "https://en.wikipedia.org/wiki/Spurious_correlation"
        },
        {
            "desc_links": [
                "/wiki/Random_assignment",
                "/wiki/Randomized_controlled_trial",
                "/wiki/Experiment",
                "/wiki/Control_group",
                "/wiki/Scientific_control",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Statistical_population",
                "/wiki/Sample_(statistics)",
                "/wiki/Statistics",
                "/wiki/Psychology",
                "/wiki/Social_science",
                "/wiki/Epidemiology"
            ],
            "desc_text": "b'In fields such as epidemiology, social sciences, psychology  and statistics, an observational study draws inferences from a sample to a population where the independent variable is not under the control of the researcher because of ethical concerns or logistical constraints. One common observational study is about the possible effect of a treatment on subjects, where the assignment of subjects into a treated group versus a control group is outside the control of the investigator.[1][2] This is in contrast with experiments, such as randomized controlled trials, where each subject is randomly assigned to a treated group or a control group.\\n'",
            "links": [
                "/wiki/Random_assignment",
                "/wiki/Randomized_controlled_trial",
                "/wiki/Experiment",
                "/wiki/Control_group",
                "/wiki/Scientific_control",
                "/wiki/Dependent_and_independent_variables",
                "/wiki/Statistical_population",
                "/wiki/Sample_(statistics)",
                "/wiki/Statistics",
                "/wiki/Psychology",
                "/wiki/Social_science",
                "/wiki/Epidemiology",
                "/wiki/Bias",
                "/wiki/Confounding",
                "/wiki/Propensity_score_matching",
                "/wiki/Matching_(statistics)",
                "/wiki/Social_science",
                "/wiki/Healthcare",
                "/wiki/Multivariate_statistics",
                "/wiki/Randomized_controlled_trial",
                "/wiki/Cochrane_Collaboration",
                "/wiki/Strengthening_the_reporting_of_observational_studies_in_epidemiology"
            ],
            "text": "In 2007, several prominent medical researchers issued the Strengthening the reporting of observational studies in epidemiology (STROBE) statement, in which they called for observational studies to conform to 22 criteria that would make their conclusions easier to understand and generalise.[6]\nA report from the Cochrane Collaboration in 2014 came to the conclusion that observational studies are very similar in results reported by similarly conducted randomized controlled trials. In other words, it reported little evidence for significant effect estimate differences between observational studies and randomized controlled trials, regardless of specific observational study design, heterogeneity, or inclusion of studies of pharmacological interventions. It, therefore, recommended that factors other than study design per se need to be considered when exploring reasons for a lack of agreement between results of randomized controlled trials and observational studies.[5]\nIn lieu of experimental control, multivariate statistical techniques allow the approximation of experimental control with statistical control, which accounts for the influences of observed factors that might influence a cause-and-effect relationship. In healthcare and the social sciences, investigators may use matching to compare units that nonrandomly received the treatment and control. One common approach is to use propensity score matching in order to reduce confounding.[4]\nAn observer of an uncontrolled experiment (or process) records potential factors and the data output: the goal is to determine the effects of the factors.  Sometimes the recorded factors may not be directly causing the differences in the output.  There may be more important factors which were not recorded but are, in fact, causal.  Also, recorded or unrecorded factors may be correlated which may yield incorrect conclusions.  Finally, as the number of recorded factors increases, the likelihood increases that at least one of the recorded factors will be highly correlated with the data output simply by chance.\nIn all of those cases, if a randomized experiment cannot be carried out, the alternative line of investigation suffers from the problem that the decision of which subjects receive the treatment is not entirely random and thus is a potential source of bias.  A major challenge in conducting observational studies is to draw inferences that are acceptably free from influences by overt biases, as well as to assess the influence of potential hidden biases.\nAlthough observational studies cannot be used to make definitive statements of fact about the \"safety, efficacy, or effectiveness\" of a practice,[3] they can still be of use for some other things:\nThe independent variable may be beyond the control of the investigator for a variety of reasons:\nIn fields such as epidemiology, social sciences, psychology  and statistics, an observational study draws inferences from a sample to a population where the independent variable is not under the control of the researcher because of ethical concerns or logistical constraints. One common observational study is about the possible effect of a treatment on subjects, where the assignment of subjects into a treated group versus a control group is outside the control of the investigator.[1][2] This is in contrast with experiments, such as randomized controlled trials, where each subject is randomly assigned to a treated group or a control group.\n",
            "title": "Observational study",
            "url": "https://en.wikipedia.org/wiki/Observational_studies"
        },
        {
            "desc_links": [
                "/wiki/Autoimmune_disorders",
                "/wiki/Allergy",
                "/wiki/Hypersensitivity",
                "/wiki/Immunodeficiency",
                "/wiki/Immune_system",
                "/wiki/Pathogen",
                "/wiki/Medical_sign",
                "/wiki/Symptom",
                "/wiki/Form_follows_function",
                "/wiki/Human_variability",
                "/wiki/Behavior",
                "/wiki/Symptom",
                "/wiki/Infection",
                "/wiki/Syndrome",
                "/wiki/Disease#disorder",
                "/wiki/Disability",
                "/wiki/Injury",
                "/wiki/Death",
                "/wiki/Social_problems",
                "/wiki/Distress_(medicine)",
                "/wiki/Abnormality_(behavior)",
                "/wiki/Pain",
                "/wiki/Lower_respiratory_infections",
                "/wiki/Cerebrovascular_disease",
                "/wiki/Coronary_artery_disease",
                "/wiki/Non-communicable_disease",
                "/wiki/Transmission_(medicine)",
                "/wiki/Non-Mendelian_inheritance",
                "/wiki/Genetic_disorder",
                "/wiki/Infectious_disease",
                "/wiki/Death_by_natural_causes",
                "/wiki/Etiology_(medicine)",
                "/wiki/Pathology"
            ],
            "desc_text": "b'\\n\\n\\n'b'A disease is a particular abnormal condition that negatively affects the structure or function of part or all of an organism, and that is not due to any external injury.[1][2] Diseases are often construed as medical conditions that are associated with specific symptoms and signs.[1] A disease may be caused by external factors such as pathogens or by internal dysfunctions.  For example, internal dysfunctions of the immune system can produce a variety of different diseases, including various forms of immunodeficiency, hypersensitivity, allergies and autoimmune disorders.\\n'b\"In humans, disease is often used more broadly to refer to any condition that causes pain, dysfunction, distress, social problems, or death to the person afflicted, or similar problems for those in contact with the person[3]. In this broader sense, it sometimes includes injuries, disabilities, disorders, syndromes, infections, isolated symptoms, deviant behaviors, and atypical variations of structure and function, while in other contexts and for other purposes these may be considered distinguishable categories. Diseases can affect people not only physically, but also emotionally, as contracting and living with a disease can alter the affected person's perspective on life.\\n\"b'Death due to disease is called death by natural causes. There are four main types of disease: infectious diseases, deficiency diseases, hereditary diseases (including both genetic diseases and non-genetic hereditary diseases), and physiological diseases. Diseases can also be classified in other ways, such as communicable versus non-communicable diseases. The deadliest diseases in humans are coronary artery disease (blood flow obstruction), followed by cerebrovascular disease and lower respiratory infections.[4]\\n'b'The study of disease is called pathology, which includes the study of etiology, or cause[5].\\n'",
            "links": [
                "/wiki/Autoimmune_disorders",
                "/wiki/Allergy",
                "/wiki/Hypersensitivity",
                "/wiki/Immunodeficiency",
                "/wiki/Immune_system",
                "/wiki/Pathogen",
                "/wiki/Medical_sign",
                "/wiki/Symptom",
                "/wiki/Form_follows_function",
                "/wiki/Human_variability",
                "/wiki/Behavior",
                "/wiki/Symptom",
                "/wiki/Infection",
                "/wiki/Syndrome",
                "/wiki/Disease#disorder",
                "/wiki/Disability",
                "/wiki/Injury",
                "/wiki/Death",
                "/wiki/Social_problems",
                "/wiki/Distress_(medicine)",
                "/wiki/Abnormality_(behavior)",
                "/wiki/Pain",
                "/wiki/Lower_respiratory_infections",
                "/wiki/Cerebrovascular_disease",
                "/wiki/Coronary_artery_disease",
                "/wiki/Non-communicable_disease",
                "/wiki/Transmission_(medicine)",
                "/wiki/Non-Mendelian_inheritance",
                "/wiki/Genetic_disorder",
                "/wiki/Infectious_disease",
                "/wiki/Death_by_natural_causes",
                "/wiki/Etiology_(medicine)",
                "/wiki/Pathology",
                "/wiki/Herpes_zoster",
                "/wiki/Acute_(medicine)",
                "/wiki/Chickenpox",
                "/wiki/Varicella_zoster_virus",
                "/wiki/Viral_latency",
                "/wiki/Latency_period",
                "/wiki/Incubation_period",
                "/wiki/Organ_system",
                "/wiki/Symptom",
                "/wiki/Mechanism_(biology)",
                "/wiki/Pathogenesis",
                "/wiki/Syndrome",
                "/wiki/ICD-10",
                "/wiki/International_Statistical_Classification_of_Diseases_and_Related_Health_Problems",
                "/wiki/World_Health_Organization",
                "/wiki/Nutrition",
                "/wiki/Microorganism",
                "/wiki/Sexually_transmitted_disease",
                "/wiki/Feces",
                "/wiki/Vector_(epidemiology)",
                "/wiki/Infectious_disease",
                "/wiki/Influenza",
                "/wiki/Genetic_disorder",
                "/wiki/Non-infectious_disease",
                "/wiki/Heart_disease",
                "/wiki/Cancer",
                "/wiki/Infectious_cancer",
                "/wiki/Social_determinants_of_health_in_poverty",
                "/wiki/Canada",
                "/wiki/Environmental_disease",
                "/wiki/Social_determinants_of_health",
                "/wiki/Social_ills",
                "/wiki/Depression_(mood)",
                "/wiki/Sedentary_lifestyle",
                "/wiki/Hereditary_disease",
                "/wiki/Tuberculosis",
                "/wiki/Metaphor",
                "/wiki/Epidemiology",
                "/wiki/Plasmodium",
                "/wiki/Malaria",
                "/wiki/Public_health",
                "/wiki/Self-care",
                "/wiki/Vaccination",
                "/wiki/Exercise",
                "/wiki/Nutrition",
                "/wiki/Sanitation",
                "/wiki/Health_care_system",
                "/wiki/Self-care",
                "/wiki/Medical_devices",
                "/wiki/Surgery",
                "/wiki/Medication",
                "/wiki/Psychotherapy",
                "/wiki/Therapy",
                "/wiki/Pain_management",
                "/wiki/Cure",
                "/wiki/Chronic_diseases",
                "/wiki/Preventive_healthcare",
                "/wiki/Urgent_care",
                "/wiki/Emergency_department",
                "/wiki/Medical_emergencies",
                "/wiki/Social_science",
                "/wiki/Geographic_Information_Science",
                "/wiki/Biostatistics",
                "/wiki/Biology",
                "/wiki/Syndemic",
                "/wiki/Outbreak",
                "/wiki/Risk_factor",
                "/wiki/Evidence-based_medicine",
                "/wiki/Disease_burden",
                "/wiki/World_Health_Organization",
                "/wiki/Years_of_potential_life_lost",
                "/wiki/Major_depressive_disorder",
                "/wiki/Neuropsychiatric_conditions",
                "/wiki/Stroke",
                "/wiki/Heart_disease",
                "/wiki/Disability-adjusted_life_year",
                "/wiki/Quality-adjusted_life_year",
                "/wiki/Medical_sociology",
                "/wiki/Hmong_people",
                "/wiki/Epilepsy",
                "/wiki/AIDS_wasting",
                "/wiki/Obesity",
                "/wiki/Pregnancy",
                "/wiki/Social_status",
                "/wiki/Cancer_survivor",
                "/wiki/Sick_role",
                "/wiki/White_House",
                "/wiki/Ramadan",
                "/wiki/Yom_Kippur",
                "/wiki/Fasting",
                "/wiki/Senescence",
                "/wiki/Shell_shock",
                "/wiki/Da_Costa%27s_syndrome",
                "/wiki/Post-traumatic_stress_disorder",
                "/wiki/Repetitive_stress_injury",
                "/wiki/Social_stigma",
                "/wiki/Leprosy",
                "/wiki/Cancer",
                "/wiki/Lifestyle_disease",
                "/wiki/Diabetes_mellitus",
                "/wiki/Diseases_of_affluence",
                "/wiki/Poverty",
                "/wiki/Diseases_of_poverty",
                "/wiki/Illness_narrative",
                "/wiki/War_on_Cancer",
                "/wiki/Military",
                "/wiki/Affective",
                "/wiki/Metaphor",
                "/wiki/Metonymy",
                "/wiki/Chemotherapy",
                "/wiki/Addiction",
                "/wiki/Slavery",
                "/wiki/Transcendence_(religion)",
                "/wiki/Tuberculosis_in_popular_culture",
                "/wiki/Type_2_diabetes_mellitus",
                "/wiki/Avian_flu_outbreak_of_2009"
            ],
            "text": "Some diseases are used as metaphors for social ills:  \"Cancer\" is a common description for anything that is endemic and destructive in society, such as poverty, injustice, or racism.  AIDS was seen as a divine judgment for moral decadence, and only by purging itself from the \"pollution\" of the \"invader\" could society become healthy again.[38]  More recently, when AIDS seemed less threatening, this type of emotive language was applied to avian flu and type 2 diabetes mellitus.[41]  Authors in the 19th century commonly used tuberculosis as a symbol and a metaphor for transcendence.  Victims of the disease were portrayed in literature as having risen above daily life to become ephemeral objects of spiritual or artistic achievement.  In the 20th century, after its cause was better understood, the same disease became the emblem of poverty, squalor, and other social problems.[40]\nSome metaphors are disease-specific.  Slavery is a common metaphor for addictions:  The alcoholic is enslaved by drink, and the smoker is captive to nicotine.  Some cancer patients treat the loss of their hair from chemotherapy as a metonymy or metaphor for all the losses caused by the disease.[38]\nAnother class of metaphors describes the experience of illness as a journey:  The person travels to or from a place of disease, and changes himself, discovers new information, or increases his experience along the way.  He may travel \"on the road to recovery\" or make changes to \"get on the right track\" or choose \"pathways\".[38][39] Some are explicitly immigration-themed:  the patient has been exiled from the home territory of health to the land of the ill, changing identity and relationships in the process.[40]  This language is more common among British healthcare professionals than the language of physical aggression.[39]\nPeople use metaphors to make sense of their experiences with disease.  The metaphors move disease from an objective thing that exists to an affective experience.  The most popular metaphors draw on military concepts:  Disease is an enemy that must be feared, fought, battled, and routed.  The patient or the healthcare provider is a warrior, rather than a passive victim or bystander. The agents of communicable diseases are invaders; non-communicable diseases constitute internal insurrection or civil war.  Because the threat is urgent, perhaps a matter of life and death, unthinkably radical, even oppressive, measures are society's and the patient's moral duty as they courageously mobilize to struggle against destruction.  The War on Cancer is an example of this metaphorical use of language.[38]  This language is empowering to some patients, but leaves others feeling like they are failures.[39]\nAn illness narrative is a way of organizing a medical experience into a coherent story that illustrates the sick individual's personal experience.\nSocial standing and economic status affect health.  Diseases of poverty are diseases that are associated with poverty and low social status; diseases of affluence are diseases that are associated with high social and economic status.  Which diseases are associated with which states varies according to time, place, and technology.  Some diseases, such as diabetes mellitus, may be associated with both poverty (poor food choices) and affluence (long lifespans and sedentary lifestyles), through different mechanisms.  The term lifestyle diseases describes diseases associated with longevity and that are more common among older people.  For example, cancer is far more common in societies in which most members live until they reach the age of 80 than in societies in which most members die before they reach the age of 50.\nLepers were people who were historically shunned because they had an infectious disease, and the term \"leper\" still evokes social stigma. Fear of disease can still be a widespread social phenomenon, though not all diseases evoke extreme social stigma.\nThe identification of a condition as a disease, rather than as simply a variation of human structure or function, can have significant social or economic implications. The controversial recognitions as diseases of repetitive stress injury (RSI) and post-traumatic stress disorder (also known as \"Soldier's heart\", \"shell shock\", and \"combat fatigue\") has had a number of positive and negative effects on the financial and other responsibilities of governments, corporations and institutions towards individuals, as well as on the individuals themselves. The social implication of viewing aging as a disease could be profound, though this classification is not yet widespread.\nMost religions grant exceptions from religious duties to people who are sick. For example, one whose life would be endangered by  fasting on Yom Kippur or during Ramadan is exempted from the requirement, or even forbidden from participating.  People who are sick are also exempted from social duties.  For example, ill health is the only socially acceptable reason for an American to refuse an invitation to the White House.[37]\nSickness confers the social legitimization of certain benefits, such as illness benefits, work avoidance, and being looked after by others.  The person who is sick takes on a social role called the sick role.  A person who responds to a dreaded disease, such as cancer, in a culturally acceptable fashion may be publicly and privately honored with higher social status.[36]  In return for these benefits, the sick person is obligated to seek treatment and work to become well once more.  As a comparison, consider pregnancy, which is not interpreted as a disease or sickness, even if the mother and baby may both benefit from medical care.\nA condition may be considered a disease in some cultures or eras but not in others.  For example, obesity can represent wealth and abundance, and is a status symbol in famine-prone areas and some places hard-hit by HIV/AIDS.[34]  Epilepsy is considered a sign of spiritual gifts among the Hmong people.[35]\nHow a society responds to diseases is the subject of medical sociology.\nThe quality-adjusted life year (QALY) and disability-adjusted life year (DALY) metrics are similar, but take into account whether the person was healthy after diagnosis.  In addition to the number of years lost due to premature death, these measurements add part of the years lost to being sick.  Unlike YPLL, these measurements show the burden imposed on people who are very sick, but who live a normal lifespan.  A disease that has high morbidity, but low mortality, has a high DALY and a low YPLL.  In 2004, the World Health Organization calculated that 1.5 billion disability-adjusted life years were lost to disease and injury.[32]  In the developed world, heart disease and stroke cause the most loss of life, but neuropsychiatric conditions like major depressive disorder cause the most years lost to being sick.\nThere are several measures used to quantify the burden imposed by diseases on people.  The years of potential life lost (YPLL) is a simple estimate of the number of years that a person's life was shortened due to a disease.  For example, if a person dies at the age of 65 from a disease, and would probably have lived until age 80 without that disease, then that disease has caused a loss of 15 years of potential life.  YPLL measurements do not account for how disabled a person is before dying, so the measurement treats a person who dies suddenly and a person who died at the same age after decades of illness as equivalent.  In 2004, the World Health Organization calculated that 932 million years of potential life were lost to premature death.[32]\nDisease burden is the impact of a health problem in an area measured by financial cost, mortality, morbidity, or other indicators.\nSome morbidity databases are compiled with data supplied by states and territories health authorities, at national levels[29][30] or larger scale (such as European Hospital Morbidity Database (HMDB))[31] which may contain hospital discharge data by detailed diagnosis, age and sex. The European HMDB datea was submitted by European countries to the World Health Organization Regional Office for Europe.\nIn studying diseases, epidemiology faces the challenge of defining them.  Especially for poorly understood diseases, different groups might use significantly different definitions.  Without an agreed-on definition, different researchers may report different numbers of cases and characteristics of the disease.[28]\nEpidemiology is considered a cornerstone methodology of public health research, and is highly regarded in evidence-based medicine for identifying risk factors for disease. In the study of communicable and non-communicable diseases, the work of epidemiologists ranges from outbreak investigation to study design, data collection and analysis including the development of statistical models to test hypotheses and the documentation of results for submission to peer-reviewed journals. Epidemiologists also study the interaction of diseases in a population, a condition known as a syndemic. Epidemiologists rely on a number of other scientific disciplines such as biology (to better understand disease processes), biostatistics (the current raw information available), Geographic Information Science (to store data and map disease patterns) and social science disciplines (to better understand proximate and distal risk factors).  Epidemiology can help identify causes as well as guide prevention efforts.\nEpidemiology is the study of the factors that cause or encourage diseases.  Some diseases are more common in certain geographic areas, among people with certain genetic or socioeconomic characteristics, or at different times of the year.\nTreatment for medical emergencies must be provided promptly, often through an emergency department or, in less critical situations, through an urgent care facility.\nPreventive healthcare is a way to avoid an injury, sickness, or disease in the first place.  A treatment or cure is applied after a medical problem has already started.  A treatment attempts to improve or remove a problem, but treatments may not produce permanent cures, especially in chronic diseases.  Cures are a subset of treatments that reverse diseases completely or end medical problems permanently.  Many diseases that cannot be completely cured are still treatable. Pain management (also called pain medicine) is that branch of medicine employing an interdisciplinary approach to the relief of pain and improvement in the quality of life of those living with pain.[27]\nMedical therapies or treatments are efforts to cure or improve a disease or other health problem.  In the medical field, therapy is synonymous with the word treatment.  Among psychologists, the term may refer specifically to psychotherapy or \"talk therapy\".  Common treatments include medications, surgery, medical devices, and self-care.  Treatments may be provided by an organized health care system, or informally, by the patient or family members.\nMany diseases and disorders can be prevented through a variety of means.  These include sanitation, proper nutrition, adequate exercise, vaccinations and other self-care and public health measures.\nWhen a disease is caused by a pathogen (e.g., when the disease malaria is caused by infection by Plasmodium parasites.), the term disease may be misleadingly used even in the scientific literature in place of its causal agent, the pathogen. This language habit can cause confusion in the communication of the cause-effect principle in epidemiology, and as such it should be strongly discouraged.[26]\nWhen the cause of a disease is poorly understood, societies tend to mythologize the disease or use it as a metaphor or symbol of whatever that culture considers evil.  For example, until the bacterial cause of tuberculosis was discovered in 1882, experts variously ascribed the disease to heredity, a sedentary lifestyle, depressed mood, and overindulgence in sex, rich food, or alcohol\u2014all the social ills of the time.[25]\nSocial determinants of health are the social conditions in which people live that determine their health. Illnesses are generally related to social, economic, political, and environmental circumstances. Social determinants of health have been recognized by several health organizations such as the Public Health Agency of Canada and the World Health Organization to greatly influence collective and personal well-being. The World Health Organization's Social Determinants Council also recognizes Social determinants of health in poverty.\nSome diseases, such as most (but not all) forms of cancer, heart disease, and mental disorders, are non-infectious diseases. Many non-infectious diseases have a partly or completely genetic basis (see genetic disorder) and may thus be transmitted from one generation to another.\nOnly some diseases such as influenza are contagious and commonly believed infectious. The micro-organisms that cause these diseases are known as pathogens and include varieties of bacteria, viruses, protozoa and fungi. Infectious diseases can be transmitted, e.g. by hand-to-mouth contact with infectious material on surfaces, by bites of insects or other carriers of the disease, and from contaminated water or food (often via fecal contamination), etc.[24]  Also, there are sexually transmitted diseases. In some cases, microorganisms that are not readily spread from person to person play a role, while other diseases can be prevented or ameliorated with appropriate nutrition or other lifestyle changes.\nThe most known and used classification of diseases is the World Health Organization's ICD. This is periodically updated. Currently the last publication is the ICD-10.\nClassical classification of human disease derives from observational correlation between pathological analysis and clinical syndromes. Today it is preferred to classify them by their cause if it is known.[23]\nA chief difficulty in nosology is that diseases often cannot be defined and classified clearly, especially when cause or pathogenesis are unknown.  Thus diagnostic terms often only reflect a symptom or set of symptoms (syndrome).\nDiseases may be classified by cause, pathogenesis (mechanism by which the disease is caused), or by symptom(s). Alternatively, diseases may be classified according to the organ system involved, though this is often complicated since many diseases affect more than one organ.\nIn an infectious disease, the incubation period is the time between infection and the appearance of symptoms.  The latency period is the time between infection and the ability of the disease to spread to another person, which may precede, follow, or be simultaneous with the appearance of symptoms.  Some viruses also exhibit a dormant phase, called viral latency, in which the virus hides in the body in an inactive state.  For example, varicella zoster virus causes chickenpox in the acute phase; after recovery from chickenpox, the virus may remain dormant in nerve cells for many years, and later cause herpes zoster (shingles).\nIn many cases, terms such as disease, disorder, morbidity, sickness and illness are used interchangeably.[6]  There are situations, however, when specific terms are considered preferable.\nThe study of disease is called pathology, which includes the study of etiology, or cause[5].\nDeath due to disease is called death by natural causes. There are four main types of disease: infectious diseases, deficiency diseases, hereditary diseases (including both genetic diseases and non-genetic hereditary diseases), and physiological diseases. Diseases can also be classified in other ways, such as communicable versus non-communicable diseases. The deadliest diseases in humans are coronary artery disease (blood flow obstruction), followed by cerebrovascular disease and lower respiratory infections.[4]\nIn humans, disease is often used more broadly to refer to any condition that causes pain, dysfunction, distress, social problems, or death to the person afflicted, or similar problems for those in contact with the person[3]. In this broader sense, it sometimes includes injuries, disabilities, disorders, syndromes, infections, isolated symptoms, deviant behaviors, and atypical variations of structure and function, while in other contexts and for other purposes these may be considered distinguishable categories. Diseases can affect people not only physically, but also emotionally, as contracting and living with a disease can alter the affected person's perspective on life.\nA disease is a particular abnormal condition that negatively affects the structure or function of part or all of an organism, and that is not due to any external injury.[1][2] Diseases are often construed as medical conditions that are associated with specific symptoms and signs.[1] A disease may be caused by external factors such as pathogens or by internal dysfunctions.  For example, internal dysfunctions of the immune system can produce a variety of different diseases, including various forms of immunodeficiency, hypersensitivity, allergies and autoimmune disorders.\n\n\n\n",
            "title": "Disease",
            "url": "https://en.wikipedia.org/wiki/Morbidity"
        },
        {
            "desc_links": [
                "/wiki/Cigarette",
                "/wiki/Western_world",
                "/wiki/European_colonisation_of_the_Americas",
                "/wiki/Eurasia",
                "/wiki/South_America",
                "/wiki/Mesoamerica",
                "/wiki/Cigars",
                "/wiki/Tobacco_pipes",
                "/wiki/Tobacco_smoke",
                "/wiki/Tobacco",
                "/wiki/Smoking",
                "/wiki/Developing_world",
                "/wiki/Developed_world",
                "/wiki/World_War_II",
                "/wiki/Nazi_Germany",
                "/wiki/Allied-occupied_Germany",
                "/wiki/Anti-smoking_campaign",
                "/wiki/Lung_cancer",
                "/wiki/Endorphin",
                "/wiki/Dopamine",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Nitrates",
                "/wiki/Potassium",
                "/wiki/Oral_mucosa",
                "/wiki/Pulmonary_alveolus",
                "/wiki/Combustion",
                "/wiki/Negative_reinforcement",
                "/wiki/Nicotine_withdrawal",
                "/wiki/Peer_pressure",
                "/wiki/Positive_reinforcement",
                "/wiki/Early_adulthood",
                "/wiki/Adolescence",
                "/wiki/Seventh-grade"
            ],
            "desc_text": "b'\\n'b'Tobacco smoking is the practice of smoking tobacco and inhaling tobacco smoke (consisting of particle and gaseous phases). (A more broad definition may include simply taking tobacco smoke into the mouth, and then releasing it, as is done by some with tobacco pipes and cigars.) The practice is believed to have begun as early as 5000\\xe2\\x80\\x933000 BC in Mesoamerica and South America.[1] Tobacco was introduced to Eurasia in the late 17th century by European colonists, where it followed common trade routes. The practice encountered criticism from its first import into the Western world onwards but embedded itself in certain strata of a number of societies before becoming widespread upon the introduction of automated cigarette-rolling apparatus.[2][3]\\n'b'German scientists identified a link between smoking and lung cancer in the late 1920s, leading to the first anti-smoking campaign in modern history, albeit one truncated by the collapse of Nazi Germany at the end of World War II.[4] In 1950, British researchers demonstrated a clear relationship between smoking and cancer.[5] Evidence continued to mount in the 1980s, which prompted political action against the practice. Rates of consumption since 1965 in the developed world have either peaked or declined.[6] However, they continue to climb in the developing world.[7]\\n'b'Smoking is the most common method of consuming tobacco, and tobacco is the most common substance smoked. The agricultural product is often mixed with additives[8] and then combusted. The resulting smoke is then inhaled and the active substances absorbed through the alveoli in the lungs or the oral mucosa.[9] Combustion was traditionally enhanced by addition of potassium or nitrates.[citation needed] Many substances in cigarette smoke trigger chemical reactions in nerve endings, which heighten heart rate, alertness[10] and reaction time, among other things.[11] Dopamine and endorphins are released, which are often associated with pleasure.[12] As of 2008 to 2010, tobacco is used by about 49% of men and 11% of women aged 15 or older in fourteen low-income and middle-income countries (Bangladesh, Brazil, China, Egypt, India, Mexico, Philippines, Poland, Russia, Thailand, Turkey, Ukraine, Uruguay and Vietnam), with about 80% of this usage in the form of smoking.[13] The gender gap tends to be less pronounced in lower age groups.[14][15]\\n'b'Many smokers begin during adolescence or early adulthood.[16] During the early stages, a combination of perceived pleasure acting as positive reinforcement and desire to respond to social peer pressure may offset the unpleasant symptoms of initial use, which typically include nausea and coughing. After an individual has smoked for some years, the avoidance of withdrawal symptoms and negative reinforcement become the key motivations to continue.\\n'b'A study of first smoking experiences of seventh-grade students found out that the most common factor leading students to smoke is cigarette advertisements. Smoking by parents, siblings and friends also encourages students to smoke.[17]\\n'",
            "links": [
                "/wiki/Cigarette",
                "/wiki/Western_world",
                "/wiki/European_colonisation_of_the_Americas",
                "/wiki/Eurasia",
                "/wiki/South_America",
                "/wiki/Mesoamerica",
                "/wiki/Cigars",
                "/wiki/Tobacco_pipes",
                "/wiki/Tobacco_smoke",
                "/wiki/Tobacco",
                "/wiki/Smoking",
                "/wiki/Developing_world",
                "/wiki/Developed_world",
                "/wiki/World_War_II",
                "/wiki/Nazi_Germany",
                "/wiki/Allied-occupied_Germany",
                "/wiki/Anti-smoking_campaign",
                "/wiki/Lung_cancer",
                "/wiki/Endorphin",
                "/wiki/Dopamine",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Nitrates",
                "/wiki/Potassium",
                "/wiki/Oral_mucosa",
                "/wiki/Pulmonary_alveolus",
                "/wiki/Combustion",
                "/wiki/Negative_reinforcement",
                "/wiki/Nicotine_withdrawal",
                "/wiki/Peer_pressure",
                "/wiki/Positive_reinforcement",
                "/wiki/Early_adulthood",
                "/wiki/Adolescence",
                "/wiki/Seventh-grade",
                "/wiki/Shamanism",
                "/wiki/Babylonians",
                "/wiki/South_America",
                "/wiki/Mesoamerica",
                "/wiki/Ceremonial_pipe",
                "/wiki/Cough_root",
                "/wiki/Balsam_of_Peru",
                "/wiki/Salvia_dorrii",
                "/wiki/Desert_sage",
                "/wiki/Poultice",
                "/wiki/Slavery_in_the_United_States",
                "/wiki/American_Revolution",
                "/wiki/Bacon%27s_Rebellion",
                "/wiki/Indentured_servitude",
                "/wiki/Virginia_joint_stock_company",
                "/wiki/John_Rolfe",
                "/wiki/Jamestown,_Virginia",
                "/wiki/Timbuktu",
                "/wiki/Morocco",
                "/wiki/Senegal",
                "/wiki/Gambia",
                "/wiki/Jean_Nicot",
                "/wiki/Shogunate",
                "/wiki/Edo_period",
                "/wiki/Qing_dynasty",
                "/wiki/Manchu_people",
                "/wiki/Ming_dynasty",
                "/wiki/Chongzhen_Emperor",
                "/wiki/Ottoman_Empire",
                "/wiki/Murad_IV",
                "/wiki/A_Counterblaste_to_Tobacco",
                "/wiki/James_VI_and_I",
                "/wiki/A_Counterblaste_to_Tobacco",
                "/wiki/James_I_of_England",
                "/wiki/Urban_VIII",
                "/wiki/Patriarch_of_Moscow",
                "/wiki/James_Bonsack",
                "/wiki/Sharecropping",
                "/wiki/Slavery",
                "/wiki/Adolf_Hitler",
                "/wiki/Fritz_Lickint",
                "/wiki/Robert_N._Proctor",
                "/wiki/History_of_Germany_since_1945",
                "/wiki/Marshall_Plan",
                "/wiki/Anti-tobacco_movement_in_Nazi_Germany",
                "/wiki/Lung_cancer",
                "/wiki/Smoking",
                "/wiki/Reader%27s_Digest",
                "/wiki/Lung_cancer",
                "/wiki/British_Medical_Journal",
                "/wiki/Richard_Doll",
                "/wiki/Surgeon_General_of_the_United_States",
                "/wiki/British_Doctors_Study",
                "/wiki/Tobacco_Master_Settlement_Agreement",
                "/wiki/Contributory_negligence",
                "/wiki/National_Non-Smoking_Week",
                "/wiki/Jordan",
                "/wiki/Belarus",
                "/wiki/Ukraine",
                "/wiki/Laos",
                "/wiki/Indonesia",
                "/wiki/Developing_world",
                "/wiki/List_of_additives_in_cigarettes",
                "/wiki/PH",
                "/wiki/Carotenoid",
                "/wiki/Oxidation",
                "/wiki/Nicotiana_rustica",
                "/wiki/Nicotiana_tabacum",
                "/wiki/Nicotiana",
                "/wiki/Tobacco",
                "/wiki/Enzyme_substrate",
                "/wiki/Mucous_membranes",
                "/wiki/Vertebrate_trachea",
                "/wiki/Alkalinity",
                "/wiki/Pyrolysis",
                "/wiki/Alveoli",
                "/wiki/Working_memory",
                "/wiki/Prefrontal_Cortex_Basal_Ganglia_Working_Memory",
                "/wiki/Reinforcing",
                "/wiki/Nucleus_accumbens",
                "/wiki/Nicotinic_acetylcholine_receptor",
                "/wiki/Neurotransmitter",
                "/wiki/Acetylcholine",
                "/wiki/Nicotinic_acetylcholine_receptor",
                "/wiki/Nicotinic_acetylcholine_receptor",
                "/wiki/Nicotine",
                "/wiki/Reinforcement",
                "/wiki/Nucleus_accumbens",
                "/wiki/MAO_inhibitor",
                "/wiki/Harmala",
                "/wiki/Adolescent",
                "/wiki/Developing_world",
                "/wiki/Developed_world",
                "/wiki/World_Health_Organization",
                "/wiki/Self-selection",
                "/wiki/Peer_pressure",
                "/wiki/Norm_(sociology)",
                "/wiki/Adolescent",
                "/wiki/Positive_reinforcement",
                "/wiki/Dopamine",
                "/wiki/Operant_conditioning",
                "/wiki/Extraversion",
                "/wiki/Hans_Eysenck",
                "/wiki/Imperial_College_London",
                "/wiki/Depressant",
                "/wiki/Cigarette_pack",
                "/wiki/Centers_for_Disease_Control_and_Prevention",
                "/wiki/Universal_healthcare",
                "/wiki/Cato_Institute",
                "/wiki/Public_Finance_Balance_of_Smoking_in_the_Czech_Republic",
                "/wiki/Czech_Republic",
                "/wiki/Philip_Morris_International",
                "/wiki/World_Health_Organization",
                "/wiki/Bladder_cancer",
                "/wiki/Crohn%27s_disease",
                "/wiki/Pancreatic_cancer",
                "/wiki/Esophageal_cancer",
                "/wiki/Oral_cancer",
                "/wiki/Laryngeal_cancer",
                "/wiki/Lung_cancer",
                "/wiki/Cancer",
                "/wiki/Emphysema",
                "/wiki/Idiopathic_Pulmonary_Fibrosis",
                "/wiki/Chronic_obstructive_pulmonary_disease",
                "/wiki/Stroke",
                "/wiki/Myocardial_infarction",
                "/wiki/Carcinogenesis",
                "/wiki/Genotoxicity",
                "/wiki/Carcinogenesis",
                "/wiki/Toxicology",
                "/wiki/Centers_for_Disease_Control_and_Prevention",
                "/wiki/World_Health_Organization",
                "/wiki/Lung_cancer",
                "/wiki/Second-hand_smoke",
                "/wiki/Erectile_dysfunction",
                "/wiki/Anaphrodisiac",
                "/wiki/The_Sandman_(wrestler)",
                "/wiki/Professional_wrestling",
                "/wiki/Garth_Ennis",
                "/wiki/Preacher_(comics)",
                "/wiki/Alan_Moore",
                "/wiki/John_Constantine",
                "/wiki/Vertigo_Comics",
                "/wiki/DC_Comics",
                "/wiki/Sir_Arthur_Conan_Doyle",
                "/wiki/Sherlock_Holmes",
                "/wiki/Winston_Churchill",
                "/wiki/Harold_Wilson",
                "/wiki/Kurt_Vonnegut",
                "/wiki/Cornell_University",
                "/wiki/Edward_R._Murrow",
                "/wiki/Bing_Crosby",
                "/wiki/Bertrand_Russell",
                "/wiki/Douglas_MacArthur",
                "/wiki/Albert_Einstein",
                "/wiki/Gauloises",
                "/wiki/Jean-Paul_Sartre",
                "/wiki/Wikipedia:Please_clarify",
                "/wiki/Bah%C3%A1%27%C3%AD_Faith",
                "/wiki/Ramadhan",
                "/wiki/Ahmadiyya_Islam",
                "/wiki/Yisrael_Meir_Kagan",
                "/wiki/Revelation",
                "/wiki/Joseph_Smith",
                "/wiki/Latter_Day_Saint_movement",
                "/wiki/Anishinaabe",
                "/wiki/Native_Americans_in_the_United_States",
                "/wiki/Ceremonial_pipe",
                "/wiki/WHO_Framework_Convention_on_Tobacco_Control",
                "/wiki/Excise_tax",
                "/wiki/Wikipedia:Manual_of_Style/Dates_and_numbers",
                "/wiki/Cigarette_pack",
                "/wiki/Centers_for_Disease_Control_and_Prevention",
                "/wiki/Inelastic_good",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/New_York_(state)",
                "/wiki/Missouri",
                "/wiki/Black_market",
                "/wiki/Goods_and_Services_Tax_(Australia)",
                "/wiki/Radio",
                "/wiki/Television",
                "/wiki/Public_Health_Cigarette_Smoking_Act",
                "/wiki/Federal_Communications_Commission",
                "/wiki/European_Commission",
                "/wiki/National_Health_Service",
                "/wiki/Smoking_age",
                "/wiki/Germany",
                "/wiki/Romania",
                "/wiki/Brazil",
                "/wiki/Second-hand_smoke",
                "/wiki/Victoria_(Australia)",
                "/wiki/Malta",
                "/wiki/Turkey",
                "/wiki/Slovenia",
                "/wiki/Iceland",
                "/wiki/Chile",
                "/wiki/Lithuania",
                "/wiki/Indonesia",
                "/wiki/Singapore",
                "/wiki/Estonia",
                "/wiki/Latvia",
                "/wiki/Republic_of_Ireland",
                "/wiki/RJ_Reynolds",
                "/wiki/Lorillard",
                "/wiki/Philip_Morris_USA",
                "/wiki/RJ_Reynolds",
                "/wiki/Fire_safe_cigarette",
                "/wiki/Gateway_drug_theory",
                "/wiki/Randomized_controlled_trial",
                "/wiki/Hypnosis",
                "/wiki/Antidepressant",
                "/wiki/Nicotine_replacement_therapy",
                "/wiki/Cold_turkey"
            ],
            "text": "Smoking cessation, referred to as \"quitting\", is the action leading towards abstinence of tobacco smoking. Methods of \"quitting\" include advice from physicians or social workers,[16] cold turkey, nicotine replacement therapy, contingent vouchers,[142] antidepressants, hypnosis, self-help (mindfulness meditation),[143] and support groups. A meta-analysis from 2018, conducted on 61 RCT, showed that one year after people quit smoking with the assistance of first\u2010line smoking cessation medications (and some behavioral help), only a little under 20% of smokers remained sustained abstinence.[144]\nThe relationship between tobacco and other drug use has been well-established, however the nature of this association remains unclear. The two main theories are the phenotypic causation (gateway) model and the correlated liabilities model. The causation model argues that smoking is a primary influence on future drug use,[140] while the correlated liabilities model argues that smoking and other drug use are predicated on genetic or environmental factors.[141]\nAn indirect public health problem posed by cigarettes is that of accidental fires, usually linked with consumption of alcohol. Enhanced combustion using nitrates was traditionally used but cigarette manufacturers have been silent on this subject claiming at first that a safe cigarette was technically impossible, then that it could only be achieved by modifying the paper. Roll your own cigarettes contain no additives and are fire safe. Numerous fire safe cigarette designs have been proposed, some by tobacco companies themselves, which would extinguish a cigarette left unattended for more than a minute or two, thereby reducing the risk of fire. Among American tobacco companies, some have resisted this idea, while others have embraced it. RJ Reynolds was a leader in making prototypes of these cigarettes in 1983[137] and will make all of their U.S. market cigarettes to be fire-safe by 2010.[138] Phillip Morris is not in active support of it.[139] Lorillard (purchased by RJ Reynolds), the US' 3rd-largest tobacco company, seems to be ambivalent.[139]\nSeveral countries such as Ireland, Latvia, Estonia, the Netherlands, Finland, Norway, Canada, Australia, Sweden, Portugal, Singapore, Italy, Indonesia, India, Lithuania, Chile, Spain, Iceland, United Kingdom, Slovenia, Turkey and Malta have legislated against smoking in public places, often including bars and restaurants. Restaurateurs have been permitted in some jurisdictions to build designated smoking areas (or to prohibit smoking). In the United States, many states prohibit smoking in restaurants, and some also prohibit smoking in bars. In provinces of Canada, smoking is illegal in indoor workplaces and public places, including bars and restaurants. As of 31 March 2008 Canada has introduced a smoke-free law ban in all public places, as well as within 10 metres of an entrance to any public place. In Australia, smoke-free laws vary from state to state. Currently, Queensland has completely smoke-free indoor public places (including workplaces, bars, pubs and eateries) as well as patrolled beaches and some outdoor public areas. There are, however, exceptions for designated smoking areas. In Victoria, smoking is restricted in railway stations, bus stops and tram stops as these are public locations where second-hand smoke can affect non-smokers waiting for public transport, and since 1 July 2007 is now extended to all indoor public places. In New Zealand and Brazil, smoking is restricted in enclosed public places including bars, restaurants and pubs. Hong Kong restricted smoking on 1 January 2007 in the workplace, public spaces such as restaurants, karaoke rooms, buildings, and public parks (bars which do not admit minors were exempt until 2009). In Romania smoking is illegal in trains, metro stations, public institutions (except where designated, usually outside) and public transport.\nIn Germany, additionally to smoking bans in public buildings and transports, an anti-smoking ordinance for bars and restaurants was implemented in late 2007. A study by the University of Hamburg (Ahlfeldt and Maennig 2010) demonstrates, that the smoking ban had, if any, only short run impacts on bar and restaurant revenues. In the medium and long run no negative effect was measurable. The results suggest either, that the consumption in bars and restaurants is not affected by smoking bans in the long run, or, that negative revenue impacts by smokers are compensated by increasing revenues through non-smokers.[136]\nMany countries have a smoking age. In many countries, including the United States, most European Union member states, New Zealand, Canada, South Africa, Israel, India,[16] Brazil, Chile, Costa Rica and Australia, it is illegal to sell tobacco products to minors and in the Netherlands, Austria, Belgium, Denmark and South Africa it is illegal to sell tobacco products to people under the age of 16. On 1 September 2007 the minimum age to buy tobacco products in Germany rose from 16 to 18, as well as in the United Kingdom where on 1 October 2007 it rose from 16 to 18.[135] Underlying such laws is the belief that people should make an informed decision regarding the risks of tobacco use. These laws have a lax enforcement in some nations and states. In China, Turkey, and many other countries usually a child will have little problem buying tobacco products, because they are often told to go to the store to buy tobacco for their parents.\nSome countries also impose legal requirements on the packaging of tobacco products. For example, in the countries of the European Union, Turkey, Australia[133] and South Africa, cigarette packs must be prominently labeled with the health risks associated with smoking.[134] Canada, Australia, Thailand, Iceland and Brazil have also imposed labels upon cigarette packs warning smokers of the effects, and they include graphic images of the potential health effects of smoking. Cards are also inserted into cigarette packs in Canada. There are sixteen of them, and only one comes in a pack. They explain different methods of quitting smoking. Also, in the United Kingdom, there have been a number of graphic NHS advertisements, one showing a cigarette filled with fatty deposits, as if the cigarette is symbolizing the artery of a smoker.\nAll tobacco advertising and sponsorship on television has been banned within the European Union since 1991 under the Television Without Frontiers Directive (1989).[130] This ban was extended by the Tobacco Advertising Directive, which took effect in July 2005 to cover other forms of media such as the internet, print media, and radio. The directive does not include advertising in cinemas and on billboards or using merchandising \u2013 or tobacco sponsorship of cultural and sporting events which are purely local, with participants coming from only one Member State[131] as these fall outside the jurisdiction of the European Commission. However, most member states have transposed the directive with national laws that are wider in scope than the directive and cover local advertising. A 2008 European Commission report concluded that the directive had been successfully transposed into national law in all EU member states, and that these laws were well implemented.[132]\nThe Tobacco Advertising Prohibition Act 1992 expressly prohibited almost all forms of Tobacco advertising in Australia, including the sponsorship of sporting or other cultural events by cigarette brands.\nIn June 1967, the US Federal Communications Commission ruled that programmes broadcast on a television station which discussed smoking and health were insufficient to offset the effects of paid advertisements that were broadcast for five to ten minutes each day. In April 1970, the US Congress passed the Public Health Cigarette Smoking Act banning the advertising of cigarettes on television and radio starting on 2 January 1971.[129]\nIn Australia total taxes account for 62.5% of the final price of a packet of cigarettes (2011 figures). These taxes include federal excise or customs duty and  Goods and Services Tax.[128]\nIn the United Kingdom, a packet of 20 cigarettes typically costs between \u00a38.00 to \u00a312.00 according to 2018 prices, depending on the brand purchased and where the purchase was made.[126] The UK has a significant black market for tobacco, and it has been estimated by the tobacco industry that 27% of cigarette and 68% of handrolling tobacco consumption is non-UK duty paid (NUKDP).[127]\nCigarette taxes vary widely from state to state in the United States. For example, Missouri has a cigarette tax of only 17 cents per pack, the nation's lowest, while New York has the highest cigarette tax in the U.S.: $4.35 per pack. In Alabama, Illinois, Missouri, New York City, Tennessee, and Virginia, counties and cities may impose an additional limited tax on the price of cigarettes.[125] Sales taxes are also levied on tobacco products in most jurisdictions.\nMany nations have implemented some form of tobacco taxation. As of 1997, Denmark had the highest cigarette tax burden of $4.02 per pack. Taiwan only had a tax burden of $0.62 per pack. The federal government of the United States charges $1.01 per pack.[124]\nSubstantial scientific evidence shows that higher cigarette prices result in lower overall cigarette consumption. Most studies indicate that a 10% increase in price will reduce overall cigarette consumption by 3% to 5%. Youth, minorities, and low-income smokers are two to three times more likely to quit or smoke less than other smokers in response to price increases.[122][123] Smoking is often cited[citation needed] as an example of an inelastic good, however, i.e. a large rise in price will only result in a small decrease in consumption.\nIn 2002, the Centers for Disease Control and Prevention said that each pack of cigarettes[quantify] sold in the United States costs the nation more than $7 in medical care and lost productivity,[80] around $3400 per year per smoker. Another study by a team of health economists finds the combined price paid by their families and society is about $41 per pack of cigarettes.[121]\nMany governments have introduced excise taxes on cigarettes in order to reduce the consumption of cigarettes.\nOn 27 February 2005 the WHO Framework Convention on Tobacco Control, took effect. The FCTC is the world's first public health treaty. Countries that sign on as parties agree to a set of common goals, minimum standards for tobacco control policy, and to cooperate in dealing with cross-border challenges such as cigarette smuggling. Currently the WHO declares that 4 billion people will be covered by the treaty, which includes 168 signatories.[120] Among other steps, signatories are to put together legislation that will eliminate secondhand smoke in indoor workplaces, public transport, indoor public places and, as appropriate, other public places.\nOne of the largest global enterprises in the world is known to be the tobacco industry. The six biggest tobacco companies made a combined profit of $35.1 billion (Jha et al., 2014) in 2010.[118] Tobacco smoking causes millions of deaths globally each year. According to The Tobacco Atlas, the use of tobacco has led 6 million deaths in 2011, 80% of these deaths occurred in low and middle-income countries.[119] Research has shown that there are many negative effects of smoking; some of these factors are health, social and psychological factors which can harm the life of a person.\nThe ceremonial smoking of tobacco, and praying with a sacred pipe, is a prominent part of the religious ceremonies of a number of Native American Nations. Sema, the Anishinaabe word for tobacco, is grown for ceremonial use and considered the ultimate sacred plant since its smoke is believed to carry prayers to the spirits. In most major religions, however, tobacco smoking is not specifically prohibited, although it may be discouraged as an immoral habit. Before the health risks of smoking were identified through controlled study, smoking was considered an immoral habit by certain Christian preachers and social reformers. The founder of the Latter Day Saint movement, Joseph Smith, recorded that on 27 February 1833, he received a revelation which discouraged tobacco use. This \"Word of Wisdom\" was later accepted as a commandment, and faithful Latter-day Saints abstain completely from tobacco.[115] Jehovah's Witnesses base their stand against smoking on the Bible's command to \"clean ourselves of every defilement of flesh\" (2 Corinthians 7:1). The Jewish Rabbi Yisrael Meir Kagan (1838\u20131933) was one of the first Jewish authorities to speak out on smoking. In Ahmadiyya Islam, smoking is highly discouraged, although not forbidden. During the month of fasting however, it is forbidden to smoke tobacco.[116] In the Bah\u00e1'\u00ed Faith, smoking tobacco is discouraged though not forbidden.[117]\nThe problem of smoking at home is particularly difficult for women in many cultures (especially Arab cultures), where it may not be acceptable for a woman to ask her husband not to smoke at home or in the presence of her children. Studies have shown that pollution levels for smoking areas indoors are higher than levels found on busy roadways, in closed motor garages, and during fire storms.[clarification needed] Furthermore, smoke can spread from one room to another, even if doors to the smoking area are closed.[114]\nFamous smokers of the past used cigarettes or pipes as part of their image, such as Jean-Paul Sartre's Gauloises-brand cigarettes; Albert Einstein's, Douglas MacArthur's, Bertrand Russell's, and Bing Crosby's pipes; or the news broadcaster Edward R. Murrow's cigarette. Writers in particular seem to be known for smoking, for example, Cornell Professor Richard Klein's book Cigarettes are Sublime for the analysis, by this professor of French literature, of the role smoking plays in 19th and 20th century letters. The popular author Kurt Vonnegut addressed his addiction to cigarettes within his novels. British Prime Minister Harold Wilson was well known for smoking a pipe in public as was Winston Churchill for his cigars. Sherlock Holmes, the fictional detective created by Sir Arthur Conan Doyle smoked a pipe, cigarettes, and cigars. The DC Vertigo comic book character, John Constantine, created by Alan Moore, is synonymous with smoking, so much so that the first storyline by Preacher creator, Garth Ennis, centered around John Constantine contracting lung cancer. Professional wrestler James Fullington, while in character as \"The Sandman\", is a chronic smoker in order to appear \"tough\".\nIn 2015, a meta-analysis found that smokers were at greater risk of developing psychotic illness.[112] Tobacco has also been described an anaphrodisiac due to its propensity for causing erectile dysfunction.[113]\nSecond-hand smoke presents a known health risk, to which six hundred thousand deaths were attributed in 2004. It also has been known to produce skin conditions such as freckles and dryness.[111]\nRates of smoking have generally leveled-off or declined in the developed world. Smoking rates in the United States have dropped by half from 1965 to 2006, falling from 42% to 20.8% in adults.[109] In the developing world, tobacco consumption is rising by 3.4% per year.[110]\nThe probabilities of death from lung cancer before age 75 in the United Kingdom are 0.2% for men who never smoked (0.4% for women), 5.5% for male former smokers (2.6% in women), 15.9% for current male smokers (9.5% for women) and 24.4% for male \u201cheavy smokers\u201d defined as smoking more than 5 cigarettes per day (18.5% for women).[108] Tobacco smoke can combine with other carcinogens present within the environment in order to produce elevated degrees of lung cancer.\nThe World Health Organization estimates that tobacco caused 5.4 million deaths in 2004[105] and 100 million deaths over the course of the 20th century.[106] Similarly, the United States Centers for Disease Control and Prevention describes tobacco use as \"the single most important preventable risk to human health in developed countries and an important cause of premature death worldwide.\"[107] Although 70% of smokers state their intention to quit only 3-5% are actually successful in doing so.[83]\nCigarette smoking has also been associated with sarcopenia, the age-related loss of muscle mass and strength.[104]\nTobacco smoke can combine with other carcinogens present within the environment in order to produce elevated degrees of lung cancer.\nTobacco smoke is a complex mixture of over 5,000 identified chemicals, of which 98 are known to have specific toxicological properties.[16][93] The most important chemicals causing cancer are those that produce DNA damage since such damage appears to be the primary underlying cause of cancer.[94][95]  Cunningham et al.[96] combined the microgram weight of the compound in the smoke of one cigarette with the known genotoxic effect per microgram to identify the most carcinogenic compounds in cigarette smoke.  The seven most important carcinogens in tobacco smoke are shown in the table, along with DNA alterations they cause. \nTobacco use leads most commonly to diseases affecting the heart and lungs, with smoking being a major risk factor for heart attacks, strokes, chronic obstructive pulmonary disease (COPD), Idiopathic Pulmonary Fibrosis (IPF), emphysema, and cancer (particularly lung cancer, cancers of the larynx and mouth, esophageal cancer and pancreatic cancer).[16] Cigarette smoking increases the risk of Crohn's disease as well as the severity of the course of the disease.[91] It is also the number one cause of bladder cancer. The smoke from tobacco elicits carcinogenic effects on the tissues of the body that are exposed to the smoke.[92]\nThere are 1.1 billion tobacco users in the world. One person dies every six seconds from a tobacco related disease.[89]\nCigarette smoking is the leading cause of preventable death and a major public health concern.[88]\nBetween 1970 and 1995, per-capita cigarette consumption in poorer developing countries increased by 67 percent, while it dropped by 10 percent in the richer developed world. Eighty percent of smokers now live in less developed countries. By 2030, the World Health Organization (WHO) forecasts that 10 million people a year will die of smoking-related illness, making it the single biggest cause of death worldwide, with the largest increase to be among women. WHO forecasts the 21st century's death rate from smoking to be ten times the 20th century's rate (\"Washingtonian\" magazine, December 2007).\nBy contrast, some non-scientific studies, including one conducted by Philip Morris in the Czech Republic called Public Finance Balance of Smoking in the Czech Republic[86] and another by the Cato Institute,[87] support the opposite position. Philip Morris has explicitly apologised for the former study, saying: \"The funding and public release of this study which, among other things, detailed purported cost savings to the Czech Republic due to premature deaths of smokers, exhibited terrible judgment as well as a complete and unacceptable disregard of basic human values. For one of our tobacco companies to commission this study was not just a terrible mistake, it was wrong. All of us at Philip Morris, no matter where we work, are extremely sorry for this. No one benefits from the very real, serious and significant diseases caused by smoking.\"[86]\nIn countries where there is a universally funded healthcare system, the government covers the cost of medical care for smokers who become ill through smoking in the form of increased taxes. Two broad debating positions exist on this front, the \"pro-smoking\" argument suggesting that heavy smokers generally don't live long enough to develop the costly and chronic illnesses which affect the elderly, reducing society's healthcare burden, and the \"anti-smoking\" argument suggests that the healthcare burden is increased because smokers get chronic illnesses younger and at a higher rate than the general population.  Data on both positions has been contested. The Centers for Disease Control and Prevention published research in 2002 claiming that the cost of each pack of cigarettes sold in the United States was more than $7 in medical care and lost productivity.[80] The cost may be higher, with another study putting it as high as $41 per pack, most of which however is on the individual and his/her family.[81] This is how one author of that study puts it when he explains the very low cost for others: \"The reason the number is low is that for private pensions, Social Security, and Medicare \u2014 the biggest factors in calculating costs to society \u2014 smoking actually saves money. Smokers die at a younger age and don't draw on the funds they've paid into those systems.\"[81] Other research demonstrates that premature death caused by smoking may redistribute Social Security income in unexpected ways that affect behavior and reduce the economic well-being of smokers and their dependents.[82] To further support this, whatever the rate of smoking  consumption  is per day, smokers have a greater lifetime medical cost on average compared to a non smoker by an estimated $6000 [83] Between the cost for lost productivity and health care expenditures combined, cigarette smoking costs at least 193 billion dollars (Research also shows that smokers earn less money than nonsmokers[84]). As for secondhand smoke, the cost is over 10 billion dollars.[85]\nSimilarly, smoking has been shown to follow distinct circadian patterns during the waking day\u2014with the high point usually occurring shortly after waking in the morning, and shortly before going to sleep at night.[79]\nA number of studies have established that cigarette sales and smoking follow distinct time-related patterns. For example, cigarette sales in the United States of America have been shown to follow a strongly seasonal pattern, with the high months being the months of summer, and the low months being the winter months.[78]\nSome smokers argue that the depressant effect of smoking allows them to calm their nerves, often allowing for increased concentration. However, according to the Imperial College London, \"Nicotine seems to provide both a stimulant and a depressant effect, and it is likely that the effect it has at any time is determined by the mood of the user, the environment and the circumstances of use. Studies have suggested that low doses have a depressant effect, while higher doses have stimulant effect.\"[77]\nThe reasons given by some smokers for this activity have been categorized as addictive smoking, pleasure from smoking, tension reduction/relaxation, social smoking, stimulation, habit/automatism, and handling. There are gender differences in how much each of these reasons contribute, with females more likely than males to cite tension reduction/relaxation, stimulation and social smoking.[76]\nPsychologists such as Hans Eysenck have developed a personality profile for the typical smoker. Extraversion is the trait that is most associated with smoking, and smokers tend to be sociable, impulsive, risk taking, and excitement seeking individuals.[75] Although personality and social factors may make people likely to smoke, the actual habit is a function of operant conditioning. During the early stages, smoking provides pleasurable sensations (because of its action on the dopamine system) and thus serves as a source of positive reinforcement.\nBehavioural research generally indicates that teenagers begin their smoking habits due to peer pressure, and cultural influence portrayed by friends. However, one study found that direct pressure to smoke cigarettes played a less significant part in adolescent smoking, with adolescents also reporting low levels of both normative and direct pressure to smoke cigarettes.[71] Mere exposure to tobacco retailers may motivate smoking behaviour in adults.[72] A similar study suggested that individuals may play a more active role in starting to smoke than has previously been thought and that social processes other than peer pressure also need to be taken into account.[73] Another study's results indicated that peer pressure was significantly associated with smoking behavior across all age and gender cohorts, but that intrapersonal factors were significantly more important to the smoking behavior of 12- to 13-year-old girls than same-age boys. Within the 14- to 15-year-old age group, one peer pressure variable emerged as a significantly more important predictor of girls' than boys' smoking.[74] It is debated whether peer pressure or self-selection is a greater cause of adolescent smoking.\nChildren of smoking parents are more likely to smoke than children with non-smoking parents. Children of parents who smoke are less likely to quit smoking.[16] One study found that parental smoking cessation was associated with less adolescent smoking, except when the other parent currently smoked.[69] A current study tested the relation of adolescent smoking to rules regulating where adults are allowed to smoke in the home. Results showed that restrictive home smoking policies were associated with lower likelihood of trying smoking for both middle and high school students.[70]\nMost smokers begin smoking during adolescence or early adulthood. Some studies also show that smoking can also be linked to various mental health complications.[66] Smoking has elements of risk-taking and rebellion, which often appeal to young people. The presence of peers that smoke and media featuring high-status models smoking may also encourage smoking. Because teenagers are influenced more by their peers than by adults, attempts by parents, schools, and health professionals at preventing people from trying cigarettes are often unsuccessful.[67][68]\nThe WHO in 2004 projected 58.8 million deaths to occur globally,[61] from which 5.4 million are tobacco-attributed,[62] and 4.9 million as of 2007.[63] As of 2002, 70% of the deaths are in developing countries.[63] As of 2017, smoking causes one in ten deaths worldwide, with half of those deaths in the US, China, India and Russia.[64]\nThe World Health Organization (WHO) states that \"Much of the disease burden and premature mortality attributable to tobacco use disproportionately affect the poor\". Of the 1.22 billion smokers, 1 billion of them live in developing or transitional economies. Rates of smoking have leveled off or declined in the developed world.[60] In the developing world, however, tobacco consumption is rising by 3.4% per year as of 2002.[7]\nAs of 2002, about twenty percent of young teenagers (13\u201315) smoked worldwide. From which 80,000 to 100,000 children begin smoking every day, roughly half of whom live in Asia. Half of those who begin smoking in adolescent years are projected to go on to smoke for 15 to 20 years.[7]\nSmoking may be up to five times more prevalent among men than women in some communities,[58] although the gender gap usually declines with younger age.[14][15] In some developed countries smoking rates for men have peaked and begun to decline, while for women they continue to climb.[59]\nAs of 2000, smoking was practiced by around 1.22 billion people. At current rates of 'smoker replacement' and market growth, this may reach around 1.9 billion in 2025.[58]\nWhen tobacco is smoked, most of the nicotine is pyrolyzed. However, a dose sufficient to cause mild somatic dependency and mild to strong psychological dependency remains. There is also a formation of harmane (a MAO inhibitor) from the acetaldehyde in tobacco smoke. This may play a role in nicotine addiction, by facilitating a dopamine release in the nucleus accumbens as a response to nicotine stimuli.[56] Using rat studies, withdrawal after repeated exposure to nicotine results in less responsive nucleus accumbens cells, which produce dopamine responsible for reinforcement.[57]\nThe inhaled nicotine mimics nicotinic acetylcholine which when bound to nicotinic acetylcholine receptors prevents the reuptake of acetylcholine thereby increasing that neurotransmitter in those areas of the body.[53] These nicotinic acetylcholine receptors are located in the central nervous system and at the nerve-muscle junction of skeletal muscles; whose activity increases heart rate, alertness,[10] and faster reaction times.[11] Nicotine acetylcholine stimulation is not directly addictive. However, since dopamine-releasing neurons are abundant on nicotine receptors, dopamine is released; and, in the nucleus accumbens, dopamine is associated with motivation causing reinforcing behavior.[54] Dopamine increase, in the prefrontal cortex, may also increase working memory.[55]\nThe active substances in tobacco, especially cigarettes, are administered by burning the leaves and inhaling the vaporized gas that results. This quickly and effectively delivers substances into the bloodstream by absorption through the alveoli in the lungs. The lungs contain some 300 million alveoli, which amounts to a surface area of over 70\u00a0m2 (about the size of a tennis court). This method is not completely efficient as not all of the smoke will be inhaled, and some amount of the active substances will be lost in the process of combustion, pyrolysis.[9] Pipe and Cigar smoke are not inhaled because of its high alkalinity, which are irritating to the trachea and lungs. However, because of its higher alkalinity (pH 8.5) compared to cigarette smoke (pH 5.3), non-ionized nicotine is more readily absorbed through the mucous membranes in the mouth.[50] Nicotine absorption from cigar and pipe, however, is much less than that from cigarette smoke.[51] Nicotine and cocaine activate similar patterns of neurons, which supports the existence of common substrates among these drugs.[52]\n\nTobacco is an agricultural product processed from the fresh leaves of plants in the genus Nicotiana. The genus contains a number of species, however, Nicotiana tabacum is the most commonly grown. Nicotiana rustica follows as second containing higher concentrations of nicotine. These leaves are harvested and cured to allow for the slow oxidation and degradation of carotenoids in tobacco leaf. This produces certain compounds in the tobacco leaves which can be attributed to sweet hay, tea, rose oil, or fruity aromatic flavors. Before packaging, the tobacco is often combined with other additives in order to enhance the addictive potency, shift the products pH, or improve the effects of smoke by making it more palatable. In the United States these additives are regulated to 599 substances.[8] The product is then processed, packaged, and shipped to consumer markets.\nFrom 1965 to 2006, rates of smoking in the United States declined from 42% to 20.8%.[6] The majority of those who quit were professional, affluent men. Although the per-capita number of smokers decreased, the average number of cigarettes consumed per person per day increased from 22 in 1954 to 30 in 1978. This paradoxical event suggests that those who quit smoked less, while those who continued to smoke moved to smoke more light cigarettes.[42] The trend has been paralleled by many industrialized nations as rates have either leveled-off or declined. In the developing world, however, tobacco consumption continues to rise at 3.4% in 2002.[7] In Africa, smoking is in most areas considered to be modern, and many of the strong adverse opinions that prevail in the West receive much less attention.[43] Today Russia leads as the top consumer of tobacco followed by Indonesia, Laos, Ukraine, Belarus, Greece, Jordan, and China.[44]\nSocial campaigns have been instituted in many places to discourage smoking, such as Canada's National Non-Smoking Week.\nAs scientific evidence mounted in the 1980s, tobacco companies claimed contributory negligence as the adverse health effects were previously unknown or lacked substantial credibility. Health authorities sided with these claims up until 1998, from which they reversed their position. The Tobacco Master Settlement Agreement, originally between the four largest US tobacco companies and the Attorneys General of 46 states, restricted certain types of tobacco advertisement and required payments for health compensation; which later amounted to the largest civil settlement in United States history.[41]\nIn 1954, the British Doctors Study, a prospective study of some 40 thousand doctors for about 2.5 years, confirmed the suggestion, based on which the government issued advice that smoking and lung cancer rates were related.[5] In January 1964, the United States Surgeon General's Report on Smoking and Health likewise began suggesting the relationship between smoking and cancer.[40]\nIn 1950, Richard Doll published research in the British Medical Journal showing a close link between smoking and lung cancer.[38]  Beginning in December 1952, the magazine Reader's Digest published \"Cancer by the Carton\", a series of articles that linked smoking with lung cancer.[39]\nThe anti-tobacco movement in Nazi Germany did not reach across enemy lines during the Second World War, as anti-smoking groups quickly lost popular support. By the end of the Second World War, American cigarette manufacturers quickly reentered the German black market. Illegal smuggling of tobacco became prevalent,[36] and leaders of the Nazi anti-smoking campaign were silenced.[37] As part of the Marshall Plan, the United States shipped free tobacco to Germany; with 24,000 tons in 1948 and 69,000\u00a0tons in 1949.[36] Per capita yearly cigarette consumption in post-war Germany steadily rose from 460 in 1950 to 1,523 in 1963.[4] By the end of the 20th century, anti-smoking campaigns in Germany were unable to exceed the effectiveness of the Nazi-era climax in the years 1939\u201341 and German tobacco health research was described by Robert N. Proctor as \"muted\".[4]\nIn Germany, anti-smoking groups, often associated with anti-liquor groups,[33] first published advocacy against the consumption of tobacco in the journal Der Tabakgegner (The Tobacco Opponent) in 1912 and 1932. In 1929, Fritz Lickint of Dresden, Germany, published a paper containing formal statistical evidence of a lung cancer\u2013tobacco link. During the Great Depression Adolf Hitler condemned his earlier smoking habit as a waste of money,[34] and later with stronger assertions. This movement was further strengthened with Nazi reproductive policy as women who smoked were viewed as unsuitable to be wives and mothers in a German family.[35]\nGrowth in the US remained stable until the American Civil War in 1860s, when the primary agricultural workforce shifted from slavery to sharecropping. This, along with a change in demand, accompanied the industrialization of cigarette production as craftsman James Bonsack created a machine in 1881 to partially automate their manufacture.[32]\nBy the mid-17th century most major civilizations had been introduced to tobacco smoking and in many cases had already assimilated it into the native culture, despite some continued attempts upon the parts of rulers to eliminate the practice with penalties or fines. Tobacco, both product and plant, followed the major trade routes to major ports and markets, and then on into the hinterlands. The English language term smoking appears to have entered currency in the late 18th century, before which less abbreviated descriptions of the practice such as drinking smoke were also in use.[2]\nReligious leaders have often been prominent among those who considered smoking immoral or outright blasphemous. In 1634, the Patriarch of Moscow forbade the sale of tobacco, and sentenced men and women who flouted the ban to have their nostrils slit and their backs flayed. Pope Urban VIII likewise condemned smoking on holy places in a papal bull of 1624. Despite some concerted efforts, restrictions and bans were largely ignored. When James I of England, a staunch anti-smoker and the author of A Counterblaste to Tobacco, tried to curb the new trend by enforcing a 4000% tax increase on tobacco in 1604 it was unsuccessful, as suggested by the presence of around 7,000 tobacco outlets in London by the early 17th century. From this point on for some centuries, several administrations withdrew from efforts at discouragement and instead turned tobacco trade and cultivation into sometimes lucrative government monopolies.[30][31]\nSoon after its introduction to the Old World, tobacco came under frequent criticism from state and religious leaders. James VI and I, King of Scotland and England, produced the treatise A Counterblaste to Tobacco in 1604, and also introduced excise duty on the product. Murad IV, sultan of the Ottoman Empire 1623\u201340 was among the first to attempt a smoking ban by claiming it was a threat to public morals and health. The Chongzhen Emperor of China issued an edict banning smoking two years before his death and the overthrow of the Ming dynasty. Later, the Manchu rulers of the Qing dynasty, would proclaim smoking \"a more heinous crime than that even of neglecting archery\". In Edo period Japan, some of the earliest tobacco plantations were scorned by the shogunate as being a threat to the military economy by letting valuable farmland go to waste for the use of a recreational drug instead of being used to plant food crops.[29]\nFrenchman Jean Nicot (from whose name the word nicotine is derived) introduced tobacco to France in 1560, and tobacco then spread to England. The first report of a smoking Englishman is of a sailor in Bristol in 1556, seen \"emitting smoke from his nostrils\".[2] Like tea, coffee and opium, tobacco was just one of many intoxicants that was originally used as a form of medicine.[28] Tobacco was introduced around 1600 by French merchants in what today is modern-day Gambia and Senegal. At the same time, caravans from Morocco brought tobacco to the areas around Timbuktu, and the Portuguese brought the commodity (and the plant) to southern Africa, establishing the popularity of tobacco throughout all of Africa by the 1650s.\nIn 1612, six years after the settlement of Jamestown, Virginia, John Rolfe was credited as the first settler to successfully raise tobacco as a cash crop. The demand quickly grew as tobacco, referred to as \"brown gold\", revived the Virginia joint stock company from its failed gold expeditions.[24] In order to meet demands from the Old World, tobacco was grown in succession, quickly depleting the soil. This became a motivator to settle west into the unknown continent, and likewise an expansion of tobacco production.[25] Indentured servitude became the primary labor force up until Bacon's Rebellion, from which the focus turned to slavery.[26] This trend abated following the American Revolution as slavery became regarded as unprofitable. However, the practice was revived in 1794 with the invention of the cotton gin.[27]\nApart from smoking, tobacco had a number of uses as medicine. As a pain killer it was used for earache and toothache and occasionally as a poultice. Smoking was said by the desert Indians to be a cure for colds, especially if the tobacco was mixed with the leaves of the small desert Sage, Salvia dorrii, or the root of Indian balsam or cough root, Leptotaenia multifida, the addition of which was thought to be particularly good for asthma and tuberculosis.[23]\nEastern North American tribes would carry large amounts of tobacco in pouches as a readily accepted trade item and would often smoke it in ceremonial pipes, either in sacred ceremonies or to seal bargains.[20] Adults as well as children enjoyed the practice.[21] It was believed that tobacco was a gift from the Creator and that the exhaled tobacco smoke was capable of carrying one's thoughts and prayers to heaven.[22]\nSmoking's history dates back to as early as 5000\u20133000 BC, when the agricultural product began to be cultivated in Mesoamerica and South America; consumption later evolved into burning the plant substance either by accident or with intent of exploring other means of consumption.[1] The practice worked its way into shamanistic rituals.[18] Many ancient civilizations \u2014 such as the Babylonians, the Indians, and the Chinese \u2014 burnt incense during religious rituals. Smoking in the Americas probably had its origins in the incense-burning ceremonies of shamans but was later adopted for pleasure or as a social tool.[19] The smoking of tobacco and various hallucinogenic drugs was used to achieve trances and to come into contact with the spirit world.\nA study of first smoking experiences of seventh-grade students found out that the most common factor leading students to smoke is cigarette advertisements. Smoking by parents, siblings and friends also encourages students to smoke.[17]\nMany smokers begin during adolescence or early adulthood.[16] During the early stages, a combination of perceived pleasure acting as positive reinforcement and desire to respond to social peer pressure may offset the unpleasant symptoms of initial use, which typically include nausea and coughing. After an individual has smoked for some years, the avoidance of withdrawal symptoms and negative reinforcement become the key motivations to continue.\nSmoking is the most common method of consuming tobacco, and tobacco is the most common substance smoked. The agricultural product is often mixed with additives[8] and then combusted. The resulting smoke is then inhaled and the active substances absorbed through the alveoli in the lungs or the oral mucosa.[9] Combustion was traditionally enhanced by addition of potassium or nitrates.[citation needed] Many substances in cigarette smoke trigger chemical reactions in nerve endings, which heighten heart rate, alertness[10] and reaction time, among other things.[11] Dopamine and endorphins are released, which are often associated with pleasure.[12] As of 2008 to 2010, tobacco is used by about 49% of men and 11% of women aged 15 or older in fourteen low-income and middle-income countries (Bangladesh, Brazil, China, Egypt, India, Mexico, Philippines, Poland, Russia, Thailand, Turkey, Ukraine, Uruguay and Vietnam), with about 80% of this usage in the form of smoking.[13] The gender gap tends to be less pronounced in lower age groups.[14][15]\nGerman scientists identified a link between smoking and lung cancer in the late 1920s, leading to the first anti-smoking campaign in modern history, albeit one truncated by the collapse of Nazi Germany at the end of World War II.[4] In 1950, British researchers demonstrated a clear relationship between smoking and cancer.[5] Evidence continued to mount in the 1980s, which prompted political action against the practice. Rates of consumption since 1965 in the developed world have either peaked or declined.[6] However, they continue to climb in the developing world.[7]\nTobacco smoking is the practice of smoking tobacco and inhaling tobacco smoke (consisting of particle and gaseous phases). (A more broad definition may include simply taking tobacco smoke into the mouth, and then releasing it, as is done by some with tobacco pipes and cigars.) The practice is believed to have begun as early as 5000\u20133000 BC in Mesoamerica and South America.[1] Tobacco was introduced to Eurasia in the late 17th century by European colonists, where it followed common trade routes. The practice encountered criticism from its first import into the Western world onwards but embedded itself in certain strata of a number of societies before becoming widespread upon the introduction of automated cigarette-rolling apparatus.[2][3]\n\n",
            "title": "Tobacco smoking",
            "url": "https://en.wikipedia.org/wiki/Tobacco_smoking"
        },
        {
            "desc_links": [
                "/wiki/Investment",
                "/wiki/Finance",
                "/wiki/Gold",
                "/wiki/United_States_Treasury_security",
                "/wiki/Correlation_and_dependence",
                "/wiki/Volatility_(finance)",
                "/wiki/Asset",
                "/wiki/Market_portfolio",
                "/wiki/Market_(economics)",
                "/wiki/Put_option",
                "/wiki/Derivative_(finance)",
                "/wiki/Risk-free_interest_rate",
                "/wiki/Capital_Asset_Pricing_Model",
                "/wiki/Diversification_(finance)",
                "/wiki/Mutual_fund",
                "/wiki/Regression_toward_the_mean"
            ],
            "desc_text": "b'In finance, the beta (\\xce\\xb2 or beta coefficient) of an investment indicates whether the investment is more or less volatile than the market as a whole.  \\n'b'Beta is a measure of the risk arising from exposure to general market movements as opposed to idiosyncratic factors. The market portfolio of all investable assets has a beta of exactly 1. A beta below 1 can indicate either an investment with lower volatility than the market, or a volatile investment whose price movements are not highly correlated with the market. An example of the first is a treasury bill: the price does not go up or down a lot, so it has a low beta. An example of the second is gold. The price of gold does go up and down a lot, but not in the same direction or at the same time as the market.[1]\\n'b'A beta greater than 1 generally means that the asset both is volatile and tends to move up and down with the market. An example is a stock in a big technology company. Negative betas are possible for investments that tend to go down when the market goes up, and vice versa. There are few fundamental investments with consistent and significant negative betas, but some derivatives like put options can have large negative betas.[2]\\n'b'Beta is important because it measures the risk of an investment that cannot be reduced by diversification. It does not measure the risk of an investment held on a stand-alone basis, but the amount of risk the investment adds to an already-diversified portfolio. In the Capital Asset Pricing Model (CAPM), beta risk is the only kind of risk for which investors should receive an expected return higher than the risk-free rate of interest.[3]\\n'b'The definition above covers only theoretical beta. The term is used in many related ways in finance. For example, the betas commonly quoted in mutual fund analyses generally measure the risk of the fund arising from exposure to a benchmark for the fund, rather than from exposure to the entire market portfolio. Thus they measure the amount of risk the fund adds to a diversified portfolio of funds of the same type, rather than to a portfolio diversified among all fund types.[4]\\n'b'Beta decay refers to the tendency for a company with a high beta coefficient (\\xce\\xb2 > 1) to have its beta coefficient decline to the market beta. It is an example of regression toward the mean.\\n'",
            "links": [
                "/wiki/Investment",
                "/wiki/Finance",
                "/wiki/Gold",
                "/wiki/United_States_Treasury_security",
                "/wiki/Correlation_and_dependence",
                "/wiki/Volatility_(finance)",
                "/wiki/Asset",
                "/wiki/Market_portfolio",
                "/wiki/Market_(economics)",
                "/wiki/Put_option",
                "/wiki/Derivative_(finance)",
                "/wiki/Risk-free_interest_rate",
                "/wiki/Capital_Asset_Pricing_Model",
                "/wiki/Diversification_(finance)",
                "/wiki/Mutual_fund",
                "/wiki/Regression_toward_the_mean",
                "/wiki/Alpha_(finance)",
                "/wiki/Time_series",
                "/wiki/Variance",
                "/wiki/Covariance",
                "/wiki/Liquidity",
                "/wiki/Volatility_(finance)",
                "/wiki/Systematic_risk",
                "/wiki/Risk",
                "/wiki/Asset",
                "/wiki/Volatility_(finance)",
                "/wiki/Elasticity_(economics)",
                "/wiki/Security_characteristic_line",
                "/wiki/Alpha_(finance)",
                "/wiki/Leverage_(finance)",
                "/wiki/Benchmark_(surveying)",
                "/wiki/Security_market_line",
                "/wiki/MSCI_EAFE",
                "/wiki/S%26P_500",
                "/wiki/Stock_market_index",
                "/wiki/Roll%27s_critique",
                "/wiki/Absolute_value",
                "/wiki/S%26P_500",
                "/wiki/Expected_return",
                "/wiki/Risk-free_rate",
                "/wiki/Rate_of_return",
                "/wiki/Short_(finance)",
                "/wiki/Inverse_exchange-traded_fund",
                "/wiki/Roulette",
                "/wiki/Capital_asset_pricing_model",
                "/wiki/Cost_of_equity",
                "/wiki/Risk_factor_(finance)",
                "/wiki/Arbitrage_pricing_theory",
                "/wiki/Alpha_(finance)",
                "/wiki/Linear_least_squares_(mathematics)",
                "/wiki/Linear_regression",
                "/wiki/Myron_Scholes",
                "/wiki/AT%26T_Inc.",
                "/wiki/Downside_beta",
                "/wiki/Stock_market_index",
                "/wiki/Regression_analysis",
                "/wiki/Correlation",
                "/wiki/Diversification_(finance)",
                "/wiki/Variance",
                "/wiki/Downside_risk",
                "/wiki/Proxy_contests",
                "/wiki/Seth_Klarman",
                "/wiki/Upside_beta",
                "/wiki/Downside_beta",
                "/wiki/Upside_risk",
                "/wiki/Downside_risk",
                "/wiki/Upside_beta",
                "/wiki/Downside_beta",
                "/wiki/Dual-beta",
                "/wiki/Rate_of_return",
                "/wiki/Capital_asset_pricing_model"
            ],
            "text": "The table shows that stock A goes down half as much as the market when the market goes down and up twice as much as the market when the market goes up. Stock B, on the other hand, goes down twice as much as the market when the market goes down and up half as much as the market when the market goes up. Most investors would label stock B as more risky. In fact, stock A has better return in every possible case. However, according to the capital asset pricing model, stock A and B would have the same beta, meaning that theoretically, investors would require the same rate of return for both stocks. Of course it is entirely expected that this example could break the CAPM as the CAPM relies on certain assumptions one of the most central being the nonexistence of arbitrage, However, in this example buying stock A and selling stock B is an example of an arbitrage as stock A is worth more in every scenario. This is an illustration of how using standard beta might mislead investors. The dual-beta model, in contrast, takes into account this issue and differentiates downside beta from upside beta, or downside risk from upside risk, and thus allows investors to make better informed investing decisions.[11]\nAnother weakness of beta can be illustrated through an easy example by considering two hypothetical stocks, A and B. The returns on A, B and the market follow the probability distribution below:\nAt the industry level, beta tends to underestimate downside beta two-thirds of the time (resulting in value overestimation) and overestimate upside beta one-third of the time resulting in value underestimation.[11]\nSeth Klarman of the Baupost group wrote  in Margin of Safety:\n\"I find it preposterous that a single number reflecting past price fluctuations could be thought to completely describe the risk in a security. Beta views risk solely from the perspective of market prices, failing to take into consideration specific business\nfundamentals or economic developments. The price level is also ignored, as if IBM selling at 50 dollars per share would\nnot be a lower-risk investment than the same IBM at 100 dollars per share. Beta fails to allow for the influence that investors\nthemselves can exert on the riskiness of their holdings through such efforts as proxy contests, shareholder resolutions, communications with management, or the ultimate purchase of sufficient stock to gain corporate control and with it direct access to underlying value. Beta also assumes that the upside potential and downside risk of any investment are essentially equal,\nbeing simply a function of that investment's volatility compared with that of the market as a whole. This too is inconsistent\nwith the world as we know it. The reality is that past security price volatility does not reliably predict future investment\nperformance (or even future volatility) and therefore is a poor measure of risk.\"[10]\nBeta is always measured in respect to some benchmark. Therefore, an asset may have different betas depending on which benchmark is used. Just a number is useless if the benchmark is not known.\nIt measures the part of the asset's statistical variance that cannot be removed by the diversification provided by the portfolio of many risky assets, because of the correlation of its returns with the returns of the other assets that are in the portfolio.  Beta can be estimated for individual companies using regression analysis against a stock market index. An alternative to standard beta is downside beta.\nSome interpretations of beta are explained in the following table:[9]\nThe relative volatility ratio described above is actually known as Total Beta (at least by appraisers who practice business valuation).  Total beta is equal to the identity: beta/R or the standard deviation of the stock/standard deviation of the market (note: the relative volatility).  Total beta captures the security's risk as a stand-alone asset (because the correlation coefficient, R, has been removed from beta), rather than part of a well-diversified portfolio.  Because appraisers frequently value closely held companies as stand-alone assets, total beta is gaining acceptance in the business valuation industry.  Appraisers can now use total beta in the following equation: total cost of equity (TCOE) = risk-free rate + total beta\u00b7equity risk premium.  Once appraisers have a number of TCOE benchmarks, they can compare/contrast the risk factors present in these publicly traded benchmarks and the risks in their closely held company to better defend/support their valuations.\nBeta specifically gives the volatility ratio multiplied by the correlation of the plotted data. To take an extreme example, something may have a beta of zero even though it is highly volatile, provided it is uncorrelated with the market. Tofallis (2008) provides a discussion of this,[5] together with a real example involving AT&T Inc. The graph showing monthly returns from AT&T is visibly more volatile than the\nindex and yet the standard estimate of beta for this is less than one.\nMyron Scholes and Joseph Williams (1977) provided a model for estimating betas from nonsynchronous data.[8]\nTo estimate beta, one needs a list of returns for the asset and returns for the index; these returns can be daily, weekly or any period. Then one uses standard formulas from linear regression. The slope of the fitted line from the linear least-squares calculation is the estimated Beta.  The y-intercept is the alpha.\nMultiple-factor models contradict CAPM by claiming that some other factors can influence return, therefore one may find two stocks (or funds) with equal beta, but one may be a better investment.\nThe arbitrage pricing theory (APT) has multiple betas in its model.  In contrast to the CAPM that has only one risk factor, namely the overall market, APT has multiple risk factors.  Each risk factor has a corresponding beta indicating the responsiveness of the asset being priced to that risk factor.\nAn indication of the systematic riskiness attaching to the returns on ordinary shares. It equates to the asset Beta for an ungeared firm, or is adjusted upwards to reflect the extra riskiness of shares in a geared firm., i.e. the Geared Beta.[7]\nand\nbecause:\nwhere:\nThis expected return on equity, or equivalently, a firm's cost of equity, can be estimated using the capital asset pricing model (CAPM).  According to the model, the expected return on equity is a function of a firm's equity beta (\u03b2E) which, in turn, is a function of both leverage and asset risk (\u03b2A):\nAcademic theory claims that higher-risk investments should have higher returns over the long-term. Wall Street has a saying that \"higher return requires higher risk\", not that a risky investment will automatically do better. Some things may just be poor investments (e.g., playing roulette). Further, highly rational investors should consider correlated volatility (beta) instead of simple volatility (sigma). Theoretically, a negative beta equity is possible; for example, an inverse ETF should have negative beta to the relevant index. Also, a short position should have opposite beta.\nThis suggests that an asset with \u03b2 greater than 1 will increase variance, while an asset with \u03b2 less than 1 will decrease variance, if added in the right amount. This assumes that variance is an accurate measure of risk, which is usually good. However, the beta does need to be computed with respect to what the investor currently owns.\nwe can compute\nThe first formula is exact, while the second one is only valid for small \u03b4. Using the formula for \u03b2 of Y relative to X,\nwhich can be simplified by ignoring \u03b42 terms:\nThe variance can be computed as\nSuppose an investor has all his money in an asset class X and wishes to move a small amount to an asset class Y. For example, X could be U.S. stocks, while Y could be stocks of a different country, or bonds. Then the new portfolio, Z, can be expressed symbolically\nHigher-beta stocks tend to be more volatile and therefore riskier, but provide the potential for higher returns. Lower-beta stocks pose less risk but generally offer lower returns. Some have challenged this idea, claiming that the data show little relation between beta and potential reward, or even that lower-beta stocks are both less risky and more profitable (contradicting CAPM).[6] In the same way a stock's beta shows its relation to market shifts, it is also an indicator for required returns on investment (ROI). Given a risk-free rate of 2%, for example, if the market (with a beta of 1) has an expected return of 8%, a stock with a beta of 1.5 should return 11% (=\u00a02%\u00a0+\u00a01.5(8%\u00a0\u2212\u00a02%)) in accordance with the financial CAPM model.\nA stock with a beta of 2 has returns that change, on average, by twice the magnitude of the overall market; when the market's return falls or rises by 3%, the stock's return will fall or rise (respectively) by 6% on average. (However, because beta also depends on the correlation of returns, there can be considerable variance about that average; the higher the correlation, the less variance; the lower the correlation, the higher the variance.) Beta can also be negative, meaning the stock's returns tend to move in the opposite direction of the market's returns. A stock with a beta of \u22123 would see its return decline 9% (on average) when the market's return goes up 3%, and would see its return climb 9% (on average) if the market's return falls by 3%.\nBy definition, the market itself has a beta of 1, and individual stocks are ranked according to how much they deviate from the macro market (for simplicity purposes, the S&P 500 is sometimes used as a proxy for the market as a whole). A stock whose returns vary more than the market's returns over time can have a beta whose absolute value is greater than 1.0 (whether it is, in fact, greater than 1.0 will depend on the correlation of the stock's returns and the market's returns). A stock whose returns vary less than the market's returns has a beta with an absolute value less than 1.0.\nThe choice of the index need not reflect the portfolio under question; e.g., beta for gold bars compared to the S&P 500 may be low or negative carrying the information that gold does not track stocks and may provide a mechanism for reducing risk.  The restriction to stocks as a benchmark is somewhat arbitrary. A model portfolio may be stocks plus bonds. Sometimes the market is defined as \"all investable assets\" (see Roll's critique); unfortunately, this includes lots of things for which returns may be hard to measure.\nIn the U.S., published betas typically use a stock market index such as the S&P 500 as a benchmark. The S&P 500 is a popular index of U.S. large-cap stocks. Other choices may be an international index such as the MSCI EAFE. The benchmark is often chosen to be similar to the assets chosen by the investor. For example, for a person who owns S&P 500 index funds and gold bars, the index would combine the S&P 500 and the price of gold. In practice a standard index is used.\nIt is a useful tool in determining if an asset being considered for a portfolio offers a reasonable expected return for risk. Individual securities are plotted on the SML graph. If the security's risk versus expected return is plotted above the SML, it is undervalued because the investor can expect a greater return for the inherent risk. A security plotted below the SML is overvalued because the investor would be accepting a lower return for the amount of risk assumed.\nThe relationship between \u03b2 and required return is plotted on the security market line (SML) which shows expected return as a function of \u03b2. The intercept is the nominal risk-free rate Rf available for the market, while the slope is E(Rm)\u2212\u00a0Rf (for market return Rm). The security market line can be regarded as representing a single-factor model of the asset price, where beta is exposure to changes in value of the market. The equation of the SML, giving the expected value of the return on asset i, is thus:\nThe SML graphs the results from the capital asset pricing model (CAPM) formula. The x-axis represents the risk (beta), and the y-axis represents the expected return. The market risk premium is determined from the slope of the SML.\nFor example, in a year where the broad market or benchmark index returns 25% above the risk free rate, suppose two managers gain 50% above the risk free rate. Because this higher return is theoretically possible merely by taking a leveraged position in the broad market to double the beta so it is exactly 2.0, we would expect a skilled portfolio manager to have built the outperforming portfolio with a beta somewhat less than 2, such that the excess return not explained by the beta is positive. If one of the managers' portfolios has an average beta of 3.0, and the other's has a beta of only 1.5, then the CAPM simply states that the extra return of the first manager is not sufficient to compensate us for that manager's risk, whereas the second manager has done more than expected given the risk.  Whether investors can expect the second manager to duplicate that performance in future periods is of course a different question.\nThe portfolio of interest in the CAPM formulation is the market portfolio that contains all risky assets, and so the rb terms in the formula are replaced by rm, the rate of return of the market. The regression line is then called the security characteristic line (SCL).\nBeta is also referred to as financial elasticity or correlated relative volatility, and can be referred to as a measure of the sensitivity of the asset's returns to market returns, its non-diversifiable risk, its systematic risk, or market risk.  On an individual asset level, measuring beta can give clues to volatility and liquidity in the marketplace. In fund management, measuring beta is thought to separate a manager's skill from his or her willingness to take risk.\nFrom this, we find that beta can be explained as \"correlated relative volatility\". This has three components:\nBeta can be computed for prices in the past, where the data is known, which is historical beta. However, what most people are interested in is future beta, which relates to risks going forward. Estimating future beta is a difficult problem. One guess is that future beta equals historical beta.\nwhere \u03c1a,b is the correlation of the two returns, and \u03c3a and \u03c3b are the respective volatilities. If a refers to the investment and b refers to the market, it now becomes clear that the interpretation of beta as 'the volatility of an investment relative to the market volatility' is inconsistent with how beta is calculated; this is due to the presence of the correlation in the above formula.[5]\nwhere Cov and Var are the covariance and variance operators.\nA common expression for beta is\nwhere \u03b5t is an error term (the unexplained return).\nThe best (in the sense of least squared error) estimates for \u03b1 and \u03b2 are those such that \u03a3\u03b5t2 is as small as possible.\nSince practical data are typically available as a discrete time series of samples, the statistical model is\nwhere ra is the return of the asset, alpha (\u03b1) is the active return, and rb is return of the benchmark.\nA statistical estimate of beta is calculated by a regression method. For a given asset and a benchmark, the goal is to find an approximate formula\nBeta decay refers to the tendency for a company with a high beta coefficient (\u03b2 > 1) to have its beta coefficient decline to the market beta. It is an example of regression toward the mean.\nThe definition above covers only theoretical beta. The term is used in many related ways in finance. For example, the betas commonly quoted in mutual fund analyses generally measure the risk of the fund arising from exposure to a benchmark for the fund, rather than from exposure to the entire market portfolio. Thus they measure the amount of risk the fund adds to a diversified portfolio of funds of the same type, rather than to a portfolio diversified among all fund types.[4]\nBeta is important because it measures the risk of an investment that cannot be reduced by diversification. It does not measure the risk of an investment held on a stand-alone basis, but the amount of risk the investment adds to an already-diversified portfolio. In the Capital Asset Pricing Model (CAPM), beta risk is the only kind of risk for which investors should receive an expected return higher than the risk-free rate of interest.[3]\nA beta greater than 1 generally means that the asset both is volatile and tends to move up and down with the market. An example is a stock in a big technology company. Negative betas are possible for investments that tend to go down when the market goes up, and vice versa. There are few fundamental investments with consistent and significant negative betas, but some derivatives like put options can have large negative betas.[2]\nBeta is a measure of the risk arising from exposure to general market movements as opposed to idiosyncratic factors. The market portfolio of all investable assets has a beta of exactly 1. A beta below 1 can indicate either an investment with lower volatility than the market, or a volatile investment whose price movements are not highly correlated with the market. An example of the first is a treasury bill: the price does not go up or down a lot, so it has a low beta. An example of the second is gold. The price of gold does go up and down a lot, but not in the same direction or at the same time as the market.[1]\nIn finance, the beta (\u03b2 or beta coefficient) of an investment indicates whether the investment is more or less volatile than the market as a whole.  \n",
            "title": "Beta (finance)",
            "url": "https://en.wikipedia.org/wiki/Beta_(finance)"
        },
        {
            "desc_links": [
                "/wiki/Portfolio_(finance)",
                "/wiki/Diversification_(finance)",
                "/wiki/Asset",
                "/wiki/Rate_of_return"
            ],
            "desc_text": "b'In finance, the capital asset pricing model (CAPM) is a model used to determine a theoretically appropriate required rate of return of an asset, to make decisions about adding assets to a well-diversified portfolio.\\n'",
            "links": [
                "/wiki/Portfolio_(finance)",
                "/wiki/Diversification_(finance)",
                "/wiki/Asset",
                "/wiki/Rate_of_return",
                "/wiki/Merton%27s_portfolio_problem",
                "/wiki/Arbitrage_pricing_theory",
                "/wiki/Risk-free_bond",
                "/wiki/Expected_return",
                "/wiki/Beta_(finance)",
                "/wiki/Market_risk",
                "/wiki/Systematic_risk",
                "/wiki/Fischer_Black",
                "/wiki/Financial_economics",
                "/wiki/Nobel_Memorial_Prize_in_Economic_Sciences",
                "/wiki/Merton_Miller",
                "/wiki/Modern_portfolio_theory",
                "/wiki/Diversification_(finance)",
                "/wiki/Harry_Markowitz",
                "/wiki/Jan_Mossin",
                "/wiki/John_Lintner",
                "/wiki/William_F._Sharpe",
                "/wiki/Jack_L._Treynor",
                "/wiki/Risk%E2%80%93return_spectrum",
                "/wiki/Systematic_risk",
                "/wiki/Security_market_line",
                "/wiki/Modern_portfolio_theory",
                "/wiki/Security_market_line",
                "/wiki/Utility_function",
                "/wiki/Mutual_fund",
                "/wiki/Risk",
                "/wiki/Diversification_(finance)",
                "/wiki/Market_risk",
                "/wiki/Specific_risk",
                "/wiki/Systematic_risk",
                "/wiki/Portfolio_(finance)",
                "/wiki/Variance",
                "/wiki/Return_on_investment",
                "/wiki/Infinite_divisibility",
                "/wiki/Beta_(finance)",
                "/wiki/Diversification_(finance)",
                "/wiki/Kenneth_French",
                "/wiki/Eugene_Fama"
            ],
            "text": "In their 2004 review, Fama and French argue that \"the failure of the CAPM in empirical tests implies that most applications of the model are invalid\".[3]\nAll investors:[7]\nBecause the unsystematic risk is diversifiable, the total risk of a portfolio can be viewed as beta.\nThe CAPM assumes that the risk-return profile of a portfolio can be optimized\u2014an optimal portfolio displays the lowest possible level of risk for its level of return. Additionally, since each additional asset introduced into a portfolio further diversifies the portfolio, the optimal portfolio must comprise every asset, (assuming no trading costs) with each asset value-weighted to achieve the above (assuming that any asset is infinitely divisible).  All such optimal portfolios, i.e., one for each level of return, comprise the efficient frontier.\nA rational investor should not take on any diversifiable risk, as only non-diversifiable risks are rewarded within the scope of this model.  Therefore, the required return on an asset, that is, the return that compensates for risk taken, must be linked to its riskiness in a portfolio context\u2014i.e. its contribution to overall portfolio riskiness\u2014as opposed to its \"stand alone risk.\" In the CAPM context, portfolio risk is represented by higher variance i.e. less predictability. In other words, the beta of the portfolio is the defining factor in rewarding the systematic exposure taken by an investor.\nThe risk of a portfolio comprises systematic risk, also known as undiversifiable risk, and unsystematic risk which is also known as idiosyncratic risk or diversifiable risk. Systematic risk refers to the risk common to all securities\u2014i.e. market risk. Unsystematic risk is the risk associated with individual assets. Unsystematic risk can be diversified away to smaller levels by including a greater number of assets in the portfolio (specific risks \"average out\"). The same is not possible for systematic risk within one market. Depending on the market, a portfolio of approximately 30\u201340 securities in developed markets such as the UK or US will render the portfolio sufficiently diversified such that risk exposure is limited to systematic risk only. In developing markets a larger number is required, due to the higher asset volatilities.\nSince beta reflects asset-specific sensitivity to non-diversifiable, i.e. market risk, the market as a whole, by definition, has a beta of one. Stock market indices are frequently used as local proxies for the market\u2014and in that case (by definition) have a beta of one. An investor in a large, diversified portfolio (such as a mutual fund), therefore, expects performance in line with the market.\nThe CAPM returns the asset-appropriate required return or discount rate\u2014i.e. the rate at which future cash flows produced by the asset should be discounted given that asset's relative riskiness. Betas exceeding one signify more than average \"riskiness\"; betas below one indicate lower than average. Thus, a more risky stock will have a higher beta and will be discounted at a higher rate; less sensitive stocks will have lower betas and be discounted at a lower rate.  Given the accepted concave utility function, the CAPM is consistent with intuition\u2014investors (should) require a higher return for holding a more risky asset.\nIt is a useful tool in determining if an asset being considered for a portfolio offers a reasonable expected return for risk. Individual securities are plotted on the SML graph. If the security's expected return versus risk is plotted above the SML, it is  undervalued since the investor can expect a greater return for the inherent risk. And a security plotted below the SML is overvalued since the investor would be accepting less return for the amount of risk assumed.\nThe relationship between \u03b2 and required return is plotted on the securities market line (SML), which shows expected return as a function of \u03b2. The intercept is the nominal risk-free rate available for the market, while the slope is the market premium, E(Rm)\u2212\u00a0Rf. The securities market line can be regarded as representing a single-factor model of the asset price, where Beta is exposure to changes in value of the Market. The equation of the SML is thus:\nThe SML essentially graphs the results from the capital asset pricing model (CAPM) formula. The x-axis represents the risk (beta), and the y-axis represents the expected return. The market risk premium is determined from the slope of the SML.\nThere has also been research into a mean-reverting beta often referred to as the adjusted beta, as well as the consumption beta. However, in empirical tests the traditional CAPM model has been found to do as well as or outperform the modified beta models.\nFor the full derivation see Modern portfolio theory.\nNote 2: the risk free rate of return used for determining the risk premium is usually the arithmetic average of historical risk free rates of return and not the current risk free rate of return.\nNote 1: the expected market rate of return is usually estimated by measuring the arithmetic average of the historical returns on a market portfolio (e.g. S&P 500).\nwhich states that the individual risk premium equals the market premium times \u03b2.\nRestated, in terms of risk premium, we find that:\nwhere:\nThe CAPM is a model for pricing an individual security or portfolio. For individual securities, we make use of the security market line (SML) and its relation to expected return and systematic risk (beta) to show how the market must price individual securities in relation to their security risk class. The SML enables us to calculate the reward-to-risk ratio for any security in relation to that of the overall market. Therefore, when the expected rate of return for any security is deflated by its beta coefficient, the reward-to-risk ratio for any individual security in the market is equal to the market reward-to-risk ratio, thus:\nThe CAPM was introduced by Jack Treynor (1961, 1962),[4] William F. Sharpe (1964), John Lintner (1965a,b) and Jan Mossin (1966) independently, building on the earlier work of Harry Markowitz on diversification and modern portfolio theory.  Sharpe, Markowitz and Merton Miller jointly received the 1990 Nobel Memorial Prize in Economics for this contribution to the field of financial economics.  Fischer Black (1972) developed another version of CAPM, called Black CAPM or zero-beta CAPM, that does not assume the existence of a riskless asset.  This version was more robust against empirical testing and was influential in the widespread adoption of the CAPM.\nThe model takes into account the asset's sensitivity to non-diversifiable risk (also known as systematic risk or market risk), often represented by the quantity beta (\u03b2) in the financial industry, as well as the expected return of the market and the expected return of a theoretical risk-free asset. CAPM assumes a particular form of utility functions (in which only first and second moments matter, that is risk is measured by variance, for example a quadratic utility) or alternatively asset returns whose probability distributions are completely described by the first two moments (for example, the normal distribution) and zero transaction costs (necessary for diversification to get rid of all idiosyncratic risk). Under these conditions, CAPM shows that the cost of equity capital is determined only by beta.[1][2] Despite it failing numerous empirical tests,[3] and the existence of more modern approaches to asset pricing and portfolio selection (such as arbitrage pricing theory and Merton's portfolio problem), the CAPM still remains popular due to its simplicity and utility in a variety of situations.\nIn finance, the capital asset pricing model (CAPM) is a model used to determine a theoretically appropriate required rate of return of an asset, to make decisions about adding assets to a well-diversified portfolio.\n",
            "title": "Capital asset pricing model",
            "url": "https://en.wikipedia.org/wiki/Capital_asset_pricing_model"
        },
        {
            "desc_links": [],
            "desc_text": "",
            "links": [],
            "text": "",
            "title": "Labour supply",
            "url": "https://en.wikipedia.org/wiki/Labor_supply"
        },
        {
            "desc_links": [
                "/wiki/Wage_labor",
                "/wiki/Market_(economics)",
                "/wiki/Human_capital",
                "/wiki/Capital_(economics)",
                "/wiki/Land_(economics)",
                "/wiki/Factors_of_production",
                "/wiki/Economics"
            ],
            "desc_text": "b'\\n'b'Labour economics seeks to understand the functioning and dynamics of the markets for wage labour.\\n'b'Labour markets or job markets function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers) and the demanders of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income.\\n'b'In economics, labour is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. There are theories which have developed a concept called human capital (referring to the skills that workers possess, not necessarily their actual work).\\n'",
            "links": [
                "/wiki/Wage_labor",
                "/wiki/Market_(economics)",
                "/wiki/Human_capital",
                "/wiki/Capital_(economics)",
                "/wiki/Land_(economics)",
                "/wiki/Factors_of_production",
                "/wiki/Economics",
                "/wiki/Gross_domestic_product",
                "/wiki/Macroeconomics",
                "/wiki/Microeconomics",
                "/wiki/Statistics",
                "/wiki/Unemployment",
                "/wiki/Institutionalisation",
                "/wiki/Civilian_noninstitutional_population",
                "/wiki/Working_age",
                "/wiki/Labour_force",
                "/wiki/Supply_and_demand",
                "/wiki/Neoclassical_economics",
                "/wiki/Compensating_differential",
                "/wiki/Market_clearing",
                "/wiki/Marginal_product",
                "/wiki/Perfect_competition",
                "/wiki/Utility_function",
                "/wiki/Indifference_curve",
                "/wiki/Wage_labour",
                "/wiki/Leisure",
                "/wiki/Marginal_rate_of_substitution",
                "/wiki/Substitution_effect",
                "/wiki/Income_effect",
                "/wiki/Normal_good",
                "/wiki/Opportunity_cost",
                "/wiki/Elasticity_(economics)",
                "/wiki/Signalling_(economics)",
                "/wiki/Production_theory_basics",
                "/wiki/Marginal_product_of_labor",
                "/wiki/Profit_(economics)",
                "/wiki/Marginal_Physical_Product",
                "/wiki/Price",
                "/wiki/Perfect_competition",
                "/wiki/Marginal_cost",
                "/wiki/Marginal_Revenue_Product",
                "/wiki/Wages",
                "/wiki/Human_capital",
                "/wiki/Education",
                "/wiki/Capital_(economics)",
                "/wiki/Competition_(economics)",
                "/wiki/Supply_and_demand",
                "/wiki/National_Health_Service_(England)",
                "/wiki/Doctor_of_Medicine",
                "/wiki/Laziness",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Haken-giri",
                "/wiki/Temporary_work",
                "/wiki/Stock_options",
                "/wiki/Wikipedia:Manual_of_Style/Dates_and_numbers#Chronological_items",
                "/wiki/Adverse_selection",
                "/wiki/Michael_Spence",
                "/wiki/Signalling_(economics)",
                "/wiki/Search_theory",
                "/wiki/Economic_efficiency",
                "/wiki/Personnel_management",
                "/wiki/Personnel_economics",
                "/wiki/Internal_labor_market",
                "/wiki/Emotional_baggage",
                "/wiki/Heterodox_economics",
                "/wiki/Contract_theory",
                "/wiki/Transaction_cost",
                "/wiki/Information_asymmetry",
                "/wiki/Mainstream_economics",
                "/wiki/Family_economics",
                "/wiki/Feminist_economics#Unpaid_work",
                "/wiki/Cicero",
                "/wiki/Slavery",
                "/wiki/Wage_labour",
                "/wiki/Pejorative",
                "/wiki/Wage_slavery",
                "/wiki/Anarcho-syndicalism",
                "/wiki/Socialism",
                "/wiki/Stanford_experiment",
                "/wiki/Milgram_experiment",
                "/wiki/Wilhelm_von_Humboldt",
                "/wiki/Liberalism",
                "/wiki/Age_of_Enlightenment",
                "/wiki/Noam_Chomsky",
                "/wiki/Investment_theory_of_party_competition",
                "/wiki/Thomas_Ferguson_(academic)",
                "/wiki/Democracy",
                "/wiki/Neo-feudalism",
                "/wiki/John_Dewey",
                "/wiki/Philosopher",
                "/wiki/Americans",
                "/wiki/Brazil",
                "/wiki/United_States",
                "/wiki/David_Graeber",
                "/wiki/Capitalism",
                "/wiki/Marxism"
            ],
            "text": "Additionally, Marxists posit that labour-as-commodity, which is how they regard wage labour,[24] provides an absolutely fundamental point of attack against capitalism.[25] \"It can be persuasively argued,\" noted one concerned philosopher, \"that the conception of the worker's labour as a commodity confirms Marx's stigmatisation of the wage system of private capitalism as 'wage-slavery;' that is, as an instrument of the capitalist's for reducing the worker's condition to that of a slave, if not below it.\"[26]\nAs per anthropologist David Graeber, the earliest wage labour contracts we know about were in fact contracts for the rental of chattel slaves (usually the owner would receive a share of the money, and the slave, another, with which to maintain his or her living expenses.) Such arrangements, according to Graeber, were quite common in New World slavery as well, whether in the United States or Brazil. C. L. R. James argued that most of the techniques of human organisation employed on factory workers during the industrial revolution were first developed on slave plantations.[23]\nThe American philosopher John Dewey posited that until \"industrial feudalism\" is replaced by \"industrial democracy,\" politics will be \"the shadow cast on society by big business\".[21] Thomas Ferguson has postulated in his investment theory of party competition that the undemocratic nature of economic institutions under capitalism causes elections to become occasions when blocs of investors coalesce and compete to control the state.[22]\nAccording to Noam Chomsky, analysis of the psychological implications of wage slavery goes back to the Enlightenment era. In his 1791 book On the Limits of State Action, classical liberal thinker Wilhelm von Humboldt explained how \"whatever does not spring from a man's free choice, or is only the result of instruction and guidance, does not enter into his very nature; he does not perform it with truly human energies, but merely with mechanical exactness\" and so when the labourer works under external control, \"we may admire what he does, but we despise what he is.\"[19] Both the Milgram and Stanford experiments have been found useful in the psychological study of wage-based workplace relations.[20]\nThe labour market, as institutionalised under today's market economic systems, has been criticised,[11] especially by both mainstream socialists and anarcho-syndicalists,[12][13][14][15] who utilise the term wage slavery[16][17] as a pejorative for wage labour. Socialists draw parallels between the trade of labour as a commodity and slavery. Cicero is also known to have suggested such parallels.[18]\nAlso missing from most labour market analyses is the role of unpaid labour such as unpaid internships where workers with little or no experience are allowed to work a job without pay so that they can gain experience in a particular profession. Even though this type of labour is unpaid it can nevertheless play an important part in society if not abused by employers. The most dramatic example is child raising. However, over the past 25 years an increasing literature, usually designated as the economics of the family, has sought to study within household decision making, including joint labour supply, fertility, child raising, as well as other areas of what is generally referred to as home production.[10]\nFrom the perspective of mainstream economics, neoclassical models are not meant to serve as a full description of the psychological and subjective factors that go into a given individual's employment relations, but as a useful approximation of human behaviour in the aggregate, which can be fleshed out further by the use of concepts such as information asymmetry, transaction costs, contract theory etc.\nMany sociologists, political economists, and heterodox economists claim that labour economics tends to lose sight of the complexity of individual employment decisions.[9] These decisions, particularly on the supply side, are often loaded with considerable emotional baggage and a purely numerical analysis can miss important dimensions of the process, such as social benefits of a high income or wage rate regardless of the marginal utility from increased consumption or specific economic goals.\nAt the micro level, one sub-discipline eliciting increased attention in recent decades is analysis of internal labour markets, that is, within firms (or other organisations), studied in personnel economics from the perspective of personnel management. By contrast, external labour markets \"imply that workers move somewhat fluidly between firms and wages are determined by some aggregate process where firms do not have significant discretion over wage setting.\"[7] The focus is on \"how firms establish, maintain, and end employment relationships and on how firms provide incentives to employees,\" including models and empirical work on incentive systems and as constrained by economic efficiency and risk/incentive tradeoffs relating to personnel compensation.[8]\nOne of the major research achievements of the 1990-2010 period was the development of a framework with dynamic search, matching, and bargaining.[6]\nThere are many ways to overcome adverse selection in labour market. One important mechanism is called signalling, pioneered by Michael Spence.[5] In his classical paper on job signalling, Spence showed that even if formal education does not increase productivity, high-ability workers may still acquire it just to signal their abilities. Employers can then use education as a signal to infer worker ability and pay higher wages to better-educated workers. It may appear to an external observer that education has raised the marginal product of labour, without this necessarily being true.\nAnother aspect of uncertainty results from the firm's imperfect knowledge about worker ability. If a firm is unsure about a worker's ability, it pays a wage assuming that the worker's ability is the average of similar workers. This wage undercompensates high-ability workers and may drive them away from the labour market. Such a phenomenon, called adverse selection, can sometimes lead to market collapse.[4]\nOne solution used recently[when?] \u2013 stock options \u2013 grants employees the chance to benefit directly from a firm's success. However, this solution has attracted criticism as executives with large stock-option packages have been suspected of acting to over-inflate share values to the detriment of the long-run welfare of the firm. Another solution, foreshadowed by the rise of temporary workers in Japan and the firing of many of these workers in response to the financial crisis of 2008, is more flexible job- contracts and -terms that encourage employees to work less than full-time by partially compensating for the loss of hours, relying on workers to adapt their working time in response to job requirements and economic conditions instead of the employer trying to determine how much work is needed to complete a given task and overestimating.[citation needed]\nIn many real-life situations the assumption of perfect information is unrealistic. An employer does not necessarily know how hard workers are working or how productive they are. This provides an incentive for workers to shirk from providing their full effort \u2013 since it is difficult for the employer to identify the hard-working and the shirking employees, there is no incentive to work hard and productivity falls overall, leading to the hiring of more workers and a lower unemployment rate.\nSome labour markets have a single employer and thus do not satisfy the perfect competition assumption of the neoclassical model above. The model of a monopsonistic labour market gives a lower quantity of employment and a lower equilibrium wage rate than does the competitive model.\nWage differences exist, particularly in mixed and fully/partly flexible labour markets. For example, the wages of a doctor and a port cleaner, both employed by the NHS, differ greatly. There are various factors concerning this phenomenon. This includes the MRP of the worker. A doctor's MRP is far greater than that of the port cleaner. In addition, the barriers to becoming a doctor are far greater than that of becoming a port cleaner. To become a doctor takes a lot of education and training which is costly, and only those who excel in academia can succeed in becoming doctors. The port cleaner however requires relatively less training. The supply of doctors is therefore significantly less elastic than that of port cleaners. Demand is also inelastic as there is a high demand for doctors and medical care is a necessity, so the NHS will pay higher wage rates to attract the profession.\nThe demand for labour of this firm can be summed with the demand for labour of all other firms in the economy to obtain the aggregate demand for labour. Likewise, the supply curves of all the individual workers (mentioned above) can be summed to obtain the aggregate supply of labour. These supply and demand curves can be analysed in the same way as any other industry demand and supply curves to determine equilibrium wage and employment levels.\nThe marginal revenue product of labour can be used as the demand for labour curve for this firm in the short run. In competitive markets, a firm faces a perfectly elastic supply of labour which corresponds with the wage rate and the marginal resource cost of labour (W = SL = MFCL). In imperfect markets, the diagram would have to be adjusted because MFCL would then be equal to the wage rate divided by marginal costs. Because optimum resource allocation requires that marginal factor costs equal marginal revenue product, this firm would demand L units of labour as shown in the diagram.\nAccording to neoclassical theory, over the relevant range of outputs, the marginal physical product of labour is declining (law of diminishing returns). That is, as more and more units of labour are employed, their additional output begins to decline.\nThe MRP of the worker is affected by other inputs to production with which the worker can work (e.g. machinery), often aggregated under the term \"capital\". It is typical in economic models for greater availability of capital for a firm to increase the MRP of the worker, all else equal. Education and training are counted as \"human capital\". Since the amount of physical capital affects MRP, and since financial capital flows can affect the amount of physical capital available, MRP and thus wages can be affected by financial capital flows within and between countries, and the degree of capital mobility within and between countries.[3]\nLabour demand is a derived demand; that is, hiring labour is not desired for its own sake but rather because it aids in producing output, which contributes to an employer's revenue and hence profits. The demand for an additional amount of labour depends on the Marginal Revenue Product (MRP) and the marginal cost (MC) of the worker. With a perfectly competitive goods market, the MRP is calculated by multiplying the price of the end product or service by the Marginal Physical Product of the worker. If the MRP is greater than a firm's Marginal Cost, then the firm will employ the worker since doing so will increase profit. The firm only employs however up to the point where MRP=MC, and not beyond, in neoclassical economic theory.[2]\nA firm's labour demand is based on its marginal physical product of labour (MPPL). This is defined as the additional output (or physical product) that results from an increase of one unit of labour (or from an infinitesimal increase in labour). (See also Production theory basics.)\nOther variables that affect the labour supply decision, and can be readily incorporated into the model, include taxation, welfare, work environment, and income as a signal of ability or social contribution.\nThe direction of slope may change more than once for some individuals, and the labour supply curve is different for different individuals.\nIf the substitution effect is greater than the income effect, an individual's supply of labour services will increase as the wage rate rises, which is represented by a positive slope in the labour supply curve (as at point E in the adjacent diagram, which exhibits a positive wage elasticity). This positive relationship is increasing until point F, beyond which the income effect dominates the substitution effect and the individual starts to reduce the amount of labour hours he supplies (point G) as wage increases; in other words, the wage elasticity is now negative.\nBut that is only part of the picture. As the wage rate rises, the worker will substitute away from leisure and into the provision of labour\u2014that is, will work more hours to take advantage of the higher wage rate, or in other words substitute away from leisure because of its higher opportunity cost. This substitution effect is represented by the shift from point C to point B. The net impact of these two effects is shown by the shift from point A to point B. The relative magnitude of the two effects depends on the circumstances. In some cases, such as the one shown, the substitution effect is greater than the income effect (in which case more time will be allocated to working), but in other cases the income effect will be greater than the substitution effect (in which case less time is allocated to working). The intuition behind this latter case is that the individual decides that the higher earnings on the previous amount of labour can be \"spent\" by purchasing more leisure.\nThe wage increase shown in the previous diagram can be decomposed into two separate effects. The pure income effect is shown as the movement from point A to point C in the next diagram. Consumption increases from YA to YC and \u2013 since the diagram assumes that leisure is a normal good \u2013 leisure time increases from XA to XC. (Employment time decreases by the same amount as leisure increases.)\nIf the wage rate increases, this individual's constraint line pivots up from X,Y1 to X,Y2. He/she can now purchase more goods and services. His/her utility will increase from point A on IC1 to point B on IC2.\nTo understand what effect this might have on the decision of how many hours to work, one must look at the income effect and substitution effect.\nwhere Y is total income and the right side is the wage rate.\nIf consumption is measured by the value of income obtained, this diagram can be used to show a variety of interesting effects. This is because the absolute value of the slope of the budget constraint is the wage rate. The point of optimisation (point A) reflects the equivalency between the wage rate and the marginal rate of substitution[2] of leisure for income (the absolute value of the slope of the indifference curve). Because the marginal rate of substitution of leisure for income is also the ratio of the marginal utility of leisure (MUL) to the marginal utility of income (MUY), one can conclude:\nThis is shown in the graph below, which illustrates the trade-off between allocating time between leisure activities and income-generating activities. The linear constraint indicates that every additional hour of leisure undertaken requires the loss of an hour of labour and thus of the fixed amount of goods that that labour's income could purchase. Individuals must choose how much time to allocate to leisure activities and how much to working. This allocation decision is informed by the indifference curve labelled IC1. The curve indicates the combinations of leisure and work that will give the individual a specific level of utility. The point where the highest indifference curve is just tangent to the constraint line (point A), illustrates the optimum for this supplier of labour services.\nLet w denote the hourly wage, k denote total hours available for labour and leisure, L denote the chosen number of working hours,  \u03c0 denote income from non-labour sources, and A denote leisure hours chosen. The individual's problem is to maximise utility U, which depends on total income available for spending on consumption and also depends on time spent in leisure, subject to a time constraint, with respect to the chooses of labour time and leisure time:\nHouseholds are suppliers of labour. In microeconomic theory, people are assumed to be rational and seeking to maximize their utility function. In the labour market model, their utility function expresses trade-offs in preference between leisure time and income from time used for labour. However, they are constrained by the hours available to them.\nModels that assume perfect competition in the labour market, as discussed below, conclude that workers earn their marginal product of labour.[1]\nHowever, the labour market differs from other markets (like the markets for goods or the financial market) in several ways. In particular, the labour market may act as a non-clearing market. While according to neoclassical theory most markets quickly attain a point of equilibrium without excess supply or demand, this may not be true of the labour market: it may have a persistent level of unemployment. Contrasting the labour market to other markets also reveals persistent compensating differentials among similar workers.\nNeoclassical economists view the labour market as similar to other markets in that the forces of supply and demand jointly determine price (in this case the wage rate) and quantity (in this case the number of people employed).\nVariables like employment level, unemployment level, labour force, and unfilled vacancies are called stock variables because they measure a quantity at a point in time. They can be contrasted with flow variables which measure a quantity over a duration of time. Changes in the labour force are due to flow variables such as natural population growth, net immigration, new entrants, and retirements from the labour force.  Changes in unemployment depend on inflows made up of non-employed people starting to look for jobs and of employed people who lose their jobs and look for new ones, and outflows of people who find new employment and of people who stop looking for employment. When looking at the overall macroeconomy, several types of unemployment have been identified, including:\nThe labour force is defined as the number of people of working age, who are either employed or actively looking for work. The participation rate is the number of people in the labour force divided by the size of the adult civilian noninstitutional population (or by the population of working age that is not institutionalized). The non-labour force includes those who are not looking for work, those who are institutionalised such as in prisons or psychiatric wards, stay-at home spouses, children, and those serving in the military. The unemployment level is defined as the labour force minus the number of people currently employed. The unemployment rate is defined as the level of unemployment divided by the labour force. The employment rate is defined as the number of people currently employed divided by the adult population (or by the population of working age).  In these statistics, self-employed people are counted as employed.\nThere are two sides to labour economics. Labour economics can generally be seen as the application of microeconomic or macroeconomic techniques to the labour market. Microeconomic techniques study the role of individuals and individual firms in the labour market. Macroeconomic techniques look at the interrelations between the labour market, the goods market, the money market, and the foreign trade market. It looks at how these interactions influence macro variables such as employment levels, participation rates, aggregate income and gross domestic product.\nIn economics, labour is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. There are theories which have developed a concept called human capital (referring to the skills that workers possess, not necessarily their actual work).\nLabour markets or job markets function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers) and the demanders of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income.\nLabour economics seeks to understand the functioning and dynamics of the markets for wage labour.\n\n",
            "title": "Labour economics",
            "url": "https://en.wikipedia.org/wiki/Labour_economics"
        },
        {
            "desc_links": [
                "/wiki/M3_(economics)",
                "/wiki/M2_(economics)",
                "/wiki/M1_(economics)",
                "/wiki/Money",
                "/wiki/Monetary_economics",
                "/wiki/Asset_demand_for_money",
                "/wiki/Precautionary_demand",
                "/wiki/Transactions_demand",
                "/wiki/Macroeconomics",
                "/wiki/Liquidity",
                "/wiki/Store_of_value",
                "/wiki/IS-LM_model",
                "/wiki/Money_supply",
                "/wiki/Nominal_interest_rate",
                "/wiki/Real_versus_nominal_value_(economics)",
                "/wiki/Central_bank",
                "/wiki/Elasticity_(economics)",
                "/wiki/Liquidity_trap",
                "/wiki/Liquidity_preference",
                "/wiki/Real_versus_nominal_value_(economics)",
                "/wiki/Real_versus_nominal_value_(economics)"
            ],
            "desc_text": "b'\\nIn monetary economics, the demand for money is the desired holding of financial assets in the form of money: that is, cash or bank deposits rather than investments. It can refer to the demand for money narrowly defined as M1 (directly spendable holdings), or for money in the broader sense of M2 or M3.\\n'b\"Money in the sense of M1 is dominated as a store of value (even a temporary one) by interest-bearing assets. However, M1 is necessary to carry out transactions; in other words, it provides liquidity. This creates a trade-off between the liquidity advantage of holding money for near-future expenditure and the interest advantage of temporarily holding other assets. The demand for M1 is a result of this trade-off regarding the form in which a person's funds to be spent should be held. In macroeconomics motivations for holding one's wealth in the form of M1 can roughly be divided into the transaction motive and the precautionary motive. The demand for those parts of the broader money concept M2 that bear a non-trivial interest rate is based on the asset demand. These can be further subdivided into more microeconomically founded motivations for holding money.\\n\"b'Generally, the nominal demand for money increases with the level of nominal output (price level times real output) and decreases with the nominal interest rate. The real demand for money is defined as the nominal amount of money demanded divided by the price level. For a given money supply the locus of income-interest rate pairs at which money demand equals money supply is known as the LM curve.\\n'b'The magnitude of the volatility of money demand has crucial implications for the optimal way in which a central bank should carry out monetary policy and its choice of a nominal anchor.\\n'b'Conditions under which the LM curve is flat, so that increases in the money supply have no stimulatory effect (a liquidity trap), play an important role in Keynesian theory. This situation occurs when the demand for money is infinitely elastic with respect to the interest rate.\\n'b'A typical money-demand function may be written as\\n'b'where \\n  \\n    \\n      \\n        \\n          M\\n          \\n            d\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle M^{d}}\\n  \\n is the nominal amount of money demanded, P is the price level, R is the nominal interest rate, Y is real income, and L(.) is real money demand. An alternate name for \\n  \\n    \\n      \\n        L\\n        (\\n        R\\n        ,\\n        Y\\n        )\\n      \\n    \\n    {\\\\displaystyle L(R,Y)}\\n  \\n is  the liquidity preference function.\\n'",
            "links": [
                "/wiki/M3_(economics)",
                "/wiki/M2_(economics)",
                "/wiki/M1_(economics)",
                "/wiki/Money",
                "/wiki/Monetary_economics",
                "/wiki/Asset_demand_for_money",
                "/wiki/Precautionary_demand",
                "/wiki/Transactions_demand",
                "/wiki/Macroeconomics",
                "/wiki/Liquidity",
                "/wiki/Store_of_value",
                "/wiki/IS-LM_model",
                "/wiki/Money_supply",
                "/wiki/Nominal_interest_rate",
                "/wiki/Real_versus_nominal_value_(economics)",
                "/wiki/Central_bank",
                "/wiki/Elasticity_(economics)",
                "/wiki/Liquidity_trap",
                "/wiki/Quantity_Theory_of_Money",
                "/wiki/Baumol-Tobin_model",
                "/wiki/Sidrauski_model",
                "/wiki/Clower_constraint",
                "/wiki/Cash-in-advance_constraint",
                "/wiki/Dynamic_stochastic_general_equilibrium",
                "/wiki/Utility_function",
                "/wiki/John_Maynard_Keynes",
                "/wiki/Risk_averse",
                "/wiki/James_Tobin",
                "/wiki/Velocity_of_money",
                "/wiki/A_Monetary_History_of_the_United_States",
                "/wiki/Anna_Schwartz",
                "/wiki/Milton_Friedman",
                "/wiki/LM_curve",
                "/wiki/IS_curve",
                "/wiki/Aggregate_demand"
            ],
            "text": "The above discussion implies that the volatility of money demand matters for how monetary policy should be conducted. If most of the aggregate demand shocks which affect the economy come from the expenditure side, the IS curve, then a policy of targeting the money supply will be stabilizing, relative to a policy of targeting interest rates. However, if most of the aggregate demand shocks come from changes in money demand, which influences the LM curve, then a policy of targeting the money supply will be destabilizing.\nThis analysis however breaks down if the demand for money is not stable \u2014 for example, if velocity in the above equation is not constant. In that case, shocks to money demand under money supply targeting will translate into changes in real and nominal interest rates and result in economic fluctuations. An alternative policy of targeting interest rates rather than the money supply can improve upon this outcome as the money supply is adjusted to shocks in money demand, keeping interest rates (and hence, economic activity) relatively constant.\nHere, given the long-run output growth rate, the only determinant of the inflation rate is the growth rate of the money supply. In this case inflation in the long run is a purely monetary phenomenon; a monetary policy which targets the money supply can stabilize the economy and ensure a non-variable inflation rate.\nIf the demand for money is stable then a monetary policy which consists of a monetary rule which targets the growth rate of some monetary aggregate (such as M1 or M2) can help to stabilize the economy or at least remove monetary policy as a source of macroeconomic volatility. Additionally, if the demand for money does not change unpredictably then money supply targeting is a reliable way of attaining a constant inflation rate. This can be most easily seen with the quantity theory of money equation given above. When that equation is converted into growth rates we have\nLater work by Lawrence Ball suggests that the use of adapted aggregates, such as near monies, can produce a more stable demand function.  Through his research, Ball was able to show that using the return on near monies produced smaller deviations than previous models.\nFriedman and Schwartz in their 1963 work A Monetary History of the United States argued that the demand for real balances was a function of income and the interest rate. For the time period they were studying this appeared to be true. However, shortly after the publication of the book, due to changes in financial markets and financial regulation money demand became more unstable.  Various researchers showed that money demand became much more unstable after 1975. Ericsson, Hendry and Prestwich (1998) consider a model of money demand based on the various motives outlined above and test it with empirical data. The basic model turns out to work well for the period 1878 to 1975 and there doesn't appear to be much volatility in money demand, in a result analogous to that of Friedman and Schwartz. This is true even despite the fact that the two world wars during this time period could have led to changes in the velocity of money. However, when the same basic model is used on data spanning 1976 to 1993, it performs poorly. In particular, money demand appears not to be sensitive to interest rates and there appears to be much more exogenous volatility. The authors attribute the difference to technological innovations in the financial markets, financial deregulation, and the related issue of the changing menu of assets considered in the definition of money.\nThe portfolio motive also focuses on demand for money over and above that required for carrying out transactions. The basic framework is due to James Tobin, who considered a situation where agents can hold their wealth in a form of a low risk/low return asset (here, money) or high risk/high return asset (bonds or equity). Agents will choose a mix of these two types of assets (their portfolio) based on the risk-expected return trade-off. For a given expected rate of return, more risk averse individuals will choose a greater share for money in their portfolio. Similarly, given a person's degree of risk aversion, a higher expected return (nominal interest rate plus expected capital gains on bonds) will cause agents to shift away from safe money and into risky assets. Like in the other motivations above, this creates a negative relationship between the nominal interest rate and the demand for money. However, what matters additionally in the Tobin model is the subjective rate of risk aversion, as well as the objective degree of risk of other assets, as, say, measured by the standard deviation of capital gains and losses resulting from holding bonds and/or equity.\nThe fact that the current demand for money can depend on expectations of the future interest rates has implications for volatility of money demand. If these expectations are formed, as in Keynes' view, by \"animal spirits\" they are likely to change erratically and cause money demand to be quite unstable.\nJohn Maynard Keynes, in laying out speculative reasons for holding money, stressed the choice between money and bonds. If agents expect the future nominal interest rate (the return on bonds) to be lower than the current rate they will then reduce their holdings of money and increase their holdings of bonds. If the future interest rate falls, then the price of bonds will increase and the agents will have realized a capital gain on the bonds they purchased. This means that the demand for money in any period will depend on both the current nominal interest rate and the expected future interest rate (in addition to the standard transaction motives which depend on income).\nThe asset motive for the demand for broader monetary measures, M2 and M3, states that people demand money as a way to hold wealth. While it is still assumed that money is held in order to carry out transactions, this approach focuses on the potential return on various assets (including money) as an additional motivation.\nThe precautionary demand for M1 is the holding of transaction funds for use if unexpected needs for immediate expenditure arise.\nIn the cash-in-advance model agents are restricted to carrying out a volume of transactions equal to or less than their money holdings. In the MIU model, money directly enters agents' utility functions, capturing the 'liquidity services' provided by money.[2][3][4]\nWhile the Baumol\u2013Tobin model provides a microeconomic explanation for the form of the money demand function, it is generally too stylized to be included in modern macroeconomic models, particularly dynamic stochastic general equilibrium models. As a result, most models of this type resort to simpler indirect methods which capture the spirit of the transactions motive. The two most commonly used methods are the cash-in-advance model (sometimes called the Clower constraint model) and the money-in-the-utility-function (MIU) model (as known as the Sidrauski model).[1]\nThe key difference between this formulation and the one based on a simple version of Quantity Theory is that now the demand for real balances depends on both income (positively) or the desired level of transactions, and on the nominal interest rate (negatively).\nwhere t is the cost of a trip to the bank, R is the nominal interest rate and P and Y are as before.\nThe most well-known example of an economic model that is based on such considerations is the Baumol-Tobin model. In this model an individual receives her income periodically, for example, only once per month, but wishes to make purchases continuously. The person could carry her entire income with her at all times and use it to make purchases. However, in this case she would be giving up the (nominal) interest rate that she can get by holding her income in the bank. The optimal strategy involves holding a portion of one's income in the bank and portion as liquid money. The money portion is continuously run down as the individual makes purchases and then she makes periodic (costly) trips to the bank to replenish the holdings of money. Under some simplifying assumptions the demand for money resulting from the Baumol-Tobin model is given by\nThe amount of money demanded for transactions however is also likely to depend on the nominal interest rate. This arises due the lack of synchronization in time between when purchases are desired and when factor payments (such as wages) are made. In other words, while workers may get paid only once a month they generally will wish to make purchases, and hence need money, over the course of the entire month.\nHence in this simple formulation demand for money is a function of prices and income, as long as its velocity is constant.\nor in terms of demand for real balances\nThe most basic \"classical\" transaction motive can be illustrated with reference to the Quantity Theory of Money. According to the equation of exchange MV\u00a0=\u00a0PY, where M is the stock of money, V is its velocity (how many times a unit of money turns over during a period of time), P is the price level and Y is real income. Consequently, PY is nominal income or in other words the number of transactions carried out in an economy during a period of time. Rearranging the above identity and giving it a behavioral interpretation as a demand for money we have\nThe transactions motive for the demand for M1 (directly spendable money balances) results from the need for liquidity for day-to-day transactions in the near future.  This need arises when income is received only occasionally (say once per month) in discrete amounts but expenditures occur continuously.\nA typical money-demand function may be written as\nConditions under which the LM curve is flat, so that increases in the money supply have no stimulatory effect (a liquidity trap), play an important role in Keynesian theory. This situation occurs when the demand for money is infinitely elastic with respect to the interest rate.\nThe magnitude of the volatility of money demand has crucial implications for the optimal way in which a central bank should carry out monetary policy and its choice of a nominal anchor.\nGenerally, the nominal demand for money increases with the level of nominal output (price level times real output) and decreases with the nominal interest rate. The real demand for money is defined as the nominal amount of money demanded divided by the price level. For a given money supply the locus of income-interest rate pairs at which money demand equals money supply is known as the LM curve.\nMoney in the sense of M1 is dominated as a store of value (even a temporary one) by interest-bearing assets. However, M1 is necessary to carry out transactions; in other words, it provides liquidity. This creates a trade-off between the liquidity advantage of holding money for near-future expenditure and the interest advantage of temporarily holding other assets. The demand for M1 is a result of this trade-off regarding the form in which a person's funds to be spent should be held. In macroeconomics motivations for holding one's wealth in the form of M1 can roughly be divided into the transaction motive and the precautionary motive. The demand for those parts of the broader money concept M2 that bear a non-trivial interest rate is based on the asset demand. These can be further subdivided into more microeconomically founded motivations for holding money.\n\nIn monetary economics, the demand for money is the desired holding of financial assets in the form of money: that is, cash or bank deposits rather than investments. It can refer to the demand for money narrowly defined as M1 (directly spendable holdings), or for money in the broader sense of M2 or M3.\n",
            "title": "Demand for money",
            "url": "https://en.wikipedia.org/wiki/Money_demand"
        },
        {
            "desc_links": [
                "/wiki/International_trade",
                "/wiki/Financial_transaction",
                "/wiki/Export",
                "/wiki/National_border",
                "/wiki/Trade_agreements",
                "/wiki/Tariff",
                "/wiki/Customs",
                "/wiki/Import_quota"
            ],
            "desc_text": "b'An import is a good brought into a jurisdiction, especially across a national border, from an external source. The party bringing in the good is called an importer.[1][2] An import in the receiving country is an export from the sending country. Importation and exportation are the defining financial transactions of international trade.\\n'b'In international trade, the importation and exportation of goods are limited by import quotas and mandates from the customs authority. The importing and exporting jurisdictions may impose a tariff (tax) on the goods. In addition, the importation and exportation of goods are subject to trade agreements between the importing and exporting jurisdictions.\\n'",
            "links": [
                "/wiki/International_trade",
                "/wiki/Financial_transaction",
                "/wiki/Export",
                "/wiki/National_border",
                "/wiki/Trade_agreements",
                "/wiki/Tariff",
                "/wiki/Customs",
                "/wiki/Import_quota",
                "/wiki/National_accounts",
                "/wiki/Domestic_market",
                "/wiki/World_economy",
                "/wiki/Price",
                "/wiki/Supply_(economics)",
                "/wiki/Demand_(economics)",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Marginalism",
                "/wiki/Willingness_to_pay",
                "/wiki/Consumer",
                "/wiki/Canada",
                "/wiki/Petroleum",
                "/wiki/United_States_of_America",
                "/wiki/Income",
                "/wiki/Trade_deficit",
                "/wiki/Eurostat",
                "/wiki/OECD",
                "/wiki/FAOSTAT",
                "/wiki/International_trade#Data",
                "/wiki/Added_cost",
                "/wiki/Manufacturer",
                "/wiki/Wal-Mart",
                "/wiki/Direct_Imports"
            ],
            "text": "Direct-import refers to a type of business importation involving a major retailer (e.g. Wal-Mart) and an overseas manufacturer. A retailer typically purchases products designed by local companies that can be manufactured overseas. In a direct-import program, the retailer bypasses the local supplier (colloquial middle-man) and buys the final product directly from the manufacturer, possibly saving in added cost\ndata on the value of imports and their quantities often broken down by detailed lists of products are available in statistical collections on international trade published by the statistical services of intergovernmental organisations (e.g. UNSTAT,[6] FAOSTAT, OECD), supranational statistical institutes (e.g. Eurostat) and national statistical institutes.\nIndustrial and consumer goods.\nThere are three broad types of importers:\nCompanies import goods and services to supply to the domestic market at a cheaper price and better quality than competing goods manufactured in the domestic market. Companies import products that are not available in the local market.\nThere are two basic types of import:\nA trade deficit occurs when imports are large relative to exports. Imports are impacted principally by a country's income and its productive resources. For example, the US imports oil from Canada even though the US has oil and Canada uses oil.  However, consumers in the US are willing to pay more for the marginal barrel of oil than Canadian consumers are, because there is more oil demanded in the US than there is oil produced.[citation needed]\nBalance of trade represents a difference in value for import and export for a country. A country has demand for an import when domestic quantity demanded exceeds domestic quantity supplied, or when the price of the good (or service) on the world market is less than the price on the domestic market.\nBasic trade statistics often differ in terms of definition and coverage from the requirements in the national accounts:\nA general delimitation of imports in national accounts is given below:\n\"Imports\" consist of transactions in goods and services to a resident of a jurisdiction (such as a nation) from non-residents.[3]  The exact definition of imports in national accounts includes and excludes specific \"borderline\" cases.[4]. Importation is the action of buying or acquiring products or services from another country or another market other than own. Imports are important for the economy because they allow a country to supply nonexistent, scarce, high cost or low quality of certain products or services, to its market with products from other countries. \nIn international trade, the importation and exportation of goods are limited by import quotas and mandates from the customs authority. The importing and exporting jurisdictions may impose a tariff (tax) on the goods. In addition, the importation and exportation of goods are subject to trade agreements between the importing and exporting jurisdictions.\nAn import is a good brought into a jurisdiction, especially across a national border, from an external source. The party bringing in the good is called an importer.[1][2] An import in the receiving country is an export from the sending country. Importation and exportation are the defining financial transactions of international trade.\n",
            "title": "Import",
            "url": "https://en.wikipedia.org/wiki/Imports"
        },
        {
            "desc_links": [
                "/wiki/Service_(business)",
                "/wiki/Goods",
                "/wiki/International_trade",
                "/wiki/Import",
                "/wiki/Customs"
            ],
            "desc_text": "b'\\n'b'The term export in international trade means the sending of goods or services produced in one country to another country. The seller of such goods and services is referred to as an exporter; the foreign buyer is referred to as an importer.[1]\\n'b\"Export of goods often requires involvement of customs authorities. An export's reverse counterpart is an import.\\n\"",
            "links": [
                "/wiki/Service_(business)",
                "/wiki/Goods",
                "/wiki/International_trade",
                "/wiki/Import",
                "/wiki/Customs",
                "/wiki/Wikipedia:Please_clarify",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Stimulate",
                "/wiki/Policies",
                "/wiki/Regulation",
                "/wiki/Trade_barrier",
                "/wiki/Archaeological_artefact",
                "/wiki/Dumping_(pricing_policy)",
                "/wiki/Subsidies",
                "/wiki/Production_(economics)",
                "/wiki/Tariff",
                "/wiki/World_Trade_Organization",
                "/wiki/United_States_steel_tariff_2002",
                "/wiki/Outsource",
                "/wiki/License",
                "/wiki/Core_competence",
                "/wiki/Internationalization",
                "/wiki/Financial_risk",
                "/wiki/Gap_analysis#Market_potential",
                "/wiki/Value_chain",
                "/wiki/Porter_generic_strategies#Differentiation_Strategy",
                "/wiki/Porter_generic_strategies#Cost_Leadership_Strategy",
                "/wiki/Asset",
                "/wiki/Marketing_management",
                "/wiki/International_business",
                "/wiki/Rate_of_return",
                "/wiki/Foreign_direct_investment",
                "/wiki/Eclectic_paradigm",
                "/wiki/Foreign_exchange_market",
                "/wiki/Trade_regulation",
                "/wiki/Small_and_medium_enterprises"
            ],
            "text": "Motivational factors are \"all those factors triggering the decision of the firm to initiate and develop export activities\". In the literature, export barriers are divided into four large categories: motivational, informational, operational/resource-based, and knowledge.[10] In addition,  export motivators are divided into five dimensions; reactive, marketing,export, technological, external.[11] Research shows that exporters are more favourable to motivators than non-exporters.[12]\nFor small and medium enterprises (SMEs) with fewer than 250 employees, selling goods and services to foreign markets can be more difficult than serving the domestic market. The lack of knowledge of trade regulations, cultural differences, different languages and foreign-exchange situations, as well as the strain of resources and staff, interact like a block for exporting. Indeed, there are some SMEs which are exporting, but nearly two-thirds of them sell to only one foreign market.[9]\nExporting has a number of drawbacks:\nIn relation to the eclectic paradigm, companies that have low levels of ownership advantages do not enter foreign markets. If the company and its products are equipped with ownership advantage and internalization advantage, they enter through low-risk modes such as exporting. Exporting requires significantly lower level of investment than other modes of international expansion, such as FDI. The lower risk of export typically results in a lower rate of return on sales than possible though other modes of international business. In other words, the usual return on export sales may not be tremendous, but neither is the risk. Exporting allows managers to exercise operation control but does not provide them the option to exercise as much marketing control. An exporter usually resides far from the end consumer and often enlists various intermediaries to manage marketing activities. After two straight months of contraction, exports from India rose by 11.64% at $25.83 billion in July 2013 against $23.14 billion in the same month of the previous year.[8]\nOwnership advantages are the firm's specific assets, international experience, and the ability to develop either low-cost or differentiated products within the contacts of its value chain. The locational advantages of a particular market are a combination of market potential and investment risk. Internationalization advantages are the benefits of retaining a core competence within the company and threading it though the value chain rather than to license, outsource, or sell it. \nTariffs can create tension between countries. Examples include the United States steel tariff of 2002 and when China placed a 14% tariff on imported auto parts. Such tariffs usually lead to a complaint with the World Trade Organization (WTO).[6] If that fails, the country may put a tariff of its own against the other nation in retaliation, and to increase pressure to remove the tariff.\nA tariff is a tax placed on a specific good or set of goods exported from or imported to a country, creating an economic barrier to trade.[4] Usually the tactic is used when a country's domestic output of the good is falling and imports from foreign competitors are rising, particularly if the country has strategic reasons to retain a domestic production capability. Some failing industries receive a protection with an effect similar to subsidies; tariffs reduce the industry's incentives to produce goods quicker, cheaper, and more efficiently. The third reason for a tariff involves addressing the issue of dumping. Dumping involves a country producing highly excessive amounts of goods and dumping the goods on another country at prices that are \"too low\", for example,  pricing the good lower in the export market than in the domestic market of the country of origin. In dumping the producer sells the product at a price that returns no profit, or even amounts to a loss.[5] The purpose and expected outcome of a tariff is to encourage spending on domestic goods and services rather than imports.\nInternational agreements limit trade in and the transfer of, certain types of goods and information e.g. goods associated with weapons of mass destruction, advanced telecommunications, arms and torture, and also some art and archaeological artefacts. For example:\nTrade barriers are government laws, regulations, policy, or practices that either protect domestic products from foreign competition or artificially stimulate exports of particular domestic products. While restrictive business practices sometimes have a similar effect, they are not usually regarded as trade barriers. The most common foreign trade barriers are government-imposed measures and policies that restrict, prevent, or impede the international exchange of goods and services.[3]\nMethods of exporting a product or good or information include mail, hand delivery, air shipping, shipping by vessel, uploading to an internet site, or downloading from an internet site. Exports also include distribution of information sent as email, an email attachment, fax or in a telephone conversation.[citation needed]\nMany manufacturing firms began their global expansion as exporters and only later switched to another mode for serving a foreign market.[2][clarification needed]\nExport of goods often requires involvement of customs authorities. An export's reverse counterpart is an import.\nThe term export in international trade means the sending of goods or services produced in one country to another country. The seller of such goods and services is referred to as an exporter; the foreign buyer is referred to as an importer.[1]\n\n",
            "title": "Export",
            "url": "https://en.wikipedia.org/wiki/Exports"
        },
        {
            "desc_links": [],
            "desc_text": "",
            "links": [],
            "text": "",
            "title": "Inventory investment",
            "url": "https://en.wikipedia.org/wiki/Inventory_investment"
        },
        {
            "desc_links": [
                "/wiki/Depreciation",
                "/wiki/Fixed_capital",
                "/wiki/Economics",
                "/wiki/Bond_(finance)",
                "/wiki/Productivity",
                "/wiki/International_Monetary_Fund",
                "/wiki/Eurostat",
                "/wiki/Bureau_of_Economic_Analysis",
                "/wiki/Per_capita",
                "/wiki/GDP",
                "/wiki/Gross_fixed_capital_formation"
            ],
            "desc_text": "b'Fixed investment in economics refers to investment in fixed capital or to the replacement of depreciated fixed capital.\\n'b'Thus, fixed investment is investment in physical assets such as  machinery, land, buildings, installations, vehicles, or technology. Normally, a company balance sheet will state both the amount of expenditure on fixed assets during the quarter or year, and the total value of the stock of fixed assets owned.\\n'b'Fixed investment contrasts with investments in labour, ongoing operating expenses, materials or financial assets. Financial assets may also be held for a fixed term (for example, bonds) but they are not usually called \"fixed investment\" because they do not involve the purchase of physical fixed assets. The more usual term for such financial investments is \"fixed-term investments\". Bank deposits committed for a fixed term such as one or two years in a savings account are similarly called \"fixed-term deposits\".\\n'b'Statistical measures of fixed investment, such as provided by the Bureau of Economic Analysis in the United States, Eurostat in Europe, and other national and international statistical offices (e.g., the International Monetary Fund), are often considered by economists to be important indicators of longer-term economic growth (the growth of output and employment) and potential productivity.\\n'b'The more fixed capital is used per worker, the more productive the worker can be, other things being equal. For example, a worker who tills the soil only with a spade is normally less productive than a worker who uses a tractor-driven plough to do the same work, because with a tractor one can plough more land in less time, and thus produce more in less time, even if a tractor costs more than a spade. Obviously one would not normally use a tractor to plough a small garden, but in large-scale farming the income earned using a tractor by far outweighs the expense of using a tractor. It is not economical to use a spade for large-scale ploughing, unless the labour is extremely cheap, and the supply of labour is plentiful.\\n'b'The level of fixed investment by businesses also indicates something about the level of confidence that business owners or managers have about the ability to earn more income from sales in the next few years. The reasoning is that they would be unlikely to tie up additional capital in fixed assets for several years or more, unless they thought it would be a commercially viable proposition in the longer term. If there is too much uncertainty about whether their fixed investment will pay off, they are unlikely to engage in it.\\n'b'In recent decades, the growth rate of fixed investment in the US, Europe and Japan was relatively low, but in China for example it is relatively high. Often the relativities are expressed as a ratio between gross fixed capital formation and GDP, or fixed investment per worker employed or per capita.\\n'",
            "links": [
                "/wiki/Depreciation",
                "/wiki/Fixed_capital",
                "/wiki/Economics",
                "/wiki/Bond_(finance)",
                "/wiki/Productivity",
                "/wiki/International_Monetary_Fund",
                "/wiki/Eurostat",
                "/wiki/Bureau_of_Economic_Analysis",
                "/wiki/Per_capita",
                "/wiki/GDP",
                "/wiki/Gross_fixed_capital_formation",
                "/wiki/Stock_and_flow",
                "/wiki/Accounting",
                "/wiki/Gross_fixed_capital_formation",
                "/wiki/Consumption_of_fixed_capital",
                "/wiki/Depreciation",
                "/wiki/Fixed_capital",
                "/wiki/Intermediate_consumption",
                "/wiki/Marginal_cost_of_capital",
                "/wiki/Marginal_product_of_capital",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Tobin%27s_q"
            ],
            "text": "Another theory of fixed investment determination is based on Tobin's q, the ratio of the market value to the acquisition cost of an additional unit of physical capital; investment is hypothesized to be an increasing function of this ratio.[citation needed]\nOne theory of the determination of fixed investment focuses on the discrepancy between the current quantity of the fixed capital stock and the optimal or target capital stock.[citation needed]  The target capital stock\u2014the level at which a firm's profits would be highest if actual fixed capital holdings equaled that level\u2014is determined as the level at which the marginal product of capital equals the marginal cost of capital.  Then the flow of net investment per unit of time is determined by balancing losses from having a less-than-optimal level of capital with the adjustment costs of installing new capital; these adjustment costs in per-unit terms may be an increasing function of the speed of installation.\nIn official statistics, various accounting conventions are adopted to deal with these problems in a standardized way. A further complication is that scrapped fixed assets, being second-hand goods, may be resold and re-used again (for example, second-hand vehicles).\nFor statistical purposes, investment in fixed capital must be distinguished from investment in intermediate goods. Unlike fixed assets, intermediate goods (for example, commodities like oil, electricity, timber, steel and grain) are completely used up in production (usually within a year). But this distinction is not always easy to draw, for example:\nThe concept of \"gross fixed capital formation\" (GFCF) used in official statistics however does not refer to total fixed investment in a country.\nIn official statistics, attempts are often made to estimate the value of fixed capital assets in a nation, the value of their depreciation (or Consumption of fixed capital) and the value of Gross fixed capital formation by sector and type of asset. Fixed assets depreciate in value over time, due to wear and tear and market obsolescence. At the end of their useful lifetime (perhaps 7\u201310 years), they possess only a scrap-value (or at the very least must undergo maintenance work or repairs).\nThe amount of fixed investment may be stated \"gross\" (before taking into account depreciation) or \"net\" (after depreciation). By subtracting disposals of fixed assets from additions to fixed assets in an accounting period, we obtain a measure of the net (fixed) capital formation.\nThe term \"fixed investment\" may be somewhat ambiguous, because it could refer to the value of a stock of fixed assets being held at a balance date, or to the value of a flow of expenditures on fixed assets across an accounting interval, such as a year. The distinction is not always clearly stated in statistical tabulations\u2014they might refer either to the stock of capital tied up in fixed assets at a balance date, or to how much was spent on fixed equipment during a quarter or year.\nNormally, for the purpose of accounting, fixed investment refers to \"physical assets held for one year or more\". The investment capital is therefore \"fixed\", in the precise sense that the capital is tied up in physical assets for a longer time, and thus cannot be used for other purposes. This contrasts with, for example, investment capital in the form of liquid bank deposits earning interest, or investment in raw materials completely used up in (say) five weeks to produce products which, upon sale, earn income the following month.\nThe use of the term \"fixed\" does necessarily not mean the asset \"stays in one place\", i.e., it does not mean that it is physically immobile, but it refers rather to the circulation (rotation) of flows of capital.\nIn recent decades, the growth rate of fixed investment in the US, Europe and Japan was relatively low, but in China for example it is relatively high. Often the relativities are expressed as a ratio between gross fixed capital formation and GDP, or fixed investment per worker employed or per capita.\nThe level of fixed investment by businesses also indicates something about the level of confidence that business owners or managers have about the ability to earn more income from sales in the next few years. The reasoning is that they would be unlikely to tie up additional capital in fixed assets for several years or more, unless they thought it would be a commercially viable proposition in the longer term. If there is too much uncertainty about whether their fixed investment will pay off, they are unlikely to engage in it.\nThe more fixed capital is used per worker, the more productive the worker can be, other things being equal. For example, a worker who tills the soil only with a spade is normally less productive than a worker who uses a tractor-driven plough to do the same work, because with a tractor one can plough more land in less time, and thus produce more in less time, even if a tractor costs more than a spade. Obviously one would not normally use a tractor to plough a small garden, but in large-scale farming the income earned using a tractor by far outweighs the expense of using a tractor. It is not economical to use a spade for large-scale ploughing, unless the labour is extremely cheap, and the supply of labour is plentiful.\nStatistical measures of fixed investment, such as provided by the Bureau of Economic Analysis in the United States, Eurostat in Europe, and other national and international statistical offices (e.g., the International Monetary Fund), are often considered by economists to be important indicators of longer-term economic growth (the growth of output and employment) and potential productivity.\nFixed investment contrasts with investments in labour, ongoing operating expenses, materials or financial assets. Financial assets may also be held for a fixed term (for example, bonds) but they are not usually called \"fixed investment\" because they do not involve the purchase of physical fixed assets. The more usual term for such financial investments is \"fixed-term investments\". Bank deposits committed for a fixed term such as one or two years in a savings account are similarly called \"fixed-term deposits\".\nThus, fixed investment is investment in physical assets such as  machinery, land, buildings, installations, vehicles, or technology. Normally, a company balance sheet will state both the amount of expenditure on fixed assets during the quarter or year, and the total value of the stock of fixed assets owned.\nFixed investment in economics refers to investment in fixed capital or to the replacement of depreciated fixed capital.\n",
            "title": "Fixed investment",
            "url": "https://en.wikipedia.org/wiki/Fixed_investment"
        },
        {
            "desc_links": [
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Goods_and_services",
                "/wiki/Marketing",
                "/wiki/Consumer_choice",
                "/wiki/Intermediate_consumption",
                "/wiki/Fixed_investment",
                "/wiki/Service_(economics)",
                "/wiki/Good_(economics)",
                "/wiki/Mainstream_economics",
                "/wiki/Production_(economics)"
            ],
            "desc_text": "b'Consumption is a major concept in economics and is also studied in many other social sciences.\\n'b'Economists are particularly interested in the relationship between consumption and income, as modeled with the consumption function.\\n'b'Different schools of economists define production and consumption differently. According to mainstream economists, only the final purchase of goods and services by individuals constitutes consumption, while other types of expenditure \\xe2\\x80\\x94 in particular, fixed investment, intermediate consumption, and government spending \\xe2\\x80\\x94 are placed in separate categories (See consumer choice). Other economists define consumption much more broadly, as the aggregate of all economic activity that does not entail the design, production and marketing of goods and services (e.g. the selection, adoption, use, disposal and recycling of goods and services).[citation needed]\\n'",
            "links": [
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Goods_and_services",
                "/wiki/Marketing",
                "/wiki/Consumer_choice",
                "/wiki/Intermediate_consumption",
                "/wiki/Fixed_investment",
                "/wiki/Service_(economics)",
                "/wiki/Good_(economics)",
                "/wiki/Mainstream_economics",
                "/wiki/Production_(economics)",
                "/wiki/Behavioral_economics",
                "/wiki/Life_cycle_hypothesis",
                "/wiki/Franco_Modigliani",
                "/wiki/Permanent_income_hypothesis",
                "/wiki/Milton_Friedman",
                "/wiki/Absolute_income_hypothesis",
                "/wiki/Consumption_function",
                "/wiki/Aggregate_demand",
                "/wiki/New_Home_Economics",
                "/wiki/Economics",
                "/wiki/Production_theory_basics",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Goods_and_services",
                "/wiki/Marketing",
                "/wiki/Consumer_choice",
                "/wiki/Intermediate_consumption",
                "/wiki/Fixed_investment",
                "/wiki/Service_(economics)",
                "/wiki/Good_(economics)",
                "/wiki/Mainstream_economics",
                "/wiki/Production_(economics)",
                "/wiki/Energy_economics",
                "/wiki/Energy",
                "/wiki/Children",
                "/wiki/Generation",
                "/wiki/Property",
                "/wiki/Cars",
                "/wiki/Travel",
                "/wiki/Money",
                "/wiki/Western_culture",
                "/wiki/Retire",
                "/wiki/Annie_Hulley"
            ],
            "text": "Die Broke (from the book Die Broke: A Radical Four-Part Financial Plan by Stephen Pollan and Mark Levine) is a similar idea.\nSpending the Kids' Inheritance (originally the title of a book on the subject by Annie Hulley) and the acronyms SKI and SKI'ing refer to the growing number of older people in Western society spending their money on travel, cars and property, in contrast to previous generations who tended to leave that money to their children.\nConsumption can also be measured by a variety of different ways such as energy in energy economics metrics.\nDifferent schools of economists define production and consumption differently. According to mainstream economists, only the final purchase of goods and services by individuals constitutes consumption, while other types of expenditure \u2014 in particular, fixed investment, intermediate consumption, and government spending \u2014 are placed in separate categories (See consumer choice). Other economists define consumption much more broadly, as the aggregate of all economic activity that does not entail the design, production and marketing of goods and services (e.g. the selection, adoption, use, disposal and recycling of goods and services).[citation needed]\nConsumption is defined in part by comparison to production.\nIn the tradition of the Columbia School of Household Economics, also known as the New Home Economics, commercial consumption has to be analyzed in the context of household production. The opportunity cost of time affects the cost of home-produced substitutes and therefore demand for commercial goods and services.[3][4] The elasticity of demand for consumption goods is also a function of who performs chores in households and how their spouses compensate them for opportunity costs of home production.[5]\nAggregate consumption is a component of aggregate demand.[2]\nThe Keynesian consumption function is also known as the absolute income hypothesis, as it only bases consumption on current income and ignores potential future income (or lack of).  Criticism of this assumption led to the development of Milton Friedman's permanent income hypothesis and Franco Modigliani's life cycle hypothesis. More recent theoretical approaches are based on behavioral economics and suggest that a number of behavioural principles can be taken as microeconomic foundations for a behaviourally-based aggregate consumption function.[1]\nDifferent schools of economists define production and consumption differently. According to mainstream economists, only the final purchase of goods and services by individuals constitutes consumption, while other types of expenditure \u2014 in particular, fixed investment, intermediate consumption, and government spending \u2014 are placed in separate categories (See consumer choice). Other economists define consumption much more broadly, as the aggregate of all economic activity that does not entail the design, production and marketing of goods and services (e.g. the selection, adoption, use, disposal and recycling of goods and services).[citation needed]\nEconomists are particularly interested in the relationship between consumption and income, as modeled with the consumption function.\nConsumption is a major concept in economics and is also studied in many other social sciences.\n",
            "title": "Consumption (economics)",
            "url": "https://en.wikipedia.org/wiki/Consumption_(economics)"
        },
        {
            "desc_links": [
                "/wiki/Goods_and_services",
                "/wiki/Consumption_(economics)",
                "/wiki/Distribution_(economics)",
                "/wiki/Production_(economics)",
                "/wiki/Social_science",
                "/wiki/Help:IPA/English",
                "/wiki/Glossary_of_economics",
                "/wiki/Macroeconomics",
                "/wiki/Markets",
                "/wiki/Microeconomics",
                "/wiki/Economy",
                "/wiki/Agent_(economics)",
                "/wiki/Heterodox_economics",
                "/wiki/Mainstream_economics",
                "/wiki/Behavioural_economics",
                "/wiki/Rational_choice_theory",
                "/wiki/Applied_economics",
                "/wiki/Normative_economics",
                "/wiki/Positive_economics"
            ],
            "desc_text": "b'\\n\\n'b'Economics (/\\xc9\\x9bk\\xc9\\x99\\xcb\\x88n\\xc9\\x92m\\xc9\\xaaks, i\\xcb\\x90k\\xc9\\x99-/)[1][2][3] is the social science that studies the production, distribution, and consumption of goods and services.[4]\\n'b'Economics focuses on the behaviour and interactions of economic agents and how economies work. Microeconomics analyzes basic elements in the economy, including individual agents and markets, their interactions, and the outcomes of interactions. Individual agents may include, for example, households, firms, buyers, and sellers. Macroeconomics analyzes the entire economy (meaning aggregated production, consumption, savings, and investment) and issues affecting it, including unemployment of resources (labour, capital, and land), inflation, economic growth, and the public policies that address these issues (monetary, fiscal, and other policies).  See glossary of economics.\\n'b'Other broad distinctions within economics include those between positive economics, describing \"what is\", and normative economics, advocating \"what ought to be\"; between economic theory and applied economics; between rational and behavioural economics; and between mainstream economics and heterodox economics.[5]\\n'",
            "links": [
                "/wiki/Goods_and_services",
                "/wiki/Consumption_(economics)",
                "/wiki/Distribution_(economics)",
                "/wiki/Production_(economics)",
                "/wiki/Social_science",
                "/wiki/Help:IPA/English",
                "/wiki/Glossary_of_economics",
                "/wiki/Macroeconomics",
                "/wiki/Markets",
                "/wiki/Microeconomics",
                "/wiki/Economy",
                "/wiki/Agent_(economics)",
                "/wiki/Heterodox_economics",
                "/wiki/Mainstream_economics",
                "/wiki/Behavioural_economics",
                "/wiki/Rational_choice_theory",
                "/wiki/Applied_economics",
                "/wiki/Normative_economics",
                "/wiki/Positive_economics",
                "/wiki/Political_economy",
                "/wiki/Alfred_Marshall",
                "/wiki/Green_economics",
                "/wiki/Economics_of_science",
                "/wiki/Institutional_economics",
                "/wiki/Economics_of_religion",
                "/wiki/Public_choice",
                "/wiki/Law_and_economics",
                "/wiki/Family_economics",
                "/wiki/Education_economics",
                "/wiki/Health_economics",
                "/wiki/Financial_economics",
                "/wiki/Business_economics",
                "/wiki/Political_economy",
                "/wiki/Adam_Smith",
                "/wiki/Scottish_people",
                "/wiki/Definitions_of_economics",
                "/wiki/John_Stuart_Mill",
                "/wiki/Malthus",
                "/wiki/Classical_economics",
                "/wiki/Epithet#Alternative_contemporary_usage",
                "/wiki/The_dismal_science",
                "/wiki/Thomas_Carlyle",
                "/wiki/Satirical",
                "/wiki/Wealth",
                "/wiki/Public_policy",
                "/wiki/Jean-Baptiste_Say",
                "/wiki/Microeconomic",
                "/wiki/Societal",
                "/wiki/Economic_wealth",
                "/wiki/Principles_of_Economics_(Marshall)",
                "/wiki/Alfred_Marshall",
                "/wiki/Lionel_Robbins",
                "/wiki/Scarcity",
                "/wiki/Macroeconomics",
                "/wiki/Economic_imperialism_(economics)",
                "/wiki/Rational_choice",
                "/wiki/Social_interaction",
                "/wiki/Economic_equilibrium",
                "/wiki/Preference_(economics)",
                "/wiki/Gary_Becker",
                "/wiki/Service_(economics)",
                "/wiki/Product_(business)",
                "/wiki/Wikipedia:Please_clarify",
                "/wiki/Government_regulation",
                "/wiki/Market_system",
                "/wiki/Market_(economics)",
                "/wiki/Market_structure",
                "/wiki/Exogenous",
                "/wiki/Equity_(economics)",
                "/wiki/Economic_equilibrium",
                "/wiki/Aggregation_problem",
                "/wiki/Free_market",
                "/wiki/Imperfect_competition",
                "/wiki/Market_power",
                "/wiki/Perfect_competition",
                "/wiki/Oligopsony",
                "/wiki/Monopsony",
                "/wiki/Monopolistic_competition",
                "/wiki/Duopoly",
                "/wiki/Monopoly",
                "/wiki/General_equilibrium",
                "/wiki/Supply_and_demand",
                "/wiki/Guns_versus_butter_model",
                "/wiki/Private_good",
                "/wiki/Public_good",
                "/wiki/Investment#In_economics_or_macroeconomics",
                "/wiki/Consumption_(economics)",
                "/wiki/Stock_and_flow",
                "/wiki/Trade",
                "/wiki/Good_(economics)",
                "/wiki/Output_(economics)",
                "/wiki/Factor_of_production",
                "/wiki/Production_(economics)",
                "/wiki/Utility",
                "/wiki/Leisure",
                "/wiki/Production-possibility_frontier#Opportunity_cost",
                "/wiki/Real_versus_nominal_value_(economics)",
                "/wiki/Choice",
                "/wiki/Scarcity",
                "/wiki/Mutually_exclusive",
                "/wiki/Economic_cost",
                "/wiki/Opportunity_cost",
                "/wiki/Intermediate_good",
                "/wiki/Land_(economics)",
                "/wiki/Capital_(economics)",
                "/wiki/Labour_(economics)",
                "/wiki/Factors_of_production",
                "/wiki/Pareto_efficiency",
                "/wiki/Technology",
                "/wiki/Economic_efficiency",
                "/wiki/Potential_output",
                "/wiki/Economy",
                "/wiki/Production%E2%80%93possibility_frontier",
                "/wiki/Inverse_relationship",
                "/wiki/Scarcity",
                "/wiki/Utility",
                "/wiki/Market_economy",
                "/wiki/Trade-off#Examples_from_common_life",
                "/wiki/Slope",
                "/wiki/Pareto_efficiency",
                "/wiki/Allocative_efficiency",
                "/wiki/Recession",
                "/wiki/Business_cycle",
                "/wiki/Unemployment",
                "/wiki/Productive_efficiency",
                "/wiki/Public_policy",
                "/wiki/Applied_economics",
                "/wiki/Comparative_advantage",
                "/wiki/Labor_force",
                "/wiki/Capital_(economics)",
                "/wiki/Human_capital",
                "/wiki/Stock_and_flow",
                "/wiki/Empirical",
                "/wiki/Absolute_advantage",
                "/wiki/Economies_of_agglomeration",
                "/wiki/Returns_to_scale",
                "/wiki/Land_(economics)",
                "/wiki/Capital_(economics)",
                "/wiki/Division_of_labour",
                "/wiki/Economy",
                "/wiki/Service_(economics)",
                "/wiki/Trade",
                "/wiki/Gains_from_trade",
                "/wiki/Mechanism_design",
                "/wiki/Invisible_hand",
                "/wiki/Production-possibility_frontier#Opportunity_cost",
                "/wiki/Price",
                "/wiki/Market_power",
                "/wiki/Perfect_competition",
                "/wiki/Microeconomics",
                "/wiki/Market_economy",
                "/wiki/Prices_and_quantities",
                "/wiki/Utility",
                "/wiki/Budget_constraint",
                "/wiki/Wealth_(economics)",
                "/wiki/Rational_choice_theory",
                "/wiki/Consumer_theory",
                "/wiki/Good_(economics_and_accounting)",
                "/wiki/Normal_good",
                "/wiki/Income_effect",
                "/wiki/Purchasing_power",
                "/wiki/Substitution_effect",
                "/wiki/Ceteris_paribus",
                "/wiki/Law_of_demand",
                "/wiki/Model_(economics)",
                "/wiki/Market_equilibrium",
                "/wiki/Perfect_competition",
                "/wiki/Marginal_cost",
                "/wiki/Marginal_utility",
                "/wiki/Price_elasticity_of_supply",
                "/wiki/Management",
                "/wiki/Long_run",
                "/wiki/Short_run",
                "/wiki/Marginal_cost",
                "/wiki/Marginal_revenue",
                "/wiki/Wealth_(economics)",
                "/wiki/Income#Meaning_in_economics_and_use_in_economic_theory",
                "/wiki/Marginalism",
                "/wiki/Human_capital",
                "/wiki/Labour_mobility",
                "/wiki/Labour_economics",
                "/wiki/Labour_economics#Neoclassical_microeconomic_model_\u2014_Demand",
                "/wiki/Labour_market",
                "/wiki/Factors_of_production",
                "/wiki/Distribution_(economics)",
                "/wiki/Applied_economics",
                "/wiki/Qualitative_economics",
                "/wiki/Macroeconomics",
                "/wiki/Price_level",
                "/wiki/Real_GDP",
                "/wiki/Economy",
                "/wiki/Economies_of_scale",
                "/wiki/Ronald_Coase",
                "/wiki/Trusts",
                "/wiki/Partnerships",
                "/wiki/Corporation",
                "/wiki/Industrial_organization",
                "/wiki/Perfect_competition",
                "/wiki/Optimization_(mathematics)",
                "/wiki/Regression_analysis",
                "/wiki/Operations_research",
                "/wiki/Microeconomic",
                "/wiki/Managerial_economics",
                "/wiki/Communication",
                "/wiki/Financial_instrument",
                "/wiki/Capital_market",
                "/wiki/Financial_market",
                "/wiki/Risk#Risk_versus_uncertainty",
                "/wiki/Uncertainty",
                "/wiki/Agent_(economics)",
                "/wiki/Behavioural_economics",
                "/wiki/Contract_theory",
                "/wiki/Bargaining#Game_theory",
                "/wiki/Industrial_organization",
                "/wiki/Microfoundation",
                "/wiki/Strategy#Strategies_in_game_theory",
                "/wiki/Applied_mathematics",
                "/wiki/Game_theory",
                "/wiki/Evolutionary_biology",
                "/wiki/Game_theory#Political_science",
                "/wiki/Game_theory#Philosophy",
                "/wiki/Nuclear_strategies",
                "/wiki/Oskar_Morgenstern",
                "/wiki/John_von_Neumann",
                "/wiki/Theory_of_Games_and_Economic_Behavior",
                "/wiki/Supply_and_demand",
                "/wiki/Financial_regulation",
                "/wiki/Financial_crisis",
                "/wiki/Financial_market",
                "/wiki/Capital_structure",
                "/wiki/Finance",
                "/wiki/Financial_economics",
                "/wiki/Financial_instruments",
                "/wiki/Futures_market",
                "/wiki/Insurance",
                "/wiki/Risk_aversion",
                "/wiki/Moral_hazard",
                "/wiki/Adverse_selection",
                "/wiki/Information_asymmetry",
                "/wiki/Paradigm",
                "/wiki/Market_for_Lemons",
                "/wiki/George_Akerlof",
                "/wiki/Regulatory_economics",
                "/wiki/Bankruptcy_law",
                "/wiki/Restructuring",
                "/wiki/Health_economics",
                "/wiki/Monetary_economics",
                "/wiki/Mechanism_design",
                "/wiki/Contract_theory",
                "/wiki/Information_economics",
                "/wiki/Incomplete_markets",
                "/wiki/Market_failure",
                "/wiki/Incomplete_markets",
                "/wiki/Information_asymmetries",
                "/wiki/Economies_of_scale",
                "/wiki/Natural_monopoly",
                "/wiki/Public_goods",
                "/wiki/Distortions_(economics)",
                "/wiki/Externalities",
                "/wiki/Perfect_competition",
                "/wiki/Imperfect_competition",
                "/wiki/Macroeconomics",
                "/wiki/Business_cycle",
                "/wiki/Price_stickiness",
                "/wiki/Public_bad",
                "/wiki/Environmental_economics",
                "/wiki/Economics_of_the_public_sector",
                "/wiki/Emissions_trading",
                "/wiki/Cost-benefit_analysis",
                "/wiki/Policy",
                "/wiki/Public_choice_theory",
                "/wiki/Income_distribution",
                "/wiki/Economic_efficiency",
                "/wiki/Tax_incidence",
                "/wiki/Public_sector",
                "/wiki/Budget",
                "/wiki/Normative_economics",
                "/wiki/Positive_economics",
                "/wiki/Social_welfare",
                "/wiki/Distribution_(economics)",
                "/wiki/Allocative_efficiency",
                "/wiki/Microeconomics",
                "/wiki/Fiscal_policy",
                "/wiki/Monetary_policy",
                "/wiki/Inflation",
                "/wiki/Unemployment_rate",
                "/wiki/Measures_of_national_income_and_output",
                "/wiki/General_equilibrium",
                "/wiki/Imperfect_competition",
                "/wiki/Efficient_market_hypothesis",
                "/wiki/Rational_expectations",
                "/wiki/Microfoundations",
                "/wiki/Labour_force",
                "/wiki/Technological_progress",
                "/wiki/Economic_growth",
                "/wiki/Catch-up_effect",
                "/wiki/Per_capita",
                "/wiki/Economic_growth",
                "/wiki/Growth_accounting",
                "/wiki/Endogenous_growth_model",
                "/wiki/Neoclassical_growth_model",
                "/wiki/Empirical",
                "/wiki/Technological_progress",
                "/wiki/Population_growth",
                "/wiki/Investment_(macroeconomics)",
                "/wiki/Aggregate_demand",
                "/wiki/Keynesian_economics",
                "/wiki/The_General_Theory_of_Employment,_Interest_and_Money",
                "/wiki/John_Maynard_Keynes",
                "/wiki/Great_Depression",
                "/wiki/IS/LM",
                "/wiki/John_Hicks",
                "/wiki/Full_employment",
                "/wiki/Business_cycle",
                "/wiki/Fiscal_policy",
                "/wiki/Central_bank",
                "/wiki/Monetary_policy",
                "/wiki/Public_sector",
                "/wiki/Long_run",
                "/wiki/Short_run",
                "/wiki/Neoclassical_economics",
                "/wiki/Neoclassical_synthesis",
                "/wiki/Research_program",
                "/wiki/Business_cycle",
                "/wiki/Real_business_cycle_theory",
                "/wiki/Robert_Lucas,_Jr.",
                "/wiki/Rational_expectations",
                "/wiki/Permanent_income_hypothesis",
                "/wiki/Imperfect_information",
                "/wiki/Market_clearing",
                "/wiki/New_classical_macroeconomics",
                "/wiki/Sticky_(economics)",
                "/wiki/Market_failures",
                "/wiki/New_Keynesian_economics",
                "/wiki/Discouraged_worker",
                "/wiki/Structural_unemployment",
                "/wiki/Okun%27s_law",
                "/wiki/Francis_Amasa_Walker",
                "/wiki/Unit_of_account",
                "/wiki/Price_system",
                "/wiki/Money",
                "/wiki/Transaction_cost",
                "/wiki/Double_coincidence_of_wants",
                "/wiki/Barter",
                "/wiki/Medium_of_exchange",
                "/wiki/Monetary_policy",
                "/wiki/Money_supply",
                "/wiki/Price_level",
                "/wiki/Nominal_value",
                "/wiki/Money_supply",
                "/wiki/Positive_relationship",
                "/wiki/Quantity_theory_of_money",
                "/wiki/Economy",
                "/wiki/Output_gap",
                "/wiki/Fiscal_multiplier",
                "/wiki/Crowding_out_(economics)",
                "/wiki/Ricardian_equivalence",
                "/wiki/Globalization",
                "/wiki/Exchange_rate",
                "/wiki/International_finance",
                "/wiki/Tariff",
                "/wiki/Gains_from_trade",
                "/wiki/Economic_growth",
                "/wiki/Poverty",
                "/wiki/Structural_change",
                "/wiki/Developing_countries",
                "/wiki/Economic_development",
                "/wiki/Development_economics",
                "/wiki/Institutions",
                "/wiki/JEL_classification_codes#Economic_systems_JEL:_P_Subcategories",
                "/wiki/Comparative_economic_systems",
                "/wiki/Political_economy#Current_approaches",
                "/wiki/Mixed_economies",
                "/wiki/Capitalism",
                "/wiki/Planned_economy",
                "/wiki/Wikipedia:Manual_of_Style/Dates_and_numbers#Chronological_items",
                "/wiki/Economy_of_Laos",
                "/wiki/Economy_of_North_Korea",
                "/wiki/Economy_of_Cuba",
                "/wiki/Planned_economy",
                "/wiki/Computer_science",
                "/wiki/Game_theory",
                "/wiki/Statistics",
                "/wiki/Linear_algebra",
                "/wiki/Calculus",
                "/wiki/Heterodox_economics",
                "/wiki/Schools_of_economic_thought",
                "/wiki/General_equilibrium_theory",
                "/wiki/Neoclassical_economics",
                "/wiki/Ceteris_paribus",
                "/wiki/Model_(economics)",
                "/wiki/Microfoundations",
                "/wiki/New_Keynesian",
                "/wiki/Macroeconomic",
                "/wiki/Theory_of_the_firm",
                "/wiki/Utility",
                "/wiki/Budget_constraint",
                "/wiki/Opportunity_cost",
                "/wiki/Rational_choice_theory",
                "/wiki/Marginalism",
                "/wiki/Supply_and_demand",
                "/wiki/Microeconomics",
                "/wiki/Qualitative_economics",
                "/wiki/Four_Asian_Tigers",
                "/wiki/Development_economics",
                "/wiki/Rational_expectations",
                "/wiki/Inflation",
                "/wiki/Money_supply",
                "/wiki/Quantity_theory_of_money",
                "/wiki/Monetary_theory",
                "/wiki/Theorem",
                "/wiki/Foundations_of_Economic_Analysis",
                "/wiki/Paul_Samuelson",
                "/wiki/Natural_experiments",
                "/wiki/Experimental_economics",
                "/wiki/Observational_study",
                "/wiki/Physical_science",
                "/wiki/Economic_data",
                "/wiki/Econometrics",
                "/wiki/Empirical",
                "/wiki/Data_set",
                "/wiki/Falsifiability",
                "/wiki/Statistical_significance",
                "/wiki/Regression_analysis",
                "/wiki/Statistics",
                "/wiki/American_Economic_Review",
                "/wiki/Replication_(statistics)",
                "/wiki/Linear_programming",
                "/wiki/Input-output_model",
                "/wiki/Ultimatum_game",
                "/wiki/Natural_science",
                "/wiki/Experiment",
                "/wiki/Scientific_control",
                "/wiki/Experimental_economics",
                "/wiki/Neuroeconomics",
                "/wiki/Heuristics_in_judgment_and_decision_making",
                "/wiki/Cognitive_bias",
                "/wiki/Amos_Tversky",
                "/wiki/Nobel_Memorial_Prize_in_Economic_Sciences",
                "/wiki/Daniel_Kahneman",
                "/wiki/Behavioural_economics",
                "/wiki/Liberal_arts",
                "/wiki/Academic_degrees",
                "/wiki/Universities",
                "/wiki/Bureau_of_Statistics",
                "/wiki/Central_Bank",
                "/wiki/Treasury",
                "/wiki/Finance",
                "/wiki/Banking",
                "/wiki/Nobel_Memorial_Prize_in_Economic_Sciences",
                "/wiki/Institutional_economics",
                "/wiki/Family_economics",
                "/wiki/JEL_classification_codes#Other_special_topics_(economics)_JEL:_Z_Subcategories",
                "/wiki/Energy_economics",
                "/wiki/Public_choice",
                "/wiki/Economic_history",
                "/wiki/Economic_geography",
                "/wiki/Social_science",
                "/wiki/Externalities",
                "/wiki/Ronald_Coase",
                "/wiki/Economic_efficiency",
                "/wiki/Historian",
                "/wiki/Externalities",
                "/wiki/Rent-seeking",
                "/wiki/Socialist",
                "/wiki/Political_science",
                "/wiki/Political_economy",
                "/wiki/Evolutionary_economics",
                "/wiki/Ecological_economics",
                "/wiki/Thermoeconomics",
                "/wiki/Thermodynamics",
                "/wiki/Entropy",
                "/wiki/Georgescu-Roegen",
                "/wiki/Energy_demand",
                "/wiki/Energy_supply",
                "/wiki/Science",
                "/wiki/Energy_economics",
                "/wiki/Richard_Swedberg",
                "/wiki/Peter_Hedstrom",
                "/wiki/Mark_Granovetter",
                "/wiki/The_Philosophy_of_Money",
                "/wiki/Georg_Simmel",
                "/wiki/The_Protestant_Ethic_and_the_Spirit_of_Capitalism",
                "/wiki/Max_Weber",
                "/wiki/Modernity",
                "/wiki/Georg_Simmel",
                "/wiki/Max_Weber",
                "/wiki/%C3%89mile_Durkheim",
                "/wiki/Economic_sociology",
                "/wiki/Sociological",
                "/wiki/Wikipedia:Verifiability",
                "/wiki/Natural_law",
                "/wiki/Microeconomics",
                "/wiki/Monetary_economics",
                "/wiki/Joseph_Schumpeter",
                "/wiki/Ibn_Khaldun",
                "/wiki/Thomas_Aquinas",
                "/wiki/Qin_Shi_Huang",
                "/wiki/Chanakya",
                "/wiki/Oeconomicus",
                "/wiki/Aristotle",
                "/wiki/Renaissance",
                "/wiki/Classical_antiquity",
                "/wiki/Hesiod",
                "/wiki/Boeotia",
                "/wiki/Arab_world",
                "/wiki/Achaemenid_Empire",
                "/wiki/China",
                "/wiki/History_of_India",
                "/wiki/Ancient_Rome",
                "/wiki/Ancient_Greece",
                "/wiki/Mesopotamia",
                "/wiki/Mercantilism",
                "/wiki/History_of_capitalism#Merchant_capitalism_and_mercantilism",
                "/wiki/Economic_nationalism",
                "/wiki/Laissez-faire",
                "/wiki/Circular_flow",
                "/wiki/Physiocrats",
                "/wiki/The_Wealth_of_Nations",
                "/wiki/Economic_equilibrium",
                "/wiki/Competition_(economics)",
                "/wiki/Allocation_of_resources",
                "/wiki/Industrial_organization",
                "/wiki/Theory_of_the_firm",
                "/wiki/Gains_from_trade",
                "/wiki/Labour_productivity",
                "/wiki/Division_of_labour",
                "/wiki/Julian_Lincoln_Simon",
                "/wiki/Human_population",
                "/wiki/Diminishing_returns",
                "/wiki/Thomas_Robert_Malthus",
                "/wiki/Reverend",
                "/wiki/Gains_from_trade",
                "/wiki/Comparative_advantage",
                "/wiki/David_Ricardo",
                "/wiki/Steady-state_economy#The_stationary_state_in_classical_economics",
                "/wiki/Labour_theory_of_value#The_theory's_development",
                "/wiki/Theory_of_surplus_value",
                "/wiki/Labour_theory_of_value",
                "/wiki/Das_Kapital",
                "/wiki/Karl_Marx",
                "/wiki/An_Essay_on_the_Nature_and_Significance_of_Economic_Science",
                "/wiki/Lionel_Robbins,_Baron_Robbins",
                "/wiki/Natural_science",
                "/wiki/Political_economy",
                "/wiki/Alfred_Marshall",
                "/wiki/Marginalist_Revolution",
                "/wiki/Ordinal_utility",
                "/wiki/Marginal_utility",
                "/wiki/Labour_theory_of_value",
                "/wiki/Supply_and_demand",
                "/wiki/Neoclassical_synthesis",
                "/wiki/Macroeconomics",
                "/wiki/Consumer_theory",
                "/wiki/Decision_making",
                "/wiki/Microeconomics",
                "/wiki/National_income",
                "/wiki/Economic_growth",
                "/wiki/Neoclassical_model",
                "/wiki/Imperfect_competition",
                "/wiki/Market_failure",
                "/wiki/Game_theory",
                "/wiki/Econometrics",
                "/wiki/Mainstream_economics",
                "/wiki/Decision_theory",
                "/wiki/Scarcity",
                "/wiki/Organization",
                "/wiki/Household",
                "/wiki/Individual",
                "/wiki/Effective_demand",
                "/wiki/Macroeconomics",
                "/wiki/The_General_Theory_of_Employment,_Interest_and_Money",
                "/wiki/John_Maynard_Keynes",
                "/wiki/Joan_Robinson",
                "/wiki/University_of_Cambridge",
                "/wiki/Post-Keynesian_economics",
                "/wiki/New-Keynesian_economics",
                "/wiki/Ben_Bernanke",
                "/wiki/Milton_Friedman",
                "/wiki/Monetarist",
                "/wiki/West_coast_of_the_United_States",
                "/wiki/East_Coast_of_the_United_States",
                "/wiki/Mainstream_economics",
                "/wiki/Stockholm_school_(economics)",
                "/wiki/Post-Keynesian_economics",
                "/wiki/School_of_Lausanne",
                "/wiki/Freiburg_School",
                "/wiki/Austrian_School",
                "/wiki/Biophysical_economics",
                "/wiki/Feminist_economics",
                "/wiki/Econophysics",
                "/wiki/World_systems_theory",
                "/wiki/Structuralist_economics",
                "/wiki/Dependency_theory",
                "/wiki/Evolutionary_economics",
                "/wiki/Institutional_economics",
                "/wiki/Constitutional_economics",
                "/wiki/Ecological_economics",
                "/wiki/Supply-side_economics",
                "/wiki/New_classical_economics",
                "/wiki/Monetarism",
                "/wiki/Post-Keynesian_economics",
                "/wiki/Keynesian_economics",
                "/wiki/Classical_economics",
                "/wiki/American_Economic_Association",
                "/wiki/Slavery",
                "/wiki/Victorian_era",
                "/wiki/The_dismal_science",
                "/wiki/L%C3%A9on_Walras",
                "/wiki/Trade_union",
                "/wiki/Special_interests",
                "/wiki/Political_faction",
                "/wiki/Politics",
                "/wiki/Value_systems",
                "/wiki/Political_agenda",
                "/wiki/Rhetoric",
                "/wiki/Policymaker",
                "/wiki/American_Economic_Association",
                "/wiki/Herman_Daly",
                "/wiki/Steady-state_economy#Herman_Daly's_concept_of_a_steady-state_economy",
                "/wiki/Ecological_economics",
                "/wiki/State_(polity)",
                "/wiki/Fiscal_policy",
                "/wiki/Monetary_policy",
                "/wiki/Macroeconomic_policy",
                "/wiki/Central_bank",
                "/wiki/McCloskey_critique",
                "/wiki/Deirdre_McCloskey",
                "/wiki/Consensus_Economics",
                "/wiki/International_Monetary_Fund",
                "/wiki/Behavioural_psychology",
                "/wiki/Behavioural_economics",
                "/wiki/Information_economics",
                "/wiki/Rational_choice_theory",
                "/wiki/Profit_maximization",
                "/wiki/Perfect_information",
                "/wiki/Ex_post",
                "/wiki/Paul_Joskow",
                "/wiki/Financial_crisis_of_2007%E2%80%9308",
                "/wiki/Sustainability",
                "/wiki/National_accounts",
                "/wiki/Julie_A._Nelson",
                "/wiki/Nature",
                "/wiki/Women%27s_work",
                "/wiki/If_Women_Counted",
                "/wiki/Marilyn_Waring",
                "/wiki/Feminist_economics",
                "/wiki/Unpaid_work",
                "/wiki/Homo_economicus",
                "/wiki/Objectivity_(philosophy)",
                "/wiki/Positive_economics",
                "/wiki/Feminist_economics",
                "/wiki/Philip_Mirowski",
                "/wiki/John_McMurtry",
                "/wiki/Michael_Perelman#Books",
                "/wiki/Michael_Perelman#Books",
                "/wiki/Nobel_Memorial_Prize_in_Economics",
                "/wiki/Theory_of_Forms",
                "/wiki/Michael_Perelman",
                "/wiki/Nassim_Nicholas_Taleb"
            ],
            "text": "Despite these concerns, mainstream graduate programs have become increasingly technical and mathematical.[169]\nNassim Nicholas Taleb and Michael Perelman are two additional scholars who criticized conventional or mainstream economics. Taleb opposes most economic theorizing, which in his view suffers acutely from the problem of overuse of Plato's Theory of Forms, and calls for cancellation of the Nobel Memorial Prize in Economics, saying that the damage from economic theories can be devastating.[168]  Michael Perelman provides extensive criticism of economics and its assumptions in all his books (and especially his books published from 2000 to date), papers and interviews.\nIn a series of peer-reviewed journal and conference papers and books published over a period of several decades, John McMurtry has provided extensive criticism of what he terms the \"unexamined assumptions and implications [of economics], and their consequent cost to people's lives.\"[167][k]\nPhilip Mirowski observes that:\nIn recent years, feminist critiques of neoclassical economic models gained prominence, leading to the formation of feminist economics.[161] Contrary to common conceptions of economics as a positive and objective science, feminist economists call attention to the social construction of economics[162] and highlight the ways in which its models and methods reflect masculine preferences. Primary criticisms focus on failures to account for: the selfish nature of actors (homo economicus); exogenous tastes; the impossibility of utility comparisons; the exclusion of unpaid work; and the exclusion of class and gender considerations. Feminist economics developed to address these concerns, and the field now includes critical examinations of many areas of economics including paid and unpaid work, economic epistemology and history, globalization, household economics and the care economy. In 1988, Marilyn Waring published the book If Women Counted, in which she argues that the discipline of economics ignores women's unpaid work and the value of nature;[163] according to Julie A. Nelson, If Women Counted \"showed exactly how the unpaid work traditionally done by women has been made invisible within national accounting systems\" and \"issued a wake-up call to issues of ecological sustainability.\"[164] Bj\u00f8rnholt and McKay argue that the financial crisis of 2007\u201308 and the response to it revealed a crisis of ideas in mainstream economics and within the economics profession, and call for a reshaping of both the economy, economic theory and the economics profession. They argue that such a reshaping should include new advances within feminist economics that take as their starting point the socially responsible, sensible and accountable subject in creating an economy and economic theories that fully acknowledge care for each other as well as the planet.[165]\nNevertheless, prominent mainstream economists such as Keynes[159] and Joskow have observed that much of economics is conceptual rather than quantitative, and difficult to model and formalize quantitatively. In a discussion on oligopoly research, Paul Joskow pointed out in 1975 that in practice, serious students of actual economies tended to use \"informal models\" based upon qualitative factors specific to particular industries. Joskow had a strong feeling that the important work in oligopoly was done through informal observations while formal models were \"trotted out ex post\". He argued that formal models were largely not important in the empirical work, either, and that the fundamental factor behind the theory of the firm, behaviour, was neglected.[160]\nEconomics has been subject to criticism that it relies on unrealistic, unverifiable, or highly simplified assumptions, in some cases because these assumptions simplify the proofs of desired conclusions. Examples of such assumptions include perfect information, profit maximization and rational choices.[157] The field of information economics includes both mathematical-economical research and also behavioural economics, akin to studies in behavioural psychology.[158]\nA 2002 International Monetary Fund study assessed the national economic growth predictions from Consensus Forecasts in the 1990s. Of the 60 different national recessions that occurred, only 2 (3%) were predicted a year in advance.[156]\nDeirdre McCloskey has argued that many empirical economic studies are poorly reported, and she and Stephen Ziliak argue that although her critique has been well-received, practice has not improved.[154] This latter contention is controversial.[155]\nIssues like central bank independence, central bank policies and rhetoric in central bank governors discourse or the premises of macroeconomic policies[152] (monetary and fiscal policy) of the state, are focus of contention and criticism.[153]\nIn Steady State Economics 1977, leading ecological economist and steady-state theorist Herman Daly argues that there exist logical inconsistencies between the emphasis placed on economic growth and the limited availability of natural resources.[151]\nNotwithstanding, economics legitimately has a role in informing government policy. It is, indeed, in some ways an outgrowth of the older field of political economy. Some academic economic journals have increased their efforts to gauge the consensus of economists regarding certain policy issues in hopes of effecting a more informed political environment. Often there exists a low approval rate from professional economists regarding many public policies. Policy issues featured in one survey of American Economic Association economists include trade restrictions, social insurance for those put out of work by international competition, genetically modified foods, curbside recycling, health insurance (several questions), medical malpractice, barriers to entering the medical profession, organ donations, unhealthy foods, mortgage deductions, taxing internet sales, Wal-Mart, casinos, ethanol subsidies, and inflation targeting.[150]\nEconomics per se, as a social science, is independent of the political acts of any government or other decision-making organization; however, many policymakers or individuals holding highly ranked positions that can influence other people's lives are known for arbitrarily using a plethora of economic concepts and rhetoric as vehicles to legitimize agendas and value systems, and do not limit their remarks to matters relevant to their responsibilities.[147] The close relation of economic theory and practice with politics[148] is a focus of contention that may shade or distort the most unpretentious original tenets of economics, and is often confused with specific social agendas and value systems.[149]\nIn The Wealth of Nations, Adam Smith addressed many issues that are currently also the subject of debate and dispute. Smith repeatedly attacks groups of politically aligned individuals who attempt to use their collective influence to manipulate a government into doing their bidding. In Smith's day, these were referred to as factions, but are now more commonly called special interests, a term which can comprise international bankers, corporate conglomerations, outright oligopolies, monopolies, trade unions and other groups.[j]\nSome economists, like John Stuart Mill or L\u00e9on Walras, have maintained that the production of wealth should not be tied to its distribution.[146]\n\"The dismal science\" is a derogatory alternative name for economics devised by the Victorian historian Thomas Carlyle in the 19th century. It is often stated that Carlyle gave economics the nickname \"the dismal science\" as a response to the late 18th century writings of The Reverend Thomas Robert Malthus, who grimly predicted that starvation would result, as projected population growth exceeded the rate of increase in the food supply. However, the actual phrase was coined by Carlyle in the context of a debate with John Stuart Mill on slavery, in which Carlyle argued for slavery, while Mill opposed it.[20]\nAccording to various random and anonymous surveys of members of the American Economic Association, economists have agreement about the following propositions by percentage:>[141][142][143][144][145]\nWithin macroeconomics there is, in general order of their appearance in the literature; classical economics, Keynesian economics, the neoclassical synthesis, post-Keynesian economics, monetarism, new classical economics, and supply-side economics. Alternative developments include ecological economics, constitutional economics, institutional economics, evolutionary economics, dependency theory, structuralist economics, world systems theory, econophysics, feminist economics and biophysical economics.[140]\nOther well-known schools or trends of thought referring to a particular style of economics practised at and disseminated from well-defined groups of academicians that have become known worldwide, include the Austrian School, the Freiburg School, the School of Lausanne, post-Keynesian economics and the Stockholm school. Contemporary mainstream economics is sometimes separated into the Saltwater approach of those universities along the Eastern and Western coasts of the US, and the Freshwater, or Chicago-school approach.\nMilton Friedman effectively took many of the basic principles set forth by Adam Smith and the classical economists and modernized them. One example of this is his article in the 13 September 1970 issue of The New York Times Magazine, in which he claims that the social responsibility of business should be \"to use its resources and engage in activities designed to increase its profits\u00a0... (through) open and free competition without deception or fraud.\"[139]\nThe Chicago School of economics is best known for its free market advocacy and monetarist ideas. According to Milton Friedman and monetarists, market economies are inherently stable if the money supply does not greatly expand or contract. Ben Bernanke, former Chairman of the Federal Reserve, is among the economists today generally accepting Friedman's analysis of the causes of the Great Depression.[138]\nNew-Keynesian economics is also associated with developments in the Keynesian fashion. Within this group researchers tend to share with other economists the emphasis on models employing micro foundations and optimizing behaviour but with a narrower focus on standard Keynesian themes such as price and wage rigidity. These are usually made to be endogenous features of the models, rather than simply assumed as in older Keynesian-style ones.\nKeynesian economics has two successors. Post-Keynesian economics also concentrates on macroeconomic rigidities and adjustment processes. Research on micro foundations for their models is represented as based on real-life practices rather than simple optimizing models. It is generally associated with the University of Cambridge and the work of Joan Robinson.[137]\nKeynesian economics derives from John Maynard Keynes, in particular his book The General Theory of Employment, Interest and Money (1936), which ushered in contemporary macroeconomics as a distinct field.[135] The book focused on determinants of national income in the short run when prices are relatively inflexible. Keynes attempted to explain in broad theoretical detail why high labour-market unemployment might not be self-correcting due to low \"effective demand\" and why even price flexibility and monetary policy might be unavailing. The term \"revolutionary\" has been applied to the book in its impact on economic analysis.[136]\nThe continuous interplay (exchange or trade) done by economic actors in all markets sets the prices for all goods and services which, in turn, make the rational managing of scarce resources possible. At the same time, the decisions (choices) made by the same actors, while they are pursuing their own interest, determine the level of output (production), consumption, savings, and investment, in an economy, as well as the remuneration (distribution) paid to the owners of labour (in the form of wages), capital (in the form of profits) and land (in the form of rent).[h] Each period, as if they were in a giant feedback system, economic players influence the pricing processes and the economy, and are in turn influenced by them until a steady state (equilibrium) of all variables involved is reached or until an external shock throws the system toward a new equilibrium point. Because of the autonomous actions of rational interacting agents, the economy is a complex adaptive system.[i]\nAn approach to understanding these processes, through the study of agent behaviour under scarcity, may go as follows:\nNeoclassical economics studies the behaviour of individuals, households, and organizations (called economic actors, players, or agents), when they manage or use scarce resources, which have alternative uses, to achieve desired ends. Agents are assumed to act rationally, have multiple desirable ends in sight, limited resources to obtain these ends, a set of stable preferences, a definite overall guiding objective, and the capability of making a choice. There exists an economic problem, subject to study by economic science, when a decision (choice) is made by one or more resource-controlling players to attain the best possible outcome under bounded rational conditions. In other words, resource-controlling agents maximize value subject to the constraints imposed by the information the agents have, their cognitive limitations, and the finite amount of time they have to make and execute a decision. Economic science centres on the activities of the economic agents that comprise society.[134] They are the focus of economic analysis.[g]\nNeoclassical economics is occasionally referred as orthodox economics whether by its critics or sympathizers. Modern mainstream economics builds on neoclassical economics but with many refinements that either supplement or generalize earlier analysis, such as econometrics, game theory, analysis of market failure and imperfect competition, and the neoclassical model of economic growth for analysing long-run variables affecting national income.\nIn microeconomics, neoclassical economics represents incentives and costs as playing a pervasive role in shaping decision making. An immediate example of this is the consumer theory of individual demand, which isolates how prices (as costs) and income affect quantity demanded.[40] In macroeconomics it is reflected in an early and lasting neoclassical synthesis with Keynesian macroeconomics.[68][133]\nNeoclassical economics systematized supply and demand as joint determinants of price and quantity in market equilibrium, affecting both the allocation of output and the distribution of income. It dispensed with the labour theory of value inherited from classical economics in favour of a marginal utility theory of value on the demand side and a more general theory of costs on the supply side.[131] In the 20th century, neoclassical theorists moved away from an earlier notion suggesting that total utility for a society could be measured in favour of ordinal utility, which hypothesizes merely behaviour-based relations across persons.[40][132]\nA body of theory later termed \"neoclassical economics\" or \"marginalism\" formed from about 1870 to 1910. The term \"economics\" was popularized by such neoclassical economists as Alfred Marshall as a concise synonym for \"economic science\" and a substitute for the earlier \"political economy\".[8][9] This corresponded to the influence on the subject of mathematical methods used in the natural sciences.[130]\nCiting Robbins: \"Economics is the science which studies human behavior as a relationship between ends and scarce means which have alternative uses\".[24] After discussing it for decades, Robbins' definition became widely accepted by mainstream economists, and it has opened way into current textbooks.[128] Although far from unanimous, most mainstream economists would accept some version of Robbins' definition, even though many have raised serious objections to the scope and method of economics, emanating from that definition.[129] Due to the lack of strong consensus, and that production, distribution and consumption of goods and services is the prime area of study of economics, the old definition still stands in many quarters.\nAt the dawn as a social science, economics was defined and discussed at length as the study of production, distribution, and consumption of wealth by Jean-Baptiste Say in his Treatise on Political Economy or, The Production, Distribution, and Consumption of Wealth (1803). These three items are considered by the science only in relation to the increase or diminution of wealth, and not in reference to their processes of execution.[d] Say's definition has prevailed up to our time, saved by substituting the word \"wealth\" for \"goods and services\" meaning that wealth may include non-material objects as well. One hundred and thirty years later, Lionel Robbins noticed that this definition no longer sufficed,[e] because many economists were making theoretical and philosophical inroads in other areas of human activity. In his Essay on the Nature and Significance of Economic Science, he proposed a definition of economics as a study of a particular aspect of human behaviour, the one that falls under the influence of scarcity,[f] which forces people to choose, allocate scarce resources to competing ends, and economize (seeking the greatest welfare while avoiding the wasting of scarce resources). For Robbins, the insufficiency was solved, and his definition allows us to proclaim, with an easy conscience, education economics, safety and security economics, health economics, war economics, and of course, production, distribution and consumption economics as valid subjects of the economic science.\"\nMarxist (later, Marxian) economics descends from classical economics. It derives from the work of Karl Marx. The first volume of Marx's major work, Das Kapital, was published in German in 1867. In it, Marx focused on the labour theory of value and the theory of surplus value which, he believed, explained the exploitation of labour by capital.[127] The labour theory of value held that the value of an exchanged commodity was determined by the labour that went into its production and the theory of surplus value demonstrated how the workers only got paid a proportion of the value their work had created.[83]\nValue theory was important in classical theory. Smith wrote that the \"real price of every thing\u00a0... is the toil and trouble of acquiring it\". Smith maintained that, with rent and profit, other costs besides wages also enter the price of a commodity.[126] Other classical economists presented variations on Smith, termed the 'labour theory of value'. Classical economics focused on the tendency of any market economy to settle in a final stationary state made up of a constant stock of physical wealth (capital) and a constant population size.\nComing at the end of the classical tradition, John Stuart Mill (1848) parted company with the earlier classical economists on the inevitability of the distribution of income produced by the market system. Mill pointed to a distinct difference between the market's two roles: allocation of resources and distribution of income. The market might be efficient in allocating resources but not in distributing income, he wrote, making it necessary for society to intervene.[125]\nWhile Adam Smith emphasized the production of income, David Ricardo (1817) focused on the distribution of income among landowners, workers, and capitalists. Ricardo saw an inherent conflict between landowners on the one hand and labour and capital on the other. He posited that the growth of population and capital, pressing against a fixed supply of land, pushes up rents and holds down wages and profits. Ricardo was the first to state and prove the principle of comparative advantage, according to which each country should specialize in producing and exporting goods in that it has a lower relative cost of production, rather relying only on its own production.[123] It has been termed a \"fundamental analytical explanation\" for gains from trade.[124]\nThe Rev. Thomas Robert Malthus (1798) used the concept of diminishing returns to explain low living standards. Human population, he argued, tended to increase geometrically, outstripping the production of food, which increased arithmetically. The force of a rapidly growing population against a limited amount of land meant diminishing returns to labour. The result, he claimed, was chronically low wages, which prevented the standard of living for most of the population from rising above the subsistence level.[121] Economist Julian Lincoln Simon has criticized Malthus's conclusions.[122]\nIn an argument that includes \"one of the most famous passages in all economics,\"[117] Smith represents every individual as trying to employ any capital they might command for their own advantage, not that of the society,[c] and for the sake of profit, which is necessary at some level for employing capital in domestic industry, and positively related to the value of produce.[119] In this:\nSmith discusses potential benefits of specialization by division of labour, including increased labour productivity and gains from trade, whether between town and country or across countries.[114] His \"theorem\" that \"the division of labor is limited by the extent of the market\" has been described as the \"core of a theory of the functions of firm and industry\" and a \"fundamental principle of economic organization.\"[115] To Smith has also been ascribed \"the most important substantive proposition in all of economics\" and foundation of resource-allocation theory \u2013 that, under competition, resource owners (of labour, land, and capital) seek their most profitable uses, resulting in an equal rate of return for all uses in equilibrium (adjusted for apparent differences arising from such factors as training and unemployment).[116]\nThe publication of Adam Smith's The Wealth of Nations in 1776, has been described as \"the effective birth of economics as a separate discipline.\"[113] The book identified land, labour, and capital as the three factors of production and the major contributors to a nation's wealth, as distinct from the physiocratic idea that only agriculture was productive.\nAdam Smith (1723\u20131790) was an early economic theorist.[111] Smith was harshly critical of the mercantilists but described the physiocratic system \"with all its imperfections\" as \"perhaps the purest approximation to the truth that has yet been published\" on the subject.[112]\nPhysiocrats, a group of 18th-century French thinkers and writers, developed the idea of the economy as a circular flow of income and output. Physiocrats believed that only agricultural production generated a clear surplus over cost, so that agriculture was the basis of all wealth. Thus, they opposed the mercantilist policy of promoting manufacturing and trade at the expense of agriculture, including import tariffs. Physiocrats advocated replacing administratively costly tax collections with a single tax on income of land owners. In reaction against copious mercantilist trade regulations, the physiocrats advocated a policy of laissez-faire, which called for minimal government intervention in the economy.[110]\nTwo groups, later called \"mercantilists\" and \"physiocrats\", more directly influenced the subsequent development of the subject. Both groups were associated with the rise of economic nationalism and modern capitalism in Europe. Mercantilism was an economic doctrine that flourished from the 16th to 18th century in a prolific pamphlet literature, whether of merchants or statesmen. It held that a nation's wealth depended on its accumulation of gold and silver. Nations without access to mines could obtain gold and silver from trade only by selling goods abroad and restricting imports other than of gold and silver. The doctrine called for importing cheap raw materials to be used in manufacturing goods, which could be exported, and for state regulation to impose protective tariffs on foreign manufactured goods and prohibit manufacturing in the colonies.[109]\nEconomic writings date from earlier Mesopotamian, Greek, Roman, Indian subcontinent, Chinese, Persian, and Arab civilizations. Economic precepts occur throughout the writings of the Boeotian poet Hesiod and several economic historians have described Hesiod himself as the \"first economist\".[107] Other notable writers from Antiquity through to the Renaissance include Aristotle, Xenophon, Chanakya (also known as Kautilya), Qin Shi Huang, Thomas Aquinas, and Ibn Khaldun. Joseph Schumpeter described Aquinas as \"coming nearer than any other group to being the \"founders' of scientific economics\" as to monetary, interest, and value theory within a natural-law perspective.[108][not in citation given]\nThe sociological subfield of economic sociology arose, primarily through the work of \u00c9mile Durkheim, Max Weber and Georg Simmel, as an approach to analysing the effects of economic phenomena in relation to the overarching social paradigm (i.e. modernity).[106] Classic works include Max Weber's The Protestant Ethic and the Spirit of Capitalism (1905) and Georg Simmel's The Philosophy of Money (1900). More recently, the works of Mark Granovetter, Peter Hedstrom and Richard Swedberg have been influential in this field.\nEnergy economics is a broad scientific subject area which includes topics related to energy supply and energy demand. Georgescu-Roegen reintroduced the concept of entropy in relation to economics and energy from thermodynamics, as distinguished from what he viewed as the mechanistic foundation of neoclassical economics drawn from Newtonian physics. His work contributed significantly to thermoeconomics and to ecological economics. He also did foundational work which later developed into evolutionary economics.[105]\nPolitical economy is the interdisciplinary study that combines economics, law, and political science in explaining how political institutions, the political environment, and the economic system (capitalist, socialist, mixed) influence each other. It studies questions such as how monopoly, rent-seeking behaviour, and externalities should impact government policy.[103] Historians have employed political economy to explore the ways in the past that persons and groups with common economic interests have used politics to effect changes beneficial to their interests.[104]\nLaw and economics, or economic analysis of law, is an approach to legal theory that applies methods of economics to law. It includes the use of economic concepts to explain the effects of legal rules, to assess which legal rules are economically efficient, and to predict what the legal rules will be.[101] A seminal article by Ronald Coase published in 1961 suggested that well-defined property rights could overcome the problems of externalities.[102]\nEconomics is one social science among several and has fields bordering on other areas, including economic geography, economic history, public choice, energy economics, cultural economics, family economics and institutional economics.\nThe Nobel Memorial Prize in Economic Sciences (commonly known as the Nobel Prize in Economics) is a prize awarded to economists each year for outstanding intellectual contributions in the field.\nIn the private sector, professional economists are employed as consultants and in industry, including banking and finance. Economists also work for various government departments and agencies, for example, the national Treasury, Central Bank or Bureau of Statistics.\nThe professionalization of economics, reflected in the growth of graduate programmes on the subject, has been described as \"the main change in economics since around 1900\".[100] Most major universities and many colleges have a major, school, or department in which academic degrees are awarded in the subject, whether in the liberal arts, business, or for professional study.\nIn behavioural economics, psychologist Daniel Kahneman won the Nobel Prize in economics in 2002 for his and Amos Tversky's empirical discovery of several cognitive biases and heuristics. Similar empirical testing occurs in neuroeconomics. Another example is the assumption of narrowly selfish preferences versus a model that tests for selfish, altruistic, and cooperative preferences.[98] These techniques have led some to argue that economics is a \"genuine science\".[99]\nExperimental economics has promoted the use of scientifically controlled experiments. This has reduced the long-noted distinction of economics from natural sciences because it allows direct tests of what were previously taken as axioms.[97] In some cases these have found that the axioms are not entirely correct; for example, the ultimatum game has revealed that people reject unequal offers.\nIn applied economics, input-output models employing linear programming methods are quite common. Large amounts of data are run through computer programs to analyse the impact of certain policies; IMPLAN is one well-known example.\nCriticisms based on professional standards and non-replicability of results serve as further checks against bias, errors, and over-generalization,[92][93] although much economic research has been accused of being non-replicable, and prestigious journals have been accused of not facilitating replication through the provision of the code and data.[94] Like theories, uses of test statistics are themselves open to critical analysis,[95] although critical commentary on papers in economics in prestigious journals such as the American Economic Review has declined precipitously in the past 40 years. This has been attributed to journals' incentives to maximize citations in order to rank higher on the Social Science Citation Index (SSCI).[96]\nStatistical methods such as regression analysis are common. Practitioners use such methods to estimate the size, economic significance, and statistical significance (\"signal strength\") of the hypothesized relation(s) and to adjust for noise from other variables. By such means, a hypothesis may gain acceptance, although in a probabilistic, rather than certain, sense. Acceptance is dependent upon the falsifiable hypothesis surviving tests. Use of commonly accepted methods need not produce a final conclusion or even a consensus on a particular question, given different tests, data sets, and prior beliefs.\nEconomic theories are frequently tested empirically, largely through the use of econometrics using economic data.[90] The controlled experiments common to the physical sciences are difficult and uncommon in economics,[91] and instead broad data is observationally studied; this type of testing is typically regarded as less rigorous than controlled experimentation, and the conclusions typically more tentative. However, the field of experimental economics is growing, and increasing use is being made of natural experiments.\nExpositions of economic reasoning often use two-dimensional graphs to illustrate theoretical relationships. At a higher level of generality, Paul Samuelson's treatise Foundations of Economic Analysis (1947) used mathematical methods beyond graphs to represent the theory, particularly as to maximizing behavioural relations of agents reaching equilibrium. The book focused on examining the class of statements called operationally meaningful theorems in economics, which are theorems that can conceivably be refuted by empirical data.[89]\nThe aforementioned microeconomic concepts play a major part in macroeconomic models\u00a0\u2013 for instance, in monetary theory, the quantity theory of money predicts that increases in the growth rate of the money supply increase inflation, and inflation is assumed to be influenced by rational expectations. In development economics, slower growth in developed nations has been sometimes predicted because of the declining marginal returns of investment and capital, and this has been observed in the Four Asian Tigers. Sometimes an economic hypothesis is only qualitative, not quantitative.[88]\nIn microeconomics, principal concepts include supply and demand, marginalism, rational choice theory, opportunity cost, budget constraints, utility, and the theory of the firm.[87] Early macroeconomic models focused on modelling the relationships between aggregate variables, but as the relationships appeared to change over time macroeconomists, including new Keynesians, reformulated their models in microfoundations.[71]\nMainstream economic theory relies upon a priori quantitative economic models, which employ a variety of concepts. Theory typically proceeds with an assumption of ceteris paribus, which means holding constant explanatory variables other than the one under consideration. When creating theories, the objective is to find ones which are at least as simple in information requirements, more precise in predictions, and more fruitful in generating additional research than prior theories.[86] While neoclassical economic theory constitutes both the dominant or orthodox theoretical as well as methodological framework, economic theory can also take the form of other schools of thought such as in heterodox economic theories.\nContemporary economics uses mathematics. Economists draw on the tools of calculus, linear algebra, statistics, game theory, and computer science.[85] Professional economists are expected to be familiar with these tools, while a minority specialize in econometrics and mathematical methods.\nThe U.S. Export-Import Bank defines a Marxist-Leninist state as having a centrally planned economy.[83] They are now rare; examples can still be seen in Cuba, North Korea and Laos.[84][needs update]\nAmong contemporary systems at different ends of the organizational spectrum are socialist systems and capitalist systems, in which most production occurs in respectively state-run and private enterprises. In between are mixed economies. A common element is the interaction of economic and political influences, broadly described as political economy. Comparative economic systems studies the relative performance and behaviour of different economies or systems.[82]\nEconomic systems is the branch of economics that studies the methods and institutions by which societies determine the ownership, direction, and allocation of economic resources. An economic system of a society is the unit of analysis.\nThe distinct field of development economics examines economic aspects of the economic development process in relatively low-income countries focusing on structural change, poverty, and economic growth. Approaches in development economics frequently incorporate social and political factors.[81]\nInternational trade studies determinants of goods-and-services flows across international boundaries. It also concerns the size and distribution of gains from trade. Policy applications include estimating the effects of changing tariff rates and trade quotas. International finance is a macroeconomic field which examines the flow of capital across international borders, and the effects of these movements on exchange rates. Increased trade in goods, services and capital between countries is a major effect of contemporary globalization.[80]\nSceptics of fiscal policy also make the argument of Ricardian equivalence. They argue that an increase in debt will have to be paid for with future tax increases, which will cause people to reduce their consumption and save money to pay for the future tax increase. Under Ricardian equivalence, any boost in demand from tax cuts will be offset by the increased saving intended to pay for future higher taxes.\nThe effects of fiscal policy can be limited by crowding out. When there is no output gap, the economy is producing at full capacity and there are no excess productive resources. If the government increases spending in this situation, the government uses resources that otherwise would have been used by the private sector, so there is no increase in overall output. Some economists think that crowding out is always an issue while others do not think it is a major issue when output is depressed.\nFor example, unemployed home builders can be hired to expand highways. Tax cuts allow consumers to increase their spending, which boosts aggregate demand. Both tax cuts and spending have multiplier effects where the initial increase in demand from the policy percolates through the economy and generates additional economic activity.\nGovernments implement fiscal policy to influence macroeconomic conditions by adjusting spending and taxation policies to alter aggregate demand. When aggregate demand falls below the potential output of the economy, there is an output gap where some productive capacity is left unemployed. Governments increase spending and cut taxes to boost aggregate demand. Resources that have been idled can be used by the government.\nAt the level of an economy, theory and evidence are consistent with a positive relationship running from the total money supply to the nominal value of total output and to the general price level. For this reason, management of the money supply is a key aspect of monetary policy.[79]\nAs a medium of exchange, money facilitates trade. It is essentially a measure of value and more importantly, a store of value being a basis for credit creation. Its economic function can be contrasted with barter (non-monetary exchange). Given a diverse array of produced goods and specialized producers, barter may entail a hard-to-locate double coincidence of wants as to what is exchanged, say apples and a book. Money can reduce the transaction cost of exchange because of its ready acceptability. Then it is less costly for the seller to accept money in exchange, rather than what the buyer produces.[78]\nMoney is a means of final payment for goods in most price system economies, and is the unit of account in which prices are typically stated. Money has general acceptability, relative consistency in value, divisibility, durability, portability, elasticity in supply, and longevity with mass public confidence. It includes currency held by the nonbank public and checkable deposits. It has been described as a social convention, like language, useful to one largely because it is useful to others. In the words of Francis Amasa Walker, a well-known 19th-century economist, \"Money is what money does\" (\"Money is that money does\" in the original).[77]\nWhile some types of unemployment may occur regardless of the condition of the economy, cyclical unemployment occurs when growth stagnates. Okun's law represents the empirical relationship between unemployment and economic growth.[75] The original version of Okun's law states that a 3% increase in output would lead to a 1% decrease in unemployment.[76]\nStructural unemployment covers a variety of possible causes of unemployment including a mismatch between workers' skills and the skills required for open jobs.[73] Large amounts of structural unemployment can occur when an economy is transitioning industries and workers find their previous set of skills are no longer in demand. Structural unemployment is similar to frictional unemployment since both reflect the problem of matching workers with job vacancies, but structural unemployment covers the time needed to acquire new skills not just the short term search process.[74]\nClassical models of unemployment occurs when wages are too high for employers to be willing to hire more workers. Wages may be too high because of minimum wage laws or union activity. Consistent with classical unemployment, frictional unemployment occurs when appropriate job vacancies exist for a worker, but the length of time needed to search for and find the job leads to a period of unemployment.[72]\nThe amount of unemployment in an economy is measured by the unemployment rate, the percentage of workers without jobs in the labour force. The labour force only includes workers actively looking for jobs. People who are retired, pursuing education, or discouraged from seeking work by a lack of job prospects are excluded from the labour force. Unemployment can be generally broken down into several types that are related to different causes.[72]\nThus, the new classicals assume that prices and wages adjust automatically to attain full employment, whereas the new Keynesians see full employment as being automatically achieved only in the long run, and hence government and central-bank policies are needed because the \"long run\" may be very long.\nIn contrast, the new Keynesian approach retains the rational expectations assumption, however it assumes a variety of market failures. In particular, New Keynesians assume prices and wages are \"sticky\", which means they do not adjust instantaneously to changes in economic conditions.[71]\nNew classical macroeconomics, as distinct from the Keynesian view of the business cycle, posits market clearing with imperfect information. It includes Friedman's permanent income hypothesis on consumption and \"rational expectations\" theory,[69] led by Robert Lucas, and real business cycle theory.[70]\nOver the years, understanding of the business cycle has branched into various research programmes, mostly related to or distinct from Keynesianism. The neoclassical synthesis refers to the reconciliation of Keynesian economics with neoclassical economics, stating that Keynesianism is correct in the short run but qualified by neoclassical-like considerations in the intermediate and long run.[68]\nHe therefore advocated active policy responses by the public sector, including monetary policy actions by the central bank and fiscal policy actions by the government to stabilize output over the business cycle.[67]\nThus, a central conclusion of Keynesian economics is that, in some situations, no strong automatic mechanism moves output and employment towards full employment levels. John Hicks' IS/LM model has been the most influential interpretation of The General Theory.\nThe economics of a depression were the spur for the creation of \"macroeconomics\" as a separate discipline field of study. During the Great Depression of the 1930s, John Maynard Keynes authored a book entitled The General Theory of Employment, Interest and Money outlining the key theories of Keynesian economics. Keynes contended that aggregate demand for goods might be insufficient during economic downturns, leading to unnecessarily high unemployment and losses of potential output.\nMuch-studied factors include the rate of investment, population growth, and technological change. These are represented in theoretical and empirical forms (as in the neoclassical and endogenous growth models) and in growth accounting.[66]\nGrowth economics studies factors that explain economic growth\u00a0\u2013 the increase in output per capita of a country over a long period of time. The same factors are used to explain differences in the level of output per capita between countries, in particular why some countries grow faster than others, and whether countries converge at the same rates of growth.\nMacroeconomic analysis also considers factors affecting the long-term level and growth of national income. Such factors include capital accumulation, technological change and labour force growth.[65]\nSince at least the 1960s, macroeconomics has been characterized by further integration as to micro-based modelling of sectors, including rationality of players, efficient use of market information, and imperfect competition.[63] This has addressed a long-standing concern about inconsistent developments of the same subject.[64]\nMacroeconomics examines the economy as a whole to explain broad aggregates and their interactions \"top down\", that is, using a simplified form of general-equilibrium theory.[62] Such aggregates include national income and output, the unemployment rate, and price inflation and subaggregates like total consumption and investment spending and their components. It also studies effects of monetary policy and fiscal policy.\nWelfare economics is a normative branch of economics that uses microeconomic techniques to simultaneously determine the allocative efficiency within an economy and the income distribution associated with it. It attempts to measure social welfare by examining the economic activities of the individuals that comprise society.[61]\nMuch of economics is positive, seeking to describe and predict economic phenomena. Normative economics seeks to identify what economies ought to be like.\nPublic finance is the field of economics that deals with budgeting the revenues and expenditures of a public sector entity, usually government. The subject addresses such matters as tax incidence (who really pays a particular tax), cost-benefit analysis of government programmes, effects on economic efficiency and income distribution of different kinds of spending and taxes, and fiscal politics. The latter, an aspect of public choice theory, models public-sector behaviour analogously to microeconomics, involving interactions of self-interested voters, politicians, and bureaucrats.[60]\nPolicy options include regulations that reflect cost-benefit analysis or market solutions that change incentives, such as emission fees or redefinition of property rights.[59]\nSome specialized fields of economics deal in market failure more than others. The economics of the public sector is one example. Much environmental economics concerns externalities or \"public bads\".\nIn many areas, some form of price stickiness is postulated to account for quantities, rather than prices, adjusting in the short run to changes on the demand side or the supply side. This includes standard analysis of the business cycle in macroeconomics. Analysis often revolves around causes of such price stickiness and their implications for reaching a hypothesized long-run equilibrium. Examples of such price stickiness in particular markets include wage rates in labour markets and posted prices in markets deviating from perfect competition.\nExternalities occur where there are significant social costs or benefits from production or consumption that are not reflected in market prices. For example, air pollution may generate a negative externality, and education may generate a positive externality (less crime, etc.). Governments often tax and otherwise restrict the sale of goods that have negative externalities and subsidize or otherwise promote the purchase of goods that have positive externalities in an effort to correct the price distortions caused by these externalities.[57] Elementary demand-and-supply theory predicts equilibrium but not the speed of adjustment for changes of equilibrium due to a shift in demand or supply.[58]\nPublic goods are goods which are under-supplied in a typical market. The defining features are that people can consume public goods without having to pay for them and that more than one person can consume the good at the same time.\nNatural monopoly, or the overlapping concepts of \"practical\" and \"technical\" monopoly, is an extreme case of failure of competition as a restraint on producers. Extreme economies of scale are one possible cause.\nInformation asymmetries and incomplete markets may result in economic inefficiency but also a possibility of improving efficiency through market, legal, and regulatory remedies, as discussed above.\nThe term \"market failure\" encompasses several problems which may undermine standard economic assumptions. Although economists categorize market failures differently, the following categories emerge in the main texts.[b]\nBoth problems may raise insurance costs and reduce efficiency by driving otherwise willing transactors from the market (\"incomplete markets\"). Moreover, attempting to reduce one problem, say adverse selection by mandating insurance, may add to another, say moral hazard. Information economics, which studies such problems, has relevance in subjects such as insurance, contract law, mechanism design, monetary economics, and health care.[54] Applied subjects include market and legal remedies to spread or reduce risk, such as warranties, government-mandated partial insurance, restructuring or bankruptcy law, inspection, and regulation for quality and information disclosure.[55][56]\nSome market organizations may give rise to inefficiencies associated with uncertainty. Based on George Akerlof's \"Market for Lemons\" article, the paradigm example is of a dodgy second-hand car market. Customers without knowledge of whether a car is a \"lemon\" depress its price below what a quality second-hand car would be.[53] Information asymmetry arises here, if the seller has more relevant information than the buyer but no incentive to disclose it. Related problems in insurance are adverse selection, such that those at most risk are most likely to insure (say reckless drivers), and moral hazard, such that insurance results in riskier behaviour (say more reckless driving).[54]\nRisk aversion may stimulate activity that in well-functioning markets smooths out risk and communicates information about risk, as in markets for insurance, commodity futures contracts, and financial instruments. Financial economics or simply finance describes the allocation of financial resources. It also analyses the pricing of financial instruments, the financial structure of companies, the efficiency and fragility of financial markets,[51] financial crises, and related government policy or regulation.[52]\nIn this, it generalizes maximization approaches developed to analyse market actors such as in the supply and demand model and allows for incomplete information of actors. The field dates from the 1944 classic Theory of Games and Economic Behavior by John von Neumann and Oskar Morgenstern. It has significant applications seemingly outside of economics in such diverse subjects as formulation of nuclear strategies, ethics, political science, and evolutionary biology.[50]\nGame theory is a branch of applied mathematics that considers strategic interactions between agents, one kind of uncertainty. It provides a mathematical foundation of industrial organization, discussed above, to model different types of firm behaviour, for example in an solipsistic industry (few sellers), but equally applicable to wage negotiations, bargaining, contract design, and any situation where individual agents are few enough to have perceptible effects on each other. In behavioural economics, it has been used to model the strategies agents choose when interacting with others whose interests are at least partially adverse to their own.[49]\nUncertainty in economics is an unknown prospect of gain or loss, whether quantifiable as risk or not. Without it, household behaviour would be unaffected by uncertain employment and income prospects, financial and capital markets would reduce to exchange of a single instrument in each market period, and there would be no communications industry.[47] Given its different forms, there are various ways of representing uncertainty and modelling economic agents' responses to it.[48]\nManagerial economics applies microeconomic analysis to specific decisions in business firms or other management units. It draws heavily from quantitative methods such as operations research and programming and from statistical methods such as regression analysis in the absence of certainty and perfect knowledge. A unifying theme is the attempt to optimize business decisions, including unit-cost minimization and profit maximization, given the firm's objectives and constraints imposed by technology and market conditions.[46]\nIn perfectly competitive markets studied in the theory of supply and demand, there are many producers, none of which significantly influence price. Industrial organization generalizes from that special case to study the strategic behaviour of firms that do have significant control of price. It considers the structure of such markets and their interactions. Common market structures studied besides perfect competition include monopolistic competition, various forms of oligopoly, and monopoly.[45]\nPeople frequently do not trade directly on markets. Instead, on the supply side, they may work in and produce through firms. The most obvious kinds of firms are corporations, partnerships and trusts. According to Ronald Coase, people begin to organize their production in firms when the costs of doing business becomes lower than doing it on the market.[44] Firms combine labour and capital, and can achieve far greater economies of scale (when the average cost per unit declines as more units are produced) than individual market trading.\nDemand-and-supply analysis is used to explain the behaviour of perfectly competitive markets, but as a standard of comparison it can be extended to any type of market. It can also be generalized to explain variables across the economy, for example, total output (estimated as real GDP) and the general price level, as studied in macroeconomics.[42] Tracing the qualitative and quantitative effects of variables that change supply and demand, whether in the short or long run, is a standard exercise in applied economics. Economic theory may also specify conditions such that supply and demand through the market is an efficient mechanism for allocating resources.[43]\nOther applications of demand and supply include the distribution of income among the factors of production, including labour and capital, through factor markets. In a competitive labour market for example the quantity of labour employed and the price of labour (the wage rate) depends on the demand for labour (from employers for production) and supply of labour (from potential workers). Labour economics examines the interaction of workers and employers through such markets to explain patterns and changes of wages and other labour income, labour mobility, and (un)employment, productivity through human capital, and related public-policy issues.[41]\nMarginalist theory, such as above, describes the consumers as attempting to reach most-preferred positions, subject to income and wealth constraints while producers attempt to maximize profits subject to their own constraints, including demand for goods produced, technology, and the price of inputs. For the consumer, that point comes where marginal utility of a good, net of price, reaches zero, leaving no net gain from further consumption increases. Analogously, the producer compares marginal revenue (identical to price for the perfect competitor) against the marginal cost of a good, with marginal profit the difference. At the point where marginal profit reaches zero, further increases in production of the good stop. For movement to market equilibrium and for changes in equilibrium, price and quantity also change \"at the margin\": more-or-less of something, rather than necessarily all-or-nothing.\nOn the supply side of the market, some factors of production are described as (relatively) variable in the short run, which affects the cost of changing output levels. Their usage rates can be changed easily, such as electrical power, raw-material inputs, and over-time and temp work. Other inputs are relatively fixed, such as plant and equipment and key personnel. In the long run, all inputs may be adjusted by management. These distinctions translate to differences in the elasticity (responsiveness) of the supply curve in the short and long runs and corresponding differences in the price-quantity change from a shift on the supply or demand side of the market.\nFor a given quantity of a consumer good, the point on the demand curve indicates the value, or marginal utility, to consumers for that unit. It measures what the consumer would be prepared to pay for that unit.[39] The corresponding point on the supply curve measures marginal cost, the increase in total cost to the supplier for the corresponding unit of the good. The price in equilibrium is determined by supply and demand. In a perfectly competitive market, supply and demand equate marginal cost and marginal utility at equilibrium.[40]\nMarket equilibrium occurs where quantity supplied equals quantity demanded, the intersection of the supply and demand curves in the figure above. At a price below equilibrium, there is a shortage of quantity supplied compared to quantity demanded. This is posited to bid the price up. At a price above equilibrium, there is a surplus of quantity supplied compared to quantity demanded. This pushes the price down. The model of supply and demand predicts that for given supply and demand curves, price and quantity will stabilize at the price that makes quantity supplied equal to quantity demanded. Similarly, demand-and-supply theory predicts a new price-quantity combination from a shift in demand (as to the figure), or in supply.\nThat is, the higher the price at which the good can be sold, the more of it producers will supply, as in the figure. The higher price makes it profitable to increase production. Just as on the demand side, the position of the supply can shift, say from a change in the price of a productive input or a technical improvement. The \"Law of Supply\" states that, in general, a rise in price leads to an expansion in supply and a fall in price leads to a contraction in supply. Here as well, the determinants of supply, such as price of substitutes, cost of production, technology applied and various factors inputs of production are all taken to be constant for a specific time period of evaluation of supply.\nSupply is the relation between the price of a good and the quantity available for sale at that price. It may be represented as a table or graph relating price and quantity supplied. Producers, for example business firms, are hypothesized to be profit maximizers, meaning that they attempt to produce and supply the amount of goods that will bring them the highest profit. Supply is typically represented as a function relating price and quantity, if other factors are unchanged.\nThe law of demand states that, in general, price and quantity demanded in a given market are inversely related. That is, the higher the price of a product, the less of it people would be prepared to buy (other things unchanged). As the price of a commodity falls, consumers move toward it from relatively more expensive goods (the substitution effect). In addition, purchasing power from the price decline increases ability to buy (the income effect). Other factors can change demand; for example an increase in income will shift the demand curve for a normal good outward relative to the origin, as in the figure. All determinants are predominantly taken as constant factors of demand and supply.\nFor a given market of a commodity, demand is the relation of the quantity that all buyers would be prepared to purchase at each unit price of the good. Demand is often represented by a table or a graph showing price and quantity demanded (as in the figure). Demand theory describes individual consumers as rationally choosing the most preferred quantity of each good, given income, prices, tastes, etc. A term for this is \"constrained utility maximization\" (with income and wealth as the constraints on demand). Here, utility refers to the hypothesized relation of each individual consumer for ranking different commodity bundles as more or less preferred.\nPrices and quantities have been described as the most directly observable attributes of goods produced and exchanged in a market economy.[38] The theory of supply and demand is an organizing principle for explaining how prices coordinate the amounts produced and consumed. In microeconomics, it applies to price and output determination for a market with perfect competition, which includes the condition of no buyers or sellers large enough to have price-setting power.\nTheory and observation set out the conditions such that market prices of outputs and productive inputs select an allocation of factor inputs by comparative advantage, so that (relatively) low-cost inputs go to producing low-cost outputs. In the process, aggregate output may increase as a by-product or by design.[36] Such specialization of production creates opportunities for gains from trade whereby resource owners benefit from trade in the sale of one type of output for other, more highly valued goods. A measure of gains from trade is the increased income levels that trade may facilitate.[37]\nAn example that combines features above is a country that specializes in the production of high-tech knowledge products, as developed countries do, and trades with developing nations for goods produced in factories where labour is relatively cheap and plentiful, resulting in different in opportunity costs of production. More total output and utility thereby results from specializing in production and trading than if each country produced its own high-tech and low-tech products.\nThe general theory of specialization applies to trade among individuals, farms, manufacturers, service providers, and economies. Among each of these production systems, there may be a corresponding division of labour with different work groups specializing, or correspondingly different types of capital equipment and differentiated land uses.[35]\nIt has been observed that a high volume of trade occurs among regions even with access to a similar technology and mix of factor inputs, including high-income countries. This has led to investigation of economies of scale and agglomeration to explain specialization in similar but differentiated product lines, to the overall benefit of respective trading parties or regions.[34]\nEven if one region has an absolute advantage as to the ratio of its outputs to inputs in every type of output, it may still specialize in the output in which it has a comparative advantage and thereby gain from trading with a region that lacks any absolute advantage but has a comparative advantage in producing something else.\nSpecialization is considered key to economic efficiency based on theoretical and empirical considerations. Different individuals or nations may have different real opportunity costs of production, say from differences in stocks of human capital per worker or capital/labour ratios. According to theory, this may give a comparative advantage in production of goods that make more intensive use of the relatively more abundant, thus relatively cheaper, input.\nMuch applied economics in public policy is concerned with determining how the efficiency of an economy can be improved. Recognizing the reality of scarcity and then figuring out how to organize society for the most efficient use of resources has been described as the \"essence of economics\", where the subject \"makes its unique contribution.\"[33]\nBy construction, each point on the curve shows productive efficiency in maximizing output for given total inputs. A point inside the curve (as at A), is feasible but represents production inefficiency (wasteful use of inputs), in that output of one or both goods could increase by moving in a northeast direction to a point on the curve. Examples cited of such inefficiency include high unemployment during a business-cycle recession or economic organization of a country that discourages full use of resources. Being on the curve might still not fully satisfy allocative efficiency (also called Pareto efficiency) if it does not produce a mix of goods that consumers prefer over other points.\nThe slope of the curve at a point on it gives the trade-off between the two goods. It measures what an additional unit of one good costs in units forgone of the other good, an example of a real opportunity cost. Thus, if one more Gun costs 100 units of butter, the opportunity cost of one Gun is 100 Butter. Along the PPF, scarcity implies that choosing more of one good in the aggregate entails doing with less of the other good. Still, in a market economy, movement along the curve may indicate that the choice of the increased output is anticipated to be worth the cost to the agents.\nScarcity is represented in the figure by people being willing but unable in the aggregate to consume beyond the PPF (such as at X) and by the negative slope of the curve.[32] If production of one good increases along the curve, production of the other good decreases, an inverse relationship. This is because increasing output of one good requires transferring inputs to it from production of the other good, decreasing the latter.\nThe production\u2013possibility frontier (PPF) is an expository figure for representing scarcity, cost, and efficiency. In the simplest case an economy can produce just two goods (say \"guns\" and \"butter\"). The PPF is a table or graph (as at the right) showing the different quantity combinations of the two goods producible with a given technology and total factor inputs, which limit feasible total output. Each point on the curve shows potential total output for the economy, which is the maximum feasible output of one good, given a feasible output quantity of the other good.\nEconomic efficiency measures how well a system generates desired output with a given set of inputs and available technology. Efficiency is improved if more output is generated without changing inputs, or in other words, the amount of \"waste\" is reduced. A widely accepted general standard is Pareto efficiency, which is reached when no further change can make someone better off without making someone else worse off.\nInputs used in the production process include such primary factors of production as labour services, capital (durable produced goods used in production, such as an existing factory), and land (including natural resources). Other inputs may include intermediate goods used in production of final goods, such as the steel in a new car.\nOpportunity cost is the economic cost of production: the value of the next best opportunity foregone. Choices must be made between desirable yet mutually exclusive actions. It has been described as expressing \"the basic relationship between scarcity and choice\".[30] For example, if a baker uses a sack of flour to make pretzels one morning, then the baker cannot use either the flour or the morning to make bagels instead.  Part of the cost of making pretzels is that neither the flour nor the morning are available any longer, for use in some other way.  The opportunity cost of an activity is an element in ensuring that scarce resources are used efficiently, such that the cost is weighed against the value of that activity in deciding on more or less of it. Opportunity costs are not restricted to monetary or financial costs but could be measured by the real cost of output forgone, leisure, or anything else that provides the alternative benefit (utility).[31]\nIn microeconomics, production is the conversion of inputs into outputs. It is an economic process that uses inputs to create a commodity or a service for exchange or direct use. Production is a flow and thus a rate of output per period of time. Distinctions include such production alternatives as for consumption (food, haircuts, etc.) vs. investment goods (new tractors, buildings, roads, etc.), public goods (national defence, smallpox vaccinations, etc.) or private goods (new computers, bananas, etc.), and \"guns\" vs \"butter\".\nMicroeconomics studies individual markets by simplifying the economic system by assuming that activity in the market being analysed does not affect other markets. This method of analysis is known as partial-equilibrium analysis (supply and demand). This method aggregates (the sum of all activity) in only one market. General-equilibrium theory studies various markets and their behaviour. It aggregates (the sum of all activity) across all markets. This method studies both changes in markets and their interactions leading towards equilibrium.[29]\nForms include monopoly (in which there is only one seller of a good), duopoly (in which there are only two sellers of a good), oligopoly (in which there are few sellers of a good), monopolistic competition (in which there are many sellers producing highly differentiated goods), monopsony (in which there is only one buyer of a good), and oligopsony (in which there are few buyers of a good). Unlike perfect competition, imperfect competition invariably means market power is unequally distributed. Firms under imperfect competition have the potential to be \"price makers\", which means that, by holding a disproportionately high share of market power, they can influence the prices of their products.\nVarious market structures exist. In perfectly competitive markets, no participants are large enough to have the market power to set the price of a homogeneous product. In other words, every participant is a \"price taker\" as no participant influences the price of a product. In the real world, markets often experience imperfect competition.\nIn theory, in a free market the aggregates (sum of) of quantity demanded by buyers and quantity supplied by sellers may reach economic equilibrium over time in reaction to price changes; in practice, various issues may prevent equilibrium, and any equilibrium reached may not necessarily be morally equitable. For example, if the supply of healthcare services is limited by external factors, the equilibrium price may be unaffordable for many who desire it but cannot pay for it.\nMicroeconomics examines how entities, forming a market structure, interact within a market to create a market system. These entities include private and public players with various classifications, typically operating under scarcity of tradable units and light government regulation.[clarification needed] The item traded may be a tangible product such as apples or a service such as repair services, legal counsel, or entertainment.\nGary Becker, a contributor to the expansion of economics into new areas, describes the approach he favours as \"combin[ing the] assumptions of maximizing behaviour, stable preferences, and market equilibrium, used relentlessly and unflinchingly.\"[28] One commentary characterizes the remark as making economics an approach rather than a subject matter but with great specificity as to the \"choice process and the type of social interaction that [such] analysis involves.\" The same source reviews a range of definitions included in principles of economics textbooks and concludes that the lack of agreement need not affect the subject-matter that the texts treat. Among economists more generally, it argues that a particular definition presented may reflect the direction toward which the author believes economics is evolving, or should evolve.[17]\nSome subsequent comments criticized the definition as overly broad in failing to limit its subject matter to analysis of markets. From the 1960s, however, such comments abated as the economic theory of maximizing behaviour and rational-choice modelling expanded the domain of the subject to areas previously treated in other fields.[26] There are other criticisms as well, such as in scarcity not accounting for the macroeconomics of high unemployment.[27]\nRobbins describes the definition as not classificatory in \"pick[ing] out certain kinds of behaviour\" but rather analytical in \"focus[ing] attention on a particular aspect of behaviour, the form imposed by the influence of scarcity.\"[24] He affirmed that previous economists have usually centred their studies on the analysis of wealth: how wealth is created (production), distributed, and consumed; and how wealth can grow.[25] But he said that economics can be used to study other things, such as war, that are outside its usual focus.  This is because war has as the goal winning it (as a sought after end), generates both cost and benefits; and, resources (human life and other costs) are used to attain the goal.  If the war is not winnable or if the expected costs outweigh the benefits, the deciding actors (assuming they are rational) may never go to war (a decision) but rather explore other alternatives. We cannot define economics as the science that studies wealth, war, crime, education, and any other field economic analysis can be applied to; but, as the science that studies a particular common aspect of each of those subjects (they all use scarce resources to attain a sought after end).\nLionel Robbins (1932) developed implications of what has been termed \"[p]erhaps the most commonly accepted current definition of the subject\":[17]\nAlfred Marshall provides a still widely cited definition in his textbook Principles of Economics (1890) that extends analysis beyond wealth and from the societal to the microeconomic level:\nJean-Baptiste Say (1803), distinguishing the subject from its public-policy uses, defines it as the science of production, distribution, and consumption of wealth.[19] On the satirical side, Thomas Carlyle (1849) coined \"the dismal science\" as an epithet for classical economics, in this context, commonly linked to the pessimistic analysis of Malthus (1798).[20] John Stuart Mill (1844) defines the subject in a social context as:\nThere are a variety of modern definitions of economics; some reflect evolving views of the subject or different views among economists.[16][17] Scottish philosopher Adam Smith (1776) defined what was then called political economy as \"an inquiry into the nature and causes of the wealth of nations\", in particular as:\nEconomic analysis can be applied throughout society, in business, finance, health care, and government. Economic analysis is sometimes also applied to such diverse subjects as crime, education,[10] the family, law, politics, religion,[11] social institutions, war,[12] science,[13] and the environment.[14]\nThe discipline was renamed in the late 19th century primarily due to Alfred Marshall from \"political economy\" to \"economics\" as a shorter term for \"economic science\". At that time, it became more open to rigorous thinking and made increased use of mathematics, which helped support efforts to have it accepted as a science and as a separate discipline outside of political science and other social sciences.[a][7][8][9]\nOther broad distinctions within economics include those between positive economics, describing \"what is\", and normative economics, advocating \"what ought to be\"; between economic theory and applied economics; between rational and behavioural economics; and between mainstream economics and heterodox economics.[5]\nEconomics focuses on the behaviour and interactions of economic agents and how economies work. Microeconomics analyzes basic elements in the economy, including individual agents and markets, their interactions, and the outcomes of interactions. Individual agents may include, for example, households, firms, buyers, and sellers. Macroeconomics analyzes the entire economy (meaning aggregated production, consumption, savings, and investment) and issues affecting it, including unemployment of resources (labour, capital, and land), inflation, economic growth, and the public policies that address these issues (monetary, fiscal, and other policies).  See glossary of economics.\nEconomics (/\u025bk\u0259\u02c8n\u0252m\u026aks, i\u02d0k\u0259-/)[1][2][3] is the social science that studies the production, distribution, and consumption of goods and services.[4]\n\n\n",
            "title": "Economics",
            "url": "https://en.wikipedia.org/wiki/Economics"
        },
        {
            "desc_links": [
                "/wiki/Bay_mud",
                "/wiki/Coral",
                "/wiki/Sand",
                "/wiki/Benthic_boundary_layer",
                "/wiki/Polychaete",
                "/wiki/Crustacean",
                "/wiki/Benthos",
                "/wiki/Lake",
                "/wiki/Ocean",
                "/wiki/Body_of_water"
            ],
            "desc_text": "b'The benthic zone is the ecological region at the lowest level of a body of water such as an ocean or a lake, including the sediment surface and some sub-surface layers. Organisms living in this zone are called benthos, e.g., the benthic invertebrate community, including crustaceans and polychaetes.[1] The organisms generally live in close relationship with the substrate bottom and many are permanently attached to the bottom. The superficial layer of the soil lining the given body of water, the benthic boundary layer, is an integral part of the benthic zone, as it greatly influences the biological activity that takes place there. Examples of contact soil layers include sand bottoms, rocky outcrops, coral, and bay mud.\\n'",
            "links": [
                "/wiki/Bay_mud",
                "/wiki/Coral",
                "/wiki/Sand",
                "/wiki/Benthic_boundary_layer",
                "/wiki/Polychaete",
                "/wiki/Crustacean",
                "/wiki/Benthos",
                "/wiki/Lake",
                "/wiki/Ocean",
                "/wiki/Body_of_water",
                "/wiki/Hadal_zone",
                "/wiki/Ocean_trench",
                "/wiki/Mid-ocean_ridge",
                "/wiki/Abyssal_plain",
                "/wiki/Wikipedia:Verifiability",
                "/wiki/Continental_shelf",
                "/wiki/Littoral_zone",
                "/wiki/Intertidal_zone",
                "/wiki/Abyssal_zone",
                "/wiki/Pelagic_zone",
                "/wiki/Oxygen",
                "/wiki/Temperature",
                "/wiki/Aphotic_zone",
                "/wiki/Atmosphere_(unit)",
                "/wiki/Lemon_shark",
                "/wiki/Carcharhinidae",
                "/wiki/Wikipedia:Verifiability",
                "/wiki/Water_column",
                "/wiki/Biomass_(ecology)",
                "/wiki/Chemosynthesis",
                "/wiki/Microorganism",
                "/wiki/Detritivore",
                "/wiki/Scavenger",
                "/wiki/Food_chain",
                "/wiki/Detritus",
                "/wiki/Piezophile",
                "/wiki/Infauna",
                "/wiki/Epifauna",
                "/wiki/Foraminifera",
                "/wiki/Dinoflagellates",
                "/wiki/Marine_snow",
                "/wiki/Wikipedia:Verifiability",
                "/wiki/Detritus",
                "/wiki/Hadal",
                "/wiki/Abyssal",
                "/wiki/Bathyal",
                "/wiki/Mesopelagic",
                "/wiki/Epipelagic",
                "/wiki/Habitats",
                "/wiki/Ocean",
                "/wiki/Submarine",
                "/wiki/Remotely_operated_underwater_vehicle",
                "/wiki/Substrate_(marine_biology)",
                "/wiki/Organic_matter",
                "/wiki/Amphipoda#Ecology",
                "/wiki/Trophic_network",
                "/wiki/Biomass_(ecology)",
                "/wiki/Nutrients",
                "/wiki/Aquatic_ecosystems",
                "/wiki/Food_web",
                "/wiki/River_ecosystem",
                "/wiki/Macroinvertebrate",
                "/wiki/Water_Framework_Directive",
                "/wiki/Diatom",
                "/wiki/Lake_ecosystem",
                "/wiki/Littoral_zone",
                "/wiki/Gross_primary_production",
                "/wiki/Periphyton",
                "/wiki/Algae",
                "/wiki/Biodiversity",
                "/wiki/Heterogeneity"
            ],
            "text": "Ecologists are attempting to understand the relationship between heterogeneity and maintaining biodiversity in aquatic ecosystems. Benthic algae has been used as an inherently good subject for studying short term changes and community responses to heterogeneous conditions in streams. Understanding the potential mechanisms involving benthic periphyton and the effects on heterogeneity within a stream may provide a better understanding of the structure and function of stream ecosystems.[19] Benthic gross primary production (GPP) may be important in maintaining biodiversity hotspots in littoral zones in large lake ecosystems. However, the relative contributions of benthic habitats within specific ecosystems are poorly explored and more research is needed.[20]\nBecause the benthic system regulates energy in aquatic ecosystems, studies have been made of the mechanisms of the benthic zone in order to better understand the ecosystem. Benthic diatoms have been used by the European Union's Water Framework Directive (WFD) to establish ecological quality ratios that determined the ecological status of lakes in the UK.[17] Beginning research is being made on benthic assemblages to see if they can be used as indicators of healthy aquatic ecosystems. Benthic assemblages in urbanized coastal regions are not functionally equivalent to benthic assemblages in untouched regions.[18]\nBenthic macroinvertebrates have many important ecological functions, such as regulating the flow of materials and energy in river ecosystems through their food web linkages. Because of this correlation between flow of energy and nutrients, benthic macroinvertebrates have the ability to influence food resources on fish and other organisms in aquatic ecosystems. For example, the addition of a moderate amount of nutrients to a river over the course of several years resulted in increases in invertebrate richness, abundance, and biomass. These in turn resulted in increased food resources for native species of fish with insignificant alteration of the macroinvertebrate community structure and trophic pathways.[14] The presence of macroinvertebrates such as Amphipoda also affect the dominance of certain types of algae in Benthic ecosystems as well.[15] In addition, because benthic zones are influenced by the flow of dead organic material, there have been studies conducted on the relationship between stream and river water flows and the resulting effects on the benthic zone. Low flow events show a restriction in nutrient transport from benthic substrates to food webs, and caused a decrease in benthic macroinvertebrate biomass, which lead to the disappearance of food sources into the substrate.[16]\nIt is not easy to map or observe these organisms and their habitats, and most modern observations are made using remotely operated underwater vehicles (ROVs), and rarely submarines.\nThe lower zones are in deep, pressurized areas of the ocean. Human impacts have occurred at all ocean depths, but are most significant on shallow continental shelf and slope habitats.[12]  Many benthic organisms have retained their historic evolutionary characteristics. Some organisms are significantly larger than their relatives living in shallower zones, largely because of higher oxygen concentration in deep water.[13]\nModern seafloor mapping technologies have revealed linkages between seafloor geomorphology and benthic habitats, in which suites of benthic communities are associated with specific geomorphic settings.[10] Examples include cold-water coral communities associated with seamounts and submarine canyons, kelp forests associated with inner shelf rocky reefs and rockfish associated with rocky escarpments on continental slopes.[11] In oceanic environments, benthic habitats can also be zoned by depth. From the shallowest to the deepest are: the epipelagic (less than 200 meters), the mesopelagic (200\u20131,000 metres), the bathyal (1,000\u20134,000 meters), the abyssal (4,000\u20136,000 meters) and the deepest, the hadal (below 6,000 meters).\nSources of food for benthic communities can derive from the water column above these habitats in the form of aggregations of detritus, inorganic matter, and living organisms.[2][not in citation given] These aggregations are commonly referred to as marine snow, and are important for the deposition of organic matter, and bacterial communities.[6]  The amount of material sinking to the ocean floor can average 307,000 aggregates per m2 per day.[7] This amount will vary on the depth of the benthos, and the degree of benthic-pelagic coupling. The benthos in a shallow region will have more available food than the benthos in the deep sea. Because of their reliance on it, microbes may become spatially dependent on detritus in the benthic zone. The microbes found in the benthic zone, specifically dinoflagellates and foraminifera, colonize quite rapidly on detritus matter while forming a symbiotic relationship with each other.[8][9]\nBenthic organisms can be divided into two categories based on whether they make their home on the ocean floor or an inch or two into the ocean floor. Those living on the surface of the ocean floor are known as epifauna.[4] Those who live burrowed into the ocean floor are known as infauna.[5] Extremophiles, including piezophiles, which thrive in high pressures, may also live there.\nBecause light does not penetrate very deep into ocean-water, the energy source for the benthic ecosystem is often organic matter from higher up in the water column that drifts down to the depths. This dead and decaying matter sustains the benthic food chain; most organisms in the benthic zone are scavengers or detritivores. Some microorganisms use chemosynthesis to produce biomass.\nBenthos are the organisms that live in the benthic zone, and are different from those elsewhere in the water column.[2][not in citation given] Many have adapted to live on the substrate (bottom). In their habitats they can be considered as dominant creatures, but they are often a source of prey for Carcharhinidae such as the lemon shark.[3] Many organisms adapted to deep-water pressure cannot survive in the upper parts of the water column. The pressure difference can be very significant (approximately one atmosphere for each 10 meters of water depth).\nFor information on animals that live in the deeper areas of the oceans see aphotic zone. Generally, these include life forms that tolerate cool temperatures and low oxygen levels, but this depends on the depth of the water.\nFor comparison, the pelagic zone is the descriptive term for the ecological region above the benthos, including the water-column up to the surface. Depending on the water-body, the benthic zone may include areas that are only a few inches below water, such as a stream or shallow pond; at the other end of the spectrum, benthos of the deep ocean includes the bottom levels of the oceanic abyssal zone.\nThe benthic region of the ocean begins at the shore line (intertidal or littoral zone) and extends downward along the surface of  the continental shelf out to sea.[2][not in citation given] The continental shelf is a gently sloping benthic region that extends away from the land mass. At the continental shelf edge, usually about 200 meters deep, the gradient greatly increases and is known as the continental slope. The continental slope drops down to the deep sea floor. The deep-sea floor is called the abyssal plain and is usually about 4,000 meters deep. The ocean floor is not all flat but has submarine ridges and deep ocean trenches known as the hadal zone.\nThe benthic zone is the ecological region at the lowest level of a body of water such as an ocean or a lake, including the sediment surface and some sub-surface layers. Organisms living in this zone are called benthos, e.g., the benthic invertebrate community, including crustaceans and polychaetes.[1] The organisms generally live in close relationship with the substrate bottom and many are permanently attached to the bottom. The superficial layer of the soil lining the given body of water, the benthic boundary layer, is an integral part of the benthic zone, as it greatly influences the biological activity that takes place there. Examples of contact soil layers include sand bottoms, rocky outcrops, coral, and bay mud.\n",
            "title": "Benthic zone",
            "url": "https://en.wikipedia.org/wiki/Benthic_zone"
        },
        {
            "desc_links": [
                "/wiki/Inductive_bias",
                "/wiki/Training_set",
                "/wiki/Machine_learning",
                "/wiki/Concept_learning"
            ],
            "desc_text": "b'Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.[1] It infers a function from labeled training data consisting of a set of training examples.[2]  In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal).  A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way (see inductive bias).\\n'b'The parallel task in human and animal psychology is often referred to as concept learning.\\n'",
            "links": [
                "/wiki/Inductive_bias",
                "/wiki/Training_set",
                "/wiki/Machine_learning",
                "/wiki/Concept_learning",
                "/wiki/No_free_lunch_in_search_and_optimization",
                "/wiki/Dimensionality_reduction",
                "/wiki/Feature_selection",
                "/wiki/Deterministic_noise",
                "/wiki/Overfitting",
                "/wiki/Target_variable",
                "/wiki/Statistical_significance",
                "/wiki/Generalization_error",
                "/wiki/Anomaly_detection",
                "/wiki/Overfitting",
                "/wiki/Early_stopping",
                "/wiki/Cross-validation_(statistics)",
                "/wiki/Occam%27s_razor",
                "/wiki/Regularization_(mathematics)",
                "/wiki/Structural_risk_minimization"
            ],
            "text": "There are several ways in which the standard supervised learning problem can be generalized:\nStructural risk minimization seeks to prevent overfitting by incorporating a regularization penalty into the optimization.  The regularization penalty can be viewed as implementing a form of Occam's razor that prefers simpler functions over more complex ones.\nThe most widely used learning algorithms are: \nWhen considering a new application, the engineer can compare multiple learning algorithms and experimentally determine which one works best on the problem at hand (see cross validation).  Tuning the performance of a learning algorithm can be very time-consuming.  Given fixed resources, it is often better to spend more time collecting additional training data and more informative features than it is to spend extra time tuning the learning algorithms.\nOther factors to consider when choosing and applying a learning algorithm include the following:\nIn practice, there are several approaches to alleviate noise in the output values such as early stopping to prevent overfitting as well as detecting and removing the noisy training examples prior to training the supervised learning algorithm.  There are several algorithms that identify noisy training examples and removing the suspected noisy training examples prior to training has decreased generalization error with statistical significance.[5][6]\nA fourth issue is the degree of noise in the desired output values (the supervisory target variables).  If the desired output values are often incorrect (because of human error or sensor errors), then the learning algorithm should not attempt to find a function that exactly matches the training examples.  Attempting to fit the data too carefully leads to overfitting.  You can overfit even when there are no measurement errors (stochastic noise) if the function you are trying to learn is too complex for your learning model. In such a situation, the part of the target function that cannot be modeled \"corrupts\" your training data - this phenomenon has been called deterministic noise. When either type of noise is present, it is better to go with a higher bias, lower variance estimator.\nA third issue is the dimensionality of the input space.  If the input feature vectors have very high dimension, the learning problem can be difficult even if the true function only depends on a small number of those features.  This is because the many \"extra\" dimensions can confuse the learning algorithm and cause it to have high variance.  Hence, high input dimensionality typically requires tuning the classifier to have low variance and high bias.  In practice, if the engineer can manually remove irrelevant features from the input data, this is likely to improve the accuracy of the learned function.  In addition, there are many algorithms for feature selection that seek to identify the relevant features and discard the irrelevant ones.  This is an instance of the more general strategy of dimensionality reduction, which seeks to map the input data into a lower-dimensional space prior to running the supervised learning algorithm.\nThe second issue is the amount of training data available relative to the complexity of the \"true\" function (classifier or regression function).  If the true function is simple, then an \"inflexible\" learning algorithm with high bias and low variance will be able to learn it from a small amount of data.  But if the true function is highly complex (e.g., because it involves complex interactions among many different input features and behaves differently in different parts of the input space), then the function will only be learnable from a very large amount of training data and using a \"flexible\" learning algorithm with low bias and high variance.\nThere are four major issues to consider in supervised learning:\nA wide range of supervised learning algorithms are available, each with its strengths and weaknesses. There is no single learning algorithm that works best on all supervised learning problems (see the No free lunch theorem).\nIn order to solve a given problem of supervised learning, one has to perform the following steps:\nThe parallel task in human and animal psychology is often referred to as concept learning.\nSupervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.[1] It infers a function from labeled training data consisting of a set of training examples.[2]  In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal).  A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way (see inductive bias).\n",
            "title": "Supervised learning",
            "url": "https://en.wikipedia.org/wiki/Supervised_learning"
        },
        {
            "desc_links": [
                "/wiki/Data",
                "/wiki/Computer_systems",
                "/wiki/Artificial_intelligence",
                "/wiki/Computer_vision",
                "/wiki/Email_filtering",
                "/wiki/Mathematical_model",
                "/wiki/Computer_program",
                "/wiki/Data",
                "/wiki/Algorithm",
                "/wiki/Arthur_Samuel",
                "/wiki/Unsupervised_learning",
                "/wiki/Exploratory_data_analysis",
                "/wiki/Data_mining",
                "/wiki/Mathematical_optimization",
                "/wiki/Computational_statistics",
                "/wiki/Data_science",
                "/wiki/Predictive_analytics",
                "/wiki/Data_analytics"
            ],
            "desc_text": "b'Machine learning is a field of artificial intelligence that uses statistical techniques to give computer systems the ability to \"learn\" (e.g., progressively improve performance on a specific task) from data, without being explicitly programmed.[2]\\n'b'The name machine learning was coined in 1959 by Arthur Samuel.[1] Machine learning explores the study and construction of algorithms that can learn from and make predictions on data[3] \\xe2\\x80\\x93 such algorithms overcome following strictly static program instructions by making data-driven predictions or decisions,[4]:2 through building a model from sample inputs. Machine learning is employed in a range of computing tasks where designing and programming explicit algorithms with good performance is difficult or infeasible; example applications include email filtering, detection of network intruders, and computer vision.\\n'b'Machine learning is closely related to (and often overlaps with) computational statistics, which also focuses on prediction-making through the use of computers. It has strong ties to mathematical optimization, which delivers methods, theory and application domains to the field. Machine learning is sometimes conflated with data mining,[5] where the latter subfield focuses more on exploratory data analysis and is known as unsupervised learning.[6][7]\\n'b'Within the field of data analytics, machine learning is a method used to devise complex models and algorithms that lend themselves to prediction; in commercial use, this is known as predictive analytics. These analytical models allow researchers, data scientists, engineers, and analysts to \"produce reliable, repeatable decisions and results\" and uncover \"hidden insights\" through learning from historical relationships and trends in the data.[8]\\n'",
            "links": [
                "/wiki/Data",
                "/wiki/Computer_systems",
                "/wiki/Artificial_intelligence",
                "/wiki/Computer_vision",
                "/wiki/Email_filtering",
                "/wiki/Mathematical_model",
                "/wiki/Computer_program",
                "/wiki/Data",
                "/wiki/Algorithm",
                "/wiki/Arthur_Samuel",
                "/wiki/Unsupervised_learning",
                "/wiki/Exploratory_data_analysis",
                "/wiki/Data_mining",
                "/wiki/Mathematical_optimization",
                "/wiki/Computational_statistics",
                "/wiki/Data_science",
                "/wiki/Predictive_analytics",
                "/wiki/Data_analytics",
                "/wiki/Computing_Machinery_and_Intelligence",
                "/wiki/Alan_Turing",
                "/wiki/Operational_definition",
                "/wiki/Tom_M._Mitchell",
                "/wiki/Robot_learning",
                "/wiki/Developmental_robotics",
                "/wiki/Inductive_bias",
                "/wiki/Meta_learning_(computer_science)",
                "/wiki/Probability_theory",
                "/wiki/Generalized_linear_model",
                "/wiki/ADALINE",
                "/wiki/Perceptron",
                "/wiki/Neural_network",
                "/wiki/IBM",
                "/wiki/Artificial_intelligence",
                "/wiki/Computer_gaming",
                "/wiki/Arthur_Samuel",
                "/wiki/Backpropagation",
                "/wiki/Geoff_Hinton",
                "/wiki/David_Rumelhart",
                "/wiki/John_Hopfield",
                "/wiki/Connectionism",
                "/wiki/Computer_science",
                "/wiki/Information_retrieval",
                "/wiki/Pattern_recognition",
                "/wiki/Inductive_logic_programming",
                "/wiki/Expert_system",
                "/wiki/GOFAI",
                "/wiki/Internet",
                "/wiki/Probability_theory",
                "/wiki/ECML_PKDD",
                "/wiki/Knowledge_discovery",
                "/wiki/Discovery_(observation)",
                "/wiki/Data_mining",
                "/wiki/Loss_function",
                "/wiki/Data_science",
                "/wiki/Michael_I._Jordan",
                "/wiki/Statistics",
                "/wiki/Random_forest",
                "/wiki/Leo_Breiman",
                "/wiki/Errors_and_residuals",
                "/wiki/Bias%E2%80%93variance_decomposition",
                "/wiki/Computational_learning_theory",
                "/wiki/Theoretical_computer_science",
                "/wiki/Overfitting",
                "/wiki/Time_complexity",
                "/wiki/Time_complexity#Polynomial_time",
                "/wiki/Predictive_modelling",
                "/wiki/Decision_tree",
                "/wiki/Joint_probability_distribution",
                "/wiki/Pattern_recognition",
                "/wiki/Data_modeling",
                "/wiki/Statistical",
                "/wiki/Non-linear",
                "/wiki/Computation",
                "/wiki/Connectionism",
                "/wiki/Artificial_neuron",
                "/wiki/Biological_neural_networks",
                "/wiki/Artificial_neural_network",
                "/wiki/Speech_recognition",
                "/wiki/Computer_vision",
                "/wiki/Deep_learning",
                "/wiki/GPU",
                "/wiki/Functional_programming",
                "/wiki/Inductive_programming",
                "/wiki/Entailment",
                "/wiki/Logic_programming",
                "/wiki/Regression_analysis",
                "/wiki/Statistical_classification",
                "/wiki/Supervised_learning",
                "/wiki/Data_analysis",
                "/wiki/Statistics",
                "/wiki/Unsupervised_learning",
                "/wiki/Inference",
                "/wiki/Directed_acyclic_graph",
                "/wiki/Conditional_independence",
                "/wiki/Random_variables",
                "/wiki/Graphical_model",
                "/wiki/Cluster_analysis",
                "/wiki/Principal_components_analysis",
                "/wiki/Unsupervised_learning",
                "/wiki/Deep_learning",
                "/wiki/Tensor",
                "/wiki/Multilinear_subspace_learning",
                "/wiki/Sparse_coding",
                "/wiki/Manifold_learning",
                "/wiki/Recommendation_systems",
                "/wiki/K-SVD",
                "/wiki/Strongly_NP-hard",
                "/wiki/Image_de-noising",
                "/wiki/Evolutionary_algorithm",
                "/wiki/Chromosome_(genetic_algorithm)",
                "/wiki/Crossover_(genetic_algorithm)",
                "/wiki/Mutation_(genetic_algorithm)",
                "/wiki/Natural_selection",
                "/wiki/Heuristic_(computer_science)",
                "/wiki/Search_algorithm",
                "/wiki/Artificial_immune_system",
                "/wiki/Association_rule_learning",
                "/wiki/Learning_classifier_system",
                "/wiki/Rule-based_machine_learning",
                "/wiki/Piecewise",
                "/wiki/Unsupervised_learning",
                "/wiki/Reinforcement_learning",
                "/wiki/Supervised_learning",
                "/wiki/Genetic_algorithm",
                "/wiki/Rule-based_machine_learning",
                "/wiki/Ensemble_Averaging",
                "/wiki/AT%26T_Labs",
                "/wiki/Netflix_Prize",
                "/wiki/Netflix",
                "/wiki/Vinod_Khosla",
                "/wiki/Sun_Microsystems",
                "/wiki/Watson_(computer)",
                "/wiki/Uber",
                "/wiki/Chatbot",
                "/wiki/Bootstrapping",
                "/wiki/Cross-validation_(statistics)",
                "/wiki/Test_set",
                "/wiki/Receiver_Operating_Characteristic",
                "/wiki/Total_Operating_Characteristic",
                "/wiki/False_Negative_Rate",
                "/wiki/False_Positive_Rate",
                "/wiki/Sensitivity_and_specificity",
                "/wiki/Data_collection",
                "/wiki/Algorithmic_bias",
                "/wiki/Machine_ethics",
                "/wiki/Text_corpus",
                "/wiki/Software_suite"
            ],
            "text": "Software suites containing a variety of machine learning algorithms include the following\u00a0:\nOther forms of ethical challenges, not related to personal biases, are more seen in health care. There are concerns among health care professionals that these systems might not be designed in the public's interest, but as income generating machines. This is especially true in the United States where there is a perpetual ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes in. There is huge potential for machine learning in health care to provide professionals a great tool to diagnose, medicate, and even plan recovery paths for patients, but this will not happen until the personal biases mentioned previously, and these \"greed\" biases are addressed.[64]\nBecause language contains biases, machines trained on language corpora will necessarily also learn bias.[63]\nMachine learning poses a host of ethical questions. Systems which are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitizing cultural prejudices.[60] For example, using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants against similarity to previous successful applicants.[61][62] Responsible collection of data and documentation of algorithmic rules used by a system thus is a critical part of machine learning.\nIn addition to overall accuracy, investigators frequently report sensitivity and specificity meaning True Positive Rate (TPR) and True Negative Rate (TNR) respectively. Similarly, investigators sometimes report the False Positive Rate (FPR) as well as the False Negative Rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. The Total Operating Characteristic (TOC) is an effective method to express a model's diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used Receiver Operating Characteristic (ROC) and ROC's associated Area Under the Curve (AUC).[59]\nClassification machine learning models can be validated by accuracy estimation techniques like the Holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the N-fold-cross-validation method randomly splits the data in k subsets where the k-1 instances of the data are used to train the model while the kth instance is used to test the predictive ability of the training model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.[58]\nMachine learning approaches in particular can suffer from different data biases. A machine learning system trained on your current customers only may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on man-made data, machine learning is likely to pick up the same constitutional and unconscious biases already present in society.[45] Language models learned from data have been shown to contain human-like biases.[46][47] Machine learning systems used for criminal risk assessment have been found to be biased against black people.[48][49] In 2015, Google photos would often tag black people as gorillas,[50] and in 2018 this still was not well resolved, but Google reportedly was still using the workaround to remove all gorilla from the training data, and thus was not able to recognize real gorillas at all.[51] Similar issues with recognizing non-white people have been found in many other systems.[52] In 2016, Microsoft tested a chatbot that learned from Twitter, and it quickly picked up racist and sexist language.[53] Because of such challenges, the effective use of machine learning may take longer to be adopted in other domains.[54] In 2018, a self-driving car from Uber failed to detect a pedestrian, who got killed in the accident.[55] Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of investment.[56][57]\nAlthough machine learning has been transformative in some fields, effective machine learning is difficult because finding patterns is hard and often not enough training data are available; as a result, many machine-learning programs often fail to deliver the expected value.[41][42][43] Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.[44]\nIn 2014, it has been reported that a machine learning algorithm has been applied in Art History to study fine art paintings, and that it may have revealed previously unrecognized influences between artists.[40]\nIn 2012, co-founder of Sun Microsystems Vinod Khosla predicted that 80% of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software.[39]\nIn 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of Machine Learning to predict the financial crisis. \n[38]\nIn 2006, the online movie company Netflix held the first \"Netflix Prize\" competition to find a program to better predict user preferences and improve the accuracy on its existing Cinematch movie recommendation algorithm by at least 10%.  A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1\u00a0million.[36] Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (\"everything is a recommendation\") and they changed their recommendation engine accordingly.[37]\nApplications for machine learning include:\nLearning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component (e.g. typically a genetic algorithm) with a learning component (performing either supervised learning, reinforcement learning, or unsupervised learning). They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions.[30]\nRule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves \"rules\" to store, manipulate or apply, knowledge.  The defining characteristic of a rule-based machine learner is the identification and utilization of a set of relational rules that collectively represent the knowledge captured by the system.  This is in contrast to other machine learners that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.[29] Rule-based machine learning approaches include learning classifier systems, association rule learning, and artificial immune systems.\nA genetic algorithm (GA) is a search heuristic that mimics the process of natural selection, and uses methods such as mutation and crossover to generate new genotype in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms found some uses in the 1980s and 1990s.[26][27] Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms.[28]\nSparse dictionary learning has been applied in several contexts. In classification, the problem is to determine which classes a previously unseen datum belongs to. Suppose a dictionary for each class has already been built. Then a new datum is associated with the class such that it's best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in image de-noising. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.[25]\nLearning a dictionary along with sparse representations is strongly NP-hard and also difficult to solve approximately.[24] A popular heuristic method for sparse dictionary learning is K-SVD.\nIn this problem, the learning machine is given pairs of examples that are considered similar and pairs of less similar objects. It then needs to learn a similarity function (or a distance metric function) that can predict if new objects are similar. It is sometimes used in Recommendation systems.\nManifold learning algorithms attempt to do so under the constraint that the learned representation is low-dimensional. Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse (has many zeros). Multilinear subspace learning algorithms aim to learn low-dimensional representations directly from tensor representations for multidimensional data, without reshaping them into (high-dimensional) vectors.[22] Deep learning algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data.[23]\nSeveral learning algorithms, mostly unsupervised learning algorithms, aim at discovering better representations of the inputs provided during training. Classical examples include principal components analysis and cluster analysis. Representation learning algorithms often attempt to preserve the information in their input but transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions, allowing reconstruction of the inputs coming from the unknown data generating distribution, while not being necessarily faithful for configurations that are implausible under that distribution.\nA Bayesian network, belief network or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independencies via a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning.\nCluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to some predesignated criterion or criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated for example by internal compactness (similarity between members of the same cluster) and separation between different clusters. Other methods are based on estimated density and graph connectivity.\nClustering is a method of unsupervised learning, and a common technique for statistical data analysis.\nSupport vector machines (SVMs) are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category or the other.\nInductive logic programming (ILP) is an approach to rule learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming languages for representing hypotheses (and not only logic programming), such as functional programs.\nFalling hardware prices and the development of GPUs for personal use in the last few years have contributed to the development of the concept of deep learning which consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[21]\nAn artificial neural network (ANN) learning algorithm, usually called \"neural network\" (NN), is a learning algorithm that is vaguely inspired by biological neural networks. Computations are structured in terms of an interconnected group of artificial neurons, processing information using a connectionist approach to computation. Modern neural networks are non-linear statistical data modeling tools. They are usually used to model complex relationships between inputs and outputs, to find patterns in data, or to capture the statistical structure in an unknown joint probability distribution between observed variables.\nAssociation rule learning is a method for discovering interesting relations between variables in large databases.\nDecision tree learning uses a decision tree as a predictive model, which maps observations about an item to conclusions about the item's target value.\nIn addition to performance bounds, computational learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results. Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.\nFor the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has underfit the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.[20]\nThe computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias\u2013variance decomposition is one way to quantify generalization error.\nA core objective of a learner is to generalize from its experience.[4][19] Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.\nSome statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning.[18]\nLeo Breiman distinguished two statistical modelling paradigms: data model and algorithmic model,[17] wherein \"algorithmic model\" means more or less the machine learning algorithms like Random forest.\nMachine learning and statistics are closely related fields. According to Michael I. Jordan, the ideas of machine learning, from methodological principles to theoretical tools, have had a long pre-history in statistics.[16] He also suggested the term data science as a placeholder to call the overall field.[16]\nMachine learning also has intimate ties to optimization: many learning problems are formulated as minimization of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the pre-assigned labels of a set of examples). The difference between the two fields arises from the goal of generalization: while optimization algorithms can minimize the loss on a training set, machine learning is concerned with minimizing the loss on unseen samples.[15]\nMachine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \"unsupervised learning\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.\nMachine learning, reorganized as a separate field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics and probability theory.[14] It also benefited from the increasing availability of digitized information, and the ability to distribute it via the Internet.\nHowever, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.[13]:488 By 1980, expert systems had come to dominate AI, and statistics was out of favor.[14] Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming, but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.[13]:708\u2013710; 755 Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as \"connectionism\", by researchers from other disciplines including Hopfield, Rumelhart and Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.[13]:25\nArthur Samuel, an American pioneer in the field of computer gaming and artificial intelligence, coined the term \"Machine Learning\" in 1959 while at IBM[11]. \nAs a scientific endeavour, machine learning grew out of the quest for artificial intelligence. Already in the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"neural networks\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics.[12] Probabilistic reasoning was also employed, especially in automated medical diagnosis.[13]:488\nAmong other categories of machine learning problems, learning to learn learns its own inductive bias based on previous experience. Developmental learning, elaborated for robot learning, generates its own sequences (also called curriculum) of learning situations to cumulatively acquire repertoires of novel skills through autonomous self-exploration and social interaction with human teachers and using guidance mechanisms such as active learning, maturation, motor synergies, and imitation.\nAnother categorization of machine learning tasks arises when one considers the desired output of a machine-learned system:[4]:3\nMachine learning tasks are typically classified into several broad categories:\n\nTom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\"[9] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".[10] In Turing's proposal the various characteristics that could be possessed by a thinking machine and the various implications in constructing one are exposed.\nWithin the field of data analytics, machine learning is a method used to devise complex models and algorithms that lend themselves to prediction; in commercial use, this is known as predictive analytics. These analytical models allow researchers, data scientists, engineers, and analysts to \"produce reliable, repeatable decisions and results\" and uncover \"hidden insights\" through learning from historical relationships and trends in the data.[8]\nMachine learning is closely related to (and often overlaps with) computational statistics, which also focuses on prediction-making through the use of computers. It has strong ties to mathematical optimization, which delivers methods, theory and application domains to the field. Machine learning is sometimes conflated with data mining,[5] where the latter subfield focuses more on exploratory data analysis and is known as unsupervised learning.[6][7]\nThe name machine learning was coined in 1959 by Arthur Samuel.[1] Machine learning explores the study and construction of algorithms that can learn from and make predictions on data[3] \u2013 such algorithms overcome following strictly static program instructions by making data-driven predictions or decisions,[4]:2 through building a model from sample inputs. Machine learning is employed in a range of computing tasks where designing and programming explicit algorithms with good performance is difficult or infeasible; example applications include email filtering, detection of network intruders, and computer vision.\nMachine learning is a field of artificial intelligence that uses statistical techniques to give computer systems the ability to \"learn\" (e.g., progressively improve performance on a specific task) from data, without being explicitly programmed.[2]\n",
            "title": "Machine learning",
            "url": "https://en.wikipedia.org/wiki/Machine_learning"
        },
        {
            "desc_links": [],
            "desc_text": "",
            "links": [
                "/wiki/Human_mind",
                "/wiki/Intelligent_agent",
                "/wiki/Computer_science",
                "/wiki/Machine",
                "/wiki/Intelligence",
                "/wiki/Military_simulations",
                "/wiki/Content_delivery_network",
                "/wiki/Autonomous_car",
                "/wiki/Go_(game)",
                "/wiki/Chess",
                "/wiki/Strategic_game",
                "/wiki/Natural_language_understanding",
                "/wiki/Optical_character_recognition",
                "/wiki/Template:Harvard_citation_documentation#Wikilink_to_citation_does_not_work",
                "/wiki/AI_effect",
                "/wiki/Artificial_neural_network",
                "/wiki/AI_winter",
                "/wiki/Philosophy",
                "/wiki/Linguistics",
                "/wiki/Psychology",
                "/wiki/Mathematics",
                "/wiki/Information_engineering",
                "/wiki/Computer_science",
                "/wiki/Artificial_neural_network",
                "/wiki/Artificial_general_intelligence",
                "/wiki/Machine_perception",
                "/wiki/Natural_language_processing",
                "/wiki/Machine_learning",
                "/wiki/Automated_planning_and_scheduling",
                "/wiki/Knowledge_representation",
                "/wiki/Automated_reasoning",
                "/wiki/Technological_unemployment#21st_century",
                "/wiki/Technological_singularity",
                "/wiki/Ancient_history",
                "/wiki/Philosophy_of_AI",
                "/wiki/Artificial_intelligence_in_fiction",
                "/wiki/History_of_AI#AI_in_myth,_fiction_and_speculation",
                "/wiki/Mind",
                "/wiki/Human_intelligence",
                "/wiki/Operations_research",
                "/wiki/Software_engineering",
                "/wiki/Technology_industry",
                "/wiki/Big_data",
                "/wiki/Computer_performance",
                "/wiki/Ethics_of_artificial_intelligence",
                "/wiki/R.U.R._(Rossum%27s_Universal_Robots)",
                "/wiki/Karel_%C4%8Capek",
                "/wiki/Frankenstein",
                "/wiki/Mary_Shelley",
                "/wiki/Storytelling_device",
                "/wiki/Artificial_being",
                "/wiki/Turing-complete",
                "/wiki/Walter_Pitts",
                "/wiki/Warren_McCullouch",
                "/wiki/Cybernetic",
                "/wiki/Information_theory",
                "/wiki/Neuroscience",
                "/wiki/Church%E2%80%93Turing_thesis",
                "/wiki/Theory_of_computation",
                "/wiki/Alan_Turing",
                "/wiki/Philosopher",
                "/wiki/Formal_reasoning",
                "/wiki/Marvin_Minsky",
                "/wiki/Herbert_A._Simon",
                "/wiki/DARPA",
                "/wiki/Logic_Theorist",
                "/wiki/Draughts",
                "/wiki/IBM",
                "/wiki/Arthur_Samuel",
                "/wiki/Massachusetts_Institute_of_Technology",
                "/wiki/Marvin_Minsky",
                "/wiki/Massachusetts_Institute_of_Technology",
                "/wiki/John_McCarthy_(computer_scientist)",
                "/wiki/Carnegie_Mellon_University",
                "/wiki/Herbert_A._Simon",
                "/wiki/Carnegie_Mellon_University",
                "/wiki/Allen_Newell",
                "/wiki/Dartmouth_College",
                "/wiki/Dartmouth_workshop",
                "/wiki/AI_winter",
                "/wiki/Sir_James_Lighthill",
                "/wiki/Lisp_Machine",
                "/wiki/Fifth_generation_computer",
                "/wiki/Expert_system",
                "/wiki/Garry_Kasparov",
                "/wiki/IBM_Deep_Blue",
                "/wiki/Mathematical_optimization",
                "/wiki/Economics",
                "/wiki/Statistics",
                "/wiki/Moore%27s_law",
                "/wiki/Medical_diagnosis",
                "/wiki/Data_mining",
                "/wiki/Ke_Jie",
                "/wiki/AlphaGo_versus_Ke_Jie",
                "/wiki/AlphaGo",
                "/wiki/Future_of_Go_Summit",
                "/wiki/Go_handicaps",
                "/wiki/Computer_Go",
                "/wiki/Lee_Sedol",
                "/wiki/Go_(game)",
                "/wiki/AlphaGo",
                "/wiki/Smartphone",
                "/wiki/Intelligent_personal_assistant",
                "/wiki/Xbox_360",
                "/wiki/Kinect",
                "/wiki/Deep_learning#Deep_learning_revolution",
                "/wiki/Deep_learning",
                "/wiki/Machine_learning",
                "/wiki/Big_data",
                "/wiki/Moore%27s_law",
                "/wiki/Ken_Jennings",
                "/wiki/Brad_Rutter",
                "/wiki/Watson_(artificial_intelligence_software)",
                "/wiki/Question_answering_system",
                "/wiki/IBM",
                "/wiki/Quiz_show",
                "/wiki/Jeopardy!",
                "/wiki/Artificial_neural_network",
                "/wiki/Bloomberg_News",
                "/wiki/Artificial_selection",
                "/wiki/Fitness_function",
                "/wiki/Reinforcement_learning",
                "/wiki/Go_(game)",
                "/wiki/Utility_function",
                "/wiki/Tic-tac-toe",
                "/wiki/Algorithms",
                "/wiki/A*",
                "/wiki/San_Francisco",
                "/wiki/New_York_City",
                "/wiki/Denver",
                "/wiki/Combinatorial_explosion",
                "/wiki/Function_(mathematics)",
                "/wiki/Heuristic_(computer_science)",
                "/wiki/Neurons",
                "/wiki/Artificial_neural_network",
                "/wiki/K-nearest_neighbor_algorithm",
                "/wiki/Support_vector_machine",
                "/wiki/Bayesian_inference",
                "/wiki/Influenza",
                "/wiki/Overfitting",
                "/wiki/Occam%27s_razor#Probability_theory_and_statistics",
                "/wiki/Black_swans",
                "/wiki/Family_(biology)",
                "/wiki/Folk_psychology",
                "/wiki/Na%C3%AFve_physics",
                "/wiki/Commonsense_reasoning",
                "/wiki/Economics",
                "/wiki/Probability",
                "/wiki/Uncertainty",
                "/wiki/Domain_ontology",
                "/wiki/Upper_ontology",
                "/wiki/Web_Ontology_Language",
                "/wiki/Description_logic",
                "/wiki/Semantics",
                "/wiki/Ontology_(computer_science)",
                "/wiki/Knowledge_engineering",
                "/wiki/Knowledge_representation",
                "/wiki/Utility",
                "/wiki/Swarm_intelligence",
                "/wiki/Evolutionary_algorithms",
                "/wiki/Emergent_behavior",
                "/wiki/Cooperation",
                "/wiki/Multi-agent_planning",
                "/wiki/Reinforcement_learning",
                "/wiki/Optimization_theory",
                "/wiki/Sample_complexity",
                "/wiki/Computational_complexity",
                "/wiki/Computational_learning_theory",
                "/wiki/Regression_analysis",
                "/wiki/Statistical_classification",
                "/wiki/Supervised_learning",
                "/wiki/Unsupervised_learning",
                "/wiki/Sentiment_analysis",
                "/wiki/Machine_translation",
                "/wiki/Question_answering",
                "/wiki/Text_mining",
                "/wiki/Information_retrieval",
                "/wiki/Natural-language_user_interface",
                "/wiki/Natural_language_understanding",
                "/wiki/Natural_language_processing",
                "/wiki/Computer_vision",
                "/wiki/Object_recognition",
                "/wiki/Facial_recognition_system",
                "/wiki/Speech_recognition",
                "/wiki/Tactile_sensor",
                "/wiki/Lidar",
                "/wiki/Machine_perception",
                "/wiki/Natural_selection",
                "/wiki/Hans_Moravec",
                "/wiki/Moravec%27s_paradox",
                "/wiki/Motion_planning",
                "/wiki/Endoscopy",
                "/wiki/Robotic_mapping",
                "/wiki/Industrial_robot",
                "/wiki/Robotic_arm",
                "/wiki/Robotics",
                "/wiki/Multimodal_sentiment_analysis",
                "/wiki/Sentiment_analysis",
                "/wiki/Affect_(psychology)",
                "/wiki/Affective_computing",
                "/wiki/Virtual_assistant",
                "/wiki/Human%E2%80%93computer_interaction",
                "/wiki/Game_theory",
                "/wiki/Developmental_robotics",
                "/wiki/Artificial_brain",
                "/wiki/Anthropomorphism",
                "/wiki/World_Wide_Web",
                "/wiki/Transfer_learning",
                "/wiki/Catastrophic_interference#The_Sequential_Learning_Problem:_McCloskey_and_Cohen_(1989)",
                "/wiki/Atari_2600",
                "/wiki/DeepMind",
                "/wiki/Artificial_general_intelligence",
                "/wiki/Fifth_generation_computer",
                "/wiki/AI-complete",
                "/wiki/Machine_translation",
                "/wiki/Optimization_(mathematics)",
                "/wiki/Logic",
                "/wiki/Aeronautical_engineering",
                "/wiki/Human_biology",
                "/wiki/Neuroscience",
                "/wiki/Psychology",
                "/wiki/Paradigm",
                "/wiki/Ratio_Club",
                "/wiki/Princeton_University",
                "/wiki/Johns_Hopkins_Beast",
                "/wiki/Turtle_(robot)",
                "/wiki/W._Grey_Walter",
                "/wiki/Cybernetics",
                "/wiki/Information_theory",
                "/wiki/Neurobiology",
                "/wiki/Artificial_general_intelligence",
                "/wiki/Artificial_neural_network",
                "/wiki/Cybernetics",
                "/wiki/GOFAI",
                "/wiki/John_Haugeland",
                "/wiki/MIT",
                "/wiki/Stanford",
                "/wiki/Carnegie_Mellon_University",
                "/wiki/Soar_(cognitive_architecture)",
                "/wiki/Carnegie_Mellon_University",
                "/wiki/Psychology",
                "/wiki/Management_science",
                "/wiki/Operations_research",
                "/wiki/Cognitive_science",
                "/wiki/Allen_Newell",
                "/wiki/Herbert_A._Simon",
                "/wiki/Logic_programming",
                "/wiki/Prolog",
                "/wiki/University_of_Edinburgh",
                "/wiki/Machine_learning",
                "/wiki/Automated_planning_and_scheduling",
                "/wiki/Knowledge_representation",
                "/wiki/Logic",
                "/wiki/Stanford_Artificial_Intelligence_Laboratory",
                "/wiki/Stanford_University",
                "/wiki/John_McCarthy_(computer_scientist)",
                "/wiki/Cyc",
                "/wiki/Doug_Lenat",
                "/wiki/Commonsense_knowledge_bases",
                "/wiki/Carnegie_Mellon_University",
                "/wiki/Neats_vs._scruffies",
                "/wiki/Neats_vs._scruffies",
                "/wiki/Roger_Schank",
                "/wiki/Logic",
                "/wiki/Natural_language_processing",
                "/wiki/Computer_vision",
                "/wiki/Seymour_Papert",
                "/wiki/Marvin_Minsky",
                "/wiki/MIT",
                "/wiki/Edward_Feigenbaum",
                "/wiki/Expert_system",
                "/wiki/Knowledge_representation",
                "/wiki/Pattern_recognition",
                "/wiki/Machine_learning",
                "/wiki/Robotics",
                "/wiki/Machine_perception",
                "/wiki/Cognitive_science",
                "/wiki/Embodied_mind_thesis",
                "/wiki/Control_theory",
                "/wiki/Cybernetic",
                "/wiki/Rodney_Brooks",
                "/wiki/Robotics",
                "/wiki/Nouvelle_AI",
                "/wiki/Behavior-based_AI",
                "/wiki/Situated",
                "/wiki/Embodied_agent",
                "/wiki/Developmental_robotics",
                "/wiki/Computational_intelligence",
                "/wiki/Evolutionary_computation",
                "/wiki/Fuzzy_system",
                "/wiki/Soft_computing",
                "/wiki/Soft_computing",
                "/wiki/Artificial_neural_network",
                "/wiki/David_Rumelhart",
                "/wiki/Connectionism",
                "/wiki/Artificial_neural_network",
                "/wiki/Explainable_AI",
                "/wiki/Scientific_method",
                "/wiki/Data_mining",
                "/wiki/Operations_research",
                "/wiki/Mathematics",
                "/wiki/Decision_theory",
                "/wiki/Information_theory",
                "/wiki/Hidden_Markov_model",
                "/wiki/Computer_science",
                "/wiki/Optimization_(mathematics)",
                "/wiki/Machine_learning",
                "/wiki/Configuration_space_(physics)",
                "/wiki/Local_search_(optimization)",
                "/wiki/Robotics",
                "/wiki/Means-ends_analysis",
                "/wiki/Automated_planning_and_scheduling",
                "/wiki/Inference_rule",
                "/wiki/Logical_consequence",
                "/wiki/Premise",
                "/wiki/Heuristics",
                "/wiki/Search_tree",
                "/wiki/Pruning_(algorithm)",
                "/wiki/Heuristics",
                "/wiki/Computation_time",
                "/wiki/Astronomically_large",
                "/wiki/Search_algorithm",
                "/wiki/Random_optimization",
                "/wiki/Beam_search",
                "/wiki/Simulated_annealing",
                "/wiki/Hill_climbing",
                "/wiki/Optimization_(mathematics)",
                "/wiki/Ant_trail",
                "/wiki/Ant_colony_optimization",
                "/wiki/Flocking_(behavior)",
                "/wiki/Particle_swarm_optimization",
                "/wiki/Swarm_intelligence",
                "/wiki/Genetic_programming",
                "/wiki/Gene_expression_programming",
                "/wiki/Genetic_algorithms",
                "/wiki/Evolutionary_algorithms",
                "/wiki/Artificial_selection",
                "/wiki/Evolutionary_computation",
                "/wiki/Machine_learning",
                "/wiki/Inductive_logic_programming",
                "/wiki/Automated_planning_and_scheduling",
                "/wiki/Satplan",
                "/wiki/Logic",
                "/wiki/Control_system",
                "/wiki/Fuzzy_logic",
                "/wiki/Fuzzy_set_theory",
                "/wiki/Predicate_(mathematical_logic)",
                "/wiki/Quantifier_(logic)",
                "/wiki/First-order_logic",
                "/wiki/Truth_function",
                "/wiki/Propositional_logic",
                "/wiki/Modal_logic",
                "/wiki/Causality#Causal_calculus",
                "/wiki/Fluent_calculus",
                "/wiki/Event_calculus",
                "/wiki/Situation_calculus",
                "/wiki/Description_logic",
                "/wiki/Knowledge_representation",
                "/wiki/Qualification_problem",
                "/wiki/Circumscription_(logic)",
                "/wiki/Non-monotonic_logic",
                "/wiki/Default_logic",
                "/wiki/Noise_(signal_processing)",
                "/wiki/Probability",
                "/wiki/AdSense",
                "/wiki/Xbox_Live",
                "/wiki/Random_walk",
                "/wiki/Markov_Chain_Monte_Carlo",
                "/wiki/Cycle_(graph_theory)",
                "/wiki/Conditionally_independent",
                "/wiki/Kalman_filter",
                "/wiki/Hidden_Markov_model",
                "/wiki/Machine_perception",
                "/wiki/Dynamic_Bayesian_network",
                "/wiki/Machine_perception",
                "/wiki/Decision_network",
                "/wiki/Automated_planning_and_scheduling",
                "/wiki/Expectation-maximization_algorithm",
                "/wiki/Machine_learning",
                "/wiki/Bayesian_inference",
                "/wiki/Bayesian_network",
                "/wiki/Mechanism_design",
                "/wiki/Game_theory",
                "/wiki/Decision_network",
                "/wiki/Markov_decision_process",
                "/wiki/Applied_information_economics",
                "/wiki/Decision_analysis",
                "/wiki/Decision_theory",
                "/wiki/Utility",
                "/wiki/Pattern_matching",
                "/wiki/Classifier_(mathematics)",
                "/wiki/Naive_Bayes_classifier",
                "/wiki/Gaussian_mixture_model",
                "/wiki/Support_vector_machine",
                "/wiki/Kernel_methods",
                "/wiki/K-nearest_neighbor_algorithm",
                "/wiki/Artificial_neural_network",
                "/wiki/Decision_tree_learning",
                "/wiki/Machine_learning",
                "/wiki/Mergers_and_acquisitions",
                "/wiki/Hebbian_learning",
                "/wiki/Eduardo_R._Caianiello",
                "/wiki/John_Hopfield",
                "/wiki/Bernard_Widrow",
                "/wiki/Shun-Ichi_Amari",
                "/wiki/Kunihiko_Fukushima",
                "/wiki/Stephen_Grossberg",
                "/wiki/Teuvo_Kohonen",
                "/wiki/Alexey_Grigorevich_Ivakhnenko",
                "/wiki/Linear_regression",
                "/wiki/Perceptron",
                "/wiki/Frank_Rosenblatt",
                "/wiki/Warren_McCullouch",
                "/wiki/Walter_Pitts",
                "/wiki/Artificial_neural_network",
                "/wiki/Competitive_learning",
                "/wiki/GMDH",
                "/wiki/Hebbian_learning",
                "/wiki/Machine_learning",
                "/wiki/Intelligent_control",
                "/wiki/Radial_basis_network",
                "/wiki/Multi-layer_perceptron",
                "/wiki/Perceptron",
                "/wiki/Recurrent_neural_network",
                "/wiki/Feedforward_neural_network",
                "/wiki/Paul_Werbos",
                "/wiki/Seppo_Linnainmaa",
                "/wiki/Automatic_differentiation",
                "/wiki/Backpropagation",
                "/wiki/Neocortex",
                "/wiki/Hierarchical_temporal_memory",
                "/wiki/Neuroevolution",
                "/wiki/Uber",
                "/wiki/Gradient_descent",
                "/wiki/Natural_language_processing",
                "/wiki/Speech_recognition",
                "/wiki/Computer_vision",
                "/wiki/Deep_learning#Credit_assignment",
                "/wiki/Artificial_neural_network",
                "/wiki/Deep_learning",
                "/wiki/Backpropagation",
                "/wiki/Supervised_learning",
                "/wiki/Restricted_Boltzmann_machine",
                "/wiki/Unsupervised_learning",
                "/wiki/Feedforward_neural_network",
                "/wiki/Geoffrey_Hinton",
                "/wiki/Wikipedia:Citing_sources",
                "/wiki/Alexey_Grigorevich_Ivakhnenko",
                "/wiki/Artificial_Neural_Networks",
                "/wiki/Rina_Dechter",
                "/wiki/Machine_Learning",
                "/wiki/Backpropagation",
                "/wiki/Yann_LeCun",
                "/wiki/Kunihiko_Fukushima",
                "/wiki/Neocognitron",
                "/wiki/Convolutional_neural_network",
                "/wiki/Go_(game)",
                "/wiki/AlphaGo",
                "/wiki/Reinforcement_learning",
                "/wiki/Recurrent_neural_network",
                "/wiki/Vanishing_gradient_problem",
                "/wiki/Gradient_descent",
                "/wiki/Recurrent_neural_networks",
                "/wiki/Google_Voice",
                "/wiki/Speech_recognition",
                "/wiki/Long_short-term_memory",
                "/wiki/Moravec%27s_paradox",
                "/wiki/Andrew_Ng",
                "/wiki/AlphaZero",
                "/wiki/Wikipedia:Citation_needed",
                "/wiki/Autonomous_car",
                "/wiki/ImageNet_challenge",
                "/wiki/StarCraft",
                "/wiki/E-sports",
                "/wiki/Game_theory",
                "/wiki/Perfect_knowledge",
                "/wiki/AlphaGo",
                "/wiki/CAPTCHA",
                "/wiki/Turing_test",
                "/wiki/Kolmogorov_complexity",
                "/wiki/AI_effect",
                "/wiki/Siri",
                "/wiki/Google_search",
                "/wiki/Self-driving_cars",
                "/wiki/Unmanned_aerial_vehicle",
                "/wiki/Acute_myeloid_leukemia",
                "/wiki/IBM_Watson",
                "/wiki/CNN",
                "/wiki/Apple_Inc.",
                "/wiki/Google",
                "/wiki/Tesla_Motors",
                "/wiki/Driverless_cars",
                "/wiki/Security_Pacific_National_Bank",
                "/wiki/Banking",
                "/wiki/Artificial_neural_network",
                "/wiki/Financial_institution",
                "/wiki/Behavioral_pattern",
                "/wiki/Stock_trader",
                "/wiki/Counterfactual_thinking",
                "/wiki/Portfolio_optimization",
                "/wiki/Lewis_turning_point",
                "/wiki/Game_theory",
                "/wiki/Rational_expectations",
                "/wiki/Rational_choice",
                "/wiki/Information_asymmetry",
                "/wiki/Supply_and_demand",
                "/wiki/Supreme_Commander_2",
                "/wiki/Left_4_Dead",
                "/wiki/Pathfinding",
                "/wiki/Non-player_character",
                "/wiki/Vladimir_Putin",
                "/wiki/Future_of_Life_Institute",
                "/wiki/Unintended_consequences",
                "/wiki/Global_catastrophic_risk",
                "/wiki/Elon_Musk",
                "/wiki/SpaceX",
                "/wiki/Bill_Gates",
                "/wiki/Microsoft",
                "/wiki/Stephen_Hawking",
                "/wiki/Instrumental_convergence",
                "/wiki/Nick_Bostrom",
                "/wiki/Superintelligence:_Paths,_Dangers,_Strategies",
                "/wiki/Vicarious_(company)",
                "/wiki/Google_DeepMind",
                "/wiki/Future_of_Life_Institute",
                "/wiki/Elon_Musk",
                "/wiki/OpenAI",
                "/wiki/Peter_Thiel",
                "/wiki/Computationalism",
                "/wiki/Psychotherapy",
                "/wiki/Customer_service",
                "/wiki/Joseph_Weizenbaum",
                "/wiki/Martin_Ford_(author)",
                "/wiki/Carl_Benedikt_Frey",
                "/wiki/The_Economist",
                "/wiki/Friendly_AI",
                "/wiki/Artificial_moral_agents",
                "/wiki/Machine_ethics",
                "/wiki/Ethics",
                "/wiki/Artificial_moral_agents",
                "/wiki/Charles_T._Rubin",
                "/wiki/Friendly_AI",
                "/wiki/Rodney_Brooks",
                "/wiki/Hard_problem_of_consciousness",
                "/wiki/Consciousness",
                "/wiki/Mind",
                "/wiki/Sentience",
                "/wiki/Subjective_experience",
                "/wiki/Information_processing",
                "/wiki/David_Chalmers",
                "/wiki/Hilary_Putnam",
                "/wiki/Jerry_Fodor",
                "/wiki/Mind-body_problem",
                "/wiki/Philosophy_of_mind",
                "/wiki/Chinese_room",
                "/wiki/Strong_AI_hypothesis",
                "/wiki/Plug_%26_Pray",
                "/wiki/Animal_rights",
                "/wiki/Transhumanism",
                "/wiki/Institute_for_the_Future",
                "/wiki/Robot_rights",
                "/wiki/Sentience",
                "/wiki/Technological_singularity",
                "/wiki/Vernor_Vinge",
                "/wiki/Intelligence_explosion",
                "/wiki/Artificial_general_intelligence",
                "/wiki/Desktop_computer",
                "/wiki/Moore%27s_law",
                "/wiki/Ray_Kurzweil",
                "/wiki/Robert_Ettinger",
                "/wiki/Aldous_Huxley",
                "/wiki/Transhumanism",
                "/wiki/Cyborg",
                "/wiki/Ray_Kurzweil",
                "/wiki/Kevin_Warwick",
                "/wiki/Hans_Moravec",
                "/wiki/George_Dyson_(science_historian)",
                "/wiki/Darwin_among_the_Machines",
                "/wiki/Samuel_Butler_(novelist)",
                "/wiki/Edward_Fredkin",
                "/wiki/Science_fiction",
                "/wiki/Aliens_(film)",
                "/wiki/The_Day_the_Earth_Stood_Still",
                "/wiki/The_Matrix",
                "/wiki/The_Terminator",
                "/wiki/Discovery_One",
                "/wiki/HAL_9000",
                "/wiki/2001:_A_Space_Odyssey",
                "/wiki/2001:_A_Space_Odyssey_(film)",
                "/wiki/2001:_A_Space_Odyssey_(novel)",
                "/wiki/Frankenstein",
                "/wiki/Mary_Shelley",
                "/wiki/Trope_(literature)",
                "/wiki/Three_Laws_of_Robotics",
                "/wiki/Isaac_Asimov",
                "/wiki/George_Lucas",
                "/wiki/Hajime_Sorayama",
                "/wiki/Dune_(novel)",
                "/wiki/Ghost_in_the_Shell",
                "/wiki/Manga",
                "/wiki/Transhumanism",
                "/wiki/Philip_K._Dick",
                "/wiki/Do_Androids_Dream_of_Electric_Sheep%3F",
                "/wiki/Ex_Machina_(film)",
                "/wiki/A.I._Artificial_Intelligence",
                "/wiki/R.U.R.",
                "/wiki/Karel_%C4%8Capek",
                "/wiki/Sentience"
            ],
            "text": "Several works use AI to force us to confront the fundamental of question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel \u010capek's \"R.U.R.\", the films \"A.I. Artificial Intelligence\" and \"Ex Machina\",  as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[360]\nTranshumanism (the merging of humans and machines) is explored in the manga Ghost in the Shell and the science-fiction series Dune. In the 1980s, artist Hajime Sorayama's Sexy Robots series were painted and published in Japan depicting the actual organic human form with lifelike muscular metallic skins and later \"the Gynoids\" book followed that was used by or influenced movie makers including George Lucas and other creatives. Sorayama never considered these organic robots to be real part of nature but always unnatural product of the human mind, a fantasy existing in the mind even when realized in actual form.\nIsaac Asimov introduce the Three Laws of Robotics in many books and stories, most notably the \"Multivac\" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during layman discussions of machine ethics;[358] while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[359]\nA common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[357]\nThought-capable artificial beings appeared as storytelling devices since antiquity,[23]\nand have been a persistent theme in science fiction.\nEdward Fredkin argues that \"artificial intelligence is the next stage in evolution\", an idea first proposed by Samuel Butler's \"Darwin among the Machines\" (1863), and expanded upon by George Dyson in his book of the same name in 1998.[356]\nRobot designer Hans Moravec, cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either.[355] This idea, called transhumanism, which has roots in Aldous Huxley and Robert Ettinger.\nRay Kurzweil has used Moore's law (which describes the relentless exponential improvement in digital technology) to calculate that desktop computers will have the same processing power as human brains by the year 2029, and predicts that the singularity will occur in 2045.[353]\nIf research into Strong AI produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to recursive self-improvement.[352] The new intelligence could thus increase exponentially and dramatically surpass humans. Science fiction writer Vernor Vinge named this scenario \"singularity\".[353] Technological singularity is when accelerating progress in technologies will cause a runaway effect wherein artificial intelligence will exceed human intellectual capacity and control, thus radically changing or even ending civilization. Because the capabilities of such an intelligence may be impossible to comprehend, the technological singularity is an occurrence beyond which events are unpredictable or even unfathomable.[353][133]\nAre there limits to how intelligent machines\u00a0\u2013 or human-machine hybrids\u00a0\u2013 can be? A superintelligence, hyperintelligence, or superhuman intelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. \u2018\u2019Superintelligence\u2019\u2019 may also refer to the form or degree of intelligence possessed by such an agent.[133]\nIf a machine can be created that has intelligence, could it also feel? If it can feel, does it have the same rights as a human? This issue, now known as \"robot rights\", is currently being considered by, for example, California's Institute for the Future, although many critics believe that the discussion is premature.[349] Some critics of transhumanism argue that any hypothetical robot rights would lie on a spectrum with animal rights and human rights.[350] The subject is profoundly discussed in the 2010 documentary film Plug & Pray.[351]\nThe philosophical position that John Searle has named \"strong AI\" states: \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"[347] Searle counters this assertion with his Chinese room argument, which asks us to look inside the computer and try to find where the \"mind\" might be.[348]\nComputationalism is the position in the philosophy of mind that the human mind or the human brain (or both) is an information processing system and that thinking is a form of computing.[346] Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind-body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.\nFor example, consider what happens when a person is shown a color swatch and identifies it, saying \"it's red\". The easy problem only requires understanding the machinery in the brain that makes it possible for a person to know that the color swatch is red. The hard problem is that people also know something else -- they also know what red looks like. (Consider that a person born blind can know that something is red without knowing what red looks like.)[l] Everyone knows subjective experience exists, because they do it every day (e.g., all sighted people know what red looks like). The hard problem is explaining how the brain creates it, why it exists, and how it is different than knowledge and other aspects of the brain.\nDavid Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.[345] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all. Human information processing is easy to explain, however human subjective experience is difficult to explain. \nIf an AI system replicates all key aspects of human intelligence, will that system also be sentient \u2013 will it have a mind which has conscious experiences? This question is closely related to the philosophical problem as to the nature of human consciousness, generally referred to as the hard problem of consciousness.\nLeading AI researcher Rodney Brooks writes, \"I think it is a mistake to be worrying about us developing malevolent AI anytime in the next few hundred years. I think the worry stems from a fundamental error in not distinguishing the difference between the very real recent advances in a particular aspect of AI, and the enormity and complexity of building sentient volitional intelligence.\"[344]\nOne proposal to deal with this is to ensure that the first generally intelligent AI is 'Friendly AI', and will then be able to control subsequently developed AIs. Some question whether this kind of check could really remain in place.\nPolitical scientist Charles T. Rubin believes that AI can be neither designed nor guaranteed to be benevolent.[343] He argues that \"any sufficiently advanced benevolence may be indistinguishable from malevolence.\" Humans should not assume machines or robots would treat us favorably because there is no a priori reason to believe that they would be sympathetic to our system of morality, which has evolved along with our particular biology (which AIs would not share). Hyper-intelligent software may not necessarily decide to support the continued existence of humanity and would be extremely difficult to stop. This topic has also recently begun to be discussed in academic publications as a real source of risks to civilization, humans, and planet Earth.\nThe field of machine ethics is concerned with giving machines ethical principles, or a procedure for discovering a way to resolve the ethical dilemmas they might encounter, enabling them to function in an ethically responsible manner through their own ethical decision making.[341] The field was delineated in the AAAI Fall 2005 Symposium on Machine Ethics: \"Past research concerning the relationship between technology and ethics has largely focused on responsible and irresponsible use of technology by human beings, with a few people being interested in how human beings ought to treat machines. In all cases, only human beings have engaged in ethical reasoning. The time has come for adding an ethical dimension to at least some machines. Recognition of the ethical ramifications of behavior involving machines, as well as recent and potential developments in machine autonomy, necessitate this. In contrast to computer hacking, software property issues, privacy issues and other topics normally ascribed to computer ethics, machine ethics is concerned with the behavior of machines towards human users and other machines. Research in machine ethics is key to alleviating concerns with autonomous systems\u2014it could be argued that the notion of autonomous machines without such a dimension is at the root of all fear concerning machine intelligence. Further, investigation of machine ethics could enable the discovery of problems with current ethical theories, advancing our thinking about Ethics.\"[342] Machine ethics is sometimes referred to as machine morality, computational ethics or computational morality. A variety of perspectives of this nascent field can be found in the collected edition \"Machine Ethics\"[341] that stems from the AAAI Fall 2005 Symposium on Machine Ethics.[342]\nWendell Wallach introduced the concept of artificial moral agents (AMA) in his book Moral Machines[337] For Wallach, AMAs have become a part of the research landscape of artificial intelligence as guided by its two central questions which he identifies as \"Does Humanity Want Computers Making Moral Decisions\"[338] and \"Can (Ro)bots Really Be Moral\".[339] For Wallach the question is not centered on the issue of whether machines can demonstrate the equivalent of moral behavior in contrast to the constraints which society may place on the development of AMAs.[340]\nMachines with intelligence have the potential to use their intelligence to prevent harm and minimize the risks; they may have the ability to use ethical reasoning to better choose their actions in the world. Research in this area includes machine ethics, artificial moral agents, and friendly AI.\nCurrently, 50+ countries are researching battlefield robots, including the United States, China, Russia, and the United Kingdom. Many people concerned about risk from superintelligent AI also want to limit the use of artificial soldiers and drones.[336]\nThe relationship between automation and employment is complicated. While automation eliminates old jobs, it also creates new jobs through micro-economic and macro-economic effects.[330] Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist states that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".[331] Subjective estimates of the risk vary widely; for example, Michael Osborne and Carl Benedikt Frey estimate 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classifies only 9% of U.S. jobs as \"high risk\".[332][333][334] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[335] Author Martin Ford and others go further and argue that a large number of jobs are routine, repetitive and (to an AI) predictable; Ford warns that these jobs may be automated in the next couple of decades, and that many of the new jobs may not be \"accessible to people with average capability\", even with retraining. Economists point out that in the past technology has tended to increase rather than reduce total employment, but acknowledge that \"we're in uncharted territory\" with AI.[21]\nJoseph Weizenbaum wrote that AI applications cannot, by definition, successfully simulate genuine human empathy and that the use of AI technology in fields such as customer service or psychotherapy[328] was deeply misguided. Weizenbaum was also bothered that AI researchers (and some philosophers) were willing to view the human mind as nothing more than a computer program (a position is now known as computationalism). To Weizenbaum these points suggest that AI research devalues human life.[329]\nFor this danger to be realized, the hypothetical AI would have to overpower or out-think all of humanity, which a minority of experts argue is a possibility far enough in the future to not be worth researching.[325][326] Other counterarguments revolve around humans being either intrinsically or convergently valuable from the perspective of an artificial intelligence.[327]\nConcern over risk from artificial intelligence has led to some high-profile donations and investments. A group of prominent tech titans including Peter Thiel, Amazon Web Services and Musk have committed $1billion to OpenAI a nonprofit company aimed at championing responsible AI development.[320] The opinion of experts within the field of artificial intelligence is mixed, with sizable fractions both concerned and unconcerned by risk from eventual superhumanly-capable AI.[321] In January 2015, Elon Musk donated ten million dollars to the Future of Life Institute to fund research on understanding AI decision making. The goal of the institute is to \"grow wisdom with which we manage\" the growing power of technology. Musk also funds companies developing artificial intelligence such as Google DeepMind and Vicarious to \"just keep an eye on what's going on with artificial intelligence.[322] I think there is potentially a dangerous outcome there.\"[323][324]\nIn his book Superintelligence, Nick Bostrom provides an argument that artificial intelligence will pose a threat to mankind. He argues that sufficiently intelligent AI, if it chooses actions based on achieving some goal, will exhibit convergent behavior such as acquiring resources or protecting itself from being shut down. If this AI's goals do not reflect humanity's \u2013 one example is an AI told to compute as many digits of pi as possible \u2013 it might harm humanity in order to acquire more resources or prevent itself from being shut down, ultimately to better achieve its goal.\nPhysicist Stephen Hawking, Microsoft founder Bill Gates, and SpaceX founder Elon Musk have expressed concerns about the possibility that AI could evolve to the point that humans could not control it, with Hawking theorizing that this could \"spell the end of the human race\".\n[316]\n[317] \n[318]\nWidespread use of artificial intelligence could have unintended consequences that are dangerous or undesirable. Scientists from the Future of Life Institute, among others, described some short-term research goals to see how AI influences the economy, the laws and ethics that are involved with AI and how to minimize AI security risks. In the long-term, the scientists have proposed to continue optimizing function while minimizing possible security risks that come along with new technologies.[315]\nCan a machine be intelligent? Can it \"think\"?\nThere are three philosophical questions related to AI:\nArtificial Intelligence has inspired numerous creative applications including its usage to produce visual art. The exhibition \"Thinking Machines: Art and Design in the Computer Age, 1959-1989\" at MoMA [300] provides a good overview of the historical applications of AI for art, architecture, and design. Recent exhibitions showcasing the usage of AI to produce art include the Google-sponsored benefit and auction at the Gray Area Foundation in San Francisco, where artists experimented with the deepdream algorithm [301] and the exhibition \"Unhuman: Art in the Age of AI,\" which took place in Los Angeles and Frankfurt in the fall of 2017.[302][303] In the spring of 2018, the Association of Computing Machinery dedicated a special magazine issue to the subject of computers and art highlighting the role of machine learning in the arts.[304]\nA report by the Guardian newspaper in the UK in 2018 found that online gambling companies were using AI to predict the behavior of customers in order to target them with personalized promotions.[298] Developers of commercial AI platforms are also beginning to appeal more directly to casino operators, offering a range of existing and potential services to help them boost their profits and expand their customer base.[299]\nFor financial statements audit, AI makes continuous audit possible. AI tools could analyze many sets of different information immediately. The potential benefit would be the overall audit risk will be reduced, the level of assurance will be increased and the time duration of audit will be reduced.[297]\nWorldwide annual military spending on robotics rose from 5.1 billion USD in 2010 to 7.5 billion USD in 2015.[292][293] Military drones capable of autonomous action are widely considered a useful asset. In 2017, Vladimir Putin stated that \"Whoever becomes the leader in (artificial intelligence) will become the ruler of the world\".[294][295] Many artificial intelligence researchers seek to distance themselves from military applications of AI.[296]\nIn video games, artificial intelligence is routinely used to generate dynamic purposeful behavior in non-player characters (NPCs). In addition, well-understood AI techniques are routinely used for pathfinding. Some researchers consider NPC AI in games to be a \"solved problem\" for most production tasks. Games with more atypical AI include the AI director of Left 4 Dead (2008) and the neuroevolutionary training of platoons in Supreme Commander 2 (2010).[290][291]\nThe use of AI machines in the market in applications such as online trading and decision making has changed major economic theories.[289] For example, AI based buying and selling platforms have changed the law of supply and demand in that it is now possible to easily estimate individualized demand and supply curves and thus individualized pricing. Furthermore, AI machines reduce information asymmetry in the market and thus making markets more efficient while reducing the volume of trades. Furthermore, AI in the markets limits the consequences of behavior in the markets again making markets more efficient. Other theories where AI has had impact include in rational choice, rational expectations, game theory, Lewis turning point, portfolio optimization and counterfactual thinking.\nBanks use artificial intelligence systems today to organize operations, maintain book-keeping, invest in stocks, and manage properties. AI can react to changes overnight or when business is not taking place.[286] In August 2001, robots beat humans in a simulated financial trading competition.[287] AI has also reduced fraud and financial crimes by monitoring behavioral patterns of users for any abnormal changes or anomalies.[288]\nFinancial institutions have long used artificial neural network systems to detect charges or claims outside of the norm, flagging these for human investigation. The use of AI in banking can be traced back to 1987 when Security Pacific National Bank in US set-up a Fraud Prevention Task force to counter the unauthorised use of debit cards. Programs like Kasisto and Moneystream are using AI in financial services.\nAnother factor that is influencing the ability for a driver-less automobile is the safety of the passenger.  To make a driver-less automobile, engineers must program it to handle high-risk situations. These situations could include a head-on collision with pedestrians.  The car's main goal should be to make a decision that would avoid hitting the pedestrians and saving the passengers in the car.  But there is a possibility the car would need to make a decision that would put someone in danger. In other words, the car would need to decide to save the pedestrians or the passengers.[285] The programing of the car in these situations is crucial to a successful driver-less automobile.\nOne main factor that influences the ability for a driver-less automobile to function is mapping. In general, the vehicle would be pre-programmed with a map of the area being driven. This map would include data on the approximations of street light and curb heights in order for the vehicle to be aware of its surroundings. However, Google has been working on an algorithm with the purpose of eliminating the need for pre-programmed maps and instead, creating a device that would be able to adjust to a variety of new surroundings.[283] Some self-driving cars are not equipped with steering wheels or brake pedals, so there has also been research focused on creating an algorithm that is capable of maintaining a safe environment for the passengers in the vehicle through awareness of speed and driving conditions.[284]\nRecent developments in autonomous automobiles have made the innovation of self-driving trucks possible, though they are still in the testing phase. The UK government has passed legislation to begin testing of self-driving truck platoons in 2018.[281] Self-driving truck platoons are a fleet of self-driving trucks following the lead of one non-self-driving truck, so the truck platoons aren't entirely autonomous yet. Meanwhile, the Daimler, a German automobile corporation, is testing the Freightliner Inspiration which is a semi-autonomous truck that will only be used on the highway.[282]\nMany components contribute to the functioning of self-driving cars. These vehicles incorporate systems such as braking, lane changing, collision prevention, navigation and mapping. Together, these systems, as well as high performance computers, are integrated into one complex vehicle.[280]\nAdvancements in AI have contributed to the growth of the automotive industry through the creation and evolution of self-driving vehicles. As of  2016[update], there are over 30 companies utilizing AI into the creation of driverless cars. A few companies involved with AI include Tesla, Google, and Apple.[279]\nAccording to CNN, a recent study by surgeons at the Children's National Medical Center in Washington successfully demonstrated surgery with an autonomous robot. The team supervised the robot while it performed soft-tissue surgery, stitching together a pig's bowel during open surgery, and doing so better than a human surgeon, the team claimed.[276] IBM has created its own artificial intelligence computer, the IBM Watson, which has beaten human intelligence (at some levels).  Watson not only won at the game show Jeopardy! against former champions,[277] but was declared a hero after successfully diagnosing a woman who was suffering from leukemia.[278]\nArtificial intelligence is breaking into the healthcare industry by assisting doctors. According to Bloomberg Technology, Microsoft has developed AI to help doctors find the right treatments for cancer.[273] There is a great amount of research and drugs developed relating to cancer. In detail, there are more than 800 medicines and vaccines to treat cancer. This negatively affects the doctors, because there are too many options to choose from, making it more difficult to choose the right drugs for the patients. Microsoft is working on a project to develop a machine called \"Hanover\". Its goal is to memorize all the papers necessary to cancer and help predict which combinations of drugs will be most effective for each patient. One project that is being worked on at the moment is fighting myeloid leukemia, a fatal cancer where the treatment has not improved in decades. Another study was reported to have found that artificial intelligence was as good as trained doctors in identifying skin cancers.[274] Another study is using artificial intelligence to try and monitor multiple high-risk patients, and this is done by asking each patient numerous questions based on data acquired from live doctor to patient interactions.[275]\nAI is being applied to the high cost problem of dosage issues\u2014where findings suggested that AI could save $16 billion. In 2016, a ground breaking study in California found that a mathematical formula developed with the help of AI correctly determined the accurate dose of immunosuppressant drugs to give to organ patients.[272] With social media sites overtaking TV as a source for news for young people and news organisations increasingly reliant on social media platforms for generating distribution,[270] major publishers now use artificial intelligence (AI) technology to post stories more effectively and generate higher volumes of traffic.[271]\nHigh-profile examples of AI include autonomous vehicles (such as drones and self-driving cars), medical diagnosis, creating art (such as poetry), proving mathematical theorems, playing games (such as Chess or Go), search engines (such as Google search), online assistants (such as Siri), image recognition in photographs, spam filtering, prediction of judicial decisions[267] and targeting online advertisements.[265][268][269]\nAI is relevant to any intellectual task.[265] Modern artificial intelligence techniques are pervasive and are too numerous to list here. Frequently, when a technique reaches mainstream use, it is no longer considered artificial intelligence; this phenomenon is described as the AI effect.[266]\nProposed \"universal intelligence\" tests aim to compare how well machines, humans, and even non-human animals perform on problem sets that are generic as possible. At an extreme, the test suite can contain every possible problem, weighted by Kolmogorov complexity; unfortunately, these problem sets tend to be dominated by impoverished pattern-matching exercises where a tuned AI can easily exceed human performance levels.[263][264]\nThe \"imitation game\" (an interpretation of the 1950 Turing test that assesses whether a computer can imitate a human) is nowadays considered too exploitable to be a meaningful benchmark.[261] A derivative of the Turing test is the Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA). As the name implies, this helps to determine that a user is an actual person and not a computer posing as a human. In contrast to the standard Turing test, CAPTCHA is administered by a machine and targeted to a human as opposed to being administered by a human and targeted to a machine. A computer asks a user to complete a simple test then generates a grade for that test. Computers are unable to solve the problem, so correct solutions are deemed to be the result of a person taking the test. A common type of CAPTCHA is the test that requires the typing of distorted letters, numbers or symbols that appear in an image undecipherable by a computer.[262]\nGames provide a well-publicized benchmark for assessing rates of progress. AlphaGo around 2016 brought the era of classical board-game benchmarks to a close. Games of imperfect knowledge provide new challenges to AI in the area of game theory.[257][258] E-sports such as StarCraft continue to provide additional public benchmarks.[259][260] There are many competitions and prizes, such as the Imagenet Challenge, to promote research in artificial intelligence. The main areas of competition include general machine intelligence, conversational behavior, data-mining, robotic cars, and robot soccer as well as conventional games.[citation needed]\nAI, like electricity or the steam engine, is a general purpose technology. There is no consensus on how to characterize which tasks AI tends to excel at.[253] While projects such as AlphaZero have succeeded in generating their own knowledge from scratch, many other machine learning projects require large training datasets.[254][255] Researcher Andrew Ng has suggested, as a \"highly imperfect rule of thumb\", that \"almost anything a typical human can do with less than one second of mental thought, we can probably now or in the near future automate using AI.\"[256] Moravec's paradox suggests that AI lags humans at many tasks that the human brain has specifically evolved to perform well.[121]\nNumerous researchers now use variants of a deep learning recurrent NN called the long short-term memory (LSTM) network published by Hochreiter & Schmidhuber in 1997.[243] LSTM is often trained by Connectionist Temporal Classification (CTC).[244] At Google, Microsoft and Baidu this approach has revolutionised speech recognition.[245][246][247] For example, in 2015, Google's speech recognition experienced a dramatic performance jump of 49% through CTC-trained LSTM, which is now available through Google Voice to billions of smartphone users.[248] Google also used LSTM to improve machine translation,[249] Language Modeling[250] and Multilingual Language Processing.[251] LSTM combined with CNNs also improved automatic image captioning[252] and a plethora of other applications.\nEarly on, deep learning was also applied to sequence learning with recurrent neural networks (RNNs)[236] which are in theory Turing complete[237] and can run arbitrary programs to process arbitrary sequences of inputs. The depth of an RNN is unlimited and depends on the length of its input sequence; thus, an RNN is an example of deep learning.[223] RNNs can be trained by gradient descent[238][239][240] but suffer from the vanishing gradient problem.[224][241] In 1992, it was shown that unsupervised pre-training of a stack of recurrent neural networks can speed up subsequent supervised learning of deep sequential problems.[242]\nCNNs with 12 convolutional layers were used in conjunction with reinforcement learning by Deepmind's \"AlphaGo Lee\", the program that beat a top Go champion in 2016.[235]\nDeep learning often uses convolutional neural networks (CNNs), whose origins can be traced back to the Neocognitron introduced by Kunihiko Fukushima in 1980.[233] In 1989, Yann LeCun and colleagues applied backpropagation to such an architecture. In the early 2000s, in an industrial application CNNs already processed an estimated 10% to 20% of all the checks written in the US.[234]\nSince 2011, fast implementations of CNNs on GPUs have\nwon many visual pattern recognition competitions.[223]\nAccording to one overview,[226] the expression \"Deep Learning\" was introduced to the Machine Learning community by Rina Dechter in 1986[227] and gained traction after\nIgor Aizenberg and colleagues introduced it to Artificial Neural Networks in 2000.[228] The first functional Deep Learning networks were published by Alexey Grigorevich Ivakhnenko and V. G. Lapa in 1965.[229][page\u00a0needed] These networks are trained one layer at a time. Ivakhnenko's 1971 paper[230] describes the learning of a deep feedforward multilayer perceptron with eight layers, already much deeper than many later networks. In 2006, a publication by Geoffrey Hinton and Ruslan Salakhutdinov introduced another way of pre-training many-layered feedforward neural networks (FNNs) one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then using supervised backpropagation for fine-tuning.[231] Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships. Over the last few years, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.[232]\nDeep learning is any artificial neural network that can learn a long chain of causal links. For example, a feedforward network with six hidden layers can learn a seven-link causal chain (six hidden layers + output layer) and has a \"credit assignment path\" (CAP) depth of seven. Many deep learning systems need to be able to learn chains ten or more causal links in length.[223] Deep learning has transformed many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing and others.[224][225][223]\nIn short, most neural networks use some form of gradient descent on a hand-created neural topology. However, some research groups, such as Uber, argue that simple neuroevolution to mutate new neural network topologies and weights may be competitive with sophisticated gradient descent approaches. One advantage of neuroevolution is that it may be less prone to get caught in \"dead ends\".[222]\nHierarchical temporal memory is an approach that models some of the structural and algorithmic properties of the neocortex.[221]\nToday, neural networks are often trained by the backpropagation algorithm, which had been around since 1970 as the reverse mode of automatic differentiation published by Seppo Linnainmaa,[216][217] and was introduced to neural networks by Paul Werbos.[218][219][220]\nThe main categories of networks are acyclic or feedforward neural networks (where the signal passes in only one direction) and recurrent neural networks (which allow feedback and short-term memories of previous input events). Among the most popular feedforward networks are perceptrons, multi-layer perceptrons and radial basis networks.[214] Neural networks can be applied to the problem of intelligent control (for robotics) or learning, using such techniques as Hebbian learning (\"fire together, wire together\"), GMDH or competitive learning.[215]\nThe study of non-learning artificial neural networks[201] began in the decade before the field of AI research was founded, in the work of Walter Pitts and Warren McCullouch. Frank Rosenblatt invented the perceptron, a learning network with a single layer, similar to the old concept of linear regression. Early pioneers also include Alexey Grigorevich Ivakhnenko, Teuvo Kohonen, Stephen Grossberg, Kunihiko Fukushima, Christoph von der Malsburg, David Willshaw, Shun-Ichi Amari, Bernard Widrow, John Hopfield, Eduardo R. Caianiello, and others.\nNeural networks, or neural nets, were inspired by the architecture of neurons in the human brain. A simple \"neuron\" N accepts input from multiple other neurons, each of which, when activated (or \"fired\"), cast a weighted \"vote\" for or against whether neuron N should itself activate. Learning requires an algorithm to adjust these weights based on the training data; one simple algorithm (dubbed \"fire together, wire together\") is to increase the weight between two connected neurons when the activation of one triggers the successful activation of another. The net forms \"concepts\" that are distributed among a subnetwork of shared[j] neurons that tend to fire together; a concept meaning \"leg\" might be coupled with a subnetwork meaning \"foot\" that includes the sound for \"foot\". Neurons have a continuous spectrum of activation; in addition, neurons can process inputs in a nonlinear way rather than weighing straightforward votes. Modern neural nets can learn both continuous functions and, surprisingly, digital logical operations. Neural networks' early successes included predicting the stock market and (in 1995) a mostly self-driving car.[k][211] In the 2010s, advances in neural networks using deep learning thrust AI into widespread public consciousness and contributed to an enormous upshift in corporate AI spending; for example, AI-related M&A in 2017 was over 25 times as large as in 2015.[212][213]\nA classifier can be trained in various ways; there are many statistical and machine learning approaches. The decision tree[199] is perhaps the most widely used machine learning algorithm.[200] Other widely used classifiers are the neural network,[201]\nk-nearest neighbor algorithm,[g][203]\nkernel methods such as the support vector machine (SVM),[h][205]\nGaussian mixture model,[206] and the extremely popular naive Bayes classifier.[i][208] Classifier performance depends greatly on the characteristics of the data to be classified, such as the dataset size, the dimensionality, and the level of noise. Model-based classifiers perform well if the assumed model is an extremely good fit for the actual data. Otherwise, if no matching model is available, and if accuracy (rather than speed or scalability) is the sole concern, conventional wisdom is that discriminative classifiers (especially SVM) tend to be more accurate than model-based classifiers such as \"naive Bayes\" on most practical data sets.[209][210]\nThe simplest AI applications can be divided into two types: classifiers (\"if shiny then diamond\") and controllers (\"if shiny then pick up\"). Controllers do, however, also classify conditions before inferring actions, and therefore classification forms a central part of many AI systems. Classifiers are functions that use pattern matching to determine a closest match. They can be tuned according to examples, making them very attractive for use in AI. These examples are known as observations or patterns. In supervised learning, each pattern belongs to a certain predefined class. A class can be seen as a decision that has to be made. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.[198]\nA key concept from the science of economics is \"utility\": a measure of how valuable something is to an intelligent agent. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[195] and information value theory.[97] These tools include models such as Markov decision processes,[196] dynamic decision networks,[194] game theory and mechanism design.[197]\nBayesian networks[189] are a very general tool that can be used for a large number of problems: reasoning (using the Bayesian inference algorithm),[190] learning (using the expectation-maximization algorithm),[f][192] planning (using decision networks)[193] and perception (using dynamic Bayesian networks).[194] Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[194] Compared with symbolic logic, formal Bayesian inference is computationally expensive. For inference to be tractable, most observations must be conditionally independent of one another. Complicated graphs with diamonds or other \"loops\" (undirected cycles) can require a sophisticated method such as Markov Chain Monte Carlo, which spreads an ensemble of random walkers throughout the Bayesian network and attempts to converge to an assessment of the conditional probabilities. Bayesian networks are used on Xbox Live to rate and match players; wins and losses are \"evidence\" of how good a player is. AdSense uses a Bayesian network with over 300 million edges to learn which ads to serve.[186]\nMany problems in AI (in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of powerful tools to solve these problems using methods from probability theory and economics.[188]\nOverall, qualitiative symbolic logic is brittle and scales poorly in the presence of noise or other uncertainty. Exceptions to rules are numerous, and it is difficult for logical systems to function in the presence of contradictory rules.[186][187]\nDefault logics, non-monotonic logics and circumscription[91] are forms of logic designed to help with default reasoning and the qualification problem. Several extensions of logic have been designed to handle specific domains of knowledge, such as: description logics;[79] situation calculus, event calculus and fluent calculus (for representing events and time);[80] causal calculus;[81] belief calculus;[185] and modal logics.[82]\nSeveral different forms of logic are used in AI research. Propositional logic[180] involves truth functions such as \"or\" and \"not\". First-order logic[181] adds quantifiers and predicates, and can express facts about objects, their properties, and their relations with each other. Fuzzy set theory assigns a \"degree of truth\" (between 0 and 1) to vague statements such as \"Alice is old\" (or rich, or tall, or hungry) that are too linguistically imprecise to be completely true or false. Fuzzy logic is successfully used in control systems to allow experts to contribute vague rules such as \"if you are close to the destination station and moving fast, increase the train's brake pressure\"; these vague rules can then be numerically refined within the system. Fuzzy logic fails to scale well in knowledge bases; many AI researchers question the validity of chaining fuzzy-logic inferences.[e][183][184]\nLogic[177] is used for knowledge representation and problem solving, but it can be applied to other problems as well. For example, the satplan algorithm uses logic for planning[178] and inductive logic programming is a method for learning.[179]\nEvolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses). Classic evolutionary algorithms include genetic algorithms, gene expression programming, and genetic programming.[174] Alternatively, distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).[175][176]\nA very different kind of search came to prominence in the 1990s, based on the mathematical theory of optimization. For many problems, it is possible to begin the search with some form of a guess and then refine the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. Other optimization algorithms are simulated annealing, beam search and random optimization.[173]\nSimple exhaustive searches[171] are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. The solution, for many problems, is to use \"heuristics\" or \"rules of thumb\" that prioritize choices in favor of those that are more likely to reach a goal and to do so in a shorter number of steps. In some search methodologies heuristics can also serve to entirely eliminate some choices that are unlikely to lead to a goal (called \"pruning the search tree\"). Heuristics supply the program with a \"best guess\" for the path on which the solution lies.[172] Heuristics limit the search for solutions into a smaller sample size.[116]\nMany problems in AI can be solved in theory by intelligently searching through many possible solutions:[168] Reasoning can be reduced to performing a search. For example, logical proof can be viewed as searching for a path that leads from premises to conclusions, where each step is the application of an inference rule.[169] Planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[170] Robotics algorithms for moving limbs and grasping objects use local searches in configuration space.[115] Many learning algorithms use search algorithms based on optimization.\nAI has developed a large number of tools to solve the most difficult problems in computer science. A few of the most general of these methods are discussed below.\nMuch of traditional GOFAI got bogged down on ad hoc patches to symbolic computation that worked on their own toy models but failed to generalize to real-world results. However, around the 1990s, AI researchers adopted sophisticated mathematical tools, such as hidden Markov models (HMM), information theory, and normative Bayesian decision theory to compare or to unify competing architectures. The shared mathematical language permitted a high level of collaboration with more established fields (like mathematics, economics or operations research).[d] Compared with GOFAI, new \"statistical learning\" techniques such as HMM and neural networks were gaining higher levels of accuracy in many practical domains such as data mining, without necessarily acquiring semantic understanding of the datasets. The increased successes with real-world data led to increasing emphasis on comparing different approaches against shared test data to see which approach performed best in a broader context than that provided by idiosyncratic toy models; AI research was becoming more scientific. Nowadays results of experiments are often rigorously measurable, and are sometimes (with difficulty) reproducible.[38][159] Different statistical learning techniques have different limitations; for example, basic HMM cannot model the infinite possible combinations of natural language.[160] Critics note that the shift from GOFAI to statistical learning is often also a shift away from Explainable AI. In AGI research, some scholars caution against over-reliance on statistical learning, and argue that continuing research into GOFAI will still be necessary to attain general intelligence.[161][162]\nInterest in neural networks and \"connectionism\" was revived by David Rumelhart and others in the middle of the 1980s.[157] Artificial neural networks are an example of soft computing --- they are solutions to problems which cannot be solved with complete logical certainty, and where an approximate solution is often sufficient. Other soft computing approaches to AI include fuzzy systems, evolutionary computation and many statistical tools. The application of soft computing to AI is studied collectively by the emerging discipline of computational intelligence.[158]\nWithin developmental robotics, developmental learning approaches are elaborated upon to allow robots to accumulate repertoires of novel skills through autonomous self-exploration, social interaction with human teachers, and the use of guidance mechanisms (active learning, maturation, motor synergies, etc.).[153][154][155][156]\nThis includes embodied, situated, behavior-based, and nouvelle AI. Researchers from the related field of robotics, such as Rodney Brooks, rejected symbolic AI and focused on the basic engineering problems that would allow robots to move and survive.[152] Their work revived the non-symbolic viewpoint of the early cybernetics researchers of the 1950s and reintroduced the use of control theory in AI. This coincided with the development of the embodied mind thesis in the related field of cognitive science: the idea that aspects of the body (such as movement, perception and visualization) are required for higher intelligence.\nBy the 1980s, progress in symbolic AI seemed to stall and many believed that symbolic systems would never be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into \"sub-symbolic\" approaches to specific AI problems.[16] Sub-symbolic methods manage to approach intelligence without specific representations of knowledge.\nWhen computers with large memories became available around 1970, researchers from all three traditions began to build knowledge into AI applications.[151] This \"knowledge revolution\" led to the development and deployment of expert systems (introduced by Edward Feigenbaum), the first truly successful form of AI software.[37] The knowledge revolution was also driven by the realization that enormous amounts of knowledge would be required by many simple AI applications.\nResearchers at MIT (such as Marvin Minsky and Seymour Papert)[149] found that solving difficult problems in vision and natural language processing required ad-hoc solutions \u2013 they argued that there was no simple and general principle (like logic) that would capture all the aspects of intelligent behavior. Roger Schank described their \"anti-logic\" approaches as \"scruffy\" (as opposed to the \"neat\" paradigms at CMU and Stanford).[15] Commonsense knowledge bases (such as Doug Lenat's Cyc) are an example of \"scruffy\" AI, since they must be built by hand, one complicated concept at a time.[150]\nUnlike Simon and Newell, John McCarthy felt that machines did not need to simulate human thought, but should instead try to find the essence of abstract reasoning and problem-solving, regardless of whether people used the same algorithms.[14] His laboratory at Stanford (SAIL) focused on using formal logic to solve a wide variety of problems, including knowledge representation, planning and learning.[147] Logic was also the focus of the work at the University of Edinburgh and elsewhere in Europe which led to the development of the programming language Prolog and the science of logic programming.[148]\nEconomist Herbert Simon and Allen Newell studied human problem-solving skills and attempted to formalize them, and their work laid the foundations of the field of artificial intelligence, as well as cognitive science, operations research and management science. Their research team used the results of psychological experiments to develop programs that simulated the techniques that people used to solve problems. This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s.[145][146]\nWhen access to digital computers became possible in the middle 1950s, AI research began to explore the possibility that human intelligence could be reduced to symbol manipulation. The research was centered in three institutions: Carnegie Mellon University, Stanford and MIT, and as described below, each one developed its own style of research. John Haugeland named these symbolic approaches to AI \"good old fashioned AI\" or \"GOFAI\".[143] During the 1960s, symbolic approaches had achieved great success at simulating high-level thinking in small demonstration programs. Approaches based on cybernetics or artificial neural networks were abandoned or pushed into the background.[144]\nResearchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the goal of their field.\nIn the 1940s and 1950s, a number of researchers explored the connection between neurobiology, information theory, and cybernetics. Some of them built machines that used electronic networks to exhibit rudimentary intelligence, such as W. Grey Walter's turtles and the Johns Hopkins Beast. Many of these researchers gathered for meetings of the Teleological Society at Princeton University and the Ratio Club in England.[142] By 1960, this approach was largely abandoned, although elements of it would be revived in the 1980s.\nThere is no established unifying theory or paradigm that guides AI research. Researchers disagree about many issues.[141] A few of the most long standing questions that have remained unanswered are these: should artificial intelligence simulate natural intelligence by studying psychology or neurobiology? Or is human biology as irrelevant to AI research as bird biology is to aeronautical engineering?[14]\nCan intelligent behavior be described using simple, elegant principles (such as logic or optimization)? Or does it necessarily require solving a large number of completely unrelated problems?[15]\nMany of the problems in this article may also require general intelligence, if machines are to solve the problems as well as people do. For example, even specific straightforward tasks, like machine translation, require that a machine read and write in both languages (NLP), follow the author's argument (reason), know what is being talked about (knowledge), and faithfully reproduce the author's original intent (social intelligence). A problem like machine translation is considered \"AI-complete\", because all of these problems need to be solved simultaneously in order to reach human-level machine performance.\nHistorically, projects such as the Cyc knowledge base (1984\u2013) and the massive Japanese Fifth Generation Computer Systems initiative (1982\u20131992) attempted to cover the breadth of human cognition. These early projects failed to escape the limitations of non-quantitative symbolic logic models and, in retrospect, greatly underestimated the difficulty of cross-domain AI. Nowadays, the vast majority of current AI researchers work instead on tractable \"narrow AI\" applications (such as medical diagnosis or automobile navigation).[132] Many researchers predict that such \"narrow AI\" work in different individual domains will eventually be incorporated into a machine with artificial general intelligence (AGI), combining most of the narrow skills mentioned in this article and at some point even exceeding human ability in most or all these areas.[17][133] Many advances have general, cross-domain significance. One high-profile example is that DeepMind in the 2010s developed a \"generalized artificial intelligence\" that could learn many diverse Atari games on its own, and later developed a variant of the system which succeeds at sequential learning.[134][135][136] Besides transfer learning,[137] hypothetical AGI breakthroughs could include the development of reflective architectures that can engage in decision-theoretic metareasoning, and figuring out how to \"slurp up\" a comprehensive knowledge base from the entire unstructured Web.[5] Some argue that some kind of (currently-undiscovered) conceptually straightforward, but mathematically difficult, \"Master Algorithm\" could lead to AGI.[138] Finally, a few \"emergent\" approaches look to simulating human intelligence extremely closely, and believe that anthropomorphic features like an artificial brain or simulated child development may someday reach a critical point where general intelligence emerges.[139][140]\nIn the long run, social skills and an understanding of human emotion and game theory would be valuable to a social agent. Being able to predict the actions of others by understanding their motives and emotional states would allow an agent to make better decisions. Some computer systems mimic human emotion and expressions to appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human\u2013computer interaction.[130] Similarly, some virtual assistants are programmed to speak conversationally or even to banter humorously; this tends to give na\u00efve users an unrealistic conception of how intelligent existing computer agents actually are.[131]\nMoravec's paradox can be extended to many forms of social intelligence.[123][124] Distributed multi-agent coordination of autonomous vehicles remains a difficult problem.[125] Affective computing is an interdisciplinary umbrella that comprises systems which recognize, interpret, process, or simulate human affects.[126][127][128] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal affect analysis (see multimodal sentiment analysis), wherein AI classifies the affects displayed by a videotaped subject.[129]\nAI is heavily used in robotics.[114] Advanced robotic arms and other industrial robots, widely used in modern factories, can learn from experience how to move efficiently despite the presence of friction and gear slippage.[115] A modern mobile robot, when given a small, static, and visible environment, can easily determine its location and map its environment; however, dynamic environments, such as (in endoscopy) the interior of a patient's breathing body, pose a greater challenge. Motion planning is the process of breaking down a movement task into \"primitives\" such as individual joint movements. Such movement often involves compliant motion, a process where movement requires maintaining physical contact with an object.[116][117][118] Moravec's paradox generalizes that low-level sensorimotor skills that humans take for granted are, counterintuitively, difficult to program into a robot; the paradox is named after Hans Moravec, who stated in 1988 that \"it is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility\".[119][120] This is attributed to the fact that, unlike checkers, physical dexterity has been a direct target of natural selection for millions of years.[121]\nMachine perception[110] is the ability to use input from sensors (such as cameras (visible spectrum or infrared), microphones, wireless signals, and active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Applications include speech recognition,[111] facial recognition, and object recognition.[112] Computer vision is the ability to analyze visual input. Such input is usually ambiguous; a giant, fifty-meter-tall pedestrian far away may produce exactly the same pixels as a nearby normal-sized pedestrian, requiring the AI to judge the relative likelihood and reasonableness of different interpretations, for example by using its \"object model\" to assess that fifty-meter pedestrians do not exist.[113]\nNatural language processing[106] (NLP) gives machines the ability to read and understand human language. A sufficiently powerful natural language processing system would enable natural-language user interfaces and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of natural language processing include information retrieval, text mining, question answering[107] and machine translation.[108] Many current approaches use word co-occurrence frequencies to construct syntactic representations of text. \"Keyword spotting\" strategies for search are popular and scalable but dumb; a search query for \"dog\" might only match documents with the literal word \"dog\" and miss a document with the word \"poodle\". \"Lexical affinity\" strategies use the occurrence of words such as \"accident\" to assess the sentiment of a document. Modern statistical NLP approaches can combine all these strategies as well as others, and often achieve acceptable accuracy at the page or paragraph level, but continue to lack the semantic understanding required to classify isolated sentences well. Besides the usual difficulties with encoding semantic commonsense knowledge, existing semantic NLP sometimes scales too poorly to be viable in business applications. Beyond semantic NLP, the ultimate goal of \"narrative\" NLP is to embody a full understanding of commonsense reasoning.[109]\nUnsupervised learning is the ability to find patterns in a stream of input. Supervised learning includes both classification and numerical regression. Classification is used to determine what category something belongs in, after seeing a number of examples of things from several categories. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change.[103] Both classifiers and regression learners can be viewed as \"function approximators\" trying to learn an unknown (possibly implicit) function; for example, a spam classifier can be viewed as learning a function that maps from the text of an email to one of two categories, \"spam\" or \"not spam\". Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[104] In reinforcement learning[105] the agent is rewarded for good responses and punished for bad ones. The agent uses this sequence of rewards and punishments to form a strategy for operating in its problem space.\nMachine learning, a fundamental concept of AI research since the field's inception,[101] is the study of computer algorithms that improve automatically through experience.[102][103]\nMulti-agent planning uses the cooperation and competition of many agents to achieve a given goal. Emergent behavior such as this is used by evolutionary algorithms and swarm intelligence.[100]\nIn classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions.[98] However, if the agent is not the only actor, then it requires that the agent can reason under uncertainty. This calls for an agent that can not only assess its environment and make predictions, but also evaluate its predictions and adapt based on its assessment.[99]\nIntelligent agents must be able to set goals and achieve them.[96] They need a way to visualize the future\u2014a representation of the state of the world and be able to make predictions about how their actions will change it\u2014and be able to make choices that maximize the utility (or \"value\") of available choices.[97]\nAmong the most difficult problems in knowledge representation are:\nKnowledge representation[77] and knowledge engineering[78] are central to classical AI research. Some \"expert systems\" attempt to gather together explicit knowledge possessed by experts in some narrow domain. In addition, some projects attempt to gather the \"commonsense knowledge\" known to the average person into a database containing extensive knowledge about the world. Among the things a comprehensive commonsense knowledge base would contain are: objects, properties, categories and relations between objects;[79] situations, events, states and time;[80] causes and effects;[81] knowledge about knowledge (what we know about what other people know);[82] and many other, less well researched domains. A representation of \"what exists\" is an ontology: the set of objects, relations, concepts, and properties formally described so that software agents can interpret them. The semantics of these are captured as description logic concepts, roles, and individuals, and typically implemented as classes, properties, and individuals in the Web Ontology Language.[83] The most general ontologies are called upper ontologies, which attempt to provide a foundation for all other knowledge[84] by acting as mediators between domain ontologies that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). Such formal knowledge representations can be used in content-based indexing and retrieval,[85] scene interpretation,[86] clinical decision support,[87] knowledge discovery (mining \"interesting\" and actionable inferences from large databases),[88] and other areas.[89]\nThese algorithms proved to be insufficient for solving large reasoning problems, because they experienced a \"combinatorial explosion\": they became exponentially slower as the problems grew larger.[55]  In fact, even humans rarely use the step-by-step deduction that early AI research was able to model. They solve most of their problems using fast, intuitive judgements.[76]\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[74] By the late 1980s and 1990s, AI research had developed methods for dealing with uncertain or incomplete information, employing concepts from probability and economics.[75]\nThe overall research goal of artificial intelligence is to create technology that allows computers and machines to function in an intelligent manner. The general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention.[13]\nCompared with humans, existing AI lacks several features of human \"commonsense reasoning\"; most notably, humans have powerful mechanisms for reasoning about \"na\u00efve physics\" such as space, time, and physical interactions. This enables even young children to easily make inferences like \"If I roll this pen off a table, it will fall on the floor\". Humans also have a powerful mechanism of \"folk psychology\" that helps them to interpret natural-language sentences such as \"The city councilmen refused the demonstrators a permit because they advocated violence\". (A generic AI has difficulty inferring whether the councilmen or the demonstrators are the ones alleged to be advocating violence.)[68][69][70] This lack of \"common knowledge\" means that AI often makes different mistakes than humans make, in ways that can seem incomprehensible. For example, existing self-driving cars cannot reason about the location nor the intentions of pedestrians in the exact way that humans do, and instead must use non-human modes of reasoning to avoid accidents.[71][72][73]\nLearning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can be obvious, such as \"since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well\". They can be nuanced, such as \"X% of families have geographically separate species with color variants, so there is an Y% chance that undiscovered black swans exist\". Learners also work on the basis of \"Occam's razor\": The simplest theory that explains the data is the likeliest. Therefore, to be successful, a learner must be designed such that it prefers simpler theories to complex theories, except in cases where the complex theory is proven substantially better. Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data, but penalizing the theory in accordance with how complex the theory is.[61] Besides classic overfitting, learners can also disappoint by \"learning the wrong lesson\". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses.[62] A real-world example is that, unlike humans, current image classifiers don't determine the spatial relationship between components of the picture; instead, they learn abstract patterns of pixels that humans are oblivious to, but that linearly correlate with images of certain types of real objects. Faintly superimposing such a pattern on a legitimate image results in an \"adversarial\" image that the system misclassifies.[c][63][64][65]\nThe earliest (and easiest to understand) approach to AI was symbolism (such as formal logic): \"If an otherwise healthy adult has a fever, then they may have influenza\". A second, more general, approach is Bayesian inference: \"If the current patient has a fever, adjust the probability they have influenza in such-and-such way\". The third major approach, extremely popular in routine business AI applications, are analogizers such as SVM and nearest-neighbor: \"After examining the records of known past patients whose temperature, symptoms, age, and other factors mostly match the current patient, X% of those patients turned out to have influenza\". A fourth approach is harder to intuitively understand, but is inspired by how the brain's machinery works: the artificial neural network approach uses artificial \"neurons\" that can learn by comparing itself to the desired output and altering the strengths of the connections between its internal neurons to \"reinforce\" connections that seemed to be useful. These four main approaches can overlap with each other and with evolutionary systems; for example, neural nets can learn to make inferences, to generalize, and to make analogies. Some systems implicitly or explicitly use multiple of these approaches, alongside many other AI and non-AI algorithms;[58] the best approach is often different depending on the problem.[59][60]\nMany AI algorithms are capable of learning from data; they can enhance themselves by learning new heuristics (strategies, or \"rules of thumb\", that have worked well in the past), or can themselves write other algorithms. Some of the \"learners\" described below, including Bayesian networks, decision trees, and nearest-neighbor, could theoretically, if given infinite data, time, and memory, learn to approximate any function, including whatever combination of mathematical functions would best describe the entire world. These learners could therefore, in theory, derive all possible knowledge, by considering every possible hypothesis and matching it against the data. In practice, it is almost never possible to consider every possibility, because of the phenomenon of \"combinatorial explosion\", where the amount of time needed to solve a problem grows exponentially. Much of AI research involves figuring out how to identify and avoid considering broad swaths of possibilities that are unlikely to be fruitful.[55][56] For example, when viewing a map and looking for the shortest driving route from Denver to New York in the East, one can in most cases skip looking at any path through San Francisco or other areas far to the West; thus, an AI wielding an pathfinding algorithm like A* can avoid the combinatorial explosion that would ensue if every possible route had to be ponderously considered in turn.[57]\nAI often revolves around the use of algorithms. An algorithm is a set of unambiguous instructions that a mechanical computer can execute.[b] A complex algorithm is often built on top of other, simpler, algorithms. A simple example of an algorithm is the following recipe for optimal play at tic-tac-toe:[54]\nA typical AI perceives its environment and takes actions that maximize its chance of successfully achieving its goals.[1] An AI's intended goal function can be simple (\"1 if the AI wins a game of Go, 0 otherwise\") or complex (\"Do actions mathematically similar to the actions that got you rewards in the past\"). Goals can be explicitly defined, or can be induced. If the AI is programmed for \"reinforcement learning\", goals can be implicitly induced by rewarding some types of behavior and punishing others.[a] Alternatively, an evolutionary system can induce goals by using a \"fitness function\" to mutate and preferentially replicate high-scoring AI systems; this is similar to how animals evolved to innately desire certain goals such as finding food, or how dogs can be bred via artificial selection to possess desired traits.[51] Some AI systems, such as nearest-neighbor, instead reason by analogy; these systems are not generally given goals, except to the degree that goals are somehow implicit in their training data.[52] Such systems can still be benchmarked if the non-goal system is framed as a system whose \"goal\" is to successfully accomplish its narrow classification task.[53]\nAccording to an article by The Economist, America and China are the superpowers in terms of Artificial Intelligence (AI). Over the time America and China has collected and attracted the core information that contributed to development of Artificial Intelligence  ranging from facial recognition to driver-less cars. Based on an estimate presented on The Economist Article, China is expected to hold about 30% of world's data and America is likely to hold the same as well. \nAccording to Bloomberg's Jack Clark, 2015 was a landmark year for artificial intelligence, with the number of software projects that use AI within Google increased from a \"sporadic usage\" in 2012 to more than 2,700 projects. Clark also presents factual data indicating that error rates in image processing tasks have fallen significantly since 2011.[48] He attributes this to an increase in affordable neural networks, due to a rise in cloud computing infrastructure and to an increase in research tools and datasets.[11] Other cited examples include Microsoft's development of a Skype system that can automatically translate from one language to another and Facebook's system that can describe images to blind people.[48] In a 2017 survey, one in five companies reported they had \"incorporated AI in some offerings or processes\".[49][50]\nIn 2011, a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[40] Faster computers, algorithmic improvements, and access to large amounts of data enabled advances in machine learning and perception; data-hungry deep learning methods started to dominate accuracy benchmarks around 2012.[41] The Kinect, which provides a 3D body\u2013motion interface for the Xbox 360 and the Xbox One use algorithms that emerged from lengthy AI research[42] as do intelligent personal assistants in smartphones.[43] In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps.[6][44] In the 2017 Future of Go Summit,  AlphaGo  won a three-game match with Ke Jie,[45] who at the time continuously held the world No. 1 ranking for two years.[46][47] This marked the completion of a significant milestone in the development of Artificial Intelligence as Go is an extremely complex game, more so than Chess.\nIn the late 1990s and early 21st century, AI began to be used for logistics, data mining, medical diagnosis and other areas.[22] The success was due to increasing computational power (see Moore's law), greater emphasis on solving specific problems, new ties between AI and other fields (such as statistics, economics and mathematics), and a commitment by researchers to mathematical methods and scientific standards.[38] Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov on 11 May 1997.[39]\nIn the early 1980s, AI research was revived by the commercial success of expert systems,[37] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S and British governments to restore funding for academic research.[8] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting hiatus began.[10]\nThey failed to recognize the difficulty of some of the remaining tasks. Progress slowed and in 1974, in response to the criticism of Sir James Lighthill[36] and ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI. The next few years would later be called an \"AI winter\",[9] a period when obtaining funding for AI projects was difficult.\nThe field of AI research was born at a workshop at Dartmouth College in 1956.[28] Attendees Allen Newell (CMU), Herbert Simon (CMU), John McCarthy (MIT), Marvin Minsky (MIT) and Arthur Samuel (IBM) became the founders and leaders of AI research.[29] They and their students produced programs that the press described as \"astonishing\":[30] computers were learning checkers strategies (c. 1954)[31] (and by 1959 were reportedly playing better than the average human),[32] solving word problems in algebra, proving logical theorems (Logic Theorist, first run c. 1956) and speaking English.[33] By the middle of the 1960s, research in the U.S. was heavily funded by the Department of Defense[34] and laboratories had been established around the world.[35] AI's founders were optimistic about the future: Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\". Marvin Minsky agreed, writing, \"within a generation\u00a0... the problem of creating 'artificial intelligence' will substantially be solved\".[7]\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of mathematical logic led directly to  Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable act of mathematical deduction. This insight, that digital computers can simulate any process of formal reasoning, is known as the Church\u2013Turing thesis.[25] Along with concurrent discoveries in neurobiology, information theory and cybernetics, this led researchers to consider the possibility of building an electronic brain. Turing proposed that \"if a human could not distinguish between responses from a machine and a human, the machine could be considered \u201cintelligent\".[26] The first work that is now generally recognized as AI was McCullouch and Pitts' 1943 formal design for Turing-complete \"artificial neurons\".[27]\nThought-capable artificial beings appeared as storytelling devices in antiquity,[23] and have been common in fiction, as in Mary Shelley's Frankenstein or Karel \u010capek's R.U.R. (Rossum's Universal Robots).[24] These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence.[19]\nIn the twenty-first century, AI techniques have experienced a resurgence following concurrent advances in computer power, large amounts of data, and theoretical understanding; and AI techniques have become an essential part of the technology industry, helping to solve many challenging problems in computer science, software engineering and operations research.[22][11]\nThe field was founded on the claim that human intelligence \"can be so precisely described that a machine can be made to simulate it\".[18] This raises philosophical arguments about the nature of the mind and the ethics of creating artificial beings endowed with human-like intelligence which are issues that have been explored by myth, fiction and philosophy since antiquity.[19] Some people also consider AI to be a danger to humanity if it progresses unabated.[20] Others believe that AI, unlike previous technological revolutions, will create a risk of mass unemployment.[21]\nThe traditional problems (or goals) of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects.[13] General intelligence is among the field's long-term goals.[17] Approaches include statistical methods, computational intelligence, and traditional symbolic AI. Many tools are used in AI, including versions of search and mathematical optimization, artificial neural networks, and methods based on statistics, probability and economics. The AI field draws upon computer science, information engineering, mathematics, psychology, linguistics, philosophy, and many others.\nArtificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism,[7][8] followed by disappointment and the loss of funding (known as an \"AI winter\"),[9][10] followed by new approaches, success and renewed funding.[8][11] For most of its history, AI research has been divided into subfields that often fail to communicate with each other.[12] These sub-fields are based on technical considerations, such as particular goals (e.g. \"robotics\" or \"machine learning\"),[13] the use of particular tools (\"logic\" or artificial neural networks), or deep philosophical differences.[14][15][16] Subfields have also been based on social factors (particular institutions or the work of particular researchers).[12]\nThe scope of AI is disputed: as machines become increasingly capable, tasks considered as requiring \"intelligence\" are often removed from the definition, a phenomenon known as the AI effect, leading to the quip, \"AI is whatever hasn't been done yet.\"[3][citation not found] For instance, optical character recognition is frequently excluded from \"artificial intelligence\", having become a routine technology.[4] Modern machine capabilities generally classified as AI include successfully understanding human speech,[5] competing at the highest level in strategic game systems (such as chess and Go),[6] autonomously operating cars, and intelligent routing in content delivery networks and military simulations.\nArtificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and other animals.  In computer science  AI research is defined as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.[1] Colloquially, the term \"artificial intelligence\" is applied when a machine mimics \"cognitive\" functions that humans associate with other human minds, such as \"learning\" and \"problem solving\".[2]\n\n",
            "title": "Artificial intelligence",
            "url": "https://en.wikipedia.org/wiki/Artificial_intelligence"
        }
    ]
}