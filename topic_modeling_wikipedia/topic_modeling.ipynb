{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In mathematics, a function[1] was originally the idealization of how a varying quantity depends on another quantity. For example, the position of a planet is a function of time. Historically, the concept was elaborated with the infinitesimal calculus at the end of the 17th century, and, until the 19th century, the functions that were considered were differentiable (that is, they had a high degree of regularity). The concept of function was formalized at the end of the 19th century in terms of set theory, and this greatly enlarged the domains of application of the concept. A function is a process or a relation that associates each element x of a set X,  the domain of the function, to a single element y of another set Y (possibly the same set), the codomain of the function. If the function is called f, this relation is denoted y = f (x) (read f of x), the element x is the argument or input of the function, and y is the value of the function, the output, or the image of x by f.[2] The symbol that is used for representing the input is the variable of the function (one often says that f is a function of the variable x).A function is uniquely represented by its graph which is the set of all pairs (x, f (x)). When the domain and the codomain are sets of numbers, each such pair may be considered as the Cartesian coordinates of a point in the plane. In general, these points form a curve, which is also called the graph of the function. This is a useful representation of the function, which is commonly used everywhere, for example in newspapers.Functions are widely used in science, and in most fields of mathematics. Their role is so important that it has been said that they are \"the central objects of investigation\" in most fields of mathematics.[3]Intuitively, a function is a process that associates to each element of a set X a unique element of a set Y.Formally, a function f from a set X to a set Y is defined by a set G of ordered pairs (x, y) such that x ∈ X, y ∈ Y, and every element of X is the first component of exactly one ordered pair in G.[4] In other words, for every x in X, there is exactly one element y such that the ordered pair (x, y) belongs to the set of pairs defining the function f. The set G is called the graph of the function. Formally speaking, it may be identified with the function, but this hides the usual interpretation of a function as a process. Therefore, in common usage, the function is generally distinguished from its graph. Functions are also called maps or mappings. However, some authors[5] reserve the word mapping to the case where the codomain Y belongs explicitly to the definition of the function. In this sense, the graph of the mapping recovers the function as the set of pairs.In the definition of function, X and Y are respectively called the domain and the codomain of the function f. If (x, y) belongs to the set defining f, then y is the image of x under f, or the value of f applied to the argument x. Especially in the context of numbers, one says also that y is the value of f for the value x of its variable, or, still shorter, y is the value of f of x, denoted as y = f(x).The range of a function is the set of the images of all elements in the domain. However, range is sometimes used as a synonym of codomain, generally in old textbooks.A univalent relation is a relation such thatUnivalent relations may be identified to functions whose domain is a subset of X.A left-total relation is a relation such that Formal functions may be strictly identified to relations that are both univalent and left total. Violating the left-totality is similar to giving a convenient encompassing set instead of the true domain, as explained above.This distinction in language and notation becomes important in cases where functions themselves serve as inputs for other functions.  (A function taking another function as an input is termed a functional.)  Other approaches to denoting functions, detailed below, avoid this problem but are less commonly used.First used by Leonhard Euler in 1734,[7] it is often useful to use a symbol for denoting a function. This symbol consists generally of a single letter in italic font, most often the lower-case letters f, g, h. Some widely used functions are represented by a symbol consisting of several letters (usually two or three, generally an abbreviation of their name). By convention, the symbol for standard functions is set in roman type, such as \"sin\" for the sine function, in contrast to functions defined on an ad hoc basis.The notation (read: \"y equals f of x\")means that the pair (x, y) belongs to the set of pairs defining the function f. If X is the domain of f, the set of pairs defining the function is thus, using set-builder notation,Often, a definition of the function is given by what f does to the explicit argument x.  For example, a function f can be defined by the equationFor explicitly expressing domain X and the codomain Y of a function f, the arrow notation is often used (read: \"the function f from X to Y\" or \"the function f mapping elements of  X to elements of Y\"):orThis is often used in relation with the arrow notation for elements (read: \"f maps x to f (x)\"), often stacked immediately below the arrow notation giving the function symbol, domain, and codomain: the latter line being more commonly written There are other, specialized notations for functions in sub-disciplines of mathematics.  For example, in linear algebra and functional analysis, linear forms and the vectors they act upon are denoted using a dual pair to show the underlying duality.  This is similar to the use of bra–ket notation in quantum mechanics.  In logic and the theory of computation, the function notation of lambda calculus is used to explicitly express the basic notions of function abstraction and application.  In category theory and homological algebra, networks of functions are described in terms of how they and their compositions commute with each other using commutative diagrams that extend and generalize the arrow notation for functions described above.According to the definition of a function, a specific function is, in general, defined by associating to every element of its domain one element of its codomain. When the domain and the codomain are sets of numbers, this association may take the form of a computation taking as input any element of the domain and producing an output in the codomain. This computation may be described by a formula. (This is the starting point of algebra, where many similar numerical computations can be replaced by a single formula that describes these computations by means of variables that represent computation inputs as unspecified numbers). This type of specification of a function frequently uses previously defined auxiliary functions. The above ways of defining functions define them \"pointwise\", that is, each value is defined independently of the other values. This is not necessarily the case.When the domain of a function is the set of nonnegative integers or, more generally, when the domain is a well ordered set, a function may be defined by induction or recursion, meaning (roughly) that the calculation of the value of the function for some given input requires values of the function for lesser inputs. For example, the Fibonacci sequence is a function from the natural numbers into themselves that is defined by two starting values and a formula, recurring to the two immediately preceding arguments (see above for the use of indices for the argument of a function): As functions may be complicated objects, it is often useful to draw the graph of a function for getting a global view of its properties. Some functions may also represented histogramsIt is possible to draw effectively the graph of a function only if the function is sufficiently regular, that is, either if the function is differentiable (or piecewise differentiable) or if its domain may be identified with the integers or a subset of the integers.Histograms are often used for representing functions whose domain is finite, or is the natural numbers or the integers. In this case, an element x of the domain is represented by an interval of the x-axis, and a point (x, y) of the graph is represented by a rectangle with basis the interval corresponding to x and height y.In statistic, histogram are often used for representing very irregular functions. For example, for representing the function that associates his weight to each member of some population, one draws the histogram of the function that associates to each weight interval the number of people, whose weights belong to this interval. There are many variants of this method, see Histogram for details.This section describes general properties of functions, that are independent of specific properties of the domain and the codomain.Some functions are uniquely defined by their domain and codomain, and are sometimes called canonical: Two functions f and g are equal if their domain and codomain sets agree and their output values agree on the whole domain. Formally, f=g if f(x)=g(x) for all x∈X, where f:X→Y and g:X→Y.A composite function g(f(x)) can be visualized as the combination of two \"machines\".A simple example of a function compositionAnother composition. In this example, (g ∘ f )(c) = #.The image of f is the image of the whole domain, that is f(X). It is also called the range of f, although the term may also refer to the codomain.[8]For example, the preimage of {4, 9} under the square function is the set {−3,−2,2,3}. The preimage by f of an element y of the codomain is sometimes called, in some contexts, the fiber of y under f.  \"One-to-one\" and \"onto\" are terms that were more common in the older English language literature; \"injective\", \"surjective\", and \"bijective\" were originally coined as French words in the second quarter of the 20th century by the Bourbaki group and imported into English.  As a word of caution, \"a one-to-one function\" is one that is injective, while a \"one-to-one correspondence\" refers to a bijective function.  Also, the statement \"f maps X onto Y\" differs from \"f  maps X into B\" in that the former implies that f is surjective), while the latter makes no assertion about the nature of f the mapping.  In a complicated reasoning, the one letter difference can easily be missed. Due to the confusing nature of this older terminology, these terms have declined in popularity relative to the Bourbakian terms, which have also the advantage to be more symmetrical.This often used for define partial inverse functions: if there is a subset S of a function f such that f|S is injective, then the canonical surjection of f|S on its image f|S(S) = f(S) is a bijection, which has an inverse function from f(S) to S. This is in this way that inverse trigonometric functions are defined. The cosine function, for example, is injective, when restricted to the interval (–0, π); the image of this restriction is the interval (–1, 1); this defines thus an inverse function from (–1, 1) to (–0, π), which is called arccosine and denoted arccos.An extension of a  function f is a function g such that f is a restriction of g. A typical use of this concept is the process of analytic continuation, that allows extending functions whose domain is a small part of the complex plane to functions whose domain is almost the whole complex plane.A multivariate function, or function of several variables is a function that depends on several arguments. Such functions are commonly encountered. For example, the position of a car on a road is a function of the time and its speed.More formally, a function of n variables is a function whose domain is a set of n-tuples.For example, multiplication of integers is a function of two variables, or bivariate function, whose domain is the set of all pairs (2-tuples) of integers, and whose codomain is the set of integers. The same is true for every binary operation. More generally, every mathematical operation is defined as a multivariate function.where the domain U has the formIt is common to also consider functions whose codomain is a product of sets. For example, Euclidean division maps every pair (a, b) of integers with b ≠ 0 to a pair of integers called the quotient and the remainder:The codomain may also be a vector space. In this case, one talks of a vector-valued function. If the domain is contained in a Euclidean space, or more generally a manifold, a vector-valued function is often called a vector field.The idea of function, starting in the 17th century, was fundamental to the new infinitesimal calculus (see History of the function concept). At that time, only real-valued functions of a real variable were considered, and all functions were assumed to be smooth. But the definition was soon extended to functions of several variables and to function of a complex variable.  In the second half of 19th century, the mathematically rigorous definition of a function was introduced, and functions with arbitrary domains and codomains were defined. Functions are now used throughout all areas of mathematics.  In introductory calculus, when the word function is used without qualification, it means a real-valued function of a single real variable.  The more general definition of a function is usually introduced to second or third year college students with STEM majors, and in their senior year they are introduced to calculus in a larger, more rigorous setting in courses such as real analysis and complex analysis.A real function is a real-valued function of a real variable, that is, a function whose codomain is the field of real numbers and whose domain is a set of real numbers that contains an interval. In this section, these functions are simply called functions.The functions that are most commonly considered in mathematics and its applications have some regularity, that is they are continuous, differentiable, and even analytic. This regularity insures that these functions can be visualized by their graphs. In this section, all functions are differentiable in some interval.Functions enjoy pointwise operations, that is, if f and g are functions, their sum, difference and product are functions defined  by The domains of the resulting functions are the intersection of the domains of f and g. The quotient of two functions is defined similarly by but the domain of the resulting function is obtained by removing the zeros of g from the intersection of the domains of f and g.Many other real functions are defined either by the implicit function theorem (the inverse function is a particular instance) or as solutions of differential equations. For example the sine and the cosine functions are the solutions of the linear differential equation such that When working with complex numbers different types of functions are used[9]: The study of complex functions is a vast subject in mathematics with many applications, and that can claim[10] to be an ancestor to many other areas of mathematics, like homotopy theory, and manifolds.In mathematical analysis, and more specifically in functional analysis, a function space is a set of scalar-valued or vector-valued functions, which share a specific property and form a topological vector space. For example, the real smooth functions with a compact support (that is, they are zero outside some compact set) form a function space that is at the basis of the theory of distributions.Function spaces play a fundamental role in advanced mathematical analysis, by allowing the use of their algebraic and topological properties for studying properties of functions. For example, all theorems of existence and uniqueness of solutions of ordinary or partial differential equations result of the study of function spaces.It is rather frequent that a function with domain X may be naturally extended to a function whose domain is a set Z that is built from X.where f (S) is the image by f of the subset S of X.Under slight abuse of notation this function on subsets is often denoted also by f.which is also a ring homomorphism.Usefulness of the concept of multi-valued functions is clearer when considering complex functions, typically analytic functions. The domain to which a complex function may be extended by analytic continuation generally consists of almost the whole complex plane. However, when extending the domain through two different paths, one often gets different values. For example, when extending the domain of the square root function, along a path of complex numbers with positive imaginary parts, one gets i for the square root of –1; while, when extending through complex numbers with negative imaginary parts, one gets –i. There are generally two ways of solving the problem. One may define a function that is not continuous along some curve, called a branch cut. Such a function is called the principal value of the function. The other way is to consider that one has a multi-valued function, which is analytic everywhere except for isolated singularities, but whose value may \"jump\" if one follows a closed loop around a singularity. This jump is called the monodromy.The definition of a function that is given in this article requires the concept of set, since the domain and the codomain of a function must be a set. This is not a problem in usual mathematics, as it is generally not difficult to consider only functions whose domain and codomain are sets, which are well defined, even if the domain is not explicitly defined. However, it is sometimes useful to consider more general functions. These generalized functions may be critical in the development of a formalization of foundations of mathematics. For example, the Von Neumann–Bernays–Gödel set theory, is an extension of the set theory in which the collection of all sets is a class. This theory includes the replacement axiom, which may be interpreted as \"if X is a set, and F is a function, then F[X] is a set\".\n"
     ]
    }
   ],
   "source": [
    "# Splitting text data and storing them in a list (of articles)\n",
    "import io\n",
    "docs = io.open(\"raw_data_1130.txt\", mode=\"r\", encoding=\"utf-8\", errors=\"ignore\").read().split('\\n') # list of strings \n",
    "titles = [docs[i] for i in range(len(docs)) if i % 2 == 0] # list of string titles\n",
    "contents = [docs[i] for i in range(len(docs)) if i % 2 == 1] # list of string contents\n",
    "print(contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing/ cleaning the data\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# remove text between parenthesis\n",
    "# contents = list(map(lambda x: re.sub(r\"\\(.*\\)\",\"\",x), contents))\n",
    "\n",
    "# remove all digits from text\n",
    "contents = list(map(lambda x: re.sub(r\"\\d+\",\"\",x), contents))\n",
    "\n",
    "stop = set(stopwords.words('english')) # set of stopwords\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    # remove stopwords and words that are too short\n",
    "    return [lemma.lemmatize(i, 'v') for i in word_tokenize(doc) if i not in stop and len(i) > 2]\n",
    "cleaned = [clean(page.lower()) for page in contents]\n",
    "\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(16197 unique tokens: ['-tuples', '.the', 'abbreviation', 'above.according', 'above.this']...)\n",
      "Dictionary(4085 unique tokens: ['.the', 'abbreviation', 'abstraction', 'abuse', 'act']...)\n",
      "Dictionary(4050 unique tokens: ['.the', 'abbreviation', 'abstraction', 'abuse', 'act']...)\n",
      "Dictionary(4000 unique tokens: ['.the', 'abbreviation', 'abstraction', 'abuse', 'act']...)\n"
     ]
    }
   ],
   "source": [
    "# Building word dicitonary\n",
    "from gensim import corpora\n",
    "# create the term dictionary of our corpus; terms are unique; each term is assigned an index\n",
    "dictionary = corpora.Dictionary(cleaned)\n",
    "print(dictionary)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.7)\n",
    "print(dictionary)\n",
    "stoplist = set('also use make people know many call include part find become like mean often different usually take wikt come give well get since type list say change see refer actually iii aisne kinds pas ask would way something need things want every str'.split())\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "dictionary.filter_tokens(stop_ids)\n",
    "print(dictionary)\n",
    "dictionary.filter_n_most_frequent(50)\n",
    "print(dictionary)\n",
    "\n",
    "# This saves the dictionary to the local disk\n",
    "dictionary.save_as_text('./dictionary.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694\n",
      "[(1, 1), (7, 1), (11, 1), (14, 1), (22, 2), (24, 2), (30, 3), (34, 29), (39, 1), (40, 2), (43, 1), (46, 1), (61, 2), (64, 1), (65, 1), (74, 2), (79, 1), (84, 2), (86, 2), (100, 1), (104, 1), (111, 1), (117, 2), (123, 3), (125, 1), (126, 1), (129, 1), (132, 3), (134, 7), (137, 1), (138, 1), (141, 3), (154, 4), (164, 1), (165, 1), (172, 3), (175, 1), (176, 2), (183, 1), (198, 1), (214, 3), (217, 1), (222, 1), (228, 1), (233, 1), (253, 1), (255, 2), (262, 2), (270, 1), (273, 2), (275, 2), (281, 1), (288, 2), (292, 3), (303, 1), (321, 1), (324, 1), (329, 1), (339, 2), (342, 1), (356, 6), (357, 1), (376, 1), (381, 1), (385, 1), (391, 1), (392, 1), (395, 2), (399, 1), (404, 6), (409, 1), (419, 4), (423, 4), (438, 2), (459, 1), (461, 1), (464, 2), (467, 1), (490, 1), (491, 2), (500, 4), (511, 24), (518, 3), (519, 1), (525, 2), (526, 1), (529, 1), (533, 1), (535, 1), (539, 2), (548, 3), (554, 3), (561, 1), (564, 1), (578, 1), (595, 1), (617, 1), (627, 1), (631, 1), (654, 1), (665, 1), (668, 1), (692, 3), (696, 5), (723, 2), (735, 1), (736, 1), (757, 2), (758, 2), (764, 3), (776, 5), (788, 1), (790, 2), (827, 1), (838, 1), (851, 1), (859, 1), (866, 1), (874, 1), (893, 1), (910, 1), (921, 1), (954, 1), (976, 1), (981, 2), (982, 1), (995, 1), (1012, 1), (1027, 2), (1066, 2), (1068, 1), (1074, 3), (1079, 1), (1110, 1), (1117, 1), (1160, 1), (1163, 1), (1178, 1), (1208, 1), (1230, 1), (1232, 1), (1270, 1), (1314, 1), (1330, 1), (1340, 1), (1383, 5), (1495, 3), (1529, 1), (1574, 1), (1639, 1), (1689, 1), (1828, 1), (1856, 1), (2126, 1), (2142, 2), (2151, 2), (2157, 2), (2197, 1), (2227, 2), (2249, 1), (2257, 5), (2271, 1), (2309, 1), (2338, 3), (2403, 2), (2422, 1), (2473, 1), (2516, 1), (2532, 1), (2549, 1), (2579, 1), (2586, 2), (2602, 1), (2665, 1), (2722, 1), (2725, 1), (2760, 1), (2809, 1), (2887, 1), (3108, 6), (3214, 2), (3293, 2), (3345, 1), (3365, 1), (3635, 2), (3848, 1), (3849, 1), (3915, 1), (3998, 23), (4168, 2), (4282, 1), (4287, 2), (4366, 3), (4475, 1), (4520, 1), (4689, 1), (4701, 1), (4744, 1), (4928, 1), (4936, 1), (4950, 3), (4960, 2), (5037, 1), (5104, 4), (5143, 1), (5160, 2), (5175, 1), (5180, 1), (5195, 1), (5225, 1), (5832, 2), (5901, 1), (6105, 1), (6107, 1), (6117, 1), (6164, 12), (6362, 1), (6495, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Creating document-term matrix from vocabulary (dictionary)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in cleaned]\n",
    "print(len(doc_term_matrix))\n",
    "print(doc_term_matrix[693])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   0.008*\"line\" + 0.007*\"map\" + 0.006*\"group\" + 0.006*\"matrices\" + 0.005*\"coordinate\" + 0.004*\"plane\" + 0.004*\"determinant\" + 0.004*\"projection\" + 0.004*\"manifold\" + 0.004*\"vectors\" \n",
      "\n",
      "2   0.009*\"line\" + 0.007*\"coordinate\" + 0.005*\"matrices\" + 0.005*\"group\" + 0.005*\"image\" + 0.004*\"ring\" + 0.004*\"equations\" + 0.004*\"polynomial\" + 0.004*\"product\" + 0.004*\"plane\" \n",
      "\n",
      "3   0.007*\"coordinate\" + 0.006*\"model\" + 0.005*\"product\" + 0.005*\"map\" + 0.005*\"cordic\" + 0.004*\"algorithm\" + 0.004*\"computer\" + 0.004*\"line\" + 0.004*\"geometry\" + 0.003*\"equations\" \n",
      "\n",
      "4   0.012*\"sequence\" + 0.008*\"group\" + 0.007*\"matrices\" + 0.006*\"equations\" + 0.005*\"row\" + 0.005*\"column\" + 0.005*\"solution\" + 0.004*\"rank\" + 0.004*\"vectors\" + 0.004*\"product\" \n",
      "\n",
      "5   0.006*\"polynomial\" + 0.006*\"equations\" + 0.005*\"row\" + 0.004*\"coordinate\" + 0.004*\"model\" + 0.004*\"line\" + 0.004*\"zero\" + 0.004*\"geometry\" + 0.004*\"solution\" + 0.004*\"data\" \n",
      "\n",
      "6   0.012*\"vectors\" + 0.011*\"product\" + 0.010*\"row\" + 0.009*\"matrices\" + 0.005*\"column\" + 0.005*\"rank\" + 0.004*\"scalar\" + 0.004*\"multiplication\" + 0.004*\"dual\" + 0.003*\"operations\" \n",
      "\n",
      "7   0.010*\"group\" + 0.008*\"coordinate\" + 0.006*\"quadratic\" + 0.006*\"cordic\" + 0.006*\"projective\" + 0.005*\"line\" + 0.004*\"hilbert\" + 0.004*\"product\" + 0.003*\"geometry\" + 0.003*\"operator\" \n",
      "\n",
      "8   0.012*\"group\" + 0.007*\"map\" + 0.005*\"coordinate\" + 0.005*\"matrices\" + 0.004*\"equations\" + 0.004*\"product\" + 0.004*\"solution\" + 0.004*\"transformation\" + 0.004*\"symmetric\" + 0.003*\"cordic\" \n",
      "\n",
      "9   0.007*\"vectors\" + 0.007*\"ring\" + 0.006*\"map\" + 0.006*\"coordinate\" + 0.006*\"matrices\" + 0.005*\"product\" + 0.004*\"orthogonal\" + 0.004*\"group\" + 0.003*\"finite\" + 0.003*\"equation\" \n",
      "\n",
      "10   0.008*\"polynomial\" + 0.007*\"equations\" + 0.005*\"ring\" + 0.005*\"equation\" + 0.005*\"coordinate\" + 0.005*\"group\" + 0.005*\"methods\" + 0.004*\"finite\" + 0.004*\"solution\" + 0.004*\"degree\" \n",
      "\n",
      "11   0.010*\"product\" + 0.008*\"vectors\" + 0.007*\"equations\" + 0.006*\"methods\" + 0.006*\"solution\" + 0.006*\"coordinate\" + 0.005*\"row\" + 0.005*\"sum\" + 0.005*\"span\" + 0.005*\"equation\" \n",
      "\n",
      "12   0.006*\"matrices\" + 0.006*\"group\" + 0.005*\"ring\" + 0.004*\"inverse\" + 0.004*\"product\" + 0.004*\"equations\" + 0.004*\"zero\" + 0.003*\"object\" + 0.003*\"peirce\" + 0.003*\"polynomial\" \n",
      "\n",
      "13   0.017*\"product\" + 0.016*\"vectors\" + 0.007*\"row\" + 0.006*\"equations\" + 0.005*\"group\" + 0.005*\"cross\" + 0.004*\"sequence\" + 0.004*\"zero\" + 0.004*\"solution\" + 0.004*\"coordinate\" \n",
      "\n",
      "14   0.018*\"polynomial\" + 0.008*\"ring\" + 0.007*\"polynomials\" + 0.005*\"determinant\" + 0.004*\"coefficients\" + 0.004*\"matrices\" + 0.004*\"decomposition\" + 0.004*\"quantum\" + 0.004*\"equation\" + 0.004*\"product\" \n",
      "\n",
      "15   0.006*\"equations\" + 0.006*\"matrices\" + 0.006*\"equation\" + 0.005*\"multiplication\" + 0.005*\"map\" + 0.005*\"euclidean\" + 0.005*\"vectors\" + 0.005*\"group\" + 0.005*\"line\" + 0.004*\"plane\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training LDA model\n",
    "# LDA automatically finds the mixture of similar words together, thus forming the topic or theme. we use this \n",
    "# unsupervised learning technique to identify the categories to which these articles belong, and the groups/clusters\n",
    "# within the collection. \n",
    "\n",
    "from gensim.models.ldamodel import LdaModel as Lda\n",
    "\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=15, id2word = dictionary)\n",
    "\n",
    "# Showing the 15 identified topics after the model is trained, where top 10 key terms are listed for each topic\n",
    "for topic in ldamodel.print_topics(num_topics=15, num_words=10):\n",
    "    print(topic[0]+1, \" \", topic[1],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles(ID) in Cluster 1: 8, 67, 70, 86, 90, 150, 151, 152, 157, 160, 169, 187, 200, 208, 315, 319, 345, 369, 378, 384, 396, 412, 421, 422, 429, 440, 454, 460, 466, 505, 520, 522, 545, 566, 571, 578, 606, 620, 647, 653, 662, 692\n",
      "\n",
      "Articles(ID) in Cluster 2: 37, 49, 60, 93, 110, 115, 117, 142, 158, 161, 180, 185, 211, 214, 286, 316, 328, 332, 359, 393, 439, 442, 443, 478, 515, 521, 535, 552, 564, 639, 649, 672\n",
      "\n",
      "Articles(ID) in Cluster 3: 19, 35, 54, 56, 65, 71, 89, 113, 114, 130, 155, 156, 179, 204, 210, 212, 222, 231, 233, 284, 296, 297, 299, 304, 307, 308, 321, 324, 334, 347, 370, 394, 395, 414, 434, 457, 484, 496, 503, 519, 526, 527, 568, 572, 603, 618, 641, 646, 657, 675, 676\n",
      "\n",
      "Articles(ID) in Cluster 4: 24, 82, 84, 96, 102, 119, 127, 134, 143, 172, 194, 213, 217, 247, 252, 265, 268, 273, 281, 311, 329, 338, 349, 350, 353, 360, 374, 379, 382, 400, 405, 415, 430, 447, 449, 508, 562, 565, 574, 638, 655, 664, 674, 679\n",
      "\n",
      "Articles(ID) in Cluster 5: 6, 16, 53, 73, 78, 87, 109, 120, 126, 133, 136, 141, 154, 170, 177, 182, 188, 197, 251, 285, 293, 336, 355, 357, 376, 377, 426, 431, 445, 458, 477, 499, 554, 581, 583, 584, 593, 625, 671\n",
      "\n",
      "Articles(ID) in Cluster 6: 1, 20, 41, 43, 46, 48, 66, 79, 83, 107, 108, 116, 162, 166, 184, 186, 189, 209, 248, 269, 276, 310, 335, 337, 340, 343, 366, 388, 392, 402, 411, 424, 436, 453, 486, 528, 529, 532, 533, 534, 539, 548, 551, 558, 563, 601, 623, 640, 654, 665, 669, 677, 681\n",
      "\n",
      "Articles(ID) in Cluster 7: 4, 17, 25, 29, 32, 38, 55, 62, 63, 75, 85, 138, 253, 278, 317, 320, 331, 380, 381, 406, 413, 468, 485, 511, 517, 553, 585, 598, 648, 684, 686, 693\n",
      "\n",
      "Articles(ID) in Cluster 8: 9, 23, 26, 68, 76, 80, 101, 129, 132, 145, 167, 173, 191, 192, 199, 205, 215, 226, 239, 257, 271, 326, 327, 372, 373, 391, 446, 471, 509, 514, 530, 531, 575, 589, 611, 636\n",
      "\n",
      "Articles(ID) in Cluster 9: 0, 27, 30, 40, 51, 122, 148, 220, 234, 237, 240, 264, 267, 341, 383, 390, 438, 483, 494, 524, 576, 579, 595, 599, 626\n",
      "\n",
      "Articles(ID) in Cluster 10: 3, 12, 14, 15, 21, 58, 59, 77, 98, 105, 111, 128, 137, 146, 147, 153, 159, 175, 181, 195, 221, 224, 225, 229, 245, 254, 255, 256, 274, 282, 288, 292, 318, 339, 351, 352, 358, 363, 364, 397, 404, 409, 410, 416, 432, 433, 455, 464, 473, 482, 487, 491, 500, 502, 504, 510, 523, 536, 549, 556, 567, 573, 582, 586, 591, 596, 597, 607, 609, 612, 613, 619, 621, 627, 632, 633, 644, 688\n",
      "\n",
      "Articles(ID) in Cluster 11: 7, 22, 36, 50, 69, 74, 94, 95, 100, 103, 118, 121, 123, 139, 164, 165, 171, 193, 196, 203, 216, 228, 243, 246, 272, 277, 279, 287, 291, 294, 325, 333, 348, 362, 375, 386, 389, 398, 423, 427, 441, 448, 469, 472, 474, 476, 498, 518, 537, 540, 541, 547, 560, 561, 602, 604, 614, 622, 624, 630, 656, 666, 668, 670, 673, 683, 685, 689, 691\n",
      "\n",
      "Articles(ID) in Cluster 12: 5, 31, 45, 47, 81, 135, 149, 176, 178, 202, 223, 230, 298, 403, 408, 419, 420, 435, 492, 497, 506, 546, 550, 557, 559, 570, 577, 600, 615, 616, 628, 642, 680, 682\n",
      "\n",
      "Articles(ID) in Cluster 13: 10, 18, 28, 33, 42, 44, 52, 61, 104, 168, 174, 206, 207, 227, 238, 241, 249, 250, 261, 263, 266, 290, 295, 300, 306, 309, 313, 346, 356, 368, 437, 444, 452, 459, 463, 465, 470, 475, 481, 488, 490, 501, 513, 516, 538, 588, 594, 610, 629, 631, 635, 643, 651, 658, 660, 690\n",
      "\n",
      "Articles(ID) in Cluster 14: 13, 39, 72, 88, 92, 97, 106, 112, 131, 144, 218, 235, 236, 244, 259, 262, 270, 283, 305, 314, 323, 342, 344, 361, 365, 367, 385, 387, 399, 407, 417, 425, 428, 480, 489, 493, 495, 525, 555, 580, 634, 650, 661, 663, 667, 687\n",
      "\n",
      "Articles(ID) in Cluster 15: 2, 11, 34, 57, 64, 91, 99, 124, 125, 140, 163, 183, 190, 198, 201, 219, 232, 260, 275, 280, 289, 301, 302, 312, 322, 330, 354, 371, 418, 450, 456, 461, 462, 479, 507, 542, 543, 544, 569, 587, 590, 592, 605, 608, 617, 637, 645, 652, 659, 678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clustering documents based on topics extracted from LDA model \n",
    "from operator import itemgetter\n",
    "def cluster(doc_term_matrix, num):\n",
    "    doc_topics = ldamodel.get_document_topics(doc_term_matrix, minimum_probability=0.20)\n",
    "    result = [[] for i in range(num)]\n",
    "    for k,topic in enumerate(doc_topics):\n",
    "        # Some articles do not have a topic\n",
    "        if topic:\n",
    "            topic.sort(key = itemgetter(1), reverse=True)\n",
    "            result[topic[0][0]].append(k)\n",
    "    for k in range(len(result)):\n",
    "        print('Articles(ID) in Cluster ' + str(k+1) + ': ' + ', '.join(map(str, result[k])))\n",
    "        print()\n",
    "    return result\n",
    "cluster_result = cluster(doc_term_matrix, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles in Cluster 1: Curse of dimensionality, Trace (linear algebra), Linear map, Relative dimension, Kempner series, Overlap–save method, Matrix determinant lemma, Projection (linear algebra), Probability box, Line segment, Identity matrix, Successive parabolic interpolation, Trace identity, Intersection curve, Linear map, Möbius transformation, Linear inequality, Rota's basis conjecture, Intersection (Euclidean geometry), Piecewise linear continuation, 3D projection, Lapped transform, Equipollence (geometry), Linear map, Lie group integrator, K-SVD, Three-dimensional space, Dimension (vector space), Majorization, Trace diagram, Projection (mathematics), Dimension (vector space), Interval contractor, Complex plane, Orthographic projection, Well-posed problem, Nyström method, Unrestricted algorithm, Discrete Fourier transform, Golden–Thompson inequality, Manifold, Ambient space\n",
      "\n",
      "Articles in Cluster 2: Skew-Hermitian matrix, Weyr canonical form, ND4S, Rank factorization, Image (mathematics), Propagation of uncertainty, Linearity, Wave function, Canonical basis, Row echelon form, ND4J (software), Movable cellular automaton, Homogeneous coordinates, Pohlke's theorem, Orientation (vector space), LAPACK, Trilinear coordinates, Image (mathematics), Quantum mechanics, Perspectivity, Rotation of axes, Transformation matrix, Zero mode, Finitely generated module, Applied element method, Bijection, Line–line intersection, Image (mathematics), Line (geometry), Translation of axes, Cartesian coordinate system, Dependence relation\n",
      "\n",
      "Articles in Cluster 3: Translation, Robotics, James Joseph Sylvester, René Descartes, Range (mathematics), List of vector spaces in mathematics, CORDIC, Mathematical model, Digital Library of Mathematical Functions, CORDIC, Computer vision, CORDIC, The Nine Chapters on the Mathematical Art, Algorithm, Surrogate model, CORDIC, CORDIC, CORDIC, Engineering, Graphics processing unit, CORDIC, Horner's method, Geometry, Abramowitz and Stegun, Digital Library of Mathematical Functions, CORDIC, Abramowitz and Stegun, CORDIC, CORDIC, CORDIC, CORDIC, CORDIC, Symbolic-numeric computation, Aitken's delta-squared process, Portal:Linear algebra, CORDIC, Pseudoscalar, Timeline of numerical analysis after 1945, Telegraphy, Gottfried Wilhelm Leibniz, Model order reduction, CORDIC, Weather forecasting, Synthetic geometry, Rod calculus, Processor (computing), Computer graphics, Abramowitz and Stegun, Mechanics, Quantification of margins and uncertainties, Portal:Linear algebra\n",
      "\n",
      "Articles in Cluster 4: Boundary particle method, Singular value decomposition, Linear regression, Matrix calculus, Hermite normal form, Hermitian adjoint, Cramer's rule, Cramer's rule, Matrix congruence, Antiunitary operator, Schur product theorem, Orthogonality, Commutation matrix, Triangle inequality, Sequence, Big M method, S-procedure, Determinant, Quadratic eigenvalue problem, Overdetermined system, Normal basis, Adjugate matrix, Normal matrix, Symplectic vector space, Orthogonal complement, Tikhonov regularization, Transpose, Semi-simplicity, Hyperplane, Non-negative matrix factorization, Loewner order, Skew-Hamiltonian matrix, Low-discrepancy sequence, Matrix (mathematics), Determinant, Sequence, Fundamental theorem of linear algebra, Transpose of a linear map, Axiom, Cramer's rule, Bernstein's constant, Rate of convergence, Regularized least squares, Woodbury matrix identity\n",
      "\n",
      "Articles in Cluster 5: Closest point method, Sinc numerical methods, Geodesy, Multi-core processor, Trajectory (fluid mechanics), Blossom (functional), Indeterminate system, Vector field reconstruction, Hundred-dollar, Hundred-digit Challenge problems, A Treatise on Electricity and Magnetism, De Boor's algorithm, Basic Linear Algebra Subprograms, Differential geometry, Maple (software), Backus–Gilbert method, Linear programming, Computational complexity, Zero matrix, Computational science, Gaussian elimination, Sparse grid, Residual (numerical analysis), Figure of the Earth, Joint spectral radius, Segre classification, Restricted isometry property, Underdetermined system, Numerical continuation, Analytic geometry, Numerical range, Field (physics), Mathematics, Savitzky–Golay filter, Productive matrix, Gaussian elimination, Zech's logarithm, Isotonic regression, Curve fitting, Giuseppe Peano\n",
      "\n",
      "Articles in Cluster 6: Binary operation, Rank (linear algebra), Nonnegative rank (linear algebra), Matrix multiplication, Linear form, Overlap–add method, Sublinear function, Function space, Linear form, File:Portal-puzzle.svg, Galerkin method, Orthogonal Procrustes problem, Elementary matrix, Dimension theorem for vector spaces, Weakened weak form, Matrix addition, Row and column spaces, Peano kernel theorem, Dual norm, Function space, Simpson's rule, Orthonormal basis, Rank (linear algebra), Gram–Schmidt process, Wild problem, Unisolvent functions, Levinson recursion, Matrix analysis, Spinors in three dimensions, Row equivalence, Dual space, Functional analysis, Scalar (mathematics), Elementary matrix, Uzawa iteration, Centrosymmetric matrix, Discretization, Dual space, Linear combination, Orthogonalization, Row and column vectors, Transfer matrix, Gram–Schmidt process, Elementary matrix, Basis function, Generalizations of Pauli matrices, Conformable matrix, Padé table, Row and column vectors, Quaternionic matrix, Pointwise, Schur complement, Linear combination\n",
      "\n",
      "Articles in Cluster 7: Multilinear algebra, Definite quadratic form, Hilbert space, Fredholm's theorem, Quadratic form, Fredholm alternative, Quadratic form, Flag (linear algebra), Immanant, Z-order curve, Fundamental matrix (computer vision), Homography, Orthonormal function system, Lanczos approximation, Linear approximation, Radial basis function, Guard digit, Coordinate system, Flag (linear algebra), Definite quadratic form, Projective space, Squeeze mapping, Absolutely convex set, Graded (mathematics), Finite von Neumann algebra, Convex cone, Coopmans approximation, Hilbert space, Linear system, Codimension, Coordinate system, Butcher group\n",
      "\n",
      "Articles in Cluster 8: General linear group, Differential-algebraic system of equations, /wiki/Linear algebra, CSS code, Ross–Fahroo lemma, Bilinear form, Fusion frame, Bilinear form, Hermann Grassmann, Abelian group, Signal-flow graph, Boundary knot method, Purification of quantum state, Group representation, Kernel (algebra), Balanced set, Dynamic relaxation, Pseudospectral knotting method, Euclidean group, Riemann solver, Choi's theorem on completely positive maps, Finitely generated abelian group, Pairing, Gabriel Cramer, Hermes Project, Special linear group, Semilinear map, Symmetric matrix, General linear group, Reflection (mathematics), Coates graph, Hypot, Scale co-occurrence matrix, Bellman pseudospectral method, Integer points in convex polyhedra, Map (mathematics)\n",
      "\n",
      "Articles in Cluster 9: Free module, Linear algebra, Atmosphere, Dieudonné determinant, Conjugate transpose, Sesquilinear form, Finite Legendre transform, Peetre's inequality, Cardinality, Linear equation over a ring, Change of basis, Module homomorphism, Function composition, Isomorphism, Steinitz exchange lemma, Linear equation over a ring, Newton fractal, Vectorization (mathematics), Function composition, Canonical map, Modeshape, Orthogonal basis, Category of modules, Coordinate space, Isomorphism\n",
      "\n",
      "Articles in Cluster 10: Gradient discretisation method, Bernstein polynomial, Linear equation, Kahan summation algorithm, Modulus of smoothness, Mixed linear complementarity problem, Quaternion, Regularized meshless method, Proper generalized decomposition, De Casteljau's algorithm, Remez algorithm, Finite field, Finite volume method, Amitsur–Levitzki theorem, Newton's identities, Zero of a function, Monic polynomial, Numerical analysis, Numerical model of the Solar System, Fangcheng (mathematics), Nonlinear eigenproblem, Finite difference, Numerical differentiation, Generalized-strain mesh-free formulation, Condition number, Multilevel fast multipole method, Sigma approximation, Whitney inequality, Numerical stability, Chebyshev nodes, Wolfram Language, Function (mathematics), Meshfree methods, Minimax approximation algorithm, Multi-time-step integration, Faddeev–LeVerrier algorithm, Equioscillation theorem, Adjoint state method, Numerical integration, Padé approximant, Singular boundary method, Van Wijngaarden transformation, Identifiability analysis, Nonstandard finite difference scheme, Order of approximation, Numerical method, Coordinate vector, Jenkins–Traub algorithm, Approximation theory, Element (mathematics), Dual basis in a field extension, Partial differential equation, Shanks transformation, Linear function, Flat (geometry), Eigengap, Reduction (mathematics), Pairwise summation, Rotation, Newton–Krylov method, Scarborough criterion, Hilbert–Poincaré series, Polynomial basis, Coordinate vector, Orthogonal diagonalization, Bunch–Nielsen–Sorensen formula, Spectral method, Approximation, Eigenvalue perturbation, Rigid body dynamics, Linear complementarity problem, Method of fundamental solutions, Wilkinson's polynomial, Quasinorm, GetFEM++, Hurwitz determinant, Series acceleration, Von Neumann stability analysis\n",
      "\n",
      "Articles in Cluster 11: Truncation error, Tensor product, Stiffness matrix, Barycentric coordinate system, Bi-directional delay line, List of numerical analysis topics, Linear span, Semi-simple operator, Pseudo-spectral method, Orthant, Runge–Kutta methods, Resolvent set, Adaptive stepsize, Iterative method, Computational statistics, Local convergence, Monte Carlo method, Parareal, Material point method, System of linear equations, Entanglement-assisted stabilizer formalism, Linear span, Ross' π lemma, Legendre pseudospectral method, MATLAB, Vector projection, Linear span, Multigrid method, System of linear equations, Basis (linear algebra), System of linear equations, Numerical methods in fluid mechanics, Matrix Chernoff bound, Quotient space (linear algebra), Levi-Civita symbol, Nonlinear system, Rayleigh's quotient in vibrations analysis, Ross–Fahroo pseudospectral method, Semi-infinite programming, System of linear equations, Order of accuracy, Zassenhaus algorithm, Direct sum of modules, Nonlinear system, Chebyshev pseudospectral method, Controlled invariant subspace, Richardson extrapolation, Round-off error, Flat pseudospectral method, Linear subspace, Approximation error, Error analysis (mathematics), Total set, System of linear equations, Multiphysics, Numerical linear algebra, Numerical error, Multilevel Monte Carlo method, Mesh generation, Basis (linear algebra), Partial differential algebraic equation, Linear subspace, Predictor–corrector method, Invariant subspace, Superconvergence, Tensor operator, Discrete wavelet transform, Explicit algebraic stress model, Discretization error\n",
      "\n",
      "Articles in Cluster 12: Bendixson's inequality, Level set (data structures), Cache (computing), Invertible matrix, Benjamin Peirce, Fast multipole method, Field extension, Invertible matrix, Invertible matrix, Karlsruhe Accurate Arithmetic, Invertible matrix, Charles Sanders Peirce, Generalized eigenvector, Rule of Sarrus, Field (mathematics), Invertible matrix, Sedrakyan's inequality, Zero object (algebra), Arthur Cayley, Carl Friedrich Gauss, Computing the permanent, Orientation of a vector bundle, Multiplicative inverse, Principal ideal domain, Karlsruhe Accurate Arithmetic, James H. Wilkinson, Affine arithmetic, Homogeneous function, James H. Wilkinson, Reality structure, Interval arithmetic, Abstract algebra, Compressed sensing, Generalized Gauss–Newton method\n",
      "\n",
      "Articles in Cluster 13: Unit vector, Polarization identity, Hamming space, Orthonormality, k-frame, Matrix norm, Sylvester's law of inertia, Frame (linear algebra), Overcompleteness, Spherical basis, Orthogonal transformation, Cartesian tensor, Antilinear map, List of finite element software packages, Dual basis, Lorentz transformation, History of Lorentz transformations, Cokernel, Pseudovector, Diagonal matrix, Dot product, Triple product, Euclidean vector, Lattice reduction, Template:Linear algebra, Kernel (linear algebra), Linear independence, Shear matrix, Minimum polynomial extrapolation, Liouville space, Multilinear form, Bidiagonal matrix, Birkhoff orthogonality, Cauchy–Schwarz inequality, Haynsworth inertia additivity formula, Euclidean vector, Seven-dimensional cross product, Linear independence, Gershgorin circle theorem, Quadruple product, Defective matrix, Kernel (linear algebra), Generator (mathematics), Unitary transformation, Mode of a linear field, Kernel (linear algebra), Vector-valued function, Cross product, Kernel (linear algebra), Mathematical analysis, Cauchy–Schwarz inequality, Dual basis, Inner product space, Diagonalizable matrix, Eigenplane, Shear mapping\n",
      "\n",
      "Articles in Cluster 14: Difference quotient, Endomorphism, Frobenius normal form, False precision, Truncated power function, Stokes operator, Book:Linear algebra, Rayleigh quotient, Trigonometric tables, Loss of significance, Lady Windermere's Fan (mathematics), Polynomial, Characteristic polynomial, Null vector, Generalized singular value decomposition, Bra–ket notation, Dual number, Truncation, Significant figures, Estrin's scheme, Relative change and difference, Characteristic polynomial, Stabilizer code, Gal's accurate tables, Significance arithmetic, Polynomial ring, Commutative ring, Jordan–Chevalley decomposition, Numeric precision in Microsoft Excel, Schmidt decomposition, Asymmetric norm, Polynomial, Delta operator, Bra–ket notation, Tapering (mathematics), Partial trace, Weyl's inequality, Frobenius normal form, Leibniz formula for determinants, Eigenoperator, Artificial precision, Sylvester's determinant identity, Square-free polynomial, Clenshaw algorithm, Ring (mathematics), Continuous wavelet\n",
      "\n",
      "Articles in Cluster 15: Angles between flats, List of uncertainty propagation software, List of linear algebra topics, Scalar multiplication, Interval propagation, Rotation (mathematics), Affine space, Matrix similarity, Split-complex number, Standard basis, Scalar multiplication, Permanent (mathematics), Norm (mathematics), Real number, FEE method, Plane (geometry), Quaternionic vector space, Independent equation, Hypercomplex number, Spectral theorem, Eigenvalues and eigenvectors, 2 × 2 real matrices, Augmented matrix, Jordan normal form, Complex conjugate, Euclidean space, Geometric transformation, Sherman–Morrison formula, Three-dimensional rotation operator, Lp space, Set (mathematics), Projection-valued measure, List of linear algebra topics, Corank, Isometry, Self-adjoint, Matrix difference equation, Complex conjugate vector space, Closed-form expression, Algebra over a field, Jordan normal form, Spectral theory, Coefficient matrix, Cyclic subspace, List of operator splitting topics, Vector space, Subset, Spread of a matrix, Invariants of tensors, Affine space\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing the exact document titles in each cluster\n",
    "for k in range(len(cluster_result)):\n",
    "    print('Articles in Cluster ' + str(k+1) + ': ' + ', '.join(map(lambda x: titles[x], cluster_result[k])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.00062025624), (1, 0.0002851983), (2, 0.00018773491), (3, 0.00031237974), (4, 0.00075876398), (5, 0.00055337959), (6, 0.0020672388), (7, 0.00025084193), (8, 0.00046323851), (9, 0.00055092655), (10, 0.00044278661), (11, 0.00022622035), (12, 0.00034563636), (13, 0.00052796141), (14, 0.000323835)]\n"
     ]
    }
   ],
   "source": [
    "term_topics = ldamodel.get_term_topics('convex', minimum_probability=0.000001)\n",
    "print(term_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Top 7 articles related to convex -------\n",
      "Homography \n",
      " 0.998413 \n",
      "\n",
      "Flag (linear algebra) \n",
      " 0.993473 \n",
      "\n",
      "Flag (linear algebra) \n",
      " 0.993473 \n",
      "\n",
      "Linear system \n",
      " 0.992412 \n",
      "\n",
      "Definite quadratic form \n",
      " 0.991884 \n",
      "\n",
      "Definite quadratic form \n",
      " 0.989251 \n",
      "\n",
      "Absolutely convex set \n",
      " 0.983626 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting related documents based on a term \n",
    "def get_related_documents(term, top, doc_term_matrix):\n",
    "    print('------- Top', top, 'articles related to',term,'-------')\n",
    "    related_docs = []\n",
    "    doc_topics = ldamodel.get_document_topics(doc_term_matrix, minimum_probability=0.20)\n",
    "    term_topics = ldamodel.get_term_topics(term, minimum_probability=0.000001)\n",
    "    term_topics.sort(key = itemgetter(1), reverse=True)\n",
    "    for k,topic in enumerate(doc_topics):\n",
    "        if topic:\n",
    "            topic.sort(key = itemgetter(1), reverse=True)\n",
    "            if topic[0][0] == term_topics[0][0]:\n",
    "                related_docs.append((k,topic[0][1]))\n",
    "    related_docs.sort(key = itemgetter(1), reverse=True)\n",
    "    result = []\n",
    "    for j,doc in enumerate(related_docs):\n",
    "        print(titles[doc[0]],\"\\n\",doc[1],\"\\n\")   \n",
    "        result.append(titles[doc[0]])\n",
    "        if j == top - 1:\n",
    "            break\n",
    "related_docs = get_related_documents('convex', 7, doc_term_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def get_theme(doc, cluster_result):\n",
    "    doc_id = titles.index(doc)\n",
    "    if doc_id == -1:\n",
    "        print('Document not found.')\n",
    "        return\n",
    "    for i, cluster in enumerate(cluster_result):\n",
    "        if doc_id in cluster:\n",
    "            return i+1\n",
    "    return 0\n",
    "cluster_num = get_theme('Absolutely convex set', cluster_result)\n",
    "print(cluster_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=694, num_nnz=169581)\n",
      "(0, 0.045342656413852538)\n"
     ]
    }
   ],
   "source": [
    "# Implementing tf-idf model; the only information needed from the previous part is the doc_term_matrix\n",
    "from gensim.models import TfidfModel, LsiModel\n",
    "tfidf_model = TfidfModel(doc_term_matrix, dictionary = dictionary)\n",
    "print(tfidf_model)\n",
    "vector = tfidf_model[doc_term_matrix[0]]\n",
    "print(vector[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LsiModel(num_terms=6533, num_topics=200, decay=1.0, chunksize=20000)\n"
     ]
    }
   ],
   "source": [
    "# Implementing LSI model; the only information needed from the previous part is the doc_term_matrix\n",
    "lsi_model = LsiModel(doc_term_matrix, id2word=dictionary)\n",
    "print(lsi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694\n"
     ]
    }
   ],
   "source": [
    "# Creating the similarity matrix from simple bag-of-words model (# of documents * # of documents)\n",
    "from gensim import similarities\n",
    "\n",
    "index = similarities.MatrixSimilarity(doc_term_matrix, num_features=len(dictionary))\n",
    "print(len(index[doc_term_matrix[693]])) # 694 * 694 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training tf-idf model from bag-of-word dataset\n",
    "model_tfidf = TfidfModel(doc_term_matrix, id2word=dictionary, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying tf-idf model to all vectors\n",
    "from gensim.corpora import MmCorpus\n",
    "MmCorpus.serialize('./corpus_tfidf.mm', model_tfidf[doc_term_matrix], progress_cnt=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixSimilarity<694 docs, 6533 features>\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = MmCorpus('./corpus_tfidf.mm') # Loading back the corpus file after applying tf-idf\n",
    "model_lsi = LsiModel(corpus_tfidf, num_topics=15, id2word=dictionary)\n",
    "# Applying LSI model to all vectors\n",
    "index = similarities.MatrixSimilarity(model_lsi[corpus_tfidf], num_features=len(dictionary))\n",
    "print(index)\n",
    "index.save('./lsi_index.mm') # Saving the similarity matrix to a local matrix market file named './lsi_model.mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694\n"
     ]
    }
   ],
   "source": [
    "# Loading the similarity matrix back from the local file\n",
    "similarity_matrix = similarities.MatrixSimilarity.load('./lsi_index.mm')\n",
    "print(len(similarity_matrix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
