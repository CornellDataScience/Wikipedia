{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n",
      "611\n"
     ]
    }
   ],
   "source": [
    "# Splitting text data and storing them in a list (of articles)\n",
    "import io\n",
    "docs = io.open(\"raw_data.txt\", mode=\"r\", encoding=\"utf-8\", errors=\"ignore\").read().split('\\n') # list of strings \n",
    "titles_raw = [docs[i] for i in range(len(docs)) if i % 2 == 0] # list of string titles\n",
    "contents_raw = [docs[i] for i in range(len(docs)) if i % 2 == 1] # list of string contents\n",
    "titles = []\n",
    "contents = []\n",
    "for i in range(len(titles_raw)):\n",
    "    if contents_raw[i] != '':\n",
    "        titles.append(titles_raw[i])\n",
    "        contents.append(contents_raw[i])\n",
    "titles = list(set(titles))\n",
    "contents = list(set(contents))\n",
    "\n",
    "print(len(titles))\n",
    "print(len(contents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing/ cleaning the data\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# remove text between parenthesis\n",
    "# contents = list(map(lambda x: re.sub(r\"\\(.*\\)\",\"\",x), contents))\n",
    "\n",
    "# remove all digits from text\n",
    "contents = list(map(lambda x: re.sub(r\"\\d+\",\"\",x), contents))\n",
    "\n",
    "stop = set(stopwords.words('english')) # set of stopwords\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    # remove stopwords and words that are too short\n",
    "    return [lemma.lemmatize(i, 'v') for i in word_tokenize(doc) if i not in stop and len(i) > 2]\n",
    "cleaned = [clean(page.lower()) for page in contents]\n",
    "\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(25740 unique tokens: ['.another', 'abstraction', 'act', 'adapt', 'algebraic']...)\n",
      "Dictionary(5934 unique tokens: ['.another', 'abstraction', 'act', 'adapt', 'algebraic']...)\n",
      "Dictionary(5896 unique tokens: ['.another', 'abstraction', 'act', 'adapt', 'algebraic']...)\n",
      "Dictionary(5846 unique tokens: ['.another', 'abstraction', 'act', 'adapt', 'algebraic']...)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Building word dicitonary\n",
    "from gensim import corpora\n",
    "# create the term dictionary of our corpus; terms are unique; each term is assigned an index\n",
    "dictionary = corpora.Dictionary(cleaned)\n",
    "print(dictionary)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.7)\n",
    "print(dictionary)\n",
    "#filtering for words that are semantically related within the dictionary \n",
    "stoplist = set('also use make people know many call include part find become like mean often different usually take wikt come give well get since type list say change see refer actually iii aisne kinds pas ask would way something need things want every str'.split())\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "dictionary.filter_tokens(stop_ids)\n",
    "print(dictionary)\n",
    "dictionary.filter_n_most_frequent(50)\n",
    "print(dictionary)\n",
    "\n",
    "# This saves the dictionary to the local disk\n",
    "dictionary.save_as_text('./dictionary.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n",
      "738\n",
      "[(4, 3), (9, 1), (10, 1), (14, 1), (15, 5), (20, 1), (38, 1), (39, 1), (50, 1), (60, 1), (63, 1), (69, 1), (75, 1), (85, 1), (93, 1), (98, 4), (103, 1), (109, 1), (174, 1), (196, 1), (202, 2), (217, 4), (226, 22), (252, 8), (253, 1), (290, 9), (320, 1), (331, 1), (348, 4), (349, 1), (426, 5), (427, 1), (471, 1), (483, 1), (517, 1), (527, 1), (528, 1), (533, 1), (537, 2), (557, 2), (562, 1), (564, 7), (592, 1), (613, 1), (625, 2), (627, 1), (641, 1), (655, 1), (679, 1), (681, 1), (689, 1), (699, 1), (703, 1), (745, 1), (750, 1), (751, 1), (757, 1), (769, 1), (788, 1), (813, 1), (832, 6), (890, 2), (900, 1), (940, 1), (1001, 1), (1010, 1), (1024, 3), (1031, 1), (1059, 1), (1096, 1), (1106, 1), (1119, 1), (1141, 3), (1150, 1), (1188, 1), (1202, 1), (1271, 2), (1276, 1), (1292, 1), (1328, 6), (1347, 3), (1386, 1), (1405, 2), (1430, 2), (1498, 1), (1532, 1), (1561, 1), (1572, 1), (1577, 1), (1599, 1), (1612, 2), (1625, 2), (1770, 1), (2091, 1), (2092, 1), (2097, 1), (2103, 3), (2178, 1), (2179, 1), (2180, 3), (2181, 2), (2182, 6), (2183, 32), (2184, 1), (2185, 2), (2186, 1), (2187, 2), (2188, 1), (2189, 1), (2190, 2), (2191, 1), (2192, 1), (2193, 2), (2194, 1), (2195, 1), (2196, 2), (2197, 2), (2198, 3), (2199, 1), (2200, 1), (2201, 1), (2202, 1), (2203, 1), (2204, 1), (2205, 1), (2206, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Creating document-term matrix from vocabulary (dictionary)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in cleaned]\n",
    "print(len(doc_term_matrix))\n",
    "print(len(doc_term_matrix[1]))\n",
    "print(doc_term_matrix[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# M = np.array([[0 for i in range(len(dictionary))] for i in range(len(dictionary))])\n",
    "# for i in range (len(doc_term_matrix)):\n",
    "#     for j in range (len(doc_term_matrix[i])):\n",
    "#         for k in range(j+1, len(doc_term_matrix[i])):\n",
    "#             M[doc_term_matrix[i][j][0]][doc_term_matrix[i][k][0]] +=1\n",
    "#             M[doc_term_matrix[i][k][0]][doc_term_matrix[i][j][0]] +=1\n",
    "#         freqMax = max(M[j])\n",
    "#         M[j] = M[j] / freqMax\n",
    "        \n",
    "# #         M[j] = [x / freqMax for x in M[j]]\n",
    "\n",
    "# for j in range(len(M)):\n",
    "#     minM = min(M[j])\n",
    "#     maxM = max(M[j])\n",
    "#     R = minM/maxM\n",
    "#     rel = R/(1+R)\n",
    "#     for k in range(len(M[j])):\n",
    "#         M[j][k] = rel\n",
    "# M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   0.007*\"matrices\" + 0.005*\"vectors\" + 0.005*\"coordinate\" + 0.005*\"group\" + 0.005*\"map\" + 0.005*\"transformation\" + 0.004*\"geometry\" + 0.004*\"euclidean\" + 0.004*\"manifold\" + 0.004*\"eigenvalues\" \n",
      "\n",
      "2   0.007*\"matrices\" + 0.007*\"row\" + 0.007*\"group\" + 0.006*\"line\" + 0.006*\"rank\" + 0.006*\"map\" + 0.004*\"vectors\" + 0.004*\"methods\" + 0.004*\"polynomial\" + 0.004*\"elements\" \n",
      "\n",
      "3   0.009*\"ring\" + 0.008*\"coordinate\" + 0.005*\"vectors\" + 0.005*\"group\" + 0.004*\"map\" + 0.004*\"multiplication\" + 0.003*\"matrices\" + 0.003*\"elements\" + 0.003*\"addition\" + 0.003*\"algorithm\" \n",
      "\n",
      "4   0.011*\"polynomial\" + 0.006*\"vectors\" + 0.005*\"sum\" + 0.004*\"model\" + 0.004*\"ring\" + 0.004*\"coefficients\" + 0.004*\"subspace\" + 0.003*\"polynomials\" + 0.003*\"matrices\" + 0.003*\"map\" \n",
      "\n",
      "5   0.011*\"group\" + 0.009*\"row\" + 0.006*\"matrices\" + 0.005*\"zero\" + 0.005*\"finite\" + 0.004*\"solution\" + 0.004*\"quadratic\" + 0.004*\"numerical\" + 0.004*\"ring\" + 0.004*\"algorithm\" \n",
      "\n",
      "6   0.008*\"polynomial\" + 0.005*\"image\" + 0.004*\"matrices\" + 0.004*\"ring\" + 0.003*\"peirce\" + 0.003*\"solution\" + 0.003*\"leibniz\" + 0.003*\"polynomials\" + 0.003*\"degree\" + 0.003*\"vectors\" \n",
      "\n",
      "7   0.008*\"line\" + 0.008*\"group\" + 0.007*\"coordinate\" + 0.007*\"vectors\" + 0.004*\"methods\" + 0.004*\"map\" + 0.004*\"frame\" + 0.004*\"row\" + 0.003*\"orthogonal\" + 0.003*\"matrices\" \n",
      "\n",
      "8   0.015*\"coordinate\" + 0.004*\"solution\" + 0.004*\"model\" + 0.004*\"line\" + 0.004*\"methods\" + 0.004*\"plane\" + 0.004*\"vectors\" + 0.004*\"elements\" + 0.003*\"describe\" + 0.003*\"work\" \n",
      "\n",
      "9   0.009*\"line\" + 0.008*\"geometry\" + 0.006*\"model\" + 0.006*\"projection\" + 0.005*\"coordinate\" + 0.005*\"orthogonal\" + 0.004*\"projective\" + 0.004*\"manifold\" + 0.004*\"affine\" + 0.003*\"group\" \n",
      "\n",
      "10   0.008*\"matrices\" + 0.006*\"ring\" + 0.006*\"map\" + 0.005*\"vectors\" + 0.005*\"sum\" + 0.005*\"solution\" + 0.004*\"row\" + 0.004*\"descartes\" + 0.003*\"problems\" + 0.003*\"determinant\" \n",
      "\n",
      "11   0.009*\"group\" + 0.007*\"polynomial\" + 0.007*\"model\" + 0.006*\"ring\" + 0.004*\"map\" + 0.004*\"elements\" + 0.004*\"finite\" + 0.004*\"work\" + 0.004*\"zero\" + 0.003*\"error\" \n",
      "\n",
      "12   0.006*\"vectors\" + 0.004*\"operator\" + 0.004*\"multiplication\" + 0.003*\"ring\" + 0.003*\"hilbert\" + 0.003*\"methods\" + 0.003*\"plane\" + 0.003*\"line\" + 0.003*\"computer\" + 0.003*\"solution\" \n",
      "\n",
      "13   0.008*\"vectors\" + 0.007*\"coordinate\" + 0.006*\"matrices\" + 0.005*\"transformation\" + 0.004*\"map\" + 0.004*\"group\" + 0.004*\"ring\" + 0.004*\"three\" + 0.004*\"operator\" + 0.003*\"sequence\" \n",
      "\n",
      "14   0.007*\"quantum\" + 0.005*\"data\" + 0.004*\"state\" + 0.004*\"solution\" + 0.004*\"methods\" + 0.004*\"finite\" + 0.003*\"computer\" + 0.003*\"problems\" + 0.003*\"rotation\" + 0.003*\"coefficients\" \n",
      "\n",
      "15   0.006*\"sequence\" + 0.006*\"dual\" + 0.006*\"vectors\" + 0.006*\"group\" + 0.005*\"matrices\" + 0.005*\"map\" + 0.005*\"elements\" + 0.004*\"ring\" + 0.004*\"coordinate\" + 0.004*\"rule\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training LDA model\n",
    "# LDA automatically finds the mixture of similar words together, thus forming the topic or theme. we use this \n",
    "# unsupervised learning technique to identify the categories to which these articles belong, and the groups/clusters\n",
    "# within the collection. \n",
    "\n",
    "from gensim.models.ldamodel import LdaModel as Lda\n",
    "\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=15, id2word = dictionary)\n",
    "\n",
    "# Showing the 15 identified topics after the model is trained, where top 10 key terms are listed for each topic\n",
    "for topic in ldamodel.print_topics(num_topics=15, num_words=10):\n",
    "    print(topic[0]+1, \" \", topic[1],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles(ID) in Cluster 1: 17, 21, 40, 41, 45, 74, 82, 94, 113, 116, 119, 172, 196, 197, 229, 259, 266, 296, 301, 309, 328, 394, 410, 435, 458, 468, 476, 492, 493, 503, 528, 545, 556, 563, 589\n",
      "\n",
      "Articles(ID) in Cluster 2: 0, 7, 8, 13, 30, 42, 53, 73, 85, 98, 102, 106, 108, 114, 124, 147, 164, 173, 187, 189, 190, 201, 202, 207, 210, 212, 214, 215, 220, 224, 228, 243, 244, 247, 283, 293, 307, 316, 317, 318, 341, 346, 364, 367, 377, 388, 389, 411, 422, 426, 427, 438, 455, 477, 481, 530, 531, 537, 567, 580, 593, 596, 598, 601\n",
      "\n",
      "Articles(ID) in Cluster 3: 64, 103, 105, 111, 205, 264, 276, 354, 379, 385, 396, 398, 478, 489, 508, 517, 544, 554, 587, 595, 599\n",
      "\n",
      "Articles(ID) in Cluster 4: 14, 20, 24, 37, 48, 79, 96, 176, 181, 184, 231, 235, 277, 295, 314, 343, 344, 352, 371, 393, 424, 500, 524, 540, 541, 572, 604\n",
      "\n",
      "Articles(ID) in Cluster 5: 5, 11, 38, 51, 57, 60, 61, 62, 70, 77, 97, 110, 127, 128, 137, 141, 153, 158, 159, 194, 213, 216, 218, 219, 246, 249, 253, 258, 270, 273, 291, 319, 324, 332, 335, 345, 353, 374, 384, 400, 406, 409, 417, 419, 443, 444, 460, 471, 483, 494, 499, 522, 549, 566, 576, 583, 592, 594, 597, 600, 602, 609\n",
      "\n",
      "Articles(ID) in Cluster 6: 10, 22, 44, 75, 123, 135, 136, 152, 178, 256, 267, 286, 287, 323, 340, 365, 380, 387, 403, 421, 436, 441, 495, 496, 510, 527, 548, 560, 569, 578, 579\n",
      "\n",
      "Articles(ID) in Cluster 7: 6, 18, 34, 63, 65, 69, 91, 92, 95, 125, 151, 167, 174, 180, 206, 221, 225, 227, 236, 239, 240, 242, 252, 284, 288, 289, 290, 292, 298, 299, 300, 302, 306, 313, 330, 382, 454, 482, 488, 501, 506, 511, 535, 543, 546, 557, 564, 577, 607\n",
      "\n",
      "Articles(ID) in Cluster 8: 9, 19, 46, 56, 67, 83, 86, 88, 99, 146, 204, 222, 255, 294, 310, 321, 338, 339, 361, 375, 376, 378, 397, 402, 513, 550, 552, 565\n",
      "\n",
      "Articles(ID) in Cluster 9: 2, 3, 23, 36, 81, 89, 93, 112, 126, 132, 134, 155, 183, 223, 261, 279, 281, 285, 304, 322, 358, 412, 432, 440, 447, 466, 485, 491, 515, 520, 525, 532, 542, 547, 561, 570, 571, 582, 591, 608\n",
      "\n",
      "Articles(ID) in Cluster 10: 31, 55, 109, 117, 139, 149, 160, 165, 179, 186, 200, 211, 226, 260, 262, 282, 303, 327, 336, 337, 351, 363, 366, 372, 390, 434, 439, 451, 459, 462, 498, 507, 518, 523, 538, 551, 558, 568, 573, 588\n",
      "\n",
      "Articles(ID) in Cluster 11: 15, 28, 43, 49, 71, 76, 78, 84, 115, 130, 148, 171, 182, 185, 192, 217, 251, 265, 274, 297, 311, 342, 348, 359, 370, 383, 399, 463, 469, 497, 502, 505, 519, 526, 533, 536, 539, 581, 603\n",
      "\n",
      "Articles(ID) in Cluster 12: 26, 52, 54, 90, 131, 150, 191, 198, 208, 238, 257, 268, 275, 333, 334, 356, 362, 368, 369, 405, 407, 408, 418, 420, 423, 442, 446, 474, 480, 487, 529, 559, 586\n",
      "\n",
      "Articles(ID) in Cluster 13: 35, 39, 47, 58, 87, 104, 142, 161, 162, 166, 168, 177, 232, 234, 237, 241, 245, 248, 308, 312, 347, 355, 357, 373, 381, 395, 401, 413, 414, 416, 428, 456, 490, 534, 584, 610\n",
      "\n",
      "Articles(ID) in Cluster 14: 12, 25, 27, 29, 32, 33, 50, 59, 68, 72, 100, 118, 122, 129, 133, 143, 144, 154, 195, 199, 209, 230, 233, 250, 254, 263, 272, 278, 315, 320, 325, 331, 349, 360, 391, 404, 415, 429, 430, 433, 449, 452, 453, 464, 465, 470, 473, 486, 504, 509, 512, 514, 555, 575, 590, 605, 606\n",
      "\n",
      "Articles(ID) in Cluster 15: 1, 4, 16, 66, 80, 101, 107, 120, 121, 138, 140, 145, 157, 163, 169, 170, 175, 188, 193, 203, 269, 271, 280, 305, 326, 329, 350, 386, 392, 425, 431, 437, 445, 448, 450, 457, 461, 467, 472, 479, 484, 516, 521, 553, 562, 574, 585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clustering documents based on topics extracted from LDA model \n",
    "from operator import itemgetter\n",
    "def cluster(doc_term_matrix, num):\n",
    "    doc_topics = ldamodel.get_document_topics(doc_term_matrix, minimum_probability=0.20)\n",
    "    result = [[] for i in range(num)]\n",
    "    for k,topic in enumerate(doc_topics):\n",
    "        # Some articles do not have a topic\n",
    "        if topic:\n",
    "            topic.sort(key = itemgetter(1), reverse=True)\n",
    "            result[topic[0][0]].append(k)\n",
    "    for k in range(len(result)):\n",
    "        print('Articles(ID) in Cluster ' + str(k+1) + ': ' + ', '.join(map(str, result[k])))\n",
    "        print()\n",
    "    return result\n",
    "cluster_result = cluster(doc_term_matrix, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles in Cluster 1: Tensor operator, Set (mathematics), Triangle inequality, Null vector, Defective matrix, Approximation theory, Series acceleration, Remez algorithm, Frame (linear algebra), Joint spectral radius, Matrix norm, Row equivalence, Sesquilinear form, Graded (mathematics), Complex conjugate vector space, MATLAB, K-SVD, Orthogonal Procrustes problem, Entanglement-assisted stabilizer formalism, Row and column spaces, Rayleigh quotient, Quotient space (linear algebra), De Casteljau's algorithm, Explicit algebraic stress model, Self-adjoint, Sparse grid, Uzawa iteration, Predictor–corrector method, Wolfram Language, Linear equation over a ring, Range (mathematics), Matrix multiplication, Generalized singular value decomposition, Hilbert–Poincaré series, Dynamic relaxation\n",
      "\n",
      "Articles in Cluster 2: Resolvent set, Piecewise linear continuation, Stiffness matrix, Portal:Linear algebra, S-procedure, Rod calculus, Engineering, Whitney inequality, Graphics processing unit, Clenshaw algorithm, Underdetermined system, Schur product theorem, Fundamental theorem of linear algebra, Rota's basis conjecture, Synthetic geometry, Dimension theorem for vector spaces, Numeric precision in Microsoft Excel, Material point method, Boundary knot method, The Nine Chapters on the Mathematical Art, Trace identity, Antiunitary operator, Truncation, Reality structure, Relative change and difference, Coordinate system, Digital Library of Mathematical Functions, Wilkinson's polynomial, List of uncertainty propagation software, Stokes operator, Flat pseudospectral method, Equipollence (geometry), Pohlke's theorem, Quaternionic vector space, Fredholm's theorem, Chebyshev pseudospectral method, Coefficient matrix, ND4S, Gabriel Cramer, Finitely generated module, Eigenoperator, Transpose, Kernel (algebra), Spectral method, Orientation (vector space), Homogeneous coordinates, Intersection (Euclidean geometry), Orthogonalization, Linear algebra, Significance arithmetic, Hyperplane, Vector field reconstruction, Unisolvent functions, Condition number, Homogeneous function, Orthogonal transformation, Bra–ket notation, Quadratic eigenvalue problem, Plane (geometry), Ring (mathematics), Weyr canonical form, Tensor product, Flat (geometry), Orthographic projection\n",
      "\n",
      "Articles in Cluster 3: Three-dimensional rotation operator, Stechkin's lemma, Numerical continuation, Function (mathematics), Projection (mathematics), Bilinear form, Function composition, Lp space, Independent equation, Basis function, Closed-form expression, Dimension (vector space), Z-order curve, Nonstandard finite difference scheme, Processor (computing), Bernstein polynomial, Affine arithmetic, Change of basis, Coordinate vector, James Joseph Sylvester, Cyclic subspace\n",
      "\n",
      "Articles in Cluster 4: Discrete Fourier transform, Lady Windermere's Fan (mathematics), Vectorization (mathematics), Multilinear form, Multilinear algebra, Benjamin Peirce, Spherical basis, Image (mathematics), Quantum mechanics, Sylvester's determinant identity, Indeterminate system, Invariants of tensors, Augmented matrix, Nonlinear eigenproblem, Group representation, Surrogate model, Axiom, Codimension, De Boor's algorithm, Multiplicative inverse, Dual basis, Stabilizer code, 3D projection, Interval arithmetic, Backus–Gilbert method, Pointwise, Linear system\n",
      "\n",
      "Articles in Cluster 5: Multiphysics, Padé table, Timeline of numerical analysis after 1945, Weather forecasting, Modulus of smoothness, Round-off error, Semi-simplicity, Gershgorin circle theorem, Gal's accurate tables, List of vector spaces in mathematics, Finite von Neumann algebra, Cross product, Overlap–add method, Finitely generated abelian group, Spectral theorem, Dual space, Padé approximant, Field (physics), Maple (software), Overcompleteness, Finite volume method, Quantification of margins and uncertainties, Truncation error, Gram–Schmidt process, Linearity, 2 × 2 real matrices, Finite difference, General linear group, Singular value decomposition, Method of fundamental solutions, Lie group integrator, Partial trace, Principal ideal domain, Eigenvalues and eigenvectors, Projection (linear algebra), Meshfree methods, Geometric transformation, Centrosymmetric matrix, Partial differential equation, Translation of axes, Nonlinear system, Endomorphism, Majorization, Legendre pseudospectral method, Approximation error, Module homomorphism, Boundary particle method, Newton's identities, Squeeze mapping, Gradient discretisation method, Eigenplane, Chebyshev nodes, Minimum polynomial extrapolation, Relative dimension, Approximation, Semilinear map, Applied element method, Scarborough criterion, Numerical differentiation, Sherman–Morrison formula, Shanks transformation, Rotation\n",
      "\n",
      "Articles in Cluster 6: Woodbury matrix identity, Trilinear coordinates, Productive matrix, Numerical method, Isotonic regression, Frobenius normal form, Compressed sensing, Conjugate transpose, Field (mathematics), Mechanics, Butcher group, Free module, Horner's method, Line–line intersection, Generalizations of Pauli matrices, Triple product, Sylvester's law of inertia, Controlled invariant subspace, Continuous wavelet, Integer points in convex polyhedra, Intersection curve, Special linear group, Commutation matrix, Levi-Civita symbol, Ross–Fahroo lemma, Regularized least squares, Purification of quantum state, Matrix (mathematics), Unitary transformation, Zassenhaus algorithm, Bunch–Nielsen–Sorensen formula\n",
      "\n",
      "Articles in Cluster 7: Euclidean space, Shear matrix, Matrix calculus, Rotation of axes, Arthur Cayley, Partial differential algebraic equation, Numerical methods in fluid mechanics, Gottfried Wilhelm Leibniz, Square-free polynomial, Orthonormal basis, Figure of the Earth, Hypercomplex number, Newton–Krylov method, Von Neumann stability analysis, Levinson recursion, Basis (linear algebra), Reduction (mathematics), Monte Carlo method, Linear inequality, Linear combination, Determinant, Rank (linear algebra), Subset, Fusion frame, Atmosphere, Characteristic polynomial, Generalized eigenvector, Lapped transform, Leibniz formula for determinants, Möbius transformation, Line (geometry), Projection-valued measure, James H. Wilkinson, Bendixson's inequality, Complex plane, Matrix determinant lemma, Rigid body dynamics, Hamming space, Transpose of a linear map, Hermann Grassmann, Bidiagonal matrix, Lorentz transformation, Curve fitting, Normal matrix, Parareal, Samuelson–Berkowitz algorithm, Algebra over a field, Dependence relation, Cokernel\n",
      "\n",
      "Articles in Cluster 8: Quaternion, Linear function, ND4J (software), CSS code, Wave function, Numerical model of the Solar System, Book:Linear algebra, Spinors in three dimensions, Computational statistics, Richardson extrapolation, Adaptive stepsize, Linear span, Quasinorm, Cartesian coordinate system, Monic polynomial, Tapering (mathematics), Fangcheng (mathematics), Mathematics, Antilinear map, Computer vision, Orthant, Matrix congruence, Kahan summation algorithm, Convex cone, Jordan normal form, Rayleigh's quotient in vibrations analysis, Ross–Fahroo pseudospectral method, Savitzky–Golay filter\n",
      "\n",
      "Articles in Cluster 9: Numerical range, Linear map, Reflection (mathematics), Unit vector, Order of approximation, Adjoint state method, Hurwitz determinant, LAPACK, Loss of significance, Matrix addition, Discretization, Hypot, Total set, Linear form, Dot product, Iterative method, Minimax approximation algorithm, Newton fractal, Cache (computing), Row echelon form, Lattice reduction, Hermitian adjoint, Analytic geometry, Faddeev–LeVerrier algorithm, Multi-time-step integration, Tikhonov regularization, Dual basis in a field extension, Vector projection, History of Lorentz transformations, Modeshape, Singular boundary method, Norm (mathematics), Real number, Elementary matrix, Closest point method, Bi-directional delay line, Simpson's rule, Zero object (algebra), Riemann solver, Galerkin method\n",
      "\n",
      "Articles in Cluster 10: Invariant subspace, Runge–Kutta methods, Weyl's inequality, Birkhoff orthogonality, Numerical analysis, Aitken's delta-squared process, Complex conjugate, Zero matrix, Spectral theory, Shear mapping, Matrix analysis, Restricted isometry property, A Treatise on Electricity and Magnetism, Line segment, Carl Friedrich Gauss, Cartesian tensor, Trajectory (fluid mechanics), Perspectivity, Orthogonality, Amitsur–Levitzki theorem, Karlsruhe Accurate Arithmetic, Row and column vectors, Hermes Project, Order of accuracy, Polynomial, Discrete wavelet transform, Differential-algebraic system of equations, Lanczos approximation, Numerical stability, /wiki/Linear algebra, Translation, Orthogonal diagonalization, Element (mathematics), Canonical basis, Canonical map, Radial basis function, Truncated power function, Schmidt decomposition, Wild problem, List of operator splitting topics\n",
      "\n",
      "Articles in Cluster 11: Projective space, Symmetric matrix, Trigonometric tables, René Descartes, Spread of a matrix, Polynomial ring, Proper generalized decomposition, Jenkins–Traub algorithm, Interval contractor, Algorithm, Identifiability analysis, Diagonal matrix, Semi-simple operator, Artificial precision, Finite Legendre transform, Steinitz exchange lemma, Adjugate matrix, Peano kernel theorem, Liouville space, Three-dimensional space, Orthogonal basis, Choi's theorem on completely positive maps, Numerical linear algebra, List of linear algebra topics, Abelian group, Charles Sanders Peirce, Well-posed problem, Identity matrix, Kernel (linear algebra), Numerical error, Linear equation, Sublinear function, Coordinate space, Commutative ring, Matrix similarity, Linear complementarity problem, Curse of dimensionality, Symplectic vector space, Hilbert space\n",
      "\n",
      "Articles in Cluster 12: Mode of a linear field, Haynsworth inertia additivity formula, Equioscillation theorem, Symbolic-numeric computation, Mathematical model, Superconvergence, Geodesy, Binary operation, Skew-Hermitian matrix, Gaussian elimination, Semi-infinite programming, Polarization identity, Level set (data structures), Permanent (mathematics), Coopmans approximation, GetFEM++, Residual (numerical analysis), Dual number, Scalar (mathematics), Computing the permanent, Van Wijngaarden transformation, Polynomial basis, Blossom (functional), Scalar multiplication, Linear subspace, Pairing, Field extension, False precision, Conformable matrix, Fundamental matrix (computer vision), Hundred-dollar, Hundred-digit Challenge problems, List of numerical analysis topics, Cauchy–Schwarz inequality\n",
      "\n",
      "Articles in Cluster 13: Barycentric coordinate system, Ambient space, Peetre's inequality, Probability box, Computer graphics, Sinc numerical methods, Diagonalizable matrix, Sedrakyan's inequality, Euclidean group, Mesh generation, Golden–Thompson inequality, Generalized-strain mesh-free formulation, Quaternionic matrix, Pseudovector, Significant figures, Split-complex number, Seven-dimensional cross product, Big M method, Multilevel Monte Carlo method, Rate of convergence, Absolutely convex set, Rule of Sarrus, Vector space, Standard basis, Jordan–Chevalley decomposition, Multigrid method, Pairwise summation, Quadruple product, Eigenvalue perturbation, Computational complexity, File:Portal-puzzle.svg, Asymmetric norm, Difference quotient, Overdetermined system, Numerical integration, Weakened weak form\n",
      "\n",
      "Articles in Cluster 14: Orthonormality, Dieudonné determinant, Discretization error, Sigma approximation, Cardinality, Normal basis, Multilevel fast multipole method, Signal-flow graph, List of finite element software packages, Computational science, Loewner order, Category of modules, Telegraphy, Zero of a function, Isometry, Immanant, Direct sum of modules, Nonnegative rank (linear algebra), Balanced set, Matrix Chernoff bound, Scale co-occurrence matrix, Movable cellular automaton, Local convergence, Pseudo-spectral method, Vector-valued function, Mathematical analysis, Skew-Hamiltonian matrix, Zech's logarithm, Generator (mathematics), Cramer's rule, Bernstein's constant, Finite field, Robotics, Fredholm alternative, Euclidean vector, Sequence, Hermite normal form, Transfer matrix, Interval propagation, Template:Linear algebra, Propagation of uncertainty, Fast multipole method, Geometry, Regularized meshless method, Linear programming, Unrestricted algorithm, Map (mathematics), Ross' π lemma, System of linear equations, Multi-core processor, Low-discrepancy sequence, Schur complement, Mixed linear complementarity problem, Differential geometry, Manifold, Overlap–save method, FEE method\n",
      "\n",
      "Articles in Cluster 15: Linear independence, Bellman pseudospectral method, Delta operator, Generalized Gauss–Newton method, Rotation (mathematics), Pseudoscalar, Eigengap, Corank, Functional analysis, Flag (linear algebra), Pseudospectral knotting method, Rank factorization, Non-negative matrix factorization, Orthogonal complement, Definite quadratic form, Orthonormal function system, Transformation matrix, Error analysis (mathematics), Matrix difference equation, Dual norm, CORDIC, Isomorphism, Giuseppe Peano, Bijection, Invertible matrix, Coates graph, Affine space, Estrin's scheme, Trace (linear algebra), Orientation of a vector bundle, Successive parabolic interpolation, Nyström method, k-frame, Angles between flats, Homography, Model order reduction, Linear regression, Basic Linear Algebra Subprograms, Abramowitz and Stegun, Inner product space, Kempner series, Quadratic form, Linear approximation, Zero mode, Trace diagram, Guard digit, Function space\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing the exact document titles in each cluster\n",
    "for k in range(len(cluster_result)):\n",
    "    print('Articles in Cluster ' + str(k+1) + ': ' + ', '.join(map(lambda x: titles[x], cluster_result[k])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0018019278), (1, 0.0003391568), (2, 0.0002601787), (3, 0.00022626804), (4, 0.00021372795), (5, 0.00057895511), (6, 0.00030629951), (7, 0.00067538727), (8, 0.00044926157), (9, 0.00035495567), (10, 0.00099961704), (11, 0.00024742377), (12, 0.00029577976), (13, 0.00029819994), (14, 0.00031532196)]\n"
     ]
    }
   ],
   "source": [
    "term_topics = ldamodel.get_term_topics('convex', minimum_probability=0.000001)\n",
    "print(term_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Top 7 articles related to convex -------\n",
      "Entanglement-assisted stabilizer formalism \n",
      " 0.996538 \n",
      "\n",
      "Row and column spaces \n",
      " 0.996451 \n",
      "\n",
      "Matrix multiplication \n",
      " 0.995357 \n",
      "\n",
      "Remez algorithm \n",
      " 0.995189 \n",
      "\n",
      "Defective matrix \n",
      " 0.994574 \n",
      "\n",
      "Complex conjugate vector space \n",
      " 0.992651 \n",
      "\n",
      "Frame (linear algebra) \n",
      " 0.992157 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting related documents based on a term \n",
    "def get_related_documents(term, top, doc_term_matrix):\n",
    "    print('------- Top', top, 'articles related to',term,'-------')\n",
    "    related_docs = []\n",
    "    doc_topics = ldamodel.get_document_topics(doc_term_matrix, minimum_probability=0.20)\n",
    "    term_topics = ldamodel.get_term_topics(term, minimum_probability=0.000001)\n",
    "    term_topics.sort(key = itemgetter(1), reverse=True)\n",
    "    for k,topic in enumerate(doc_topics):\n",
    "        if topic:\n",
    "            topic.sort(key = itemgetter(1), reverse=True)\n",
    "            if topic[0][0] == term_topics[0][0]:\n",
    "                related_docs.append((k,topic[0][1]))\n",
    "    related_docs.sort(key = itemgetter(1), reverse=True)\n",
    "    result = []\n",
    "    for j,doc in enumerate(related_docs):\n",
    "        print(titles[doc[0]],\"\\n\",doc[1],\"\\n\")   \n",
    "        result.append(titles[doc[0]])\n",
    "        if j == top - 1:\n",
    "            break\n",
    "related_docs = get_related_documents('convex', 7, doc_term_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "def get_theme(doc, cluster_result):\n",
    "    doc_id = titles.index(doc)\n",
    "    if doc_id == -1:\n",
    "        print('Document not found.')\n",
    "        return\n",
    "    for i, cluster in enumerate(cluster_result):\n",
    "        if doc_id in cluster:\n",
    "            return i+1\n",
    "    return 0\n",
    "cluster_num = get_theme('Absolutely convex set', cluster_result)\n",
    "print(cluster_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=611, num_nnz=143903)\n",
      "(0, 0.056852536755099284)\n"
     ]
    }
   ],
   "source": [
    "# Implementing tf-idf model; the only information needed from the previous part is the doc_term_matrix\n",
    "from gensim.models import TfidfModel, LsiModel\n",
    "tfidf_model = TfidfModel(doc_term_matrix, dictionary = dictionary)\n",
    "print(tfidf_model)\n",
    "vector = tfidf_model[doc_term_matrix[0]]\n",
    "print(vector[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LsiModel(num_terms=5846, num_topics=200, decay=1.0, chunksize=20000)\n"
     ]
    }
   ],
   "source": [
    "# Implementing LSI model; the only information needed from the previous part is the doc_term_matrix\n",
    "lsi_model = LsiModel(doc_term_matrix, id2word=dictionary)\n",
    "print(lsi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n"
     ]
    }
   ],
   "source": [
    "# Creating the similarity matrix from simple bag-of-words model (# of documents * # of documents)\n",
    "from gensim import similarities\n",
    "\n",
    "index = similarities.MatrixSimilarity(doc_term_matrix, num_features=len(dictionary))\n",
    "print(len(index[doc_term_matrix[610]])) # 611 * 611 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training tf-idf model from bag-of-word dataset\n",
    "model_tfidf = TfidfModel(doc_term_matrix, id2word=dictionary, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying tf-idf model to all vectors\n",
    "from gensim.corpora import MmCorpus\n",
    "MmCorpus.serialize('./corpus_tfidf.mm', model_tfidf[doc_term_matrix], progress_cnt=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixSimilarity<611 docs, 5846 features>\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = MmCorpus('./corpus_tfidf.mm') # Loading back the corpus file after applying tf-idf\n",
    "model_lsi = LsiModel(corpus_tfidf, num_topics=15, id2word=dictionary)\n",
    "# Applying LSI model to all vectors\n",
    "index = similarities.MatrixSimilarity(model_lsi[corpus_tfidf], num_features=len(dictionary))\n",
    "print(index)\n",
    "index.save('./lsi_index.mm') # Saving the similarity matrix to a local matrix market file named './lsi_model.mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n"
     ]
    }
   ],
   "source": [
    "# Loading the similarity matrix back from the local file\n",
    "similarity_matrix = similarities.MatrixSimilarity.load('./lsi_index.mm')\n",
    "print(len(similarity_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
