{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n",
      "611\n"
     ]
    }
   ],
   "source": [
    "# Splitting text data and storing them in a list (of articles)\n",
    "import io\n",
    "docs = io.open(\"raw_data.txt\", mode=\"r\", encoding=\"utf-8\", errors=\"ignore\").read().split('\\n') # list of strings \n",
    "titles_raw = [docs[i] for i in range(len(docs)) if i % 2 == 0] # list of string titles\n",
    "contents_raw = [docs[i] for i in range(len(docs)) if i % 2 == 1] # list of string contents\n",
    "titles = []\n",
    "contents = []\n",
    "for i in range(len(titles_raw)):\n",
    "    if contents_raw[i] != '':\n",
    "        titles.append(titles_raw[i])\n",
    "        contents.append(contents_raw[i])\n",
    "titles = list(set(titles))\n",
    "contents = list(set(contents))\n",
    "\n",
    "print(len(titles))\n",
    "print(len(contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing/ cleaning the data\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# remove text between parenthesis\n",
    "# contents = list(map(lambda x: re.sub(r\"\\(.*\\)\",\"\",x), contents))\n",
    "\n",
    "# remove all digits from text\n",
    "contents = list(map(lambda x: re.sub(r\"\\d+\",\"\",x), contents))\n",
    "\n",
    "stop = set(stopwords.words('english')) # set of stopwords\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    # remove stopwords and words that are too short\n",
    "    return [lemma.lemmatize(i, 'v') for i in word_tokenize(doc) if i not in stop and len(i) > 2]\n",
    "cleaned = [clean(page.lower()) for page in contents]\n",
    "\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(25740 unique tokens: ['.another', 'abstraction', 'act', 'adapt', 'algebraic']...)\n",
      "Dictionary(5934 unique tokens: ['.another', 'abstraction', 'act', 'adapt', 'algebraic']...)\n",
      "Dictionary(5896 unique tokens: ['.another', 'abstraction', 'act', 'adapt', 'algebraic']...)\n",
      "Dictionary(5846 unique tokens: ['.another', 'abstraction', 'act', 'adapt', 'algebraic']...)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Building word dicitonary\n",
    "from gensim import corpora\n",
    "# create the term dictionary of our corpus; terms are unique; each term is assigned an index\n",
    "dictionary = corpora.Dictionary(cleaned)\n",
    "print(dictionary)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.7)\n",
    "print(dictionary)\n",
    "#filtering for words that are semantically related within the dictionary \n",
    "stoplist = set('also use make people know many call include part find become like mean often different usually take wikt come give well get since type list say change see refer actually iii aisne kinds pas ask would way something need things want every str'.split())\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "dictionary.filter_tokens(stop_ids)\n",
    "print(dictionary)\n",
    "dictionary.filter_n_most_frequent(50)\n",
    "print(dictionary)\n",
    "\n",
    "# This saves the dictionary to the local disk\n",
    "dictionary.save_as_text('./dictionary.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n",
      "738\n",
      "[(4, 3), (9, 1), (10, 1), (14, 1), (15, 5), (20, 1), (38, 1), (39, 1), (50, 1), (60, 1), (63, 1), (69, 1), (75, 1), (85, 1), (93, 1), (98, 4), (103, 1), (109, 1), (174, 1), (196, 1), (202, 2), (217, 4), (226, 22), (252, 8), (253, 1), (290, 9), (320, 1), (331, 1), (348, 4), (349, 1), (426, 5), (427, 1), (471, 1), (483, 1), (517, 1), (527, 1), (528, 1), (533, 1), (537, 2), (557, 2), (562, 1), (564, 7), (592, 1), (613, 1), (625, 2), (627, 1), (641, 1), (655, 1), (679, 1), (681, 1), (689, 1), (699, 1), (703, 1), (745, 1), (750, 1), (751, 1), (757, 1), (769, 1), (788, 1), (813, 1), (832, 6), (890, 2), (900, 1), (940, 1), (1001, 1), (1010, 1), (1024, 3), (1031, 1), (1059, 1), (1096, 1), (1106, 1), (1119, 1), (1141, 3), (1150, 1), (1188, 1), (1202, 1), (1271, 2), (1276, 1), (1292, 1), (1328, 6), (1347, 3), (1386, 1), (1405, 2), (1430, 2), (1498, 1), (1532, 1), (1561, 1), (1572, 1), (1577, 1), (1599, 1), (1612, 2), (1625, 2), (1770, 1), (2091, 1), (2092, 1), (2097, 1), (2103, 3), (2178, 1), (2179, 1), (2180, 3), (2181, 2), (2182, 6), (2183, 32), (2184, 1), (2185, 2), (2186, 1), (2187, 2), (2188, 1), (2189, 1), (2190, 2), (2191, 1), (2192, 1), (2193, 2), (2194, 1), (2195, 1), (2196, 2), (2197, 2), (2198, 3), (2199, 1), (2200, 1), (2201, 1), (2202, 1), (2203, 1), (2204, 1), (2205, 1), (2206, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Creating document-term matrix from vocabulary (dictionary)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in cleaned]\n",
    "print(len(doc_term_matrix))\n",
    "print(len(doc_term_matrix[1]))\n",
    "print(doc_term_matrix[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# M = np.array([[0 for i in range(len(dictionary))] for i in range(len(dictionary))])\n",
    "# for i in range (len(doc_term_matrix)):\n",
    "#     for j in range (len(doc_term_matrix[i])):\n",
    "#         for k in range(j+1, len(doc_term_matrix[i])):\n",
    "#             M[doc_term_matrix[i][j][0]][doc_term_matrix[i][k][0]] +=1\n",
    "#             M[doc_term_matrix[i][k][0]][doc_term_matrix[i][j][0]] +=1\n",
    "#         freqMax = max(M[j])\n",
    "#         M[j] = M[j] / freqMax\n",
    "        \n",
    "# #         M[j] = [x / freqMax for x in M[j]]\n",
    "\n",
    "# for j in range(len(M)):\n",
    "#     minM = min(M[j])\n",
    "#     maxM = max(M[j])\n",
    "#     R = minM/maxM\n",
    "#     rel = R/(1+R)\n",
    "#     for k in range(len(M[j])):\n",
    "#         M[j][k] = rel\n",
    "# M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   0.008*\"vectors\" + 0.008*\"model\" + 0.006*\"ring\" + 0.005*\"group\" + 0.005*\"coordinate\" + 0.004*\"cross\" + 0.004*\"structure\" + 0.004*\"process\" + 0.003*\"polynomial\" + 0.003*\"unit\" \n",
      "\n",
      "2   0.007*\"row\" + 0.007*\"solution\" + 0.005*\"methods\" + 0.005*\"matrices\" + 0.004*\"problems\" + 0.004*\"vectors\" + 0.004*\"sequence\" + 0.004*\"coordinate\" + 0.004*\"rank\" + 0.004*\"numerical\" \n",
      "\n",
      "3   0.006*\"model\" + 0.006*\"line\" + 0.005*\"sequence\" + 0.005*\"affine\" + 0.004*\"coordinate\" + 0.004*\"elements\" + 0.004*\"tensor\" + 0.004*\"state\" + 0.003*\"projection\" + 0.003*\"quantum\" \n",
      "\n",
      "4   0.006*\"row\" + 0.006*\"group\" + 0.005*\"vectors\" + 0.004*\"coordinate\" + 0.004*\"data\" + 0.004*\"map\" + 0.004*\"matrices\" + 0.004*\"solution\" + 0.004*\"algorithm\" + 0.003*\"cache\" \n",
      "\n",
      "5   0.005*\"methods\" + 0.005*\"polynomial\" + 0.005*\"vectors\" + 0.004*\"group\" + 0.004*\"matrices\" + 0.004*\"problems\" + 0.004*\"finite\" + 0.004*\"element\" + 0.003*\"...\" + 0.003*\"problem\" \n",
      "\n",
      "6   0.010*\"coordinate\" + 0.006*\"line\" + 0.006*\"transformation\" + 0.005*\"map\" + 0.005*\"group\" + 0.004*\"lorentz\" + 0.004*\"image\" + 0.004*\"row\" + 0.004*\"plane\" + 0.004*\"transformations\" \n",
      "\n",
      "7   0.008*\"line\" + 0.006*\"engineer\" + 0.005*\"solution\" + 0.004*\"map\" + 0.004*\"model\" + 0.004*\"plane\" + 0.003*\"geometry\" + 0.003*\"coefficients\" + 0.003*\"mathematical\" + 0.003*\"polynomial\" \n",
      "\n",
      "8   0.008*\"matrices\" + 0.006*\"coordinate\" + 0.005*\"projective\" + 0.005*\"plane\" + 0.004*\"map\" + 0.004*\"geometry\" + 0.004*\"quadratic\" + 0.004*\"vectors\" + 0.004*\"group\" + 0.003*\"work\" \n",
      "\n",
      "9   0.014*\"group\" + 0.011*\"ring\" + 0.005*\"map\" + 0.004*\"generate\" + 0.004*\"finitely\" + 0.004*\"coordinate\" + 0.004*\"elements\" + 0.003*\"line\" + 0.003*\"polynomial\" + 0.003*\"methods\" \n",
      "\n",
      "10   0.007*\"ring\" + 0.005*\"group\" + 0.005*\"vectors\" + 0.004*\"multiplication\" + 0.004*\"matrices\" + 0.004*\"scalar\" + 0.004*\"quantum\" + 0.003*\"trace\" + 0.003*\"solution\" + 0.003*\"norm\" \n",
      "\n",
      "11   0.006*\"polynomial\" + 0.006*\"matrices\" + 0.005*\".mw-parser-output\" + 0.004*\"vectors\" + 0.004*\"map\" + 0.004*\"algorithm\" + 0.004*\"determinant\" + 0.004*\"methods\" + 0.003*\"variables\" + 0.003*\"solution\" \n",
      "\n",
      "12   0.008*\"line\" + 0.005*\"vectors\" + 0.004*\"plane\" + 0.004*\"quantum\" + 0.003*\"three\" + 0.003*\"group\" + 0.003*\"geometry\" + 0.003*\"data\" + 0.003*\"coordinate\" + 0.003*\"row\" \n",
      "\n",
      "13   0.010*\"polynomial\" + 0.007*\"map\" + 0.006*\"matrices\" + 0.005*\"elements\" + 0.004*\"polynomials\" + 0.004*\"geometry\" + 0.004*\"line\" + 0.004*\"group\" + 0.004*\"model\" + 0.003*\"ring\" \n",
      "\n",
      "14   0.011*\"coordinate\" + 0.009*\"group\" + 0.007*\"finite\" + 0.005*\"matrices\" + 0.005*\"root\" + 0.005*\"ring\" + 0.005*\"line\" + 0.005*\"geometry\" + 0.005*\"polynomial\" + 0.005*\"abelian\" \n",
      "\n",
      "15   0.012*\"vectors\" + 0.007*\"matrices\" + 0.006*\"operator\" + 0.006*\"hilbert\" + 0.005*\"map\" + 0.005*\"group\" + 0.005*\"finite\" + 0.004*\"row\" + 0.004*\"elements\" + 0.004*\"coordinate\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training LDA model\n",
    "# LDA automatically finds the mixture of similar words together, thus forming the topic or theme. we use this \n",
    "# unsupervised learning technique to identify the categories to which these articles belong, and the groups/clusters\n",
    "# within the collection. \n",
    "\n",
    "from gensim.models.ldamodel import LdaModel as Lda\n",
    "\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=15, id2word = dictionary)\n",
    "\n",
    "# Showing the 15 identified topics after the model is trained, where top 10 key terms are listed for each topic\n",
    "for topic in ldamodel.print_topics(num_topics=15, num_words=10):\n",
    "    print(topic[0]+1, \" \", topic[1],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles(ID) in Cluster 1: 25, 52, 53, 72, 84, 93, 98, 104, 126, 129, 154, 178, 189, 192, 195, 222, 238, 241, 244, 278, 286, 289, 356, 357, 362, 429, 434, 448, 456, 493, 498, 510, 525, 531, 540, 552, 573, 580, 592, 597, 607\n",
      "\n",
      "Articles(ID) in Cluster 2: 7, 13, 21, 23, 26, 35, 36, 69, 70, 71, 83, 92, 96, 97, 130, 137, 155, 161, 164, 171, 187, 190, 202, 205, 251, 258, 275, 284, 294, 314, 320, 326, 336, 344, 346, 354, 363, 401, 411, 424, 437, 458, 467, 473, 495, 521, 530, 536, 543, 554, 556, 567, 576, 586\n",
      "\n",
      "Articles(ID) in Cluster 3: 10, 22, 49, 54, 65, 68, 140, 169, 183, 220, 252, 291, 312, 323, 335, 365, 370, 400, 432, 485, 561, 568, 588, 601\n",
      "\n",
      "Articles(ID) in Cluster 4: 12, 32, 57, 61, 73, 102, 131, 148, 157, 172, 173, 206, 229, 270, 301, 352, 359, 361, 382, 405, 407, 413, 430, 435, 462, 472, 480, 489, 563, 569, 571, 600\n",
      "\n",
      "Articles(ID) in Cluster 5: 11, 19, 46, 101, 113, 141, 150, 151, 152, 158, 163, 165, 219, 223, 230, 231, 233, 262, 267, 307, 309, 329, 338, 341, 349, 350, 368, 376, 404, 412, 421, 422, 428, 439, 443, 447, 457, 482, 494, 497, 502, 505, 506, 512, 519, 528, 537, 551, 572, 574, 583\n",
      "\n",
      "Articles(ID) in Cluster 6: 3, 18, 48, 50, 62, 64, 79, 122, 167, 199, 209, 235, 250, 255, 266, 279, 280, 360, 377, 465, 496, 535, 599\n",
      "\n",
      "Articles(ID) in Cluster 7: 37, 76, 82, 106, 110, 117, 118, 175, 176, 193, 201, 236, 247, 256, 372, 379, 394, 403, 409, 414, 425, 491, 550, 557, 589, 591, 595, 598, 602\n",
      "\n",
      "Articles(ID) in Cluster 8: 0, 5, 47, 56, 103, 132, 143, 200, 211, 227, 268, 306, 316, 374, 387, 398, 399, 416, 426, 427, 431, 436, 461, 469, 475, 507, 516, 524, 527, 539, 553, 558, 590\n",
      "\n",
      "Articles(ID) in Cluster 9: 4, 14, 66, 80, 85, 114, 121, 124, 133, 138, 144, 153, 160, 162, 182, 188, 198, 208, 216, 221, 253, 259, 263, 272, 300, 343, 367, 375, 383, 390, 392, 396, 402, 468, 474, 487, 501, 508, 515, 523, 533, 581\n",
      "\n",
      "Articles(ID) in Cluster 10: 8, 108, 134, 166, 168, 177, 197, 212, 260, 276, 290, 340, 355, 358, 393, 441, 481, 500, 513, 514, 518, 522, 544, 548\n",
      "\n",
      "Articles(ID) in Cluster 11: 16, 24, 29, 31, 33, 74, 81, 90, 94, 109, 136, 156, 159, 170, 174, 184, 196, 204, 210, 225, 249, 254, 274, 281, 285, 302, 308, 325, 328, 345, 369, 408, 454, 464, 466, 479, 484, 566, 582, 584\n",
      "\n",
      "Articles(ID) in Cluster 12: 27, 34, 40, 42, 59, 63, 77, 78, 87, 105, 111, 112, 228, 237, 273, 277, 283, 311, 331, 339, 381, 391, 395, 445, 463, 478, 486, 541, 555, 575, 593, 604, 609\n",
      "\n",
      "Articles(ID) in Cluster 13: 1, 2, 17, 28, 41, 89, 125, 149, 179, 185, 186, 203, 207, 215, 232, 239, 245, 257, 261, 265, 315, 318, 337, 342, 347, 364, 366, 380, 386, 406, 417, 420, 442, 444, 477, 483, 499, 509, 511, 517, 545, 549, 560, 587, 596, 605\n",
      "\n",
      "Articles(ID) in Cluster 14: 30, 38, 43, 60, 75, 99, 115, 116, 119, 142, 217, 218, 224, 234, 240, 242, 288, 303, 304, 319, 321, 324, 373, 378, 385, 389, 415, 418, 451, 452, 470, 471, 492, 532, 542, 562, 577, 578, 579\n",
      "\n",
      "Articles(ID) in Cluster 15: 6, 9, 15, 20, 39, 44, 45, 51, 55, 58, 67, 86, 88, 91, 95, 100, 107, 120, 123, 127, 128, 135, 139, 145, 146, 147, 180, 181, 191, 194, 213, 214, 226, 243, 246, 248, 264, 269, 271, 282, 287, 292, 293, 295, 296, 297, 298, 299, 305, 310, 317, 322, 327, 330, 332, 333, 334, 351, 353, 371, 384, 388, 397, 410, 419, 423, 433, 438, 440, 446, 449, 450, 453, 455, 459, 460, 476, 488, 490, 503, 504, 520, 526, 529, 534, 538, 546, 547, 559, 564, 565, 570, 585, 594, 603, 606, 608, 610\n",
      "\n",
      "[25, 52, 53, 72, 84, 93, 98, 104, 126, 129, 154, 178, 189, 192, 195, 222, 238, 241, 244, 278, 286, 289, 356, 357, 362, 429, 434, 448, 456, 493, 498, 510, 525, 531, 540, 552, 573, 580, 592, 597, 607]\n"
     ]
    }
   ],
   "source": [
    "# Clustering documents based on topics extracted from LDA model \n",
    "from operator import itemgetter\n",
    "def cluster(doc_term_matrix, num):\n",
    "    doc_topics = ldamodel.get_document_topics(doc_term_matrix, minimum_probability=0.20)\n",
    "    result = [[] for i in range(num)]\n",
    "    for k,topic in enumerate(doc_topics):\n",
    "        # Some articles do not have a topic\n",
    "        if topic:\n",
    "            topic.sort(key = itemgetter(1), reverse=True)\n",
    "            result[topic[0][0]].append(k)\n",
    "    for k in range(len(result)):\n",
    "        print('Articles(ID) in Cluster ' + str(k+1) + ': ' + ', '.join(map(str, result[k])))\n",
    "        print()\n",
    "    return result\n",
    "cluster_result = cluster(doc_term_matrix, 15)\n",
    "print(cluster_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles in Cluster 1: Wild problem, Orthogonal Procrustes problem, Row echelon form, Multiplicative inverse, Finite difference, Padé approximant, Equioscillation theorem, Zassenhaus algorithm, Partial differential algebraic equation, Quadratic eigenvalue problem, Chebyshev nodes, Interval arithmetic, Generalized-strain mesh-free formulation, Haynsworth inertia additivity formula, Differential geometry, Robotics, Symplectic vector space, History of Lorentz transformations, Newton–Krylov method, Pseudoscalar, Bilinear form, Integer points in convex polyhedra, Perspectivity, Cross product, Matrix (mathematics), Monic polynomial, Diagonal matrix, Hermitian adjoint, Birkhoff orthogonality, James Joseph Sylvester, CORDIC, Frame (linear algebra), Flat (geometry), Hermite normal form, Z-order curve, Real number, Significance arithmetic, Rotation, Dynamic relaxation, Numerical integration, Basis (linear algebra)\n",
      "\n",
      "Articles in Cluster 2: Wave function, Square-free polynomial, Linear equation over a ring, Sequence, Linear function, Book:Linear algebra, Timeline of numerical analysis after 1945, Gram–Schmidt process, Weyl's inequality, Vector space, Vectorization (mathematics), Numerical methods in fluid mechanics, Stiffness matrix, Movable cellular automaton, Lady Windermere's Fan (mathematics), Polynomial basis, Immanant, Reduction (mathematics), Gal's accurate tables, False precision, Numerical continuation, Rotation of axes, Abramowitz and Stegun, S-procedure, Bi-directional delay line, Linear programming, Basis function, Ambient space, Entanglement-assisted stabilizer formalism, Triple product, Linear approximation, Principal ideal domain, Hilbert space, Linear equation, Gaussian elimination, Conjugate transpose, Polynomial ring, Multilinear form, Majorization, Peano kernel theorem, Defective matrix, Projection-valued measure, Analytic geometry, Minimum polynomial extrapolation, Angles between flats, Numerical linear algebra, Algebra over a field, Linear form, Regularized meshless method, Nonlinear eigenproblem, Dual number, Linear subspace, Closed-form expression, Resolvent set\n",
      "\n",
      "Articles in Cluster 3: Polarization identity, Euclidean vector, Commutation matrix, Runge–Kutta methods, LAPACK, Trilinear coordinates, Binary operation, Continuous wavelet, Material point method, Minimax approximation algorithm, Truncation error, Transpose, K-SVD, Dependence relation, Successive parabolic interpolation, Delta operator, Reflection (mathematics), Matrix Chernoff bound, Multi-core processor, Self-adjoint, Remez algorithm, Interval propagation, Indeterminate system, Non-negative matrix factorization\n",
      "\n",
      "Articles in Cluster 4: Method of fundamental solutions, Partial trace, Plane (geometry), Finite volume method, Approximation theory, Giuseppe Peano, Matrix congruence, Orthogonal basis, Algorithm, Overcompleteness, Amitsur–Levitzki theorem, Relative change and difference, Atmosphere, Mixed linear complementarity problem, Mode of a linear field, CSS code, Proper generalized decomposition, Difference quotient, Finite field, Order of accuracy, Linear combination, Orthographic projection, Orthonormal function system, Seven-dimensional cross product, Tensor operator, Linear complementarity problem, MATLAB, Wolfram Language, Sparse grid, Applied element method, Restricted isometry property, Telegraphy\n",
      "\n",
      "Articles in Cluster 5: Whitney inequality, Homogeneous coordinates, Model order reduction, Spherical basis, Stokes operator, Loewner order, Quaternionic vector space, Matrix difference equation, Reality structure, Multi-time-step integration, Coopmans approximation, Rayleigh quotient, Lp space, Artificial precision, Zech's logarithm, Samuelson–Berkowitz algorithm, Rotation (mathematics), Matrix analysis, Compressed sensing, Nonnegative rank (linear algebra), Map (mathematics), Processor (computing), Normal basis, Generalized Gauss–Newton method, Antiunitary operator, Singular boundary method, Guard digit, Quotient space (linear algebra), Nonlinear system, Cartesian tensor, Mathematical analysis, A Treatise on Electricity and Magnetism, Field extension, Linear system, Explicit algebraic stress model, Definite quadratic form, Sylvester's law of inertia, Scalar multiplication, Pairing, Quantification of margins and uncertainties, Sherman–Morrison formula, Projection (mathematics), Norm (mathematics), Split-complex number, Kahan summation algorithm, File:Portal-puzzle.svg, Zero object (algebra), List of operator splitting topics, Complex conjugate vector space, Numerical model of the Solar System, Cache (computing)\n",
      "\n",
      "Articles in Cluster 6: Leibniz formula for determinants, Orthogonal complement, Invariants of tensors, Centrosymmetric matrix, Quasinorm, Generalized eigenvector, Free module, Overlap–add method, Monte Carlo method, Bellman pseudospectral method, Geometry, Richardson extrapolation, Uzawa iteration, Manifold, Category of modules, Ross–Fahroo lemma, System of linear equations, Generalizations of Pauli matrices, Liouville space, Sinc numerical methods, Rank (linear algebra), Computational complexity, Homogeneous function\n",
      "\n",
      "Articles in Cluster 7: Module homomorphism, Normal matrix, Superconvergence, Generator (mathematics), Computational statistics, Truncated power function, Karlsruhe Accurate Arithmetic, Eigenvalues and eigenvectors, De Boor's algorithm, Eigenvalue perturbation, Overdetermined system, Antilinear map, Translation of axes, Adjoint state method, Sublinear function, Sylvester's determinant identity, Multigrid method, Translation, Set (mathematics), James H. Wilkinson, Truncation, Discrete Fourier transform, Finitely generated abelian group, Intersection (Euclidean geometry), Orthogonal transformation, Semi-simple operator, Nyström method, Line–line intersection, Linear inequality\n",
      "\n",
      "Articles in Cluster 8: Squeeze mapping, Finitely generated module, Trigonometric tables, Peetre's inequality, Low-discrepancy sequence, Template:Linear algebra, Modeshape, Invariant subspace, Legendre pseudospectral method, De Casteljau's algorithm, Complex plane, Scalar (mathematics), Isotonic regression, Aitken's delta-squared process, Simpson's rule, Overlap–save method, List of linear algebra topics, Underdetermined system, Scale co-occurrence matrix, Differential-algebraic system of equations, Isomorphism, Pseudospectral knotting method, Multilinear algebra, Dieudonné determinant, List of numerical analysis topics, List of finite element software packages, Synthetic geometry, Jenkins–Traub algorithm, Lorentz transformation, Segre classification, Zero matrix, Graded (mathematics), Cramer's rule\n",
      "\n",
      "Articles in Cluster 9: Pohlke's theorem, Gradient discretisation method, Chebyshev pseudospectral method, Zero of a function, Dual basis in a field extension, Basic Linear Algebra Subprograms, Möbius transformation, Ross–Fahroo pseudospectral method, Cyclic subspace, Galerkin method, Homography, ND4J (software), Generalized singular value decomposition, Hilbert–Poincaré series, Balanced set, Maple (software), Three-dimensional rotation operator, Estrin's scheme, Condition number, Augmented matrix, Range (mathematics), Canonical map, Lanczos approximation, Bendixson's inequality, Inner product space, Engineering, Bunch–Nielsen–Sorensen formula, Three-dimensional space, Orthogonalization, Singular value decomposition, Scarborough criterion, Affine space, Vector projection, Coordinate system, Total set, Riemann solver, Hypercomplex number, List of uncertainty propagation software, Permanent (mathematics), Partial differential equation, GetFEM++, Cartesian coordinate system\n",
      "\n",
      "Articles in Cluster 10: ND4S, Linearity, Adaptive stepsize, Stabilizer code, Jordan–Chevalley decomposition, Frobenius normal form, Discrete wavelet transform, Hermann Grassmann, Matrix multiplication, Stechkin's lemma, Dual norm, Kernel (algebra), Eigengap, Function composition, Coordinate space, The Nine Chapters on the Mathematical Art, Hundred-dollar, Hundred-digit Challenge problems, Intersection curve, Projective space, Fundamental matrix (computer vision), Eigenplane, Quaternionic matrix, Weyr canonical form, k-frame\n",
      "\n",
      "Articles in Cluster 11: Schur complement, René Descartes, Dual basis, Unitary transformation, Butcher group, Sedrakyan's inequality, Schmidt decomposition, Kernel (linear algebra), Controlled invariant subspace, Spread of a matrix, Weather forecasting, Linear regression, Matrix determinant lemma, Mathematical model, Change of basis, Zero mode, Vector-valued function, Trace diagram, Order of approximation, Symmetric matrix, Dual space, Surrogate model, Dimension theorem for vector spaces, Lattice reduction, Hypot, Meshfree methods, Tikhonov regularization, Boundary particle method, Digital Library of Mathematical Functions, Determinant, Semi-simplicity, Matrix norm, Predictor–corrector method, Dot product, Wilkinson's polynomial, Eigenoperator, Semilinear map, Mesh generation, Well-posed problem, Quaternion\n",
      "\n",
      "Articles in Cluster 12: Bra–ket notation, Multiphysics, Barycentric coordinate system, FEE method, Numerical error, Trace identity, Padé table, Commutative ring, Rota's basis conjecture, Transformation matrix, Curve fitting, Triangle inequality, Pairwise summation, Savitzky–Golay filter, Spectral theorem, Quadruple product, Asymmetric norm, Field (mathematics), Choi's theorem on completely positive maps, Line segment, Tapering (mathematics), Semi-infinite programming, Complex conjugate, Numerical differentiation, Boundary knot method, Orthonormal basis, Adjugate matrix, Orthonormality, Numeric precision in Microsoft Excel, Coefficient matrix, Curse of dimensionality, Trajectory (fluid mechanics), Cokernel\n",
      "\n",
      "Articles in Cluster 13: Error analysis (mathematics), Pseudovector, Rayleigh's quotient in vibrations analysis, Corank, Loss of significance, Affine arithmetic, Residual (numerical analysis), Linear algebra, Golden–Thompson inequality, Graphics processing unit, Hurwitz determinant, Geometric transformation, Approximation, Spectral method, Portal:Linear algebra, Dimension (vector space), Matrix addition, Rate of convergence, Clenshaw algorithm, Mechanics, Rule of Sarrus, Abelian group, Computer vision, Backus–Gilbert method, Modulus of smoothness, Tensor product, Fusion frame, Row and column spaces, /wiki/Linear algebra, Fast multipole method, Special linear group, Rigid body dynamics, Van Wijngaarden transformation, Computer graphics, Axiom, Computational science, Bijection, Euclidean space, General linear group, Coates graph, Independent equation, Numerical analysis, Endomorphism, List of vector spaces in mathematics, Signal-flow graph, Carl Friedrich Gauss\n",
      "\n",
      "Articles in Cluster 14: Elementary matrix, Weakened weak form, Faddeev–LeVerrier algorithm, Newton's identities, Unrestricted algorithm, Linear independence, Significant figures, Parareal, Horner's method, Orthant, Local convergence, Discretization, Orthogonal diagonalization, Numerical range, Computing the permanent, Flag (linear algebra), Field (physics), Matrix similarity, Diagonalizable matrix, Identity matrix, Radial basis function, Abstract algebra, Element (mathematics), Gottfried Wilhelm Leibniz, Ross' π lemma, Quadratic form, Symbolic-numeric computation, Numerical method, Multilevel fast multipole method, Jordan normal form, Shanks transformation, Sesquilinear form, Ring (mathematics), Von Neumann stability analysis, Joint spectral radius, Big M method, Function space, Productive matrix, Skew-Hermitian matrix\n",
      "\n",
      "Articles in Cluster 15: Closest point method, Bidiagonal matrix, Rod calculus, Flat pseudospectral method, Level set (data structures), Propagation of uncertainty, Function (mathematics), Unit vector, Levinson recursion, Approximation error, Schur product theorem, Piecewise linear continuation, Figure of the Earth, Direct sum of modules, Matrix calculus, Functional analysis, Iterative method, Charles Sanders Peirce, Trace (linear algebra), Absolutely convex set, 2 × 2 real matrices, Spinors in three dimensions, Fangcheng (mathematics), Skew-Hamiltonian matrix, Bernstein's constant, Codimension, Line (geometry), Probability box, Coordinate vector, Woodbury matrix identity, Linear span, Orientation of a vector bundle, Hermes Project, Pseudo-spectral method, Orientation (vector space), Benjamin Peirce, Arthur Cayley, Relative dimension, Fundamental theorem of linear algebra, Null vector, Finite von Neumann algebra, Image (mathematics), Rank factorization, Hyperplane, Nonstandard finite difference scheme, Lapped transform, Fredholm's theorem, Invertible matrix, Numerical stability, Mathematics, Regularized least squares, Purification of quantum state, Steinitz exchange lemma, Shear mapping, Projection (linear algebra), Isometry, Unisolvent functions, Gabriel Cramer, Quantum mechanics, Conformable matrix, Canonical basis, Characteristic polynomial, Polynomial, Convex cone, Transpose of a linear map, Gershgorin circle theorem, Finite Legendre transform, Round-off error, Spectral theory, Newton fractal, Euclidean group, Standard basis, Levi-Civita symbol, Hamming space, Identifiability analysis, Kempner series, Row and column vectors, Multilevel Monte Carlo method, Equipollence (geometry), Group representation, Cauchy–Schwarz inequality, Lie group integrator, Bernstein polynomial, Blossom (functional), Series acceleration, Discretization error, Transfer matrix, Fredholm alternative, Interval contractor, Sigma approximation, Shear matrix, Pointwise, Vector field reconstruction, 3D projection, Subset, Orthogonality, Cardinality, Linear map\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing the exact document titles in each cluster\n",
    "for k in range(len(cluster_result)):\n",
    "    print('Articles in Cluster ' + str(k+1) + ': ' + ', '.join(map(lambda x: titles[x], cluster_result[k])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.00022110497), (1, 0.00016792426), (2, 0.00032883399), (3, 0.00043806454), (4, 0.0016067401), (5, 0.00042094782), (6, 0.00027711256), (7, 0.00027777485), (8, 0.00032803151), (9, 0.00024615283), (10, 0.00016691041), (11, 0.00075386651), (12, 0.00036691342), (13, 0.00042411749), (14, 0.0010462548)]\n"
     ]
    }
   ],
   "source": [
    "term_topics = ldamodel.get_term_topics('convex', minimum_probability=0.000001)\n",
    "print(term_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Top 7 articles related to image -------\n",
      "Invariants of tensors \n",
      " 0.997946 \n",
      "\n",
      "Rank (linear algebra) \n",
      " 0.997274 \n",
      "\n",
      "System of linear equations \n",
      " 0.994274 \n",
      "\n",
      "Uzawa iteration \n",
      " 0.988889 \n",
      "\n",
      "Richardson extrapolation \n",
      " 0.988618 \n",
      "\n",
      "Orthogonal complement \n",
      " 0.984181 \n",
      "\n",
      "Homogeneous function \n",
      " 0.984037 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting related documents based on a term \n",
    "def get_related_documents(term, top, doc_term_matrix):\n",
    "    print('------- Top', top, 'articles related to',term,'-------')\n",
    "    related_docs = []\n",
    "    doc_topics = ldamodel.get_document_topics(doc_term_matrix, minimum_probability=0.20)\n",
    "    term_topics = ldamodel.get_term_topics(term, minimum_probability=0.000001)\n",
    "    term_topics.sort(key = itemgetter(1), reverse=True)\n",
    "    for k,topic in enumerate(doc_topics):\n",
    "        if topic:\n",
    "            topic.sort(key = itemgetter(1), reverse=True)\n",
    "            if topic[0][0] == term_topics[0][0]:\n",
    "                related_docs.append((k,topic[0][1]))\n",
    "    related_docs.sort(key = itemgetter(1), reverse=True)\n",
    "    result = []\n",
    "    for j,doc in enumerate(related_docs):\n",
    "        print(titles[doc[0]],\"\\n\",doc[1],\"\\n\")   \n",
    "        result.append(titles[doc[0]])\n",
    "        if j == top - 1:\n",
    "            break\n",
    "related_docs = get_related_documents('image', 7, doc_term_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "def get_theme(doc, cluster_result):\n",
    "    doc_id = titles.index(doc)\n",
    "    if doc_id == -1:\n",
    "        print('Document not found.')\n",
    "        return\n",
    "    for i, cluster in enumerate(cluster_result):\n",
    "        if doc_id in cluster:\n",
    "            return i+1\n",
    "    return 0\n",
    "cluster_num = get_theme('Absolutely convex set', cluster_result)\n",
    "print(cluster_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=611, num_nnz=143903)\n",
      "(0, 0.056852536755099284)\n"
     ]
    }
   ],
   "source": [
    "# Implementing tf-idf model; the only information needed from the previous part is the doc_term_matrix\n",
    "from gensim.models import TfidfModel, LsiModel\n",
    "tfidf_model = TfidfModel(doc_term_matrix, dictionary = dictionary)\n",
    "print(tfidf_model)\n",
    "vector = tfidf_model[doc_term_matrix[0]]\n",
    "print(vector[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LsiModel(num_terms=5846, num_topics=200, decay=1.0, chunksize=20000)\n"
     ]
    }
   ],
   "source": [
    "# Implementing LSI model; the only information needed from the previous part is the doc_term_matrix\n",
    "lsi_model = LsiModel(doc_term_matrix, id2word=dictionary)\n",
    "print(lsi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n"
     ]
    }
   ],
   "source": [
    "# Creating the similarity matrix from simple bag-of-words model (# of documents * # of documents)\n",
    "from gensim import similarities\n",
    "\n",
    "index = similarities.MatrixSimilarity(doc_term_matrix, num_features=len(dictionary))\n",
    "print(len(index[doc_term_matrix[610]])) # 611 * 611 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training tf-idf model from bag-of-word dataset\n",
    "model_tfidf = TfidfModel(doc_term_matrix, id2word=dictionary, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying tf-idf model to all vectors\n",
    "from gensim.corpora import MmCorpus\n",
    "MmCorpus.serialize('./corpus_tfidf.mm', model_tfidf[doc_term_matrix], progress_cnt=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixSimilarity<611 docs, 5846 features>\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = MmCorpus('./corpus_tfidf.mm') # Loading back the corpus file after applying tf-idf\n",
    "model_lsi = LsiModel(corpus_tfidf, num_topics=15, id2word=dictionary)\n",
    "# Applying LSI model to all vectors\n",
    "index = similarities.MatrixSimilarity(model_lsi[corpus_tfidf], num_features=len(dictionary))\n",
    "print(index)\n",
    "index.save('./lsi_index.mm') # Saving the similarity matrix to a local matrix market file named './lsi_model.mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n"
     ]
    }
   ],
   "source": [
    "# Loading the similarity matrix back from the local file\n",
    "similarity_matrix = similarities.MatrixSimilarity.load('./lsi_index.mm')\n",
    "print(len(similarity_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
