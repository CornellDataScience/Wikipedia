{
    "topics1": [
        {
            "desc": "b'In probability theory, the normal (or Gaussian or Gauss or Laplace-Gauss) distribution is a very common continuous probability distribution. Normal distributions are important in statistics and are often used in the natural and social sciences to represent real-valued random variables whose distributions are not known.[1][2] A random variable with a Gaussian distribution is said to be normally distributed and is called a normal deviate.'b'The normal distribution is useful because of the central limit theorem. In its most general form, under some conditions (which include finite variance), it states that averages of samples of observations of random variables independently drawn from independent distributions converge in distribution to the normal, that is, become normally distributed when the number of observations is sufficiently large. Physical quantities that are expected to be the sum of many independent processes (such as measurement errors) often have distributions that are nearly normal.[3] Moreover, many results and methods (such as propagation of uncertainty and least squares parameter fitting) can be derived analytically in explicit form when the relevant variables are normally distributed.'b\"The normal distribution is sometimes informally called the bell curve. However, many other distributions are bell-shaped (such as the Cauchy, Student's t, and logistic distributions).\"b'The probability density of the normal distribution is'b'where'b''",
            "freq": 20,
            "title": "Normal distribution",
            "url": "https://en.wikipedia.org/wiki/Normal_distribution"
        }
    ],
    "topics2": [
        {
            "desc": "b'Sample size determination is the act of choosing the number of observations or replicates to include in a statistical sample. The sample size is an important feature of any empirical study in which the goal is to make inferences about a population from a sample. In practice, the sample size used in a study is determined based on the expense of data collection, and the need to have sufficient statistical power. In complicated studies there may be several different sample sizes involved in the study: for example, in a stratified survey there would be different sample sizes for each stratum. In a census, data are collected on the entire population, hence the sample size is equal to the population size. In experimental design, where a study may be divided into different treatment groups, this may be different sample sizes for each group.'b'Sample sizes may be chosen in several different ways:'b''",
            "freq": 2,
            "title": "Sample size determination",
            "url": "https://en.wikipedia.org/wiki/Sample_size"
        },
        {
            "desc": "b'In probability theory and statistics, the binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent experiments, each asking a yes\\xe2\\x80\\x93no question, and each with its own boolean-valued outcome: a random variable containing single bit of information: success/yes/true/one (with probability p) or failure/no/false/zero (with probability q = 1 \\xe2\\x88\\x92 p). A single success/failure experiment is also called a Bernoulli trial or Bernoulli experiment and a sequence of outcomes is called a Bernoulli process; for a single trial, i.e., n = 1, the binomial distribution is a Bernoulli distribution. The binomial distribution is the basis for the popular binomial test of statistical significance.'b'The binomial distribution is frequently used to model the number of successes in a sample of size n drawn with replacement from a population of size N. If the sampling is carried out without replacement, the draws are not independent and so the resulting distribution is a hypergeometric distribution, not a binomial one. However, for N much larger than n, the binomial distribution remains a good approximation, and is widely used.'b''",
            "freq": 2,
            "title": "Binomial distribution",
            "url": "https://en.wikipedia.org/wiki/Binomial_distribution"
        },
        {
            "desc": "b'In mathematics, the limit of a sequence is the value that the terms of a sequence \"tend to\".[1] If such a limit exists, the sequence is called convergent. A sequence which does not converge is said to be divergent.[2] The limit of a sequence is said to be the fundamental notion on which the whole of analysis ultimately rests.[1]'b'Limits can be defined in any metric or topological space, but are usually first encountered in the real numbers.'b''",
            "freq": 1,
            "title": "Limit of a sequence",
            "url": "https://en.wikipedia.org/wiki/Limit_of_a_sequence"
        }
    ],
    "topics3": [
        {
            "desc": "b'In probability theory, the de Moivre\\xe2\\x80\\x93Laplace theorem, which is a special case of the central limit theorem, states that the normal distribution may be used as an approximation to the binomial distribution under certain conditions. In particular, the theorem shows that the probability mass function of the random number of \"successes\" observed in a series of n independent Bernoulli trials, each having probability p of success (a binomial distribution with n trials), converges to the probability density function of the normal distribution with mean np and standard deviation \\xe2\\x88\\x9anp(1-p), as n grows large, assuming p is not 0 or 1.'b'The theorem appeared in the second edition of The Doctrine of Chances by Abraham de Moivre, published in 1738. Although de Moivre did not use the term \"Bernoulli trials\", he wrote about the probability distribution of the number of times \"heads\" appears when a coin is tossed 3600 times.[1]'b'This is one derivation of the particular Gaussian function used in the normal distribution.'b''",
            "freq": 2,
            "title": "De Moivre\u2013Laplace theorem",
            "url": "https://en.wikipedia.org/wiki/De_Moivre%E2%80%93Laplace_theorem"
        },
        {
            "desc": "b'In mathematics and in particular mathematical dynamics, discrete time and continuous time are two alternative frameworks within which to model variables that evolve over time.'b''",
            "freq": 2,
            "title": "Discrete time and continuous time",
            "url": "https://en.wikipedia.org/wiki/Continuous_time"
        },
        {
            "desc": "b'Positivism is a philosophical theory stating that certain (\"positive\") knowledge is based on natural phenomena and their properties and relations. Thus, information derived from sensory experience, interpreted through reason and logic, forms the exclusive source of all certain knowledge.[1] Positivism holds that valid knowledge (certitude or truth) is found only in this a posteriori knowledge.'b'Verified data (positive facts) received from the senses are known as empirical evidence; thus positivism is based on empiricism.[1]'b'Positivism also holds that society, like the physical world, operates according to general laws. Introspective and intuitive knowledge is rejected, as are metaphysics and theology. Although the positivist approach has been a recurrent theme in the history of western thought,[2] the modern sense of the approach was formulated by the philosopher Auguste Comte in the early 19th century.[3] Comte argued that, much as the physical world operates according to gravity and other absolute laws, so does society,[4] and further developed positivism into a Religion of Humanity.'b''",
            "freq": 1,
            "title": "Positivism",
            "url": "https://en.wikipedia.org/wiki/Positivism"
        }
    ],
    "topics4": [
        {
            "desc": "b'The word probability has been used in a variety of ways since it was first applied to the mathematical study of games of chance. Does probability measure the real, physical tendency of something to occur or is it a measure of how strongly one believes it will occur, or does it draw on both these elements? In answering such questions, mathematicians interpret the probability values of probability theory.'b'There are two broad categories[1][2] of probability interpretations which can be called \"physical\" and \"evidential\" probabilities. Physical probabilities, which are also called objective or frequency probabilities, are associated with random physical systems such as roulette wheels, rolling dice and radioactive atoms. In such systems, a given type of event (such as a die yielding a six) tends to occur at a persistent rate, or \"relative frequency\", in a long run of trials. Physical probabilities either explain, or are invoked to explain, these stable frequencies. The two main kinds of theory of physical probability are frequentist accounts (such as those of Venn,[3] Reichenbach[4] and von Mises[5]) and propensity accounts (such as those of Popper, Miller, Giere and Fetzer).[6]'b\"Evidential probability, also called Bayesian probability, can be assigned to any statement whatsoever, even when no random process is involved, as a way to represent its subjective plausibility, or the degree to which the statement is supported by the available evidence. On most accounts, evidential probabilities are considered to be degrees of belief, defined in terms of dispositions to gamble at certain odds. The four main evidential interpretations are the classical (e.g. Laplace's)[7] interpretation, the subjective interpretation (de Finetti[8] and Savage[9]), the epistemic or inductive interpretation (Ramsey,[10] Cox[11]) and the logical interpretation (Keynes[12] and Carnap[13]). There are also evidential interpretations of probability covering groups, which are often labelled as 'intersubjective' (proposed by Gillies[14] and Rowbottom[6]).\"b'Some interpretations of probability are associated with approaches to statistical inference, including theories of estimation and hypothesis testing. The physical interpretation, for example, is taken by followers of \"frequentist\" statistical methods, such as Ronald Fisher, Jerzy Neyman and Egon Pearson. Statisticians of the opposing Bayesian school typically accept the existence and importance of physical probabilities, but also consider the calculation of evidential probabilities to be both valid and necessary in statistics. This article, however, focuses on the interpretations of probability rather than theories of statistical inference.'b'The terminology of this topic is rather confusing, in part because probabilities are studied within a variety of academic fields. The word \"frequentist\" is especially tricky. To philosophers it refers to a particular theory of physical probability, one that has more or less been abandoned. To scientists, on the other hand, \"frequentist probability\" is just another name for physical (or objective) probability. Those who promote Bayesian inference view \"frequentist statistics\" as an approach to statistical inference that recognises only physical probabilities. Also the word \"objective\", as applied to probability, sometimes means exactly what \"physical\" means here, but is also used of evidential probabilities that are fixed by rational constraints, such as logical and epistemic probabilities.'b''",
            "freq": 2,
            "title": "Probability interpretations",
            "url": "https://en.wikipedia.org/wiki/Interpretation_of_probability"
        },
        {
            "desc": "b'In probability theory, the expected value of a random variable, intuitively, is the long-run average value of repetitions of the experiment it represents. For example, the expected value in rolling a six-sided die is 3.5, because the average of all the numbers that come up in an extremely large number of rolls is close to 3.5. Less roughly, the law of large numbers states that the arithmetic mean of the values almost surely converges to the expected value as the number of repetitions approaches infinity. The expected value is also known as the expectation, mathematical expectation, EV, average, mean value, mean, or first moment.'b'More practically, the expected value of a discrete random variable is the probability-weighted average of all possible values. In other words, each possible value the random variable can assume is multiplied by its probability of occurring, and the resulting products are summed to produce the expected value. The same principle applies to an absolutely continuous random variable, except that an integral of the variable with respect to its probability density replaces the sum. The formal definition subsumes both of these and also works for distributions which are neither discrete nor absolutely continuous; the expected value of a random variable is the integral of the random variable with respect to its probability measure.[1][2]'b'The expected value does not exist for random variables having some distributions with large \"tails\", such as the Cauchy distribution.[3] For random variables such as these, the long-tails of the distribution prevent the sum/integral from converging.'b\"The expected value is a key aspect of how one characterizes a probability distribution; it is one type of location parameter. By contrast, the variance is a measure of dispersion of the possible values of the random variable around the expected value. The variance itself is defined in terms of two expectations: it is the expected value of the squared deviation of the variable's value from the variable's expected value.\"b'The expected value plays important roles in a variety of contexts. In regression analysis, one desires a formula in terms of observed data that will give a \"good\" estimate of the parameter giving the effect of some explanatory variable upon a dependent variable. The formula will give different estimates using different samples of data, so the estimate it gives is itself a random variable. A formula is typically considered good in this context if it is an unbiased estimator\\xe2\\x80\\x94that is, if the expected value of the estimate (the average value it would give over an arbitrarily large number of separate samples) can be shown to equal the true value of the desired parameter.'b'In decision theory, and in particular in choice under uncertainty, an agent is described as making an optimal choice in the context of incomplete information. For risk neutral agents, the choice involves using the expected values of uncertain quantities, while for risk averse agents it involves maximizing the expected value of some objective function such as a von Neumann\\xe2\\x80\\x93Morgenstern utility function. One example of using expected value in reaching optimal decisions is the Gordon\\xe2\\x80\\x93Loeb model of information security investment. According to the model, one can conclude that the amount a firm spends to protect information should generally be only a small fraction of the expected loss (i.e., the expected value of the loss resulting from a cyber/information security breach).[4]'b''",
            "freq": 2,
            "title": "Expected value",
            "url": "https://en.wikipedia.org/wiki/Expected_value"
        },
        {
            "desc": "b'In probability theory and statistics, covariance is a measure of the joint variability of two random variables.[1] If the greater values of one variable mainly correspond with the greater values of the other variable, and the same holds for the lesser values, (i.e., the variables tend to show similar behavior), the covariance is positive.[2] In the opposite case, when the greater values of one variable mainly correspond to the lesser values of the other, (i.e., the variables tend to show opposite behavior), the covariance is negative. The sign of the covariance therefore shows the tendency in the linear relationship between the variables. The magnitude of the covariance is not easy to interpret because it is not normalized and hence depends on the magnitudes of the variables. The normalized version of the covariance, the correlation coefficient, however, shows by its magnitude the strength of the linear relation.'b'A distinction must be made between (1) the covariance of two random variables, which is a population parameter that can be seen as a property of the joint probability distribution, and (2) the sample covariance, which in addition to serving as a descriptor of the sample, also serves as an estimated value of the population parameter.'b''",
            "freq": 2,
            "title": "Covariance",
            "url": "https://en.wikipedia.org/wiki/Covariance"
        }
    ]
}
