{
    "topics": [
        {
            "desc": "b'In linear algebra, an eigenvector or characteristic vector of a linear transformation is a non-zero vector that only changes by a scalar factor when that linear transformation is applied to it. More formally, if T is a linear transformation from a vector space V over a field F into itself and v is a vector in V that is not the zero vector, then v is an eigenvector of T if T(v) is a scalar multiple of v. This condition can be written as the equation'b'where \\xce\\xbb is a scalar in the field F, known as the eigenvalue, characteristic value, or characteristic root associated with the eigenvector v.'b'If the vector space V is finite-dimensional, then the linear transformation T can be represented as a square matrix A, and the vector v by a column vector, rendering the above mapping as a matrix multiplication on the left hand side and a scaling of the column vector on the right hand side in the equation'b'There is a correspondence between n by n square matrices and linear transformations from an n-dimensional vector space to itself. For this reason, it is equivalent to define eigenvalues and eigenvectors using either the language of matrices or the language of linear transformations.[1][2]'b'Geometrically an eigenvector, corresponding to a real nonzero eigenvalue, points in a direction that is stretched by the transformation and the eigenvalue is the factor by which it is stretched. If the eigenvalue is negative, the direction is reversed.[3]'b''",
            "freq": 20,
            "title": "Eigenvalues and eigenvectors",
            "url": "https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors"
        },
        {
            "desc": "b'In mathematics, a partial differential equation (PDE) is a differential equation that contains unknown multivariable functions and their partial derivatives. PDEs are used to formulate problems involving functions of several variables, and are either solved by hand, or used to create a relevant computer model. A special case is ordinary differential equations (ODEs), which deal with functions of a single variable and their derivatives.'b'PDEs can be used to describe a wide variety of phenomena such as sound, heat, electrostatics, electrodynamics, fluid dynamics, elasticity, or quantum mechanics. These seemingly distinct physical phenomena can be formalised similarly in terms of PDEs. Just as ordinary differential equations often model one-dimensional dynamical systems, partial differential equations often model multidimensional systems. PDEs find their generalisation in stochastic partial differential equations.'b''",
            "freq": 3,
            "title": "Partial differential equation",
            "url": "https://en.wikipedia.org/wiki/Partial_differential_equation"
        },
        {
            "desc": "b'The mathematical concept of a Hilbert space, named after David Hilbert, generalizes the notion of Euclidean space. It extends the methods of vector algebra and calculus from the two-dimensional Euclidean plane and three-dimensional space to spaces with any finite or infinite number of dimensions. A Hilbert space is an abstract vector space possessing the structure of an inner product that allows length and angle to be measured. Furthermore, Hilbert spaces are complete: there are enough limits in the space to allow the techniques of calculus to be used.'b'Hilbert spaces arise naturally and frequently in mathematics and physics, typically as infinite-dimensional function spaces. The earliest Hilbert spaces were studied from this point of view in the first decade of the 20th century by David Hilbert, Erhard Schmidt, and Frigyes Riesz. They are indispensable tools in the theories of partial differential equations, quantum mechanics, Fourier analysis (which includes applications to signal processing and heat transfer)\\xe2\\x80\\x94and ergodic theory, which forms the mathematical underpinning of thermodynamics. John von Neumann coined the term Hilbert space for the abstract concept that underlies many of these diverse applications. The success of Hilbert space methods ushered in a very fruitful era for functional analysis. Apart from the classical Euclidean spaces, examples of Hilbert spaces include spaces of square-integrable functions, spaces of sequences, Sobolev spaces consisting of generalized functions, and Hardy spaces of holomorphic functions.'b'Geometric intuition plays an important role in many aspects of Hilbert space theory. Exact analogs of the Pythagorean theorem and parallelogram law hold in a Hilbert space. At a deeper level, perpendicular projection onto a subspace (the analog of \"dropping the altitude\" of a triangle) plays a significant role in optimization problems and other aspects of the theory. An element of a Hilbert space can be uniquely specified by its coordinates with respect to a set of coordinate axes (an orthonormal basis), in analogy with Cartesian coordinates in the plane. When that set of axes is countably infinite, the Hilbert space can also be usefully thought of in terms of the space of infinite sequences that are square-summable. The latter space is often in the older literature referred to as the Hilbert space. Linear operators on a Hilbert space are likewise fairly concrete objects: in good cases, they are simply transformations that stretch the space by different factors in mutually perpendicular directions in a sense that is made precise by the study of their spectrum.'b''",
            "freq": 3,
            "title": "Hilbert space",
            "url": "https://en.wikipedia.org/wiki/Hilbert_space"
        },
        {
            "desc": "b'In mathematics, a partial differential equation (PDE) is a differential equation that contains unknown multivariable functions and their partial derivatives. PDEs are used to formulate problems involving functions of several variables, and are either solved by hand, or used to create a relevant computer model. A special case is ordinary differential equations (ODEs), which deal with functions of a single variable and their derivatives.'b'PDEs can be used to describe a wide variety of phenomena such as sound, heat, electrostatics, electrodynamics, fluid dynamics, elasticity, or quantum mechanics. These seemingly distinct physical phenomena can be formalised similarly in terms of PDEs. Just as ordinary differential equations often model one-dimensional dynamical systems, partial differential equations often model multidimensional systems. PDEs find their generalisation in stochastic partial differential equations.'b''",
            "freq": 2,
            "title": "Partial differential equation",
            "url": "https://en.wikipedia.org/wiki/Partial_differential_equation"
        },
        {
            "desc": "b'In mathematics, a partial differential equation (PDE) is a differential equation that contains unknown multivariable functions and their partial derivatives. PDEs are used to formulate problems involving functions of several variables, and are either solved by hand, or used to create a relevant computer model. A special case is ordinary differential equations (ODEs), which deal with functions of a single variable and their derivatives.'b'PDEs can be used to describe a wide variety of phenomena such as sound, heat, electrostatics, electrodynamics, fluid dynamics, elasticity, or quantum mechanics. These seemingly distinct physical phenomena can be formalised similarly in terms of PDEs. Just as ordinary differential equations often model one-dimensional dynamical systems, partial differential equations often model multidimensional systems. PDEs find their generalisation in stochastic partial differential equations.'b''",
            "freq": 3,
            "title": "Partial differential equation",
            "url": "https://en.wikipedia.org/wiki/Partial_differential_equation"
        },
        {
            "desc": "b'In mathematics, a Fourier series (English: /\\xcb\\x88f\\xca\\x8a\\xc9\\x99ri\\xcb\\x8ce\\xc9\\xaa/)[1] is a way to represent a function as the sum of simple sine waves. More formally, it decomposes any periodic function or periodic signal into the sum of a (possibly infinite) set of simple oscillating functions, namely sines and cosines (or, equivalently, complex exponentials). The discrete-time Fourier transform is a periodic function, often defined in terms of a Fourier series. The Z-transform, another example of application, reduces to a Fourier series for the important case |z|=1. Fourier series are also central to the original proof of the Nyquist\\xe2\\x80\\x93Shannon sampling theorem. The study of Fourier series is a branch of Fourier analysis.'b''",
            "freq": 2,
            "title": "Fourier series",
            "url": "https://en.wikipedia.org/wiki/Fourier_series"
        },
        {
            "desc": "b'In mathematics, and more specifically in abstract algebra, an algebraic structure on a set A (called carrier set or underlying set) is a collection of finitary operations on A; the set A with this structure is also called an algebra.[1]'b'Examples of algebraic structures include groups, rings, fields, and lattices. More complex structures can be defined by introducing multiple operations, different underlying sets, or by altering the defining axioms. Examples of more complex algebraic structures include vector spaces, modules, and algebras.'b'The properties of specific algebraic structures are studied in abstract algebra. The general theory of algebraic structures has been formalized in universal algebra. The language of category theory is used to express and study relationships between different classes of algebraic and non-algebraic objects. This is because it is sometimes possible to find strong connections between some classes of objects, sometimes of different kinds. For example, Galois theory establishes a connection between certain fields and groups: two algebraic structures of different kinds.'b''",
            "freq": 2,
            "title": "Algebraic structure",
            "url": "https://en.wikipedia.org/wiki/Algebraic_structure"
        },
        {
            "desc": "b'In mathematics, the dimension of a vector space V is the cardinality (i.e. the number of vectors) of a basis of V over its base field.[1] It is sometimes called Hamel dimension (after Georg Hamel) or algebraic dimension to distinguish it from other types of dimension.'b'For every vector space there exists a basis,[a] and all bases of a vector space have equal cardinality;[b] as a result, the dimension of a vector space is uniquely defined. We say V is finite-dimensional if the dimension of V is finite, and infinite-dimensional if its dimension is infinite.'b'The dimension of the vector space V over the field F can be written as dimF(V) or as [V\\xc2\\xa0: F], read \"dimension of V over F\". When F can be inferred from context, dim(V) is typically written.'b''",
            "freq": 2,
            "title": "Dimension (vector space)",
            "url": "https://en.wikipedia.org/wiki/Dimension_(vector_space)"
        },
        {
            "desc": "b'Geometry (from the Ancient Greek: \\xce\\xb3\\xce\\xb5\\xcf\\x89\\xce\\xbc\\xce\\xb5\\xcf\\x84\\xcf\\x81\\xce\\xaf\\xce\\xb1; geo- \"earth\", -metron \"measurement\") is a branch of mathematics concerned with questions of shape, size, relative position of figures, and the properties of space. A mathematician who works in the field of geometry is called a geometer.'b\"Geometry arose independently in a number of early cultures as a practical way for dealing with lengths, areas, and volumes. Geometry began to see elements of formal mathematical science emerging in the West as early as the 6th century BC.[1] By the 3rd century BC, geometry was put into an axiomatic form by Euclid, whose treatment, Euclid's Elements, set a standard for many centuries to follow.[2] Geometry arose independently in India, with texts providing rules for geometric constructions appearing as early as the 3rd century BC.[3] Islamic scientists preserved Greek ideas and expanded on them during the Middle Ages.[4] By the early 17th century, geometry had been put on a solid analytic footing by mathematicians such as Ren\\xc3\\xa9 Descartes and Pierre de Fermat. Since then, and into modern times, geometry has expanded into non-Euclidean geometry and manifolds, describing spaces that lie beyond the normal range of human experience.[5]\"b'While geometry has evolved significantly throughout the years, there are some general concepts that are more or less fundamental to geometry. These include the concepts of points, lines, planes, surfaces, angles, and curves, as well as the more advanced notions of manifolds and topology or metric.[6]'b'Geometry has applications to many fields, including art, architecture, physics, as well as to other branches of mathematics.'b''",
            "freq": 3,
            "title": "Geometry",
            "url": "https://en.wikipedia.org/wiki/Geometry"
        },
        {
            "desc": "b'A mathematical model is a description of a system using mathematical concepts and language. The process of developing a mathematical model is termed mathematical modeling. Mathematical models are used in the natural sciences (such as physics, biology, earth science, chemistry) and engineering disciplines (such as computer science, artificial intelligence), as well as in the social sciences (such as economics, psychology, sociology, political science). Physicists, mathematicians, engineers, statisticians, operations research analysts, and economists use mathematical models most extensively[citation needed]. A model may help to explain a system and to study the effects of different components, and to make predictions about behaviour.'b''",
            "freq": 2,
            "title": "Mathematical model",
            "url": "https://en.wikipedia.org/wiki/Mathematical_model"
        }
    ]
}