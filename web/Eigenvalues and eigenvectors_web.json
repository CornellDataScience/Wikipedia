[{
    "topics1": [
        {
            "desc": "b'In linear algebra, an eigenvector or characteristic vector of a linear transformation is a non-zero vector that only changes by a scalar factor when that linear transformation is applied to it. More formally, if T is a linear transformation from a vector space V over a field F into itself and v is a vector in V that is not the zero vector, then v is an eigenvector of T if T(v) is a scalar multiple of v. This condition can be written as the equation'b'where \\xce\\xbb is a scalar in the field F, known as the eigenvalue, characteristic value, or characteristic root associated with the eigenvector v.'b'If the vector space V is finite-dimensional, then the linear transformation T can be represented as a square matrix A, and the vector v by a column vector, rendering the above mapping as a matrix multiplication on the left hand side and a scaling of the column vector on the right hand side in the equation'b'There is a correspondence between n by n square matrices and linear transformations from an n-dimensional vector space to itself. For this reason, it is equivalent to define eigenvalues and eigenvectors using either the language of matrices or the language of linear transformations.[1][2]'b'Geometrically an eigenvector, corresponding to a real nonzero eigenvalue, points in a direction that is stretched by the transformation and the eigenvalue is the factor by which it is stretched. If the eigenvalue is negative, the direction is reversed.[3]'b''",
            "freq": 20,
            "title": "Eigenvalues and eigenvectors",
            "url": "https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors"
        }
    ]},
    {"topics": [
        {
            "desc": "b'In linear algebra, the transpose of a matrix is an operator which flips a matrix over its diagonal, that is it switches the row and column indices of the matrix by producing another matrix denoted as AT (also written A\\xe2\\x80\\xb2, Atr, tA or At). It is achieved by any one of the following equivalent actions:'b'Formally, the i th row, j th column element of AT is the j th row, i th column element of A:'b'If A is an m \\xc3\\x97 n matrix then AT is an n \\xc3\\x97 m matrix.'b'The transpose of a matrix was introduced in 1858 by the British mathematician Arthur Cayley.[1]'b''",
            "freq": 3,
            "title": "Transpose",
            "url": "https://en.wikipedia.org/wiki/Transpose"
        },
        {
            "desc": "b'In mathematics, particularly in semigroup theory, a transformation is a function f that maps a set X to itself, i.e. f\\xc2\\xa0: X \\xe2\\x86\\x92 X.[1][2][3] In other areas of mathematics, a transformation may simply be any function, regardless of domain and codomain.[4] This wider sense shall not be considered in this article; refer instead to the article on function for that sense.'b'Examples include linear transformations and affine transformations, rotations, reflections and translations. These can be carried out in Euclidean space, particularly in R2 (two dimensions) and R3 (three dimensions). They are also operations that can be performed using linear algebra, and described explicitly using matrices.'b''",
            "freq": 3,
            "title": "Transformation (function)",
            "url": "https://en.wikipedia.org/wiki/Transformation_(function)"
        },
        {
            "desc": "b'In linear algebra, the column space (also called the range or image) of a matrix A is the span (set of all possible linear combinations) of its column vectors. The column space of a matrix is the image or range of the corresponding matrix transformation.'b'Let \\n  \\n    \\n      \\n        \\n          F\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbb {F} }\\n  \\n be a field. The column space of an m\\xe2\\x80\\xaf\\xc3\\x97\\xe2\\x80\\xafn matrix with components from \\n  \\n    \\n      \\n        \\n          F\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbb {F} }\\n  \\n is a linear subspace of the m-space \\n  \\n    \\n      \\n        \\n          \\n            F\\n          \\n          \\n            m\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbb {F} ^{m}}\\n  \\n. The dimension of the column space is called the rank of the matrix and is at most min(m,\\xe2\\x80\\xafn).[1] A definition for matrices over a ring \\n  \\n    \\n      \\n        \\n          K\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbb {K} }\\n  \\n is also possible.'b'The row space is defined similarly.'b'This article considers matrices of real numbers. The row and column spaces are subspaces of the real spaces Rn and Rm respectively.'b''",
            "freq": 3,
            "title": "Row and column spaces",
            "url": "https://en.wikipedia.org/wiki/Row_and_column_spaces"
        }
    ]},
    {"topics": [
        {
            "desc": "b'Linear algebra is the branch of mathematics concerning linear equations such as'b'linear functions such as'b'and their representations through matrices and vector spaces.[1][2][3]'b'Linear algebra is central to almost all areas of mathematics. For instance, linear algebra is fundamental in modern presentations of geometry, including for defining basic objects such as lines, planes and rotations. Also, functional analysis may be basically viewed as the application of linear algebra to spaces of functions. Linear algebra is also used in most sciences and engineering areas, because it allows modeling many natural phenomena, and efficiently computing with such models. For nonlinear systems, which cannot be modeled with linear algebra, linear algebra is often used as a first approximation.'b''",
            "freq": 6,
            "title": "Linear algebra",
            "url": "https://en.wikipedia.org/wiki/Linear_algebra"
        },
        {
            "desc": "b'Three-dimensional space (also: 3-space or, rarely, tri-dimensional space) is a geometric setting in which three values (called parameters) are required to determine the position of an element (i.e., point). This is the informal meaning of the term dimension.'b'In physics and mathematics, a sequence of n numbers can be understood as a location in n-dimensional space. When n = 3, the set of all such locations is called three-dimensional Euclidean space. It is commonly represented by the symbol \\xe2\\x84\\x9d3. This serves as a three-parameter model of the physical universe (that is, the spatial part, without considering time) in which all known matter exists. However, this space is only one example of a large variety of spaces in three dimensions called 3-manifolds. In this classical example, when the three values refer to measurements in different directions (coordinates), any three directions can be chosen, provided that vectors in these directions do not all lie in the same 2-space (plane). Furthermore, in this case, these three values can be labeled by any combination of three chosen from the terms width, height, depth, and breadth.'b''",
            "freq": 3,
            "title": "Three-dimensional space",
            "url": "https://en.wikipedia.org/wiki/Three-dimensional_space"
        },
        {
            "desc": "b'In linear algebra, the transpose of a matrix is an operator which flips a matrix over its diagonal, that is it switches the row and column indices of the matrix by producing another matrix denoted as AT (also written A\\xe2\\x80\\xb2, Atr, tA or At). It is achieved by any one of the following equivalent actions:'b'Formally, the i th row, j th column element of AT is the j th row, i th column element of A:'b'If A is an m \\xc3\\x97 n matrix then AT is an n \\xc3\\x97 m matrix.'b'The transpose of a matrix was introduced in 1858 by the British mathematician Arthur Cayley.[1]'b''",
            "freq": 2,
            "title": "Transpose",
            "url": "https://en.wikipedia.org/wiki/Transpose"
        }
    ]},
    {"topics": [
        {
            "desc": "b'Linear algebra is the branch of mathematics concerning linear equations such as'b'linear functions such as'b'and their representations through matrices and vector spaces.[1][2][3]'b'Linear algebra is central to almost all areas of mathematics. For instance, linear algebra is fundamental in modern presentations of geometry, including for defining basic objects such as lines, planes and rotations. Also, functional analysis may be basically viewed as the application of linear algebra to spaces of functions. Linear algebra is also used in most sciences and engineering areas, because it allows modeling many natural phenomena, and efficiently computing with such models. For nonlinear systems, which cannot be modeled with linear algebra, linear algebra is often used as a first approximation.'b''",
            "freq": 4,
            "title": "Linear algebra",
            "url": "https://en.wikipedia.org/wiki/Linear_algebra"
        },
        {
            "desc": "b'In linear algebra, the column space (also called the range or image) of a matrix A is the span (set of all possible linear combinations) of its column vectors. The column space of a matrix is the image or range of the corresponding matrix transformation.'b'Let \\n  \\n    \\n      \\n        \\n          F\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbb {F} }\\n  \\n be a field. The column space of an m\\xe2\\x80\\xaf\\xc3\\x97\\xe2\\x80\\xafn matrix with components from \\n  \\n    \\n      \\n        \\n          F\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbb {F} }\\n  \\n is a linear subspace of the m-space \\n  \\n    \\n      \\n        \\n          \\n            F\\n          \\n          \\n            m\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbb {F} ^{m}}\\n  \\n. The dimension of the column space is called the rank of the matrix and is at most min(m,\\xe2\\x80\\xafn).[1] A definition for matrices over a ring \\n  \\n    \\n      \\n        \\n          K\\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbb {K} }\\n  \\n is also possible.'b'The row space is defined similarly.'b'This article considers matrices of real numbers. The row and column spaces are subspaces of the real spaces Rn and Rm respectively.'b''",
            "freq": 3,
            "title": "Row and column spaces",
            "url": "https://en.wikipedia.org/wiki/Row_and_column_spaces"
        },
        {
            "desc": "b'In linear algebra, functional analysis, and related areas of mathematics, a norm is a function that assigns a strictly positive length or size to each vector in a vector space\\xe2\\x80\\x94save for the zero vector, which is assigned a length of zero. A seminorm, on the other hand, is allowed to assign zero length to some non-zero vectors (in addition to the zero vector).'b'A norm must also satisfy certain properties pertaining to scalability and additivity which are given in the formal definition below.'b'A simple example is two dimensional Euclidean space R2 equipped with the \"Euclidean norm\" (see below). Elements in this vector space (e.g., (3, 7)) are usually drawn as arrows in a 2-dimensional cartesian coordinate system starting at the origin (0, 0). The Euclidean norm assigns to each vector the length of its arrow. Because of this, the Euclidean norm is often known as the magnitude.'b'A vector space on which a norm is defined is called a normed vector space. Similarly, a vector space with a seminorm is called a seminormed vector space. It is often possible to supply a norm for a given vector space in more than one way.'b''",
            "freq": 2,
            "title": "Norm (mathematics)",
            "url": "https://en.wikipedia.org/wiki/Norm_(mathematics)"
        }
    ]}
]
